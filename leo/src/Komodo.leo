<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet ekr_test?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.5">
	<global_window_position top="17" left="400" height="729" width="865"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20080121105857"><vh>Startup</vh>
<v t="ekr.20080121105230.3"><vh>@chapters</vh></v>
</v>
<v t="ekr.20080121105800"><vh>create-at-auto-nodes</vh></v>
<v t="ekr.20080121122039"><vh>@button remove license</vh></v>
<v t="ekr.20080121105837" a="E"><vh>Komodo autocompleter code</vh>
<v t="ekr.20080121152156" a="TV"><vh>Diary</vh></v>
<v t="ekr.20080121105837.1"><vh>Komodo notes</vh>
<v t="ekr.20080121105837.2"><vh>.rng files</vh></v>
</v>
<v t="ekr.20080121133057"><vh>Important doc nodes</vh>
<v t="ekr.20080121133057.1"><vh>&lt;&lt; citadel.py docstring &gt;&gt;</vh></v>
<v t="ekr.20080121133057.2"><vh>&lt;&lt; class CitadelBuffer docstring &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1770"><vh>&lt;&lt; database.py docstring &gt;&gt; (important)</vh></v>
<v t="ekr.20080121105837.1853"><vh>sdk/share/lang_LANG.py (Important)</vh></v>
<v t="ekr.20080121151821"><vh>&lt;&lt; LangIntel docstring &gt;&gt;</vh></v>
</v>
<v t="ekr.20080121105837.3"><vh>Komodo code</vh>
<v t="ekr.20080121105837.4"><vh>license1</vh></v>
<v t="ekr.20080121140752"><vh>license2</vh></v>
<v t="ekr.20080121105837.1815"><vh>lib/sdk</vh>
<v t="ekr.20080121105837.1816"><vh>sdk/bin</vh>
<v t="ekr.20080121105837.1817"><vh>codeintel.py</vh>
<v t="ekr.20080121105837.1818"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1819"><vh>class Shell</vh>
<v t="ekr.20080121105837.1820"><vh>get_optparser</vh></v>
<v t="ekr.20080121105837.1821"><vh>postoptparse</vh></v>
<v t="ekr.20080121105837.1822"><vh>do_scan</vh></v>
<v t="ekr.20080121105837.1823"><vh>do_html</vh></v>
</v>
<v t="ekr.20080121105837.1824"><vh>Internal support functions</vh>
<v t="ekr.20080121105837.1825"><vh>_url_from_local_path</vh></v>
<v t="ekr.20080121105837.1826"><vh>_should_include_path</vh></v>
<v t="ekr.20080121105837.1827"><vh>_paths_from_path_patterns</vh></v>
<v t="ekr.20080121105837.1828"><vh>class _PerLevelFormatter</vh>
<v t="ekr.20080121105837.1829"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1830"><vh>format</vh></v>
</v>
<v t="ekr.20080121105837.1831"><vh>_setup_logging</vh></v>
</v>
<v t="ekr.20080121105837.1832"><vh>Main line</vh>
<v t="ekr.20080121105837.1833"><vh>_do_main</vh></v>
<v t="ekr.20080121105837.1834"><vh>main</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1835"><vh>luddite.py</vh>
<v t="ekr.20080121105837.1836"><vh>imports</vh></v>
<v t="ekr.20080121105837.1837"><vh>_set_lib_path</vh></v>
<v t="ekr.20080121105837.1838"><vh>class Shell</vh>
<v t="ekr.20080121105837.1839"><vh>get_optparser</vh></v>
<v t="ekr.20080121105837.1840"><vh>postoptparse</vh></v>
<v t="ekr.20080121105837.1841"><vh>do_just_compile</vh></v>
<v t="ekr.20080121105837.1842"><vh>do_deprecated_compile</vh></v>
<v t="ekr.20080121105837.1843"><vh>_do_parse</vh></v>
<v t="ekr.20080121105837.1844"><vh>do_deprecated_package</vh></v>
<v t="ekr.20080121105837.1845"><vh>do_lex</vh></v>
<v t="ekr.20080121105837.1846"><vh>do_lexhtml</vh></v>
</v>
<v t="ekr.20080121105837.1847"><vh>class _PerLevelFormatter</vh>
<v t="ekr.20080121105837.1848"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1849"><vh>format</vh></v>
</v>
<v t="ekr.20080121105837.1850"><vh>_setup_logging</vh></v>
<v t="ekr.20080121105837.1851"><vh>_url_from_local_path</vh></v>
</v>
</v>
<v t="ekr.20080121134628"><vh>sdk/pylib</vh>
<v t="ekr.20080121134650"><vh>cmdln.py</vh>
<v t="ekr.20080121134847"><vh>cmdln declarations</vh></v>
<v t="ekr.20080121134847.1"><vh>class CmdlnError</vh>
<v t="ekr.20080121134847.2"><vh>__init__</vh></v>
<v t="ekr.20080121134847.3"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121134847.4"><vh>class CmdlnUserError</vh></v>
<v t="ekr.20080121134847.5"><vh>alias</vh></v>
<v t="ekr.20080121134847.6"><vh>class RawCmdln</vh>
<v t="ekr.20080121134847.7"><vh>__init__</vh></v>
<v t="ekr.20080121134847.8"><vh>get_optparser</vh></v>
<v t="ekr.20080121134847.9"><vh>postoptparse</vh></v>
<v t="ekr.20080121134847.10"><vh>main</vh></v>
<v t="ekr.20080121134847.11"><vh>cmd</vh></v>
<v t="ekr.20080121134847.12"><vh>_str</vh></v>
<v t="ekr.20080121134847.13"><vh>cmdloop</vh></v>
<v t="ekr.20080121134847.14"><vh>precmd</vh></v>
<v t="ekr.20080121134847.15"><vh>postcmd</vh></v>
<v t="ekr.20080121134847.16"><vh>cmdexc</vh></v>
<v t="ekr.20080121134847.17"><vh>onecmd</vh></v>
<v t="ekr.20080121134847.18"><vh>_dispatch_cmd</vh></v>
<v t="ekr.20080121134847.19"><vh>default</vh></v>
<v t="ekr.20080121134847.20"><vh>parseline</vh></v>
<v t="ekr.20080121134847.21"><vh>helpdefault</vh></v>
<v t="ekr.20080121134847.22"><vh>do_help</vh></v>
<v t="ekr.20080121134847.23"><vh>_help_reindent</vh></v>
<v t="ekr.20080121134847.24"><vh>_help_preprocess</vh></v>
<v t="ekr.20080121134847.25"><vh>_help_preprocess_name</vh></v>
<v t="ekr.20080121134847.26"><vh>_help_preprocess_option_list</vh></v>
<v t="ekr.20080121134847.27"><vh>_help_preprocess_command_list</vh></v>
<v t="ekr.20080121134847.28"><vh>_gen_names_and_attrs</vh></v>
<v t="ekr.20080121134847.29"><vh>_help_preprocess_help_list</vh></v>
<v t="ekr.20080121134847.30"><vh>_help_preprocess_cmd_name</vh></v>
<v t="ekr.20080121134847.31"><vh>_help_preprocess_cmd_usage</vh></v>
<v t="ekr.20080121134847.32"><vh>_help_preprocess_cmd_option_list</vh></v>
<v t="ekr.20080121134847.33"><vh>_get_canonical_cmd_name</vh></v>
<v t="ekr.20080121134847.34"><vh>_get_canonical_map</vh></v>
<v t="ekr.20080121134847.35"><vh>_get_cmd_handler</vh></v>
<v t="ekr.20080121134847.36"><vh>_do_EOF</vh></v>
<v t="ekr.20080121134847.37"><vh>emptyline</vh></v>
</v>
<v t="ekr.20080121134847.38"><vh>class StopOptionProcessing</vh></v>
<v t="ekr.20080121134847.39"><vh>class _OptionParserEx</vh>
<v t="ekr.20080121134847.40"><vh>error</vh></v>
<v t="ekr.20080121134847.41"><vh>exit</vh></v>
</v>
<v t="ekr.20080121134847.42"><vh>class CmdlnOptionParser</vh>
<v t="ekr.20080121134847.43"><vh>__init__</vh></v>
<v t="ekr.20080121134847.44"><vh>print_help</vh></v>
<v t="ekr.20080121134847.45"><vh>error</vh></v>
</v>
<v t="ekr.20080121134847.46"><vh>class SubCmdOptionParser</vh>
<v t="ekr.20080121134847.47"><vh>set_cmdln_info</vh></v>
<v t="ekr.20080121134847.48"><vh>print_help</vh></v>
<v t="ekr.20080121134847.49"><vh>error</vh></v>
</v>
<v t="ekr.20080121134847.50"><vh>option</vh></v>
<v t="ekr.20080121134847.51"><vh>class Cmdln</vh>
<v t="ekr.20080121134847.52"><vh>_dispatch_cmd</vh></v>
</v>
<v t="ekr.20080121134847.53"><vh>_format_linedata</vh></v>
<v t="ekr.20080121134847.54"><vh>_summarize_doc</vh></v>
<v t="ekr.20080121134847.55"><vh>line2argv</vh></v>
<v t="ekr.20080121134847.56"><vh>argv2line</vh></v>
<v t="ekr.20080121134847.57"><vh>_dedentlines</vh></v>
<v t="ekr.20080121134847.58"><vh>_dedent</vh></v>
<v t="ekr.20080121134847.59"><vh>_get_indent</vh></v>
<v t="ekr.20080121134847.60"><vh>_get_trailing_whitespace</vh></v>
</v>
<v t="ekr.20080121134650.1"><vh>koextlib.py</vh>
<v t="ekr.20080121134847.61"><vh>koextlib declarations</vh></v>
<v t="ekr.20080121134847.62"><vh>class KoExtError</vh></v>
<v t="ekr.20080121134847.63"><vh>is_ext_dir</vh></v>
<v t="ekr.20080121134847.64"><vh>validate_ext_name</vh></v>
<v t="ekr.20080121134847.65"><vh>validate_ext_id</vh></v>
<v t="ekr.20080121134847.66"><vh>validate_ext_version</vh></v>
<v t="ekr.20080121134847.67"><vh>validate_ext_creator</vh></v>
<v t="ekr.20080121134847.68"><vh>create_ext_skel</vh></v>
<v t="ekr.20080121134847.69"><vh>create_udl_lang_skel</vh></v>
<v t="ekr.20080121134847.70"><vh>create_codeintel_lang_skel</vh></v>
<v t="ekr.20080121134847.71"><vh>build_ext</vh></v>
<v t="ekr.20080121134847.72"><vh>class KomodoInfo</vh>
<v t="ekr.20080121134847.73"><vh>_where_am_i</vh></v>
<v t="ekr.20080121134847.74"><vh>in_src_tree</vh></v>
<v t="ekr.20080121134847.75"><vh>xpidl_path</vh></v>
<v t="ekr.20080121134847.76"><vh>sdk_dir</vh></v>
<v t="ekr.20080121134847.77"><vh>idl_dir</vh></v>
<v t="ekr.20080121134847.78"><vh>udl_dir</vh></v>
<v t="ekr.20080121134847.79"><vh>_get_bkconfig_var</vh></v>
<v t="ekr.20080121134847.80"><vh>py_lib_dirs</vh></v>
<v t="ekr.20080121134847.81"><vh>moz_bin_dir</vh></v>
<v t="ekr.20080121134847.82"><vh>ext_dirs</vh></v>
</v>
<v t="ekr.20080121134847.83"><vh>class ExtensionInfo</vh>
<v t="ekr.20080121134847.84"><vh>__init__</vh></v>
<v t="ekr.20080121134847.85"><vh>_install_rdf_info</vh></v>
<v t="ekr.20080121134847.86"><vh>name</vh></v>
<v t="ekr.20080121134847.87"><vh>version</vh></v>
<v t="ekr.20080121134847.88"><vh>id</vh></v>
<v t="ekr.20080121134847.89"><vh>codename</vh></v>
<v t="ekr.20080121134847.90"><vh>pkg_name</vh></v>
</v>
<v t="ekr.20080121134847.91"><vh>_code_safe_lang_from_lang</vh></v>
<v t="ekr.20080121134847.92"><vh>_module_from_path</vh></v>
<v t="ekr.20080121134847.93"><vh>_query_yes_no_quit</vh></v>
<v t="ekr.20080121134847.94"><vh>_query</vh></v>
<v t="ekr.20080121134847.95"><vh>_banner</vh></v>
<v t="ekr.20080121134847.96"><vh>_dedentlines</vh></v>
<v t="ekr.20080121134847.97"><vh>_dedent</vh></v>
<v t="ekr.20080121134847.98"><vh>_xpidl</vh></v>
<v t="ekr.20080121134847.99"><vh>_luddite_compile</vh></v>
<v t="ekr.20080121134847.100"><vh>_trim_files_in_dir</vh></v>
<v t="ekr.20080121134847.101"><vh>_rmtree_OnError</vh></v>
<v t="ekr.20080121134847.102"><vh>_rmtree</vh></v>
<v t="ekr.20080121134847.103"><vh>__run_log</vh></v>
<v t="ekr.20080121134847.104"><vh>_run</vh></v>
<v t="ekr.20080121134847.105"><vh>_run_in_dir</vh></v>
<v t="ekr.20080121134847.106"><vh>_rm</vh></v>
<v t="ekr.20080121134847.107"><vh>_mv</vh></v>
<v t="ekr.20080121134847.108"><vh>_cp</vh></v>
<v t="ekr.20080121134847.109"><vh>_mkdir</vh></v>
</v>
</v>
<v t="ekr.20080121134949"><vh>sdk/pylib/ludditelib</vh>
<v t="ekr.20080121134949.1"><vh>cmdln.py</vh>
<v t="ekr.20080121135406"><vh>cmdln declarations</vh></v>
<v t="ekr.20080121135406.1"><vh>class CmdlnError</vh>
<v t="ekr.20080121135406.2"><vh>__init__</vh></v>
<v t="ekr.20080121135406.3"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121135406.4"><vh>class CmdlnUserError</vh></v>
<v t="ekr.20080121135406.5"><vh>alias</vh></v>
<v t="ekr.20080121135406.6"><vh>class RawCmdln</vh>
<v t="ekr.20080121135406.7"><vh>__init__</vh></v>
<v t="ekr.20080121135406.8"><vh>get_optparser</vh></v>
<v t="ekr.20080121135406.9"><vh>postoptparse</vh></v>
<v t="ekr.20080121135406.10"><vh>main</vh></v>
<v t="ekr.20080121135406.11"><vh>cmd</vh></v>
<v t="ekr.20080121135406.12"><vh>_str</vh></v>
<v t="ekr.20080121135406.13"><vh>cmdloop</vh></v>
<v t="ekr.20080121135406.14"><vh>precmd</vh></v>
<v t="ekr.20080121135406.15"><vh>postcmd</vh></v>
<v t="ekr.20080121135406.16"><vh>cmdexc</vh></v>
<v t="ekr.20080121135406.17"><vh>onecmd</vh></v>
<v t="ekr.20080121135406.18"><vh>_dispatch_cmd</vh></v>
<v t="ekr.20080121135406.19"><vh>default</vh></v>
<v t="ekr.20080121135406.20"><vh>parseline</vh></v>
<v t="ekr.20080121135406.21"><vh>helpdefault</vh></v>
<v t="ekr.20080121135406.22"><vh>do_help</vh></v>
<v t="ekr.20080121135406.23"><vh>_help_reindent</vh></v>
<v t="ekr.20080121135406.24"><vh>_help_preprocess</vh></v>
<v t="ekr.20080121135406.25"><vh>_help_preprocess_name</vh></v>
<v t="ekr.20080121135406.26"><vh>_help_preprocess_option_list</vh></v>
<v t="ekr.20080121135406.27"><vh>_help_preprocess_command_list</vh></v>
<v t="ekr.20080121135406.28"><vh>_gen_names_and_attrs</vh></v>
<v t="ekr.20080121135406.29"><vh>_help_preprocess_help_list</vh></v>
<v t="ekr.20080121135406.30"><vh>_help_preprocess_cmd_name</vh></v>
<v t="ekr.20080121135406.31"><vh>_help_preprocess_cmd_usage</vh></v>
<v t="ekr.20080121135406.32"><vh>_help_preprocess_cmd_option_list</vh></v>
<v t="ekr.20080121135406.33"><vh>_get_canonical_cmd_name</vh></v>
<v t="ekr.20080121135406.34"><vh>_get_canonical_map</vh></v>
<v t="ekr.20080121135406.35"><vh>_get_cmd_handler</vh></v>
<v t="ekr.20080121135406.36"><vh>_do_EOF</vh></v>
<v t="ekr.20080121135406.37"><vh>emptyline</vh></v>
</v>
<v t="ekr.20080121135406.38"><vh>class StopOptionProcessing</vh></v>
<v t="ekr.20080121135406.39"><vh>class _OptionParserEx</vh>
<v t="ekr.20080121135406.40"><vh>error</vh></v>
<v t="ekr.20080121135406.41"><vh>exit</vh></v>
</v>
<v t="ekr.20080121135406.42"><vh>class CmdlnOptionParser</vh>
<v t="ekr.20080121135406.43"><vh>__init__</vh></v>
<v t="ekr.20080121135406.44"><vh>print_help</vh></v>
<v t="ekr.20080121135406.45"><vh>error</vh></v>
</v>
<v t="ekr.20080121135406.46"><vh>class SubCmdOptionParser</vh>
<v t="ekr.20080121135406.47"><vh>set_cmdln_info</vh></v>
<v t="ekr.20080121135406.48"><vh>print_help</vh></v>
<v t="ekr.20080121135406.49"><vh>error</vh></v>
</v>
<v t="ekr.20080121135406.50"><vh>option</vh></v>
<v t="ekr.20080121135406.51"><vh>class Cmdln</vh>
<v t="ekr.20080121135406.52"><vh>_dispatch_cmd</vh></v>
</v>
<v t="ekr.20080121135406.53"><vh>_format_linedata</vh></v>
<v t="ekr.20080121135406.54"><vh>_summarize_doc</vh></v>
<v t="ekr.20080121135406.55"><vh>line2argv</vh></v>
<v t="ekr.20080121135406.56"><vh>argv2line</vh></v>
<v t="ekr.20080121135406.57"><vh>_dedentlines</vh></v>
<v t="ekr.20080121135406.58"><vh>_dedent</vh></v>
<v t="ekr.20080121135406.59"><vh>_get_indent</vh></v>
<v t="ekr.20080121135406.60"><vh>_get_trailing_whitespace</vh></v>
</v>
<v t="ekr.20080121134949.2"><vh>commands.py</vh>
<v t="ekr.20080121135406.61"><vh>commands declarations</vh></v>
<v t="ekr.20080121135406.62"><vh>compile</vh></v>
<v t="ekr.20080121135406.63"><vh>deprecated_compile</vh></v>
<v t="ekr.20080121135406.64"><vh>parse</vh></v>
<v t="ekr.20080121135406.65"><vh>deprecated_package</vh></v>
<v t="ekr.20080121135406.66"><vh>_get_build_dir</vh></v>
<v t="ekr.20080121135406.67"><vh>_codename_from_name</vh></v>
<v t="ekr.20080121135406.68"><vh>__run_log</vh></v>
<v t="ekr.20080121135406.69"><vh>_run</vh></v>
<v t="ekr.20080121135406.70"><vh>_run_in_dir</vh></v>
</v>
<v t="ekr.20080121134949.3"><vh>common.py</vh>
<v t="ekr.20080121135406.71"><vh>common declarations</vh></v>
<v t="ekr.20080121135406.72"><vh>class LudditeError</vh></v>
<v t="ekr.20080121135406.73"><vh>is_source_tree_layout</vh></v>
<v t="ekr.20080121135406.74"><vh>norm_guid</vh></v>
<v t="ekr.20080121135406.75"><vh>generate_guid</vh></v>
</v>
<v t="ekr.20080121134949.4"><vh>constants.py</vh>
<v t="ekr.20080121135406.76"><vh>constants declarations</vh></v>
</v>
<v t="ekr.20080121134949.5"><vh>debug.py</vh>
<v t="ekr.20080121135406.77"><vh>debug declarations</vh></v>
<v t="ekr.20080121135406.78"><vh>_add_libs</vh></v>
<v t="ekr.20080121135406.79"><vh>lex</vh></v>
<v t="ekr.20080121135406.80"><vh>lex_to_html</vh></v>
<v t="ekr.20080121135406.81"><vh>_style_names_from_style_num</vh></v>
<v t="ekr.20080121135406.82"><vh>_lexudl_path_escape</vh></v>
<v t="ekr.20080121135406.83"><vh>_urlescape</vh></v>
<v t="ekr.20080121135406.84"><vh>class UDLLexer</vh>
<v t="ekr.20080121135406.85"><vh>__init__</vh></v>
<v t="ekr.20080121135406.86"><vh>_gen_lexres_candidate_paths</vh></v>
<v t="ekr.20080121135406.87"><vh>_get_lexres_path</vh></v>
</v>
<v t="ekr.20080121135406.88"><vh>class Accessor</vh>
<v t="ekr.20080121135406.89"><vh>char_at_pos</vh></v>
<v t="ekr.20080121135406.90"><vh>style_at_pos</vh></v>
<v t="ekr.20080121135406.91"><vh>line_and_col_at_pos</vh></v>
<v t="ekr.20080121135406.92"><vh>gen_char_and_style_back</vh></v>
<v t="ekr.20080121135406.93"><vh>gen_char_and_style</vh></v>
<v t="ekr.20080121135406.94"><vh>match_at_pos</vh></v>
<v t="ekr.20080121135406.95"><vh>line_from_pos</vh></v>
<v t="ekr.20080121135406.96"><vh>line_start_pos_from_pos</vh></v>
<v t="ekr.20080121135406.97"><vh>pos_from_line_and_col</vh></v>
<v t="ekr.20080121135406.98"><vh>text</vh></v>
<v t="ekr.20080121135406.99"><vh>text_range</vh></v>
<v t="ekr.20080121135406.100"><vh>length</vh></v>
<v t="ekr.20080121135406.101"><vh>gen_tokens</vh></v>
<v t="ekr.20080121135406.102"><vh>contiguous_style_range_from_pos</vh></v>
</v>
<v t="ekr.20080121135406.103"><vh>class SilverCityAccessor</vh>
<v t="ekr.20080121135406.104"><vh>__init__</vh></v>
<v t="ekr.20080121135406.105"><vh>reset_content</vh></v>
<v t="ekr.20080121135406.106"><vh>tokens</vh></v>
<v t="ekr.20080121135406.107"><vh>char_at_pos</vh></v>
<v t="ekr.20080121135406.108"><vh>_token_at_pos</vh></v>
<v t="ekr.20080121135406.109"><vh>style_at_pos</vh></v>
<v t="ekr.20080121135406.110"><vh>line_and_col_at_pos</vh></v>
<v t="ekr.20080121135406.111"><vh>gen_char_and_style_back</vh></v>
<v t="ekr.20080121135406.112"><vh>gen_char_and_style</vh></v>
<v t="ekr.20080121135406.113"><vh>match_at_pos</vh></v>
<v t="ekr.20080121135406.114"><vh>line_from_pos</vh></v>
<v t="ekr.20080121135406.115"><vh>line_start_pos_from_pos</vh></v>
<v t="ekr.20080121135406.116"><vh>pos_from_line_and_col</vh></v>
<v t="ekr.20080121135406.117"><vh>text</vh></v>
<v t="ekr.20080121135406.118"><vh>text_range</vh></v>
<v t="ekr.20080121135406.119"><vh>length</vh></v>
<v t="ekr.20080121135406.120"><vh>gen_tokens</vh></v>
<v t="ekr.20080121135406.121"><vh>contiguous_style_range_from_pos</vh></v>
</v>
<v t="ekr.20080121135406.122"><vh>_htmlescape</vh></v>
<v t="ekr.20080121135406.123"><vh>_indent</vh></v>
<v t="ekr.20080121135406.124"><vh>_escaped_text_from_text</vh></v>
<v t="ekr.20080121135406.125"><vh>_one_line_summary_from_text</vh></v>
</v>
<v t="ekr.20080121134949.6"><vh>gen.py (Error)</vh>
<v t="ekr.20080121135406.126"><vh>gen declarations</vh></v>
<v t="ekr.20080121135406.127"><vh>isTemplateStateName</vh></v>
<v t="ekr.20080121135406.128"><vh>die</vh></v>
<v t="ekr.20080121135406.129"><vh>warn</vh></v>
<v t="ekr.20080121135406.130"><vh>qq</vh></v>
<v t="ekr.20080121135406.131"><vh>test_assign_entry</vh></v>
<v t="ekr.20080121135406.132"><vh>class MainObj</vh>
<v t="ekr.20080121135406.133"><vh>__init__</vh></v>
<v t="ekr.20080121135406.134"><vh>_get_safe_lang_name</vh></v>
<v t="ekr.20080121135406.135"><vh>calcUniqueStates</vh></v>
<v t="ekr.20080121135406.136"><vh>_split_quote_string</vh></v>
<v t="ekr.20080121135406.137"><vh>_all_words</vh></v>
<v t="ekr.20080121135406.138"><vh>_has_ptn_var</vh></v>
<v t="ekr.20080121135406.139"><vh>_state_num_from_name</vh></v>
<v t="ekr.20080121135406.140"><vh>dumpAsTable</vh></v>
<v t="ekr.20080121135406.141"><vh>dumpLanguageService</vh></v>
<v t="ekr.20080121135406.142"><vh>emitScratchBuffer</vh></v>
<v t="ekr.20080121135406.143"><vh>escapeStr</vh></v>
<v t="ekr.20080121135406.144"><vh>fullStyleName</vh></v>
<v t="ekr.20080121135406.145"><vh>generateKomodoTemplateFile</vh></v>
<v t="ekr.20080121135406.146"><vh>getFamilyOwner</vh></v>
<v t="ekr.20080121135406.147"><vh>internStateName</vh></v>
<v t="ekr.20080121135406.148"><vh>setFamilyOwner</vh></v>
</v>
<v t="ekr.20080121135406.149"><vh>class CurrentInfo</vh>
<v t="ekr.20080121135406.150"><vh>__init__</vh></v>
<v t="ekr.20080121135406.151"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121135406.152"><vh>class Analyzer</vh>
<v t="ekr.20080121135406.153"><vh>__init__</vh></v>
<v t="ekr.20080121135406.154"><vh>semanticCheck</vh></v>
<v t="ekr.20080121135406.155"><vh>_assign_once_dups_ok</vh></v>
<v t="ekr.20080121135406.156"><vh>processTree</vh></v>
<v t="ekr.20080121135406.157"><vh>_favor_upto_color</vh></v>
</v>
</v>
<v t="ekr.20080121134949.7"><vh>lex.py (Intermixed tabs and blanks)</vh>
<v t="ekr.20080121135406.158"><vh>lex declarations</vh></v>
<v t="ekr.20080121135406.159"><vh>class LexError</vh>
<v t="ekr.20080121135406.160"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121135406.161"><vh>class LexToken</vh>
<v t="ekr.20080121135406.162"><vh>__str__</vh></v>
<v t="ekr.20080121135406.163"><vh>__repr__</vh></v>
<v t="ekr.20080121135406.164"><vh>skip</vh></v>
</v>
<v t="ekr.20080121135406.165"><vh>class Lexer</vh>
<v t="ekr.20080121135406.166"><vh>__init__</vh></v>
<v t="ekr.20080121135406.167"><vh>__copy__</vh></v>
<v t="ekr.20080121135406.168"><vh>input</vh></v>
<v t="ekr.20080121135406.169"><vh>errtoken</vh></v>
<v t="ekr.20080121135406.170"><vh>realtoken</vh></v>
</v>
<v t="ekr.20080121135406.171"><vh>validate_file</vh></v>
<v t="ekr.20080121135406.172"><vh>_read_lextab</vh></v>
<v t="ekr.20080121135406.173"><vh>lex</vh></v>
<v t="ekr.20080121135406.174"><vh>runmain</vh></v>
</v>
<v t="ekr.20080121134949.8"><vh>lexer.py</vh>
<v t="ekr.20080121135406.175"><vh>lexer declarations</vh></v>
<v t="ekr.20080121135406.176"><vh>t_LB_NAME</vh></v>
<v t="ekr.20080121135406.177"><vh>t_NUMBER</vh></v>
<v t="ekr.20080121135406.178"><vh>t_LB_NL</vh></v>
<v t="ekr.20080121135406.179"><vh>t_error</vh></v>
<v t="ekr.20080121135406.180"><vh>t_comment</vh></v>
<v t="ekr.20080121135406.181"><vh>t_nl_escape</vh></v>
<v t="ekr.20080121135406.182"><vh>t_LB_STRING</vh></v>
<v t="ekr.20080121135406.183"><vh>t_LB_REGEX</vh></v>
<v t="ekr.20080121135406.184"><vh>class Lexer</vh>
<v t="ekr.20080121135406.185"><vh>__init__</vh></v>
<v t="ekr.20080121135406.186"><vh>token</vh></v>
<v t="ekr.20080121135406.187"><vh>input</vh></v>
<v t="ekr.20080121135406.188"><vh>_test</vh></v>
</v>
<v t="ekr.20080121135406.189"><vh>get_input</vh></v>
<v t="ekr.20080121135406.190"><vh>do_main</vh></v>
<v t="ekr.20080121135406.191"><vh>main</vh></v>
</v>
<v t="ekr.20080121134949.9"><vh>parser.py</vh>
<v t="ekr.20080121135406.192"><vh>parser declarations</vh></v>
<v t="ekr.20080121135406.193"><vh>keep_non_empty_dicts</vh></v>
<v t="ekr.20080121135406.194"><vh>keep_non_empty_lists</vh></v>
<v t="ekr.20080121135406.195"><vh>combine_filter_list_dict</vh></v>
<v t="ekr.20080121135406.196"><vh>combine_filter_list_item</vh></v>
<v t="ekr.20080121135406.197"><vh>combine_filter_list</vh></v>
<v t="ekr.20080121135406.198"><vh>p_program</vh></v>
<v t="ekr.20080121135406.199"><vh>p_statements</vh></v>
<v t="ekr.20080121135406.200"><vh>p_statements_1</vh></v>
<v t="ekr.20080121135406.201"><vh>p_statements_2</vh></v>
<v t="ekr.20080121135406.202"><vh>p_statement</vh></v>
<v t="ekr.20080121135406.203"><vh>p_statement_1</vh></v>
<v t="ekr.20080121135406.204"><vh>p_statement_2</vh></v>
<v t="ekr.20080121135406.205"><vh>p_pattern</vh></v>
<v t="ekr.20080121135406.206"><vh>p_fold_stmt</vh></v>
<v t="ekr.20080121135406.207"><vh>p_plus_or_minus</vh></v>
<v t="ekr.20080121135406.208"><vh>p_include</vh></v>
<v t="ekr.20080121135406.209"><vh>p_namespace_decln</vh></v>
<v t="ekr.20080121135406.210"><vh>p_public_id_decln</vh></v>
<v t="ekr.20080121135406.211"><vh>p_system_id_decln</vh></v>
<v t="ekr.20080121135406.212"><vh>p_family_decln</vh></v>
<v t="ekr.20080121135406.213"><vh>p_initial</vh></v>
<v t="ekr.20080121135406.214"><vh>p_keyword_list</vh></v>
<v t="ekr.20080121135406.215"><vh>p_keyword_style</vh></v>
<v t="ekr.20080121135406.216"><vh>p_xlanguage</vh></v>
<v t="ekr.20080121135406.217"><vh>p_sublanguage</vh></v>
<v t="ekr.20080121135406.218"><vh>p_name_and_string_list</vh></v>
<v t="ekr.20080121135406.219"><vh>p_stateBlock</vh></v>
<v t="ekr.20080121135406.220"><vh>p_transitions</vh></v>
<v t="ekr.20080121135406.221"><vh>p_transitions_1</vh></v>
<v t="ekr.20080121135406.222"><vh>p_transitions_2</vh></v>
<v t="ekr.20080121135406.223"><vh>p_transition</vh></v>
<v t="ekr.20080121135406.224"><vh>p_transition_1</vh></v>
<v t="ekr.20080121135406.225"><vh>p_transition_2</vh></v>
<v t="ekr.20080121135406.226"><vh>p_transition_3</vh></v>
<v t="ekr.20080121135406.227"><vh>p_transition_4</vh></v>
<v t="ekr.20080121135406.228"><vh>p_cmds_and_trans</vh></v>
<v t="ekr.20080121135406.229"><vh>p_cmds_and_trans_1</vh></v>
<v t="ekr.20080121135406.230"><vh>p_cmds_and_trans_2</vh></v>
<v t="ekr.20080121135406.231"><vh>p_cmds_and_trans_3</vh></v>
<v t="ekr.20080121135406.232"><vh>p_cmds_and_trans_4</vh></v>
<v t="ekr.20080121135406.233"><vh>p_cmds_and_trans_5</vh></v>
<v t="ekr.20080121135406.234"><vh>p_state_tran</vh></v>
<v t="ekr.20080121135406.235"><vh>p_tokenCheckBlock</vh></v>
<v t="ekr.20080121135406.236"><vh>p_tokenCheckDeclns</vh></v>
<v t="ekr.20080121135406.237"><vh>p_tokenCheckDeclns_1</vh></v>
<v t="ekr.20080121135406.238"><vh>p_tokenCheckDeclns_2</vh></v>
<v t="ekr.20080121135406.239"><vh>p_tokenCheckDecln</vh></v>
<v t="ekr.20080121135406.240"><vh>p_tokenCheckDecln1</vh></v>
<v t="ekr.20080121135406.241"><vh>p_tokenCheckDecln2</vh></v>
<v t="ekr.20080121135406.242"><vh>p_action_type</vh></v>
<v t="ekr.20080121135406.243"><vh>p_action_selectors</vh></v>
<v t="ekr.20080121135406.244"><vh>p_start_style_stmt</vh></v>
<v t="ekr.20080121135406.245"><vh>p_end_style_stmt</vh></v>
<v t="ekr.20080121135406.246"><vh>p_string_const</vh></v>
<v t="ekr.20080121135406.247"><vh>p_pattern_const</vh></v>
<v t="ekr.20080121135406.248"><vh>p_state_name</vh></v>
<v t="ekr.20080121135406.249"><vh>p_cmds</vh></v>
<v t="ekr.20080121135406.250"><vh>p_cmds_1</vh></v>
<v t="ekr.20080121135406.251"><vh>p_cmds_2</vh></v>
<v t="ekr.20080121135406.252"><vh>p_cmd</vh></v>
<v t="ekr.20080121135406.253"><vh>p_paint_cmd</vh></v>
<v t="ekr.20080121135406.254"><vh>p_paint_name</vh></v>
<v t="ekr.20080121135406.255"><vh>p_no_keyword_cmd</vh></v>
<v t="ekr.20080121135406.256"><vh>p_at_eoltran_cmd</vh></v>
<v t="ekr.20080121135406.257"><vh>p_redo_cmd</vh></v>
<v t="ekr.20080121135406.258"><vh>p_clear_delimiter_cmd</vh></v>
<v t="ekr.20080121135406.259"><vh>p_keep_delimiter_cmd</vh></v>
<v t="ekr.20080121135406.260"><vh>p_set_delimiter_cmd</vh></v>
<v t="ekr.20080121135406.261"><vh>p_set_opposite_delimiter_cmd</vh></v>
<v t="ekr.20080121135406.262"><vh>p_spush_check_cmd</vh></v>
<v t="ekr.20080121135406.263"><vh>p_opt_paren_state_name</vh></v>
<v t="ekr.20080121135406.264"><vh>p_opt_paren_state_name_1</vh></v>
<v t="ekr.20080121135406.265"><vh>p_opt_paren_state_name_2</vh></v>
<v t="ekr.20080121135406.266"><vh>p_spop_check_cmd</vh></v>
<v t="ekr.20080121135406.267"><vh>p_color_sym</vh></v>
<v t="ekr.20080121135406.268"><vh>p_name</vh></v>
<v t="ekr.20080121135406.269"><vh>p_names_and_strings</vh></v>
<v t="ekr.20080121135406.270"><vh>p_names_and_strings_1</vh></v>
<v t="ekr.20080121135406.271"><vh>p_names_and_strings_2</vh></v>
<v t="ekr.20080121135406.272"><vh>p_name_or_string_opt_comma</vh></v>
<v t="ekr.20080121135406.273"><vh>p_name_or_string_opt_comma_1</vh></v>
<v t="ekr.20080121135406.274"><vh>p_name_or_string_opt_comma_2</vh></v>
<v t="ekr.20080121135406.275"><vh>p_name_or_string</vh></v>
<v t="ekr.20080121135406.276"><vh>p_opt_paren_number</vh></v>
<v t="ekr.20080121135406.277"><vh>p_paren_number</vh></v>
<v t="ekr.20080121135406.278"><vh>p_eol_seq</vh></v>
<v t="ekr.20080121135406.279"><vh>p_opt_colon_eol</vh></v>
<v t="ekr.20080121135406.280"><vh>p_eol</vh></v>
<v t="ekr.20080121135406.281"><vh>p_opt_colon</vh></v>
<v t="ekr.20080121135406.282"><vh>p_opt_comma</vh></v>
<v t="ekr.20080121135406.283"><vh>p_opt_term</vh></v>
<v t="ekr.20080121135406.284"><vh>p_opt_token_check</vh></v>
<v t="ekr.20080121135406.285"><vh>p_empty</vh></v>
<v t="ekr.20080121135406.286"><vh>p_error</vh></v>
<v t="ekr.20080121135406.287"><vh>_wrap_read_file</vh></v>
<v t="ekr.20080121135406.288"><vh>_read_file</vh></v>
<v t="ekr.20080121135406.289"><vh>parse_udl_path</vh></v>
</v>
<v t="ekr.20080121134949.10"><vh>uuid.py</vh>
<v t="ekr.20080121135406.290"><vh>uuid declarations</vh></v>
<v t="ekr.20080121135406.291"><vh>class UUID</vh>
<v t="ekr.20080121135406.292"><vh>__init__</vh></v>
<v t="ekr.20080121135406.293"><vh>__cmp__</vh></v>
<v t="ekr.20080121135406.294"><vh>__str__</vh></v>
<v t="ekr.20080121135406.295"><vh>__repr__</vh></v>
<v t="ekr.20080121135406.296"><vh>get_bytes</vh></v>
<v t="ekr.20080121135406.297"><vh>set_bytes</vh></v>
<v t="ekr.20080121135406.298"><vh>get_urn</vh></v>
<v t="ekr.20080121135406.299"><vh>get_variant</vh></v>
<v t="ekr.20080121135406.300"><vh>set_variant</vh></v>
<v t="ekr.20080121135406.301"><vh>get_version</vh></v>
<v t="ekr.20080121135406.302"><vh>set_version</vh></v>
</v>
<v t="ekr.20080121135406.303"><vh>unixgetaddr</vh></v>
<v t="ekr.20080121135406.304"><vh>wingetaddr</vh></v>
<v t="ekr.20080121135406.305"><vh>getaddr</vh></v>
<v t="ekr.20080121135406.306"><vh>uuid1</vh></v>
<v t="ekr.20080121135406.307"><vh>uuid3</vh></v>
<v t="ekr.20080121135406.308"><vh>uuid4</vh></v>
<v t="ekr.20080121135406.309"><vh>uuid5</vh></v>
</v>
<v t="ekr.20080121134949.11"><vh>yacc.py</vh>
<v t="ekr.20080121135406.310"><vh>yacc declarations</vh></v>
<v t="ekr.20080121135406.311"><vh>class YaccError</vh></v>
<v t="ekr.20080121135406.312"><vh>class YaccSymbol</vh>
<v t="ekr.20080121135406.313"><vh>__str__</vh></v>
<v t="ekr.20080121135406.314"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121135406.315"><vh>class YaccProduction</vh>
<v t="ekr.20080121135406.316"><vh>__init__</vh></v>
<v t="ekr.20080121135406.317"><vh>__getitem__</vh></v>
<v t="ekr.20080121135406.318"><vh>__setitem__</vh></v>
<v t="ekr.20080121135406.319"><vh>__len__</vh></v>
<v t="ekr.20080121135406.320"><vh>lineno</vh></v>
<v t="ekr.20080121135406.321"><vh>linespan</vh></v>
<v t="ekr.20080121135406.322"><vh>pushback</vh></v>
</v>
<v t="ekr.20080121135406.323"><vh>class Parser</vh>
<v t="ekr.20080121135406.324"><vh>__init__</vh></v>
<v t="ekr.20080121135406.325"><vh>errok</vh></v>
<v t="ekr.20080121135406.326"><vh>restart</vh></v>
<v t="ekr.20080121135406.327"><vh>parse</vh></v>
</v>
<v t="ekr.20080121135406.328"><vh>validate_file</vh></v>
<v t="ekr.20080121135406.329"><vh>validate_dict</vh></v>
<v t="ekr.20080121135406.330"><vh>initialize_vars</vh></v>
<v t="ekr.20080121135406.331"><vh>class Production</vh>
<v t="ekr.20080121135406.332"><vh>__init__</vh></v>
<v t="ekr.20080121135406.333"><vh>__str__</vh></v>
<v t="ekr.20080121135406.334"><vh>__repr__</vh></v>
<v t="ekr.20080121135406.335"><vh>lr_item</vh></v>
</v>
<v t="ekr.20080121135406.336"><vh>class MiniProduction</vh></v>
<v t="ekr.20080121135406.337"><vh>is_identifier</vh></v>
<v t="ekr.20080121135406.338"><vh>add_production</vh></v>
<v t="ekr.20080121135406.339"><vh>add_function</vh></v>
<v t="ekr.20080121135406.340"><vh>compute_reachable</vh></v>
<v t="ekr.20080121135406.341"><vh>mark_reachable_from</vh></v>
<v t="ekr.20080121135406.342"><vh>compute_terminates</vh></v>
<v t="ekr.20080121135406.343"><vh>verify_productions</vh></v>
<v t="ekr.20080121135406.344"><vh>build_lritems</vh></v>
<v t="ekr.20080121135406.345"><vh>add_precedence</vh></v>
<v t="ekr.20080121135406.346"><vh>augment_grammar</vh></v>
<v t="ekr.20080121135406.347"><vh>first</vh></v>
<v t="ekr.20080121135406.348"><vh>compute_follow</vh></v>
<v t="ekr.20080121135406.349"><vh>compute_first1</vh></v>
<v t="ekr.20080121135406.350"><vh>lr_init_vars</vh></v>
<v t="ekr.20080121135406.351"><vh>lr0_closure</vh></v>
<v t="ekr.20080121135406.352"><vh>lr0_goto</vh></v>
<v t="ekr.20080121135406.353"><vh>lr0_goto_setnumber</vh></v>
<v t="ekr.20080121135406.354"><vh>lr0_kernel</vh></v>
<v t="ekr.20080121135406.355"><vh>lr0_items</vh></v>
<v t="ekr.20080121135406.356"><vh>slr_parse_table</vh></v>
<v t="ekr.20080121135406.357"><vh>lr1_closure</vh></v>
<v t="ekr.20080121135406.358"><vh>add_lookaheads</vh></v>
<v t="ekr.20080121135406.359"><vh>ReduceNonterminals</vh></v>
<v t="ekr.20080121135406.360"><vh>ReduceToTerminals</vh></v>
<v t="ekr.20080121135406.361"><vh>ReduceToNonterminals</vh></v>
<v t="ekr.20080121135406.362"><vh>lalr_parse_table</vh></v>
<v t="ekr.20080121135406.363"><vh>lr_write_tables</vh></v>
<v t="ekr.20080121135406.364"><vh>lr_read_tables</vh></v>
<v t="ekr.20080121135406.365"><vh>yacc</vh></v>
<v t="ekr.20080121135406.366"><vh>yacc_cleanup</vh></v>
<v t="ekr.20080121135406.367"><vh>parse</vh></v>
</v>
<v t="ekr.20080121134949.12"><vh>__init__.py</vh></v>
</v>
<v t="ekr.20080121105837.1852"><vh>sdk/share</vh>
<v t="ekr.20080121105837.1853"><vh>sdk/share/lang_LANG.py (Important)</vh></v>
<v t="ekr.20080121105837.1854"><vh>cix-2.0.rng</vh></v>
</v>
</v>
<v t="ekr.20080121105837.7"><vh>lib/mozilla/python/komodo/codeintel2</vh>
<v t="ekr.20080121105837.1855"><vh>codeintel2/stdlibs/*.cix</vh>
<v t="ekr.20080121123437"><vh>pywin32.cix (TRUNCATED)</vh></v>
</v>
<v t="ekr.20080121105837.8"><vh>codeintel2</vh>
<v t="ekr.20080121105837.9"><vh>accessor.py</vh>
<v t="ekr.20080121105837.10"><vh>accessor declarations</vh></v>
<v t="ekr.20080121105837.11"><vh>class Accessor</vh>
<v t="ekr.20080121105837.12"><vh>char_at_pos</vh></v>
<v t="ekr.20080121105837.13"><vh>style_at_pos</vh></v>
<v t="ekr.20080121105837.14"><vh>line_and_col_at_pos</vh></v>
<v t="ekr.20080121105837.15"><vh>gen_char_and_style_back</vh></v>
<v t="ekr.20080121105837.16"><vh>gen_char_and_style</vh></v>
<v t="ekr.20080121105837.17"><vh>match_at_pos</vh></v>
<v t="ekr.20080121105837.18"><vh>line_from_pos</vh></v>
<v t="ekr.20080121105837.19"><vh>line_start_pos_from_pos</vh></v>
<v t="ekr.20080121105837.20"><vh>pos_from_line_and_col</vh></v>
<v t="ekr.20080121105837.21"><vh>text</vh></v>
<v t="ekr.20080121105837.22"><vh>text_range</vh></v>
<v t="ekr.20080121105837.23"><vh>length</vh></v>
<v t="ekr.20080121105837.24"><vh>gen_tokens</vh></v>
<v t="ekr.20080121105837.25"><vh>contiguous_style_range_from_pos</vh></v>
</v>
<v t="ekr.20080121105837.26"><vh>class SilverCityAccessor</vh>
<v t="ekr.20080121105837.27"><vh>__init__</vh></v>
<v t="ekr.20080121105837.28"><vh>reset_content</vh></v>
<v t="ekr.20080121105837.29"><vh>tokens</vh></v>
<v t="ekr.20080121105837.30"><vh>char_at_pos</vh></v>
<v t="ekr.20080121105837.31"><vh>_token_at_pos</vh></v>
<v t="ekr.20080121105837.32"><vh>style_at_pos</vh></v>
<v t="ekr.20080121105837.33"><vh>line_and_col_at_pos</vh></v>
<v t="ekr.20080121105837.34"><vh>gen_char_and_style_back</vh></v>
<v t="ekr.20080121105837.35"><vh>gen_char_and_style</vh></v>
<v t="ekr.20080121105837.36"><vh>match_at_pos</vh></v>
<v t="ekr.20080121105837.37"><vh>line_from_pos</vh></v>
<v t="ekr.20080121105837.38"><vh>line_start_pos_from_pos</vh></v>
<v t="ekr.20080121105837.39"><vh>pos_from_line_and_col</vh></v>
<v t="ekr.20080121105837.40"><vh>text</vh></v>
<v t="ekr.20080121105837.41"><vh>text_range</vh></v>
<v t="ekr.20080121105837.42"><vh>length</vh></v>
<v t="ekr.20080121105837.43"><vh>gen_tokens</vh></v>
<v t="ekr.20080121105837.44"><vh>contiguous_style_range_from_pos</vh></v>
</v>
<v t="ekr.20080121105837.45"><vh>class SciMozAccessor</vh>
<v t="ekr.20080121105837.46"><vh>__init__</vh></v>
<v t="ekr.20080121105837.47"><vh>char_at_pos</vh></v>
<v t="ekr.20080121105837.48"><vh>style_at_pos</vh></v>
<v t="ekr.20080121105837.49"><vh>line_and_col_at_pos</vh></v>
<v t="ekr.20080121105837.50"><vh>gen_char_and_style_back</vh></v>
<v t="ekr.20080121105837.51"><vh>gen_char_and_style</vh></v>
<v t="ekr.20080121105837.52"><vh>line_from_pos</vh></v>
<v t="ekr.20080121105837.53"><vh>line_start_pos_from_pos</vh></v>
<v t="ekr.20080121105837.54"><vh>pos_from_line_and_col</vh></v>
<v t="ekr.20080121105837.55"><vh>text</vh></v>
<v t="ekr.20080121105837.56"><vh>text_range</vh></v>
<v t="ekr.20080121105837.57"><vh>length</vh></v>
<v t="ekr.20080121105837.58"><vh>gen_tokens</vh></v>
<v t="ekr.20080121105837.59"><vh>contiguous_style_range_from_pos</vh></v>
</v>
<v t="ekr.20080121105837.60"><vh>class KoDocumentAccessor</vh>
<v t="ekr.20080121105837.61"><vh>__init__</vh></v>
<v t="ekr.20080121105837.62"><vh>_scimoz_proxy_from_scimoz</vh></v>
<v t="ekr.20080121105837.63"><vh>scimoz</vh></v>
</v>
<v t="ekr.20080121105837.64"><vh>class AccessorCache</vh>
<v t="ekr.20080121105837.65"><vh>__init__</vh></v>
<v t="ekr.20080121105837.66"><vh>_reset</vh></v>
<v t="ekr.20080121105837.67"><vh>_extendCacheBackwards</vh></v>
<v t="ekr.20080121105837.68"><vh>_extendCacheForwards</vh></v>
<v t="ekr.20080121105837.69"><vh>dump</vh></v>
<v t="ekr.20080121105837.70"><vh>setCacheFetchSize</vh></v>
<v t="ekr.20080121105837.71"><vh>resetToPosition</vh></v>
<v t="ekr.20080121105837.72"><vh>getCurrentPosCharStyle</vh></v>
<v t="ekr.20080121105837.73"><vh>getPrevPosCharStyle</vh></v>
<v t="ekr.20080121105837.74"><vh>getPrecedingPosCharStyle</vh></v>
<v t="ekr.20080121105837.75"><vh>getTextBackWithStyle</vh></v>
<v t="ekr.20080121105837.76"><vh>getNextPosCharStyle</vh></v>
<v t="ekr.20080121105837.77"><vh>getSucceedingPosCharStyle</vh></v>
<v t="ekr.20080121105837.78"><vh>getTextForwardWithStyle</vh></v>
<v t="ekr.20080121105837.79"><vh>text_range</vh></v>
</v>
<v t="ekr.20080121105837.80"><vh>_test</vh></v>
</v>
<v t="ekr.20080121105837.81"><vh>buffer.py (error)</vh>
<v t="ekr.20080121105837.82"><vh>buffer declarations</vh></v>
<v t="ekr.20080121105837.83"><vh>class Buffer</vh>
<v t="ekr.20080121105837.84"><vh>__init__</vh></v>
<v t="ekr.20080121105837.85"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.86"><vh>env</vh></v>
<v t="ekr.20080121105837.87"><vh>langintel</vh></v>
<v t="ekr.20080121105837.88"><vh>lang_from_pos</vh></v>
<v t="ekr.20080121105837.89"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.90"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.91"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.92"><vh>cplns_from_trg</vh></v>
<v t="ekr.20080121105837.93"><vh>calltips_from_trg</vh></v>
<v t="ekr.20080121105837.94"><vh>curr_calltip_arg_range</vh></v>
<v t="ekr.20080121105837.95"><vh>libs</vh></v>
<v t="ekr.20080121105837.96"><vh>to_html (error: underindented docstring)</vh></v>
<v t="ekr.20080121105837.97"><vh>_html_from_trg_error</vh></v>
<v t="ekr.20080121105837.98"><vh>_html_from_trg</vh></v>
<v t="ekr.20080121105837.99"><vh>style_names_from_style_num</vh></v>
<v t="ekr.20080121105837.100"><vh>string_styles</vh></v>
<v t="ekr.20080121105837.101"><vh>comment_styles</vh></v>
<v t="ekr.20080121105837.102"><vh>number_styles</vh></v>
</v>
<v t="ekr.20080121105837.103"><vh>_htmlescape</vh></v>
<v t="ekr.20080121105837.104"><vh>_doctest</vh></v>
</v>
<v t="ekr.20080121105837.105"><vh>citadel.py (Important)</vh>
<v t="ekr.20080121133057.1"><vh>&lt;&lt; citadel.py docstring &gt;&gt;</vh></v>
<v t="ekr.20080121105837.106"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.107"><vh>class CitadelBuffer</vh>
<v t="ekr.20080121133057.2"><vh>&lt;&lt; class CitadelBuffer docstring &gt;&gt;</vh></v>
<v t="ekr.20080121105837.108"><vh>__init__</vh></v>
<v t="ekr.20080121105837.109"><vh>acquire_lock</vh></v>
<v t="ekr.20080121105837.110"><vh>release_lock</vh></v>
<v t="ekr.20080121105837.111"><vh>_load_buf_data_once</vh></v>
<v t="ekr.20080121105837.112"><vh>defn_trg_from_pos</vh></v>
<v t="ekr.20080121105837.113"><vh>defns_from_trg</vh></v>
<v t="ekr.20080121105837.114"><vh>scan_time</vh></v>
<v t="ekr.20080121105837.115"><vh>scan_error</vh></v>
<v t="ekr.20080121105837.116"><vh>blob_from_lang</vh></v>
<v t="ekr.20080121105837.117"><vh>tree</vh></v>
<v t="ekr.20080121105837.118"><vh>cix</vh></v>
<v t="ekr.20080121105837.119"><vh>scan</vh></v>
<v t="ekr.20080121105837.120"><vh>scoperef_from_pos</vh></v>
<v t="ekr.20080121105837.121"><vh>scoperef_from_blob_and_line</vh></v>
<v t="ekr.20080121105837.122"><vh>load</vh></v>
<v t="ekr.20080121105837.123"><vh>unload</vh></v>
</v>
<v t="ekr.20080121105837.124"><vh>class ImportHandler</vh>
<v t="ekr.20080121105837.125"><vh>__init__</vh></v>
<v t="ekr.20080121105837.126"><vh>setCustomPath</vh></v>
<v t="ekr.20080121105837.127"><vh>setEnvPath</vh></v>
<v t="ekr.20080121105837.128"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.129"><vh>_getPath</vh></v>
<v t="ekr.20080121105837.130"><vh>findModuleOnDisk</vh></v>
<v t="ekr.20080121105837.131"><vh>findSubImportsOnDisk</vh></v>
<v t="ekr.20080121105837.132"><vh>findModule</vh></v>
<v t="ekr.20080121105837.133"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.134"><vh>find_importables_in_dir</vh></v>
<v t="ekr.20080121105837.135"><vh>import_blob_name</vh></v>
</v>
<v t="ekr.20080121105837.136"><vh>class CitadelEvaluator</vh>
<v t="ekr.20080121105837.137"><vh>__init__</vh></v>
<v t="ekr.20080121105837.138"><vh>__str__</vh></v>
<v t="ekr.20080121105837.139"><vh>post_process_cplns</vh></v>
<v t="ekr.20080121105837.140"><vh>post_process_calltips</vh></v>
<v t="ekr.20080121105837.141"><vh>post_process_defns</vh></v>
<v t="ekr.20080121105837.142"><vh>request_reeval</vh></v>
<v t="ekr.20080121105837.143"><vh>import_resolution_failure</vh></v>
<v t="ekr.20080121105837.144"><vh>debug</vh></v>
<v t="ekr.20080121105837.145"><vh>info</vh></v>
<v t="ekr.20080121105837.146"><vh>warn</vh></v>
<v t="ekr.20080121105837.147"><vh>error</vh></v>
</v>
<v t="ekr.20080121105837.148"><vh>class Citadel</vh>
<v t="ekr.20080121105837.149"><vh>__init__</vh></v>
<v t="ekr.20080121105837.150"><vh>set_lang_info</vh></v>
<v t="ekr.20080121105837.151"><vh>cile_driver_from_lang</vh></v>
<v t="ekr.20080121105837.152"><vh>is_citadel_cpln_lang</vh></v>
<v t="ekr.20080121105837.153"><vh>get_citadel_cpln_langs</vh></v>
<v t="ekr.20080121105837.154"><vh>finalize</vh></v>
<v t="ekr.20080121105837.155"><vh>batch_update</vh></v>
<v t="ekr.20080121105837.156"><vh>_batch_update_completed</vh></v>
<v t="ekr.20080121105837.157"><vh>import_handler_from_lang</vh></v>
</v>
</v>
<v t="ekr.20080121105837.158"><vh>citadel_common.py</vh>
<v t="ekr.20080121105837.159"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.160"><vh>class ScanRequest</vh>
<v t="ekr.20080121105837.161"><vh>__init__</vh></v>
<v t="ekr.20080121105837.162"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.163"><vh>__str__</vh></v>
<v t="ekr.20080121105837.164"><vh>complete</vh></v>
<v t="ekr.20080121105837.165"><vh>wait</vh></v>
<v t="ekr.20080121105837.166"><vh>loadContent</vh></v>
<v t="ekr.20080121105837.167"><vh>calculateMD5</vh></v>
<v t="ekr.20080121105837.168"><vh>getCanonicalPath</vh></v>
</v>
</v>
<v t="ekr.20080121105837.169"><vh>common.py</vh>
<v t="ekr.20080121105837.170"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.171"><vh>&lt;&lt; globals &gt;&gt;</vh></v>
<v t="ekr.20080121105837.172"><vh>Error classes</vh>
<v t="ekr.20080121105837.173"><vh>class CodeIntelError</vh></v>
<v t="ekr.20080121105837.174"><vh>class NotATriggerError</vh></v>
<v t="ekr.20080121105837.175"><vh>class EvalError</vh></v>
<v t="ekr.20080121105837.176"><vh>class EvalTimeout</vh></v>
<v t="ekr.20080121105837.177"><vh>class VirtualMethodError</vh></v>
<v t="ekr.20080121105837.178"><vh>class CitadelError</vh></v>
<v t="ekr.20080121105837.179"><vh>class NoBufferAccessorError</vh></v>
<v t="ekr.20080121105837.180"><vh>class CILEError</vh></v>
<v t="ekr.20080121105837.181"><vh>class CIXError</vh></v>
<v t="ekr.20080121105837.182"><vh>class CIDBError</vh></v>
<v t="ekr.20080121105837.183"><vh>class DatabaseError</vh></v>
<v t="ekr.20080121105837.184"><vh>class CorruptDatabase</vh></v>
<v t="ekr.20080121105837.185"><vh>class NotFoundInDatabase</vh></v>
<v t="ekr.20080121105837.186"><vh>class CITDLError</vh></v>
<v t="ekr.20080121105837.187"><vh>class NoModuleEntry</vh>
<v t="ekr.20080121105837.188"><vh>__init__</vh></v>
<v t="ekr.20080121105837.189"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121105837.190"><vh>class NoCIDBModuleEntry</vh>
<v t="ekr.20080121105837.191"><vh>__init__</vh></v>
<v t="ekr.20080121105837.192"><vh>__str__</vh></v>
</v>
</v>
<v t="ekr.20080121105837.193"><vh>Common base classes</vh>
<v t="ekr.20080121105837.194"><vh>class Trigger</vh>
<v t="ekr.20080121105837.195"><vh>__init__</vh></v>
<v t="ekr.20080121105837.196"><vh>id</vh></v>
<v t="ekr.20080121105837.197"><vh>name</vh></v>
<v t="ekr.20080121105837.198"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.199"><vh>is_same</vh></v>
</v>
<v t="ekr.20080121105837.200"><vh>class Definition</vh>
<v t="ekr.20080121105837.201"><vh>__init__</vh></v>
<v t="ekr.20080121105837.202"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121105837.203"><vh>class CILEDriver</vh>
<v t="ekr.20080121105837.204"><vh>__init__</vh></v>
<v t="ekr.20080121105837.205"><vh>scan</vh></v>
<v t="ekr.20080121105837.206"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.207"><vh>scan_multilang</vh></v>
<v t="ekr.20080121105837.208"><vh>scan_csl_tokens</vh></v>
</v>
<v t="ekr.20080121105837.209"><vh>class EvalController</vh>
<v t="ekr.20080121105837.210"><vh>__init__</vh></v>
<v t="ekr.20080121105837.211"><vh>start</vh></v>
<v t="ekr.20080121105837.212"><vh>set_desc</vh></v>
<v t="ekr.20080121105837.213"><vh>done</vh></v>
<v t="ekr.20080121105837.214"><vh>is_done</vh></v>
<v t="ekr.20080121105837.215"><vh>abort</vh></v>
<v t="ekr.20080121105837.216"><vh>is_aborted</vh></v>
<v t="ekr.20080121105837.217"><vh>wait</vh></v>
<v t="ekr.20080121105837.218"><vh>debug</vh></v>
<v t="ekr.20080121105837.219"><vh>info</vh></v>
<v t="ekr.20080121105837.220"><vh>warn</vh></v>
<v t="ekr.20080121105837.221"><vh>error</vh></v>
<v t="ekr.20080121105837.222"><vh>set_cplns</vh></v>
<v t="ekr.20080121105837.223"><vh>set_calltips</vh></v>
<v t="ekr.20080121105837.224"><vh>set_defns</vh></v>
</v>
<v t="ekr.20080121105837.225"><vh>class LogEvalController</vh>
<v t="ekr.20080121105837.226"><vh>__init__</vh></v>
<v t="ekr.20080121105837.227"><vh>debug</vh></v>
<v t="ekr.20080121105837.228"><vh>info</vh></v>
<v t="ekr.20080121105837.229"><vh>warn</vh></v>
<v t="ekr.20080121105837.230"><vh>error</vh></v>
</v>
<v t="ekr.20080121105837.231"><vh>class Evaluator</vh>
<v t="ekr.20080121105837.232"><vh>__init__</vh></v>
<v t="ekr.20080121105837.233"><vh>eval</vh></v>
</v>
</v>
<v t="ekr.20080121105837.234"><vh>Helper methods</vh>
<v t="ekr.20080121105837.235"><vh>symbolType2Name</vh></v>
<v t="ekr.20080121105837.236"><vh>xmlencode</vh></v>
<v t="ekr.20080121105837.237"><vh>xmlattrstr</vh></v>
<v t="ekr.20080121105837.238"><vh>isUnsavedPath</vh></v>
<v t="ekr.20080121105837.239"><vh>canonicalizePath</vh></v>
<v t="ekr.20080121105837.240"><vh>parseAttributes</vh></v>
</v>
</v>
<v t="ekr.20080121105837.241"><vh>constants_css.py</vh>
<v t="ekr.20080121105837.242"><vh>constants_css declarations</vh></v>
</v>
<v t="ekr.20080121105837.243"><vh>environment.py</vh>
<v t="ekr.20080121105837.244"><vh>environment declarations</vh></v>
<v t="ekr.20080121105837.245"><vh>class Environment</vh>
<v t="ekr.20080121105837.246"><vh>__init__</vh></v>
<v t="ekr.20080121105837.247"><vh>__del__</vh></v>
<v t="ekr.20080121105837.248"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.249"><vh>has_envvar</vh></v>
<v t="ekr.20080121105837.250"><vh>get_envvar</vh></v>
<v t="ekr.20080121105837.251"><vh>get_all_envvars</vh></v>
<v t="ekr.20080121105837.252"><vh>has_pref</vh></v>
<v t="ekr.20080121105837.253"><vh>get_pref</vh></v>
<v t="ekr.20080121105837.254"><vh>get_all_prefs</vh></v>
<v t="ekr.20080121105837.255"><vh>add_pref_observer</vh></v>
<v t="ekr.20080121105837.256"><vh>remove_pref_observer</vh></v>
<v t="ekr.20080121105837.257"><vh>remove_all_pref_observers</vh></v>
<v t="ekr.20080121105837.258"><vh>assoc_patterns_from_lang</vh></v>
<v t="ekr.20080121105837.259"><vh>get_proj_base_dir</vh></v>
</v>
<v t="ekr.20080121105837.260"><vh>class SimplePrefsEnvironment</vh>
<v t="ekr.20080121105837.261"><vh>__init__</vh></v>
<v t="ekr.20080121105837.262"><vh>set_pref</vh></v>
<v t="ekr.20080121105837.263"><vh>has_pref</vh></v>
<v t="ekr.20080121105837.264"><vh>get_pref</vh></v>
<v t="ekr.20080121105837.265"><vh>get_all_prefs</vh></v>
<v t="ekr.20080121105837.266"><vh>add_pref_observer</vh></v>
<v t="ekr.20080121105837.267"><vh>remove_pref_observer</vh></v>
<v t="ekr.20080121105837.268"><vh>remove_all_pref_observers</vh></v>
<v t="ekr.20080121105837.269"><vh>_notify_pref_observers</vh></v>
</v>
<v t="ekr.20080121105837.270"><vh>class DefaultEnvironment</vh>
<v t="ekr.20080121105837.271"><vh>__init__</vh></v>
</v>
</v>
<v t="ekr.20080121105837.272"><vh>gencix_utils.py</vh>
<v t="ekr.20080121105837.273"><vh>gencix_utils declarations</vh></v>
<v t="ekr.20080121105837.274"><vh>standardizeJSType</vh></v>
<v t="ekr.20080121105837.275"><vh>condenseSpaces</vh></v>
<v t="ekr.20080121105837.276"><vh>remove_directory</vh></v>
<v t="ekr.20080121105837.277"><vh>getText</vh></v>
<v t="ekr.20080121105837.278"><vh>getAllTextFromSubElements</vh></v>
<v t="ekr.20080121105837.279"><vh>setCixDoc</vh></v>
<v t="ekr.20080121105837.280"><vh>setCixDocFromNodeChildren</vh></v>
<v t="ekr.20080121105837.281"><vh>addCixArgument</vh></v>
<v t="ekr.20080121105837.282"><vh>addCixReturns</vh></v>
<v t="ekr.20080121105837.283"><vh>addCixType</vh></v>
<v t="ekr.20080121105837.284"><vh>addCixAttribute</vh></v>
<v t="ekr.20080121105837.285"><vh>addClassRef</vh></v>
<v t="ekr.20080121105837.286"><vh>addInterfaceRef</vh></v>
<v t="ekr.20080121105837.287"><vh>setCixSignature</vh></v>
<v t="ekr.20080121105837.288"><vh>createCixVariable</vh></v>
<v t="ekr.20080121105837.289"><vh>createCixFunction</vh></v>
<v t="ekr.20080121105837.290"><vh>createCixInterface</vh></v>
<v t="ekr.20080121105837.291"><vh>createCixClass</vh></v>
<v t="ekr.20080121105837.292"><vh>createCixModule</vh></v>
<v t="ekr.20080121105837.293"><vh>createOrFindCixModule</vh></v>
<v t="ekr.20080121105837.294"><vh>createCixFile</vh></v>
<v t="ekr.20080121105837.295"><vh>createCixRoot</vh></v>
<v t="ekr.20080121105837.296"><vh>prettify</vh></v>
<v t="ekr.20080121105837.297"><vh>get_cix_string</vh></v>
<v t="ekr.20080121105837.298"><vh>remove_cix_line_numbers_from_tree</vh></v>
</v>
<v t="ekr.20080121105837.299"><vh>indexer.py (underindented comments)</vh>
<v t="ekr.20080121105837.300"><vh>indexer declarations</vh></v>
<v t="ekr.20080121105837.301"><vh>class _PriorityQueue</vh>
<v t="ekr.20080121105837.302"><vh>_put</vh></v>
<v t="ekr.20080121105837.303"><vh>_init</vh></v>
<v t="ekr.20080121105837.304"><vh>_get</vh></v>
</v>
<v t="ekr.20080121105837.305"><vh>class _Request</vh>
<v t="ekr.20080121105837.306"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.307"><vh>class _UniqueRequestPriorityQueue</vh>
<v t="ekr.20080121105837.308"><vh>__init__</vh></v>
<v t="ekr.20080121105837.309"><vh>_put</vh></v>
<v t="ekr.20080121105837.310"><vh>_get</vh></v>
</v>
<v t="ekr.20080121105837.311"><vh>class _StagingRequestQueue</vh>
<v t="ekr.20080121105837.312"><vh>__init__</vh></v>
<v t="ekr.20080121105837.313"><vh>finalize</vh></v>
<v t="ekr.20080121105837.314"><vh>stage</vh></v>
<v t="ekr.20080121105837.315"><vh>_stagingThread</vh></v>
</v>
<v t="ekr.20080121105837.316"><vh>class XMLParseRequest</vh>
<v t="ekr.20080121105837.317"><vh>__init__</vh></v>
<v t="ekr.20080121105837.318"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.319"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121105837.320"><vh>class ScanRequest</vh>
<v t="ekr.20080121105837.321"><vh>__init__</vh></v>
<v t="ekr.20080121105837.322"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.323"><vh>__str__</vh></v>
<v t="ekr.20080121105837.324"><vh>complete</vh></v>
<v t="ekr.20080121105837.325"><vh>wait</vh></v>
</v>
<v t="ekr.20080121105837.326"><vh>class PreloadBufLibsRequest</vh>
<v t="ekr.20080121105837.327"><vh>__init__</vh></v>
<v t="ekr.20080121105837.328"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.329"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121105837.330"><vh>class PreloadLibRequest</vh>
<v t="ekr.20080121105837.331"><vh>__init__</vh></v>
<v t="ekr.20080121105837.332"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.333"><vh>__str__</vh></v>
</v>
<v t="ekr.20080121105837.334"><vh>class IndexerStopRequest</vh>
<v t="ekr.20080121105837.335"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121105837.336"><vh>class IndexerPauseRequest</vh>
<v t="ekr.20080121105837.337"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121105837.338"><vh>class Indexer</vh>
<v t="ekr.20080121105837.339"><vh>class StopIndexing</vh></v>
<v t="ekr.20080121105837.340"><vh>__init__</vh></v>
<v t="ekr.20080121105837.341"><vh>finalize</vh></v>
<v t="ekr.20080121105837.342"><vh>pause</vh></v>
<v t="ekr.20080121105837.343"><vh>resume</vh></v>
<v t="ekr.20080121105837.344"><vh>stage_request</vh></v>
<v t="ekr.20080121105837.345"><vh>add_request</vh></v>
<v t="ekr.20080121105837.346"><vh>run</vh></v>
<v t="ekr.20080121105837.347"><vh>_iteration</vh></v>
</v>
<v t="ekr.20080121105837.348"><vh>class BatchUpdater</vh>
<v t="ekr.20080121105837.349"><vh>__init__</vh></v>
<v t="ekr.20080121105837.350"><vh>start</vh></v>
<v t="ekr.20080121105837.351"><vh>abort</vh></v>
<v t="ekr.20080121105837.352"><vh>is_aborted</vh></v>
<v t="ekr.20080121105837.353"><vh>done</vh></v>
<v t="ekr.20080121105837.354"><vh>add_request</vh></v>
<v t="ekr.20080121105837.355"><vh>num_files_to_process</vh></v>
<v t="ekr.20080121105837.356"><vh>progress</vh></v>
<v t="ekr.20080121105837.357"><vh>debug</vh></v>
<v t="ekr.20080121105837.358"><vh>info</vh></v>
<v t="ekr.20080121105837.359"><vh>warn</vh></v>
<v t="ekr.20080121105837.360"><vh>error</vh></v>
<v t="ekr.20080121105837.361"><vh>_subscheduler_request_started</vh></v>
<v t="ekr.20080121105837.362"><vh>_subscheduler_completed</vh></v>
<v t="ekr.20080121105837.363"><vh>_get_scheduler</vh></v>
<v t="ekr.20080121105837.364"><vh>run</vh></v>
<v t="ekr.20080121105837.365"><vh>_cidb_upgrade_progress_callback</vh></v>
<v t="ekr.20080121105837.366"><vh>_handle_upgrade_request</vh></v>
<v t="ekr.20080121105837.367"><vh>_handle_cix_request</vh></v>
<v t="ekr.20080121105837.368"><vh>_handle_lang_request</vh></v>
<v t="ekr.20080121105837.369"><vh>_handle_directory_request</vh></v>
</v>
<v t="ekr.20080121105837.370"><vh>_indent</vh></v>
</v>
<v t="ekr.20080121105837.371"><vh>jsdoc.py</vh>
<v t="ekr.20080121105837.372"><vh>jsdoc declarations</vh></v>
<v t="ekr.20080121105837.373"><vh>class JSDocParameter</vh>
<v t="ekr.20080121105837.374"><vh>__init__</vh></v>
<v t="ekr.20080121105837.375"><vh>__repr__</vh></v>
</v>
<v t="ekr.20080121105837.376"><vh>class JSDoc</vh>
<v t="ekr.20080121105837.377"><vh>__init__</vh></v>
<v t="ekr.20080121105837.378"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.379"><vh>_reset</vh></v>
<v t="ekr.20080121105837.380"><vh>_getTypeField</vh></v>
<v t="ekr.20080121105837.381"><vh>_getTypeFieldFromString</vh></v>
<v t="ekr.20080121105837.382"><vh>_handle_base</vh></v>
<v t="ekr.20080121105837.383"><vh>_handle_extends</vh></v>
<v t="ekr.20080121105837.384"><vh>_handle_class</vh></v>
<v t="ekr.20080121105837.385"><vh>_handle_constructor</vh></v>
<v t="ekr.20080121105837.386"><vh>_handle_namespace</vh></v>
<v t="ekr.20080121105837.387"><vh>_handle_private</vh></v>
<v t="ekr.20080121105837.388"><vh>_handle_static</vh></v>
<v t="ekr.20080121105837.389"><vh>_handle_final</vh></v>
<v t="ekr.20080121105837.390"><vh>_handle_deprecated</vh></v>
<v t="ekr.20080121105837.391"><vh>_handle_param</vh></v>
<v t="ekr.20080121105837.392"><vh>_handle_tags</vh></v>
<v t="ekr.20080121105837.393"><vh>_handle_type</vh></v>
<v t="ekr.20080121105837.394"><vh>_handle_return</vh></v>
<v t="ekr.20080121105837.395"><vh>_handle_returns</vh></v>
<v t="ekr.20080121105837.396"><vh>parse</vh></v>
<v t="ekr.20080121105837.397"><vh>isClass</vh></v>
<v t="ekr.20080121105837.398"><vh>isConstructor</vh></v>
<v t="ekr.20080121105837.399"><vh>isPrivate</vh></v>
<v t="ekr.20080121105837.400"><vh>isStatic</vh></v>
<v t="ekr.20080121105837.401"><vh>isConstant</vh></v>
<v t="ekr.20080121105837.402"><vh>isDeprecated</vh></v>
</v>
<v t="ekr.20080121105837.403"><vh>_test</vh></v>
<v t="ekr.20080121105837.404"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.405"><vh>langintel.py</vh>
<v t="ekr.20080121105837.406"><vh>langintel declarations</vh>
<v t="ekr.20080121151821"><vh>&lt;&lt; LangIntel docstring &gt;&gt;</vh></v>
</v>
<v t="ekr.20080121105837.407"><vh>class LangIntel</vh>
<v t="ekr.20080121105837.408"><vh>__init__</vh></v>
<v t="ekr.20080121105837.409"><vh>cb_blob_detail_from_elem_and_buf</vh></v>
<v t="ekr.20080121105837.410"><vh>cb_import_data_from_elem</vh></v>
<v t="ekr.20080121105837.411"><vh>cb_variable_data_from_elem</vh></v>
<v t="ekr.20080121105837.412"><vh>cb_function_detail_from_elem</vh></v>
<v t="ekr.20080121105837.413"><vh>cb_class_detail_from_elem</vh></v>
<v t="ekr.20080121105837.414"><vh>cb_interface_detail_from_elem</vh></v>
<v t="ekr.20080121105837.415"><vh>cb_namespace_detail_from_elem</vh></v>
<v t="ekr.20080121105837.416"><vh>cb_data_from_elem_and_buf</vh></v>
</v>
<v t="ekr.20080121105837.417"><vh>class ParenStyleCalltipIntelMixin</vh>
<v t="ekr.20080121105837.418"><vh>calltip_verify_termination</vh></v>
<v t="ekr.20080121105837.419"><vh>curr_calltip_arg_range</vh></v>
</v>
<v t="ekr.20080121105837.420"><vh>class ProgLangTriggerIntelMixin</vh>
<v t="ekr.20080121105837.421"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.422"><vh>_is_terminating_char</vh></v>
</v>
<v t="ekr.20080121105837.423"><vh>class PythonCITDLExtractorMixin</vh>
<v t="ekr.20080121105837.424"><vh>_citdl_expr_from_pos</vh></v>
<v t="ekr.20080121105837.425"><vh>citdl_expr_from_trg</vh></v>
</v>
<v t="ekr.20080121105837.426"><vh>class Arg</vh>
<v t="ekr.20080121105837.427"><vh>__init__</vh></v>
<v t="ekr.20080121105837.428"><vh>done</vh></v>
<v t="ekr.20080121105837.429"><vh>append_ch</vh></v>
<v t="ekr.20080121105837.430"><vh>append_default_ch</vh></v>
<v t="ekr.20080121105837.431"><vh>__nonzero__</vh></v>
<v t="ekr.20080121105837.432"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.433"><vh>name</vh></v>
<v t="ekr.20080121105837.434"><vh>default</vh></v>
<v t="ekr.20080121105837.435"><vh>span</vh></v>
</v>
<v t="ekr.20080121105837.436"><vh>_parse_calltip</vh></v>
</v>
<v t="ekr.20080121105837.437"><vh>Language-specific...</vh>
<v t="ekr.20080121105837.733"><vh>shared_lexer.py</vh>
<v t="ekr.20080121105837.734"><vh>shared_lexer declarations</vh></v>
<v t="ekr.20080121105837.735"><vh>class Token</vh>
<v t="ekr.20080121105837.736"><vh>__init__</vh></v>
<v t="ekr.20080121105837.737"><vh>clone</vh></v>
<v t="ekr.20080121105837.738"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.739"><vh>class Signature</vh>
<v t="ekr.20080121105837.740"><vh>__init__</vh></v>
<v t="ekr.20080121105837.741"><vh>open</vh></v>
<v t="ekr.20080121105837.742"><vh>close</vh></v>
<v t="ekr.20080121105837.743"><vh>text</vh></v>
<v t="ekr.20080121105837.744"><vh>append</vh></v>
<v t="ekr.20080121105837.745"><vh>replace</vh></v>
<v t="ekr.20080121105837.746"><vh>is_gathering</vh></v>
</v>
<v t="ekr.20080121105837.747"><vh>class Lexer</vh>
<v t="ekr.20080121105837.748"><vh>__init__</vh></v>
<v t="ekr.20080121105837.749"><vh>build_dict</vh></v>
<v t="ekr.20080121105837.750"><vh>is_string_token</vh></v>
<v t="ekr.20080121105837.751"><vh>contains_nl</vh></v>
<v t="ekr.20080121105837.752"><vh>_adapt_line</vh></v>
<v t="ekr.20080121105837.753"><vh>_get_next_token</vh></v>
<v t="ekr.20080121105837.754"><vh>_get_eof_token</vh></v>
<v t="ekr.20080121105837.755"><vh>matches_whitespace</vh></v>
<v t="ekr.20080121105837.756"><vh>get_curr_indentation</vh></v>
<v t="ekr.20080121105837.757"><vh>curr_comment</vh></v>
<v t="ekr.20080121105837.758"><vh>clear_comments</vh></v>
<v t="ekr.20080121105837.759"><vh>has_comment</vh></v>
<v t="ekr.20080121105837.760"><vh>is_udl_markup_family</vh></v>
<v t="ekr.20080121105837.761"><vh>is_udl_css_family</vh></v>
<v t="ekr.20080121105837.762"><vh>is_udl_csl_family</vh></v>
<v t="ekr.20080121105837.763"><vh>is_udl_ssl_family</vh></v>
<v t="ekr.20080121105837.764"><vh>is_udl_tpl_family</vh></v>
<v t="ekr.20080121105837.765"><vh>start_sig</vh></v>
<v t="ekr.20080121105837.766"><vh>stop_sig</vh></v>
<v t="ekr.20080121105837.767"><vh>trim_ws</vh></v>
<v t="ekr.20080121105837.768"><vh>get_sig</vh></v>
<v t="ekr.20080121105837.769"><vh>put_back</vh></v>
<v t="ekr.20080121105837.770"><vh>curr_line_no</vh></v>
<v t="ekr.20080121105837.771"><vh>append_split_tokens</vh></v>
<v t="ekr.20080121105837.772"><vh>get_next_token</vh></v>
</v>
<v t="ekr.20080121105837.773"><vh>class UDLLexerClassifier</vh>
<v t="ekr.20080121105837.774"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.775"><vh>style_comment</vh></v>
<v t="ekr.20080121105837.776"><vh>style_default</vh></v>
<v t="ekr.20080121105837.777"><vh>style_operator</vh></v>
</v>
<v t="ekr.20080121105837.778"><vh>read_and_detab</vh></v>
<v t="ekr.20080121105837.779"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.780"><vh>shared_parser.py</vh>
<v t="ekr.20080121105837.781"><vh>shared_parser declarations</vh></v>
<v t="ekr.20080121105837.782"><vh>class CommonClassifier</vh>
<v t="ekr.20080121105837.783"><vh>get_quote_patterns</vh></v>
<v t="ekr.20080121105837.784"><vh>is_identifier_or_keyword</vh></v>
</v>
<v t="ekr.20080121105837.785"><vh>class UDLClassifier</vh>
<v t="ekr.20080121105837.786"><vh>get_builtin_type</vh></v>
<v t="ekr.20080121105837.787"><vh>is_any_operator</vh></v>
<v t="ekr.20080121105837.788"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.789"><vh>is_comment_structured</vh></v>
<v t="ekr.20080121105837.790"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.791"><vh>is_index_op</vh></v>
<v t="ekr.20080121105837.792"><vh>is_interpolating_string</vh></v>
<v t="ekr.20080121105837.793"><vh>is_keyword</vh></v>
<v t="ekr.20080121105837.794"><vh>is_number</vh></v>
<v t="ekr.20080121105837.795"><vh>is_operator</vh></v>
<v t="ekr.20080121105837.796"><vh>is_string</vh></v>
<v t="ekr.20080121105837.797"><vh>is_string_qw</vh></v>
<v t="ekr.20080121105837.798"><vh>is_symbol</vh></v>
<v t="ekr.20080121105837.799"><vh>is_variable</vh></v>
<v t="ekr.20080121105837.800"><vh>is_variable_array</vh></v>
<v t="ekr.20080121105837.801"><vh>is_variable_scalar</vh></v>
<v t="ekr.20080121105837.802"><vh>tokenStyleToContainerStyle</vh></v>
<v t="ekr.20080121105837.803"><vh>style_identifier</vh></v>
<v t="ekr.20080121105837.804"><vh>style_operator</vh></v>
<v t="ekr.20080121105837.805"><vh>style_word</vh></v>
</v>
</v>
<v t="ekr.20080121131522"><vh>Python stuff...</vh>
<v t="ekr.20080121105837.1387"><vh>lang_python.py</vh>
<v t="ekr.20080121105837.1388"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1389"><vh>class PythonLexer</vh>
<v t="ekr.20080121105837.1390"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1391"><vh>class PythonImportsEvaluator</vh>
<v t="ekr.20080121105837.1392"><vh>__str__</vh></v>
<v t="ekr.20080121105837.1393"><vh>eval</vh></v>
</v>
<v t="ekr.20080121105837.1394"><vh>class PythonLangIntel</vh>
<v t="ekr.20080121105837.1395"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1396"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1397"><vh>_python_from_env</vh></v>
<v t="ekr.20080121105837.1398"><vh>_python_info_from_python</vh></v>
<v t="ekr.20080121105837.1399"><vh>_gen_python_import_paths_from_dirs</vh></v>
<v t="ekr.20080121105837.1400"><vh>_gen_python_import_paths_from_pth_path</vh></v>
<v t="ekr.20080121105837.1401"><vh>_extra_dirs_from_env</vh></v>
<v t="ekr.20080121105837.1402"><vh>_buf_indep_libs_from_env</vh></v>
<v t="ekr.20080121105837.1403"><vh>libs_from_buf</vh></v>
<v t="ekr.20080121105837.1404"><vh>_invalidate_cache</vh></v>
<v t="ekr.20080121105837.1405"><vh>_invalidate_cache_and_rescan_extra_dirs</vh></v>
</v>
<v t="ekr.20080121105837.1406"><vh>class PythonBuffer</vh>
<v t="ekr.20080121105837.1407"><vh>libs</vh></v>
<v t="ekr.20080121105837.1408"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1409"><vh>_last_logical_line</vh></v>
</v>
<v t="ekr.20080121105837.1410"><vh>class PythonImportHandler</vh>
<v t="ekr.20080121105837.1411"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1412"><vh>_shellOutForPath</vh></v>
<v t="ekr.20080121105837.1413"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1414"><vh>_getStdCIXScanId</vh></v>
<v t="ekr.20080121105837.1415"><vh>findModule</vh></v>
<v t="ekr.20080121105837.1416"><vh>findModuleOnDisk</vh></v>
<v t="ekr.20080121105837.1417"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1418"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.1419"><vh>find_importables_in_dir</vh></v>
</v>
<v t="ekr.20080121105837.1420"><vh>class PythonCILEDriver</vh>
<v t="ekr.20080121105837.1421"><vh>scan_purelang</vh></v>
</v>
<v t="ekr.20080121105837.1422"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.445"><vh>pythoncile.py</vh>
<v t="ekr.20080121105837.446"><vh>&lt;&lt; docstring &gt;&gt;</vh></v>
<v t="ekr.20080121105837.447"><vh>&lt;&lt; dev notes &gt;&gt;</vh></v>
<v t="ekr.20080121105837.448"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.449"><vh>&lt;&lt; globals &gt;&gt;</vh></v>
<v t="ekr.20080121105837.450"><vh>class PythonCILEError</vh></v>
<v t="ekr.20080121105837.451"><vh>_isclass</vh></v>
<v t="ekr.20080121105837.452"><vh>_isfunction</vh></v>
<v t="ekr.20080121105837.453"><vh>class AST2CIXVisitor</vh>
<v t="ekr.20080121105837.454"><vh>__init__</vh></v>
<v t="ekr.20080121105837.455"><vh>emit</vh></v>
<v t="ekr.20080121105837.456"><vh>cix_module</vh></v>
<v t="ekr.20080121105837.457"><vh>cix_import</vh></v>
<v t="ekr.20080121105837.458"><vh>cix_symbols</vh></v>
<v t="ekr.20080121105837.459"><vh>cix_symbol</vh></v>
<v t="ekr.20080121105837.460"><vh>cix_types</vh></v>
<v t="ekr.20080121105837.461"><vh>cix_variable</vh></v>
<v t="ekr.20080121105837.462"><vh>cix_classref</vh></v>
<v t="ekr.20080121105837.463"><vh>cix_class</vh></v>
<v t="ekr.20080121105837.464"><vh>cix_argument</vh></v>
<v t="ekr.20080121105837.465"><vh>cix_function</vh></v>
<v t="ekr.20080121105837.466"><vh>getCIX</vh></v>
<v t="ekr.20080121105837.467"><vh>visitModule</vh></v>
<v t="ekr.20080121105837.468"><vh>visitReturn</vh></v>
<v t="ekr.20080121105837.469"><vh>visitClass</vh></v>
<v t="ekr.20080121105837.470"><vh>visitFunction</vh></v>
<v t="ekr.20080121105837.471"><vh>visitImport</vh></v>
<v t="ekr.20080121105837.472"><vh>visitFrom</vh></v>
<v t="ekr.20080121105837.473"><vh>_assignVariable</vh></v>
<v t="ekr.20080121105837.474"><vh>_visitSimpleAssign</vh></v>
<v t="ekr.20080121105837.475"><vh>visitAssign</vh></v>
<v t="ekr.20080121105837.476"><vh>_resolveObjectRef</vh></v>
<v t="ekr.20080121105837.477"><vh>_guessTypes</vh></v>
<v t="ekr.20080121105837.478"><vh>_getExprRepr</vh></v>
<v t="ekr.20080121105837.479"><vh>_getCITDLExprRepr</vh></v>
</v>
<v t="ekr.20080121105837.480"><vh>_quietCompilerParse</vh></v>
<v t="ekr.20080121105837.481"><vh>_quietCompile</vh></v>
<v t="ekr.20080121105837.482"><vh>_getAST</vh></v>
<v t="ekr.20080121105837.483"><vh>scan</vh></v>
<v t="ekr.20080121105837.484"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.964"><vh>tree_python.py</vh>
<v t="ekr.20080121105837.967"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.968"><vh>eval_calltips</vh></v>
<v t="ekr.20080121105837.969"><vh>eval_defns</vh></v>
<v t="ekr.20080121105837.970"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.971"><vh>_join_citdl_expr</vh></v>
<v t="ekr.20080121105837.972"><vh>_calltip_from_func</vh></v>
<v t="ekr.20080121105837.973"><vh>_calltip_from_class</vh></v>
<v t="ekr.20080121105837.974"><vh>_ctor_hit_from_class</vh></v>
<v t="ekr.20080121105837.975"><vh>_calltip_from_hit</vh></v>
<v t="ekr.20080121105837.976"><vh>_members_from_elem</vh></v>
<v t="ekr.20080121105837.977"><vh>_members_from_hit</vh></v>
<v t="ekr.20080121105837.978"><vh>_hit_from_citdl</vh></v>
<v t="ekr.20080121105837.979"><vh>_hit_from_first_part</vh></v>
<v t="ekr.20080121105837.980"><vh>_hit_from_elem_imports</vh></v>
<v t="ekr.20080121105837.981"><vh>_hit_from_call</vh></v>
<v t="ekr.20080121105837.982"><vh>_hit_from_getattr</vh></v>
<v t="ekr.20080121105837.983"><vh>_hit_from_variable_type_inference</vh></v>
<v t="ekr.20080121105837.984"><vh>_hit_from_type_inference</vh></v>
<v t="ekr.20080121105837.985"><vh>built_in_blob</vh></v>
<v t="ekr.20080121105837.986"><vh>parent_scoperef_from_scoperef</vh></v>
<v t="ekr.20080121105837.987"><vh>_elem_from_scoperef</vh></v>
</v>
</v>
<v t="ekr.20080121131751"><vh>Other languages</vh>
<v t="ekr.20080121105837.438"><vh>xxx cile.py (Code Inteligence Language Engine)</vh>
<v t="ekr.20080121105837.439"><vh>perlcile.py</vh>
<v t="ekr.20080121105837.440"><vh>perlcile declarations</vh></v>
<v t="ekr.20080121105837.441"><vh>scan</vh></v>
<v t="ekr.20080121105837.442"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.443"><vh>scan_multilang</vh></v>
<v t="ekr.20080121105837.444"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.485"><vh>rubycile.py</vh>
<v t="ekr.20080121105837.486"><vh>rubycile declarations</vh></v>
<v t="ekr.20080121105837.487"><vh>class RubyCILEError</vh></v>
<v t="ekr.20080121105837.488"><vh>class _DirInfo</vh>
<v t="ekr.20080121105837.489"><vh>__init__</vh></v>
<v t="ekr.20080121105837.490"><vh>get_files</vh></v>
<v t="ekr.20080121105837.491"><vh>_changed</vh></v>
<v t="ekr.20080121105837.492"><vh>_create</vh></v>
<v t="ekr.20080121105837.493"><vh>_files</vh></v>
<v t="ekr.20080121105837.494"><vh>_mtime</vh></v>
<v t="ekr.20080121105837.495"><vh>_update</vh></v>
</v>
<v t="ekr.20080121105837.496"><vh>rails_role_from_path</vh></v>
<v t="ekr.20080121105837.497"><vh>check_insert_rails_env</vh></v>
<v t="ekr.20080121105837.498"><vh>scan</vh></v>
<v t="ekr.20080121105837.499"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.500"><vh>scan_multilang</vh></v>
<v t="ekr.20080121105837.501"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.502"><vh>tclcile.py</vh>
<v t="ekr.20080121105837.503"><vh>tclcile declarations</vh></v>
<v t="ekr.20080121105837.504"><vh>class TclCILEError</vh></v>
<v t="ekr.20080121105837.505"><vh>scan</vh></v>
<v t="ekr.20080121105837.506"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.507"><vh>scan_multilang</vh></v>
<v t="ekr.20080121105837.508"><vh>main</vh></v>
</v>
</v>
<v t="ekr.20080121105837.509"><vh>Lexers and parsers</vh>
<v t="ekr.20080121105837.510"><vh>perl_lexer.py (error)</vh>
<v t="ekr.20080121105837.511"><vh>perl_lexer declarations</vh></v>
<v t="ekr.20080121105837.512"><vh>class PerlLexerClassifier</vh>
<v t="ekr.20080121105837.513"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.514"><vh>style_comment</vh></v>
<v t="ekr.20080121105837.515"><vh>style_default</vh></v>
<v t="ekr.20080121105837.516"><vh>style_operator</vh></v>
</v>
<v t="ekr.20080121105837.517"><vh>class _CommonLexer</vh>
<v t="ekr.20080121105837.518"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.519"><vh>class PerlLexer</vh>
<v t="ekr.20080121105837.520"><vh>__init__</vh></v>
<v t="ekr.20080121105837.521"><vh>_fix_token_list</vh></v>
</v>
<v t="ekr.20080121105837.522"><vh>class PerlMultiLangLexer</vh>
<v t="ekr.20080121105837.523"><vh>__init__</vh></v>
<v t="ekr.20080121105837.524"><vh>_build_tokens</vh></v>
<v t="ekr.20080121105837.525"><vh>_fix_token_list</vh></v>
<v t="ekr.20080121105837.526"><vh>get_csl_tokens</vh></v>
<v t="ekr.20080121105837.527"><vh>has_perl_code</vh></v>
</v>
<v t="ekr.20080121105837.528"><vh>provide_sample_code</vh></v>
</v>
<v t="ekr.20080121105837.529"><vh>perl_parser.py (underindented comment)</vh>
<v t="ekr.20080121105837.530"><vh>perl_parser declarations</vh></v>
<v t="ekr.20080121105837.531"><vh>memoize</vh></v>
<v t="ekr.20080121105837.532"><vh>class TimingRe</vh>
<v t="ekr.20080121105837.533"><vh>__init__</vh></v>
<v t="ekr.20080121105837.534"><vh>sub</vh></v>
<v t="ekr.20080121105837.535"><vh>match</vh></v>
<v t="ekr.20080121105837.536"><vh>search</vh></v>
<v t="ekr.20080121105837.537"><vh>split</vh></v>
<v t="ekr.20080121105837.538"><vh>findall</vh></v>
<v t="ekr.20080121105837.539"><vh>_timing_operation</vh></v>
</v>
<v t="ekr.20080121105837.540"><vh>re_compile</vh></v>
<v t="ekr.20080121105837.541"><vh>re_sub</vh></v>
<v t="ekr.20080121105837.542"><vh>class PerlCommonClassifier</vh>
<v t="ekr.20080121105837.543"><vh>is_array_cb</vh></v>
<v t="ekr.20080121105837.544"><vh>is_scalar_cb</vh></v>
<v t="ekr.20080121105837.545"><vh>is_pod_cb</vh></v>
<v t="ekr.20080121105837.546"><vh>is_string_qw_cb</vh></v>
<v t="ekr.20080121105837.547"><vh>quote_patterns_cb</vh></v>
<v t="ekr.20080121105837.548"><vh>quote_patterns_cb_aux</vh></v>
</v>
<v t="ekr.20080121105837.549"><vh>class UDLClassifier</vh></v>
<v t="ekr.20080121105837.550"><vh>class PerlClassifier</vh>
<v t="ekr.20080121105837.551"><vh>get_builtin_type</vh></v>
<v t="ekr.20080121105837.552"><vh>is_any_operator</vh></v>
<v t="ekr.20080121105837.553"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.554"><vh>is_comment_structured</vh></v>
<v t="ekr.20080121105837.555"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.556"><vh>is_index_op</vh></v>
<v t="ekr.20080121105837.557"><vh>is_interpolating_string</vh></v>
<v t="ekr.20080121105837.558"><vh>is_keyword</vh></v>
<v t="ekr.20080121105837.559"><vh>is_number</vh></v>
<v t="ekr.20080121105837.560"><vh>is_operator</vh></v>
<v t="ekr.20080121105837.561"><vh>is_string</vh></v>
<v t="ekr.20080121105837.562"><vh>is_string_qw</vh></v>
<v t="ekr.20080121105837.563"><vh>is_symbol</vh></v>
<v t="ekr.20080121105837.564"><vh>is_variable</vh></v>
<v t="ekr.20080121105837.565"><vh>is_variable_array</vh></v>
<v t="ekr.20080121105837.566"><vh>is_variable_scalar</vh></v>
<v t="ekr.20080121105837.567"><vh>style_identifier</vh></v>
<v t="ekr.20080121105837.568"><vh>style_word</vh></v>
</v>
<v t="ekr.20080121105837.569"><vh>_get_classifier</vh></v>
<v t="ekr.20080121105837.570"><vh>class ModuleInfo</vh>
<v t="ekr.20080121105837.571"><vh>__init__</vh></v>
<v t="ekr.20080121105837.572"><vh>doStartNS</vh></v>
<v t="ekr.20080121105837.573"><vh>doEndNS</vh></v>
<v t="ekr.20080121105837.574"><vh>getNS</vh></v>
<v t="ekr.20080121105837.575"><vh>doSetArg</vh></v>
<v t="ekr.20080121105837.576"><vh>doSetParent</vh></v>
<v t="ekr.20080121105837.577"><vh>doStartFn</vh></v>
<v t="ekr.20080121105837.578"><vh>doEndFn</vh></v>
<v t="ekr.20080121105837.579"><vh>doStartVar</vh></v>
<v t="ekr.20080121105837.580"><vh>doEndVar</vh></v>
<v t="ekr.20080121105837.581"><vh>set_or_append</vh></v>
<v t="ekr.20080121105837.582"><vh>doSetVar</vh></v>
<v t="ekr.20080121105837.583"><vh>add_imported_module</vh></v>
<v t="ekr.20080121105837.584"><vh>printDocInfo</vh></v>
<v t="ekr.20080121105837.585"><vh>_get_first_sentence</vh></v>
<v t="ekr.20080121105837.586"><vh>printDocString</vh></v>
<v t="ekr.20080121105837.587"><vh>_process_e_pod</vh></v>
<v t="ekr.20080121105837.588"><vh>_wrap_process_e_pod</vh></v>
<v t="ekr.20080121105837.589"><vh>_simple_depod</vh></v>
<v t="ekr.20080121105837.590"><vh>_depod</vh></v>
<v t="ekr.20080121105837.591"><vh>trim_ws</vh></v>
<v t="ekr.20080121105837.592"><vh>printClassParents</vh></v>
<v t="ekr.20080121105837.593"><vh>printImports</vh></v>
<v t="ekr.20080121105837.594"><vh>printTypeInfo</vh></v>
<v t="ekr.20080121105837.595"><vh>printVariables</vh></v>
<v t="ekr.20080121105837.596"><vh>printFunctions</vh></v>
<v t="ekr.20080121105837.597"><vh>tryGettingDoc_Sig</vh></v>
</v>
<v t="ekr.20080121105837.598"><vh>class NamespaceInfo</vh>
<v t="ekr.20080121105837.599"><vh>__init__</vh></v>
<v t="ekr.20080121105837.600"><vh>isProbablyClass</vh></v>
</v>
<v t="ekr.20080121105837.601"><vh>class FunctionInfo</vh>
<v t="ekr.20080121105837.602"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.603"><vh>class Parser</vh>
<v t="ekr.20080121105837.604"><vh>__init__</vh></v>
<v t="ekr.20080121105837.605"><vh>_is_stmt_end_op</vh></v>
<v t="ekr.20080121105837.606"><vh>_is_string</vh></v>
<v t="ekr.20080121105837.607"><vh>printHeader</vh></v>
<v t="ekr.20080121105837.608"><vh>printContents</vh></v>
<v t="ekr.20080121105837.609"><vh>printTrailer</vh></v>
<v t="ekr.20080121105837.610"><vh>at_end_expression</vh></v>
<v t="ekr.20080121105837.611"><vh>collect_multiple_args</vh></v>
<v t="ekr.20080121105837.612"><vh>collect_single_arg</vh></v>
<v t="ekr.20080121105837.613"><vh>de_quote_string</vh></v>
<v t="ekr.20080121105837.614"><vh>finish_var_assignment</vh></v>
<v t="ekr.20080121105837.615"><vh>get_exported_names</vh></v>
<v t="ekr.20080121105837.616"><vh>get_for_vars</vh></v>
<v t="ekr.20080121105837.617"><vh>get_list_of_var_names</vh></v>
<v t="ekr.20080121105837.618"><vh>get_list_of_strings</vh></v>
<v t="ekr.20080121105837.619"><vh>get_our_vars</vh></v>
<v t="ekr.20080121105837.620"><vh>get_parent_namespaces</vh></v>
<v t="ekr.20080121105837.621"><vh>_get_property_token</vh></v>
<v t="ekr.20080121105837.622"><vh>get_rest_of_subpath</vh></v>
<v t="ekr.20080121105837.623"><vh>get_string_array</vh></v>
<v t="ekr.20080121105837.624"><vh>get_used_vars</vh></v>
<v t="ekr.20080121105837.625"><vh>look_for_object_var_assignment</vh></v>
<v t="ekr.20080121105837.626"><vh>look_for_var_assignment</vh></v>
<v t="ekr.20080121105837.627"><vh>process_import</vh></v>
<v t="ekr.20080121105837.628"><vh>process_module</vh></v>
<v t="ekr.20080121105837.629"><vh>get_CIX</vh></v>
<v t="ekr.20080121105837.630"><vh>produce_CIX</vh></v>
<v t="ekr.20080121105837.631"><vh>produce_CIX_NoHeader</vh></v>
<v t="ekr.20080121105837.632"><vh>parse</vh></v>
<v t="ekr.20080121105837.633"><vh>process_package_inner_contents</vh></v>
<v t="ekr.20080121105837.634"><vh>process_sub_contents</vh></v>
<v t="ekr.20080121105837.635"><vh>process_use</vh></v>
<v t="ekr.20080121105837.636"><vh>skip_anon_sub_contents</vh></v>
<v t="ekr.20080121105837.637"><vh>skip_to_close_match</vh></v>
<v t="ekr.20080121105837.638"><vh>skip_to_close_paren</vh></v>
<v t="ekr.20080121105837.639"><vh>skip_to_end_of_stmt</vh></v>
<v t="ekr.20080121105837.640"><vh>start_process_sub_definition</vh></v>
</v>
<v t="ekr.20080121105837.641"><vh>pp</vh></v>
<v t="ekr.20080121105837.642"><vh>main</vh></v>
</v>
<v t="ekr.20080121105837.643"><vh>ruby_lexer.py (error)</vh>
<v t="ekr.20080121105837.644"><vh>ruby_lexer declarations</vh></v>
<v t="ekr.20080121105837.645"><vh>class RubyLexerClassifier</vh>
<v t="ekr.20080121105837.646"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.647"><vh>style_comment</vh></v>
<v t="ekr.20080121105837.648"><vh>style_default</vh></v>
<v t="ekr.20080121105837.649"><vh>style_operator</vh></v>
</v>
<v t="ekr.20080121105837.650"><vh>class _CommonLexer</vh>
<v t="ekr.20080121105837.651"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.652"><vh>class RubyLexer</vh>
<v t="ekr.20080121105837.653"><vh>__init__</vh></v>
<v t="ekr.20080121105837.654"><vh>_fix_token_list</vh></v>
</v>
<v t="ekr.20080121105837.655"><vh>class RubyMultiLangLexer</vh>
<v t="ekr.20080121105837.656"><vh>__init__</vh></v>
<v t="ekr.20080121105837.657"><vh>_build_tokens</vh></v>
<v t="ekr.20080121105837.658"><vh>_fix_token_list</vh></v>
<v t="ekr.20080121105837.659"><vh>get_csl_tokens</vh></v>
<v t="ekr.20080121105837.660"><vh>has_ruby_code</vh></v>
</v>
<v t="ekr.20080121105837.661"><vh>provide_sample_code</vh></v>
</v>
<v t="ekr.20080121105837.662"><vh>ruby_parser.py (intermixed tabs &amp; blanks)</vh>
<v t="ekr.20080121105837.663"><vh>ruby_parser declarations</vh></v>
<v t="ekr.20080121105837.664"><vh>class RubyCommonClassifier</vh>
<v t="ekr.20080121105837.665"><vh>is_array_cb</vh></v>
<v t="ekr.20080121105837.666"><vh>is_scalar_cb</vh></v>
<v t="ekr.20080121105837.667"><vh>is_pod_cb</vh></v>
<v t="ekr.20080121105837.668"><vh>is_string_qw_cb</vh></v>
<v t="ekr.20080121105837.669"><vh>is_symbol_cb</vh></v>
<v t="ekr.20080121105837.670"><vh>quote_patterns_cb</vh></v>
<v t="ekr.20080121105837.671"><vh>quote_patterns_cb_aux</vh></v>
</v>
<v t="ekr.20080121105837.672"><vh>class UDLClassifier</vh></v>
<v t="ekr.20080121105837.673"><vh>class RubyClassifier</vh>
<v t="ekr.20080121105837.674"><vh>__init__</vh></v>
<v t="ekr.20080121105837.675"><vh>get_builtin_type</vh></v>
<v t="ekr.20080121105837.676"><vh>is_any_operator</vh></v>
<v t="ekr.20080121105837.677"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.678"><vh>is_comment_structured</vh></v>
<v t="ekr.20080121105837.679"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.680"><vh>is_interpolating_string</vh></v>
<v t="ekr.20080121105837.681"><vh>is_keyword</vh></v>
<v t="ekr.20080121105837.682"><vh>is_number</vh></v>
<v t="ekr.20080121105837.683"><vh>is_operator</vh></v>
<v t="ekr.20080121105837.684"><vh>is_string</vh></v>
<v t="ekr.20080121105837.685"><vh>is_symbol</vh></v>
<v t="ekr.20080121105837.686"><vh>tokenStyleToContainerStyle</vh></v>
<v t="ekr.20080121105837.687"><vh>style_identifier</vh></v>
<v t="ekr.20080121105837.688"><vh>style_operator</vh></v>
<v t="ekr.20080121105837.689"><vh>style_word</vh></v>
</v>
<v t="ekr.20080121105837.690"><vh>remove_hashes</vh></v>
<v t="ekr.20080121105837.691"><vh>class RailsMigrationData</vh>
<v t="ekr.20080121105837.692"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.693"><vh>class RailsMigrationBlock</vh>
<v t="ekr.20080121105837.694"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.695"><vh>get_inflector</vh></v>
<v t="ekr.20080121105837.696"><vh>class Parser</vh>
<v t="ekr.20080121105837.697"><vh>__init__</vh></v>
<v t="ekr.20080121105837.698"><vh>class_has_method</vh></v>
<v t="ekr.20080121105837.699"><vh>curr_block_start_indentation</vh></v>
<v t="ekr.20080121105837.700"><vh>compare_curr_ind</vh></v>
<v t="ekr.20080121105837.701"><vh>dump</vh></v>
<v t="ekr.20080121105837.702"><vh>rails_migration_class_tree</vh></v>
<v t="ekr.20080121105837.703"><vh>parse</vh></v>
<v t="ekr.20080121105837.704"><vh>get_parsing_objects</vh></v>
<v t="ekr.20080121105837.705"><vh>parse_open_parens</vh></v>
<v t="ekr.20080121105837.706"><vh>parse_attr_stmt_capture_info</vh></v>
<v t="ekr.20080121105837.707"><vh>parse_attr_stmts</vh></v>
<v t="ekr.20080121105837.708"><vh>parse_assignment</vh></v>
<v t="ekr.20080121105837.709"><vh>_actual_string_from_string_or_symbol</vh></v>
<v t="ekr.20080121105837.710"><vh>_parse_migration_create_table_block</vh></v>
<v t="ekr.20080121105837.711"><vh>_parse_migration_add_column_stmt</vh></v>
<v t="ekr.20080121105837.712"><vh>_finish_interpolating_string</vh></v>
<v t="ekr.20080121105837.713"><vh>_at_end_expression</vh></v>
<v t="ekr.20080121105837.714"><vh>skip_to_op</vh></v>
<v t="ekr.20080121105837.715"><vh>de_quote_string</vh></v>
<v t="ekr.20080121105837.716"><vh>_finishVarAssignment</vh></v>
<v t="ekr.20080121105837.717"><vh>_finish_list</vh></v>
<v t="ekr.20080121105837.718"><vh>_set_basename_method</vh></v>
<v t="ekr.20080121105837.719"><vh>_test_interpolate_string</vh></v>
<v t="ekr.20080121105837.720"><vh>_test_for_builtin_type</vh></v>
<v t="ekr.20080121105837.721"><vh>_test_token_style</vh></v>
<v t="ekr.20080121105837.722"><vh>_try_loading_relative_library</vh></v>
<v t="ekr.20080121105837.723"><vh>_create_relative_libname</vh></v>
<v t="ekr.20080121105837.724"><vh>_extract_alias_name</vh></v>
<v t="ekr.20080121105837.725"><vh>parse_aux</vh></v>
<v t="ekr.20080121105837.726"><vh>parse_nested_expn</vh></v>
<v t="ekr.20080121105837.727"><vh>parse_simple_expn</vh></v>
<v t="ekr.20080121105837.728"><vh>parse_method_args</vh></v>
<v t="ekr.20080121105837.729"><vh>parse_method</vh></v>
<v t="ekr.20080121105837.730"><vh>parse_classref</vh></v>
<v t="ekr.20080121105837.731"><vh>get_fully_qualified_name</vh></v>
<v t="ekr.20080121105837.732"><vh>get_fully_qualified_name_as_list</vh></v>
</v>
</v>
<v t="ekr.20080121105837.806"><vh>tcl_lexer.py (intermixed tabs &amp; blanks)</vh>
<v t="ekr.20080121105837.807"><vh>tcl_lexer declarations</vh></v>
<v t="ekr.20080121105837.808"><vh>class TclLexerClassifier</vh>
<v t="ekr.20080121105837.809"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.810"><vh>style_comment</vh></v>
<v t="ekr.20080121105837.811"><vh>style_default</vh></v>
<v t="ekr.20080121105837.812"><vh>style_operator</vh></v>
</v>
<v t="ekr.20080121105837.813"><vh>class TclLexer</vh>
<v t="ekr.20080121105837.814"><vh>__init__</vh></v>
<v t="ekr.20080121105837.815"><vh>_fix_token_list</vh></v>
</v>
<v t="ekr.20080121105837.816"><vh>provide_sample_code</vh></v>
</v>
<v t="ekr.20080121105837.817"><vh>tcl_parser.py</vh>
<v t="ekr.20080121105837.818"><vh>tcl_parser declarations</vh></v>
<v t="ekr.20080121105837.819"><vh>class TclClassifier</vh>
<v t="ekr.20080121105837.820"><vh>get_builtin_type</vh></v>
<v t="ekr.20080121105837.821"><vh>is_any_operator</vh></v>
<v t="ekr.20080121105837.822"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.823"><vh>is_comment_structured</vh></v>
<v t="ekr.20080121105837.824"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.825"><vh>is_interpolating_string</vh></v>
<v t="ekr.20080121105837.826"><vh>is_keyword</vh></v>
<v t="ekr.20080121105837.827"><vh>is_number</vh></v>
<v t="ekr.20080121105837.828"><vh>is_operator</vh></v>
<v t="ekr.20080121105837.829"><vh>is_string</vh></v>
<v t="ekr.20080121105837.830"><vh>is_symbol</vh></v>
<v t="ekr.20080121105837.831"><vh>quote_patterns_cb</vh></v>
<v t="ekr.20080121105837.832"><vh>style_identifier</vh></v>
<v t="ekr.20080121105837.833"><vh>style_operator</vh></v>
<v t="ekr.20080121105837.834"><vh>style_word</vh></v>
</v>
<v t="ekr.20080121105837.835"><vh>remove_hashes</vh></v>
<v t="ekr.20080121105837.836"><vh>class Parser</vh>
<v t="ekr.20080121105837.837"><vh>__init__</vh></v>
<v t="ekr.20080121105837.838"><vh>get_fully_qualified_name</vh></v>
<v t="ekr.20080121105837.839"><vh>parse</vh></v>
<v t="ekr.20080121105837.840"><vh>get_parsing_objects</vh></v>
<v t="ekr.20080121105837.841"><vh>parse_method</vh></v>
<v t="ekr.20080121105837.842"><vh>parse_assignment</vh></v>
<v t="ekr.20080121105837.843"><vh>_finishVarAssignment</vh></v>
<v t="ekr.20080121105837.844"><vh>parse_aux</vh></v>
</v>
</v>
</v>
<v t="ekr.20080121105837.845"><vh>tree_*.py</vh>
<v t="ekr.20080121105837.846"><vh>tree_javascript.py</vh>
<v t="ekr.20080121105837.847"><vh>tree_javascript declarations</vh></v>
<v t="ekr.20080121105837.848"><vh>class CandidatesForTreeEvaluator</vh>
<v t="ekr.20080121105837.849"><vh>_elem_from_scoperef</vh></v>
<v t="ekr.20080121105837.850"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.851"><vh>_join_citdl_expr</vh></v>
</v>
<v t="ekr.20080121105837.852"><vh>class JavaScriptTreeEvaluator</vh>
<v t="ekr.20080121105837.853"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.854"><vh>eval_calltips</vh></v>
<v t="ekr.20080121105837.855"><vh>eval_defns</vh></v>
<v t="ekr.20080121105837.856"><vh>parent_scoperef_from_scoperef</vh></v>
<v t="ekr.20080121105837.857"><vh>langintel</vh></v>
<v t="ekr.20080121105837.858"><vh>libs</vh></v>
<v t="ekr.20080121105837.859"><vh>built_in_blob</vh></v>
<v t="ekr.20080121105837.860"><vh>_hit_from_first_token</vh></v>
<v t="ekr.20080121105837.861"><vh>_members_from_hits</vh></v>
<v t="ekr.20080121105837.862"><vh>_calltip_from_func</vh></v>
<v t="ekr.20080121105837.863"><vh>_calltip_from_class</vh></v>
<v t="ekr.20080121105837.864"><vh>_calltips_from_hits</vh></v>
<v t="ekr.20080121105837.865"><vh>_hits_from_citdl</vh></v>
<v t="ekr.20080121105837.866"><vh>_hits_from_call</vh></v>
<v t="ekr.20080121105837.867"><vh>_hit_from_getattr</vh></v>
<v t="ekr.20080121105837.868"><vh>_hits_from_variable_type_inference</vh></v>
<v t="ekr.20080121105837.869"><vh>_hits_from_type_inference</vh></v>
<v t="ekr.20080121105837.870"><vh>_hits_from_first_part</vh></v>
</v>
<v t="ekr.20080121105837.871"><vh>_add_xpcom_blob</vh></v>
<v t="ekr.20080121105837.872"><vh>_xpcom_iid_to_cix</vh></v>
</v>
<v t="ekr.20080121105837.873"><vh>tree_perl.py</vh>
<v t="ekr.20080121105837.874"><vh>tree_perl declarations</vh></v>
<v t="ekr.20080121105837.875"><vh>class _PerlPkgTable</vh>
<v t="ekr.20080121105837.876"><vh>__init__</vh></v>
<v t="ekr.20080121105837.877"><vh>_generator</vh></v>
<v t="ekr.20080121105837.878"><vh>pkg_from_pkg_name</vh></v>
<v t="ekr.20080121105837.879"><vh>mod_and_pkg_from_pkg_name</vh></v>
<v t="ekr.20080121105837.880"><vh>gen_loaded_pkgs</vh></v>
<v t="ekr.20080121105837.881"><vh>_gen_loaded_pkgs</vh></v>
<v t="ekr.20080121105837.882"><vh>_imported_mod_names_from_mod</vh></v>
<v t="ekr.20080121105837.883"><vh>_pkg_info_from_mod</vh></v>
</v>
<v t="ekr.20080121105837.884"><vh>class CandidatesForTreeEvaluator</vh>
<v t="ekr.20080121105837.885"><vh>built_in_blob</vh></v>
<v t="ekr.20080121105837.886"><vh>parent_scoperef_from_scoperef</vh></v>
<v t="ekr.20080121105837.887"><vh>_elem_from_scoperef</vh></v>
<v t="ekr.20080121105837.888"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.889"><vh>_join_citdl_expr</vh></v>
<v t="ekr.20080121105837.890"><vh>_check_infinite_recursion</vh></v>
</v>
<v t="ekr.20080121105837.891"><vh>class PerlTreeEvaluatorBase</vh>
<v t="ekr.20080121105837.892"><vh>__init__</vh></v>
<v t="ekr.20080121105837.893"><vh>pre_eval</vh></v>
<v t="ekr.20080121105837.894"><vh>_func_members_from_pkg</vh></v>
<v t="ekr.20080121105837.895"><vh>post_process_cplns</vh></v>
</v>
<v t="ekr.20080121105837.896"><vh>class PerlPackageMembersTreeEvaluator</vh>
<v t="ekr.20080121105837.897"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.898"><vh>_members_from_pkg</vh></v>
</v>
<v t="ekr.20080121105837.899"><vh>class PerlPackageSubsTreeEvaluator</vh>
<v t="ekr.20080121105837.900"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.901"><vh>_func_members_from_pkg</vh></v>
</v>
<v t="ekr.20080121105837.902"><vh>class PerlTreeEvaluator</vh>
<v t="ekr.20080121105837.903"><vh>__init__</vh></v>
<v t="ekr.20080121105837.904"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.905"><vh>eval_calltips</vh></v>
<v t="ekr.20080121105837.906"><vh>eval_defns</vh></v>
<v t="ekr.20080121105837.907"><vh>_perl_type_from_elem</vh></v>
<v t="ekr.20080121105837.908"><vh>_calltip_from_func</vh></v>
<v t="ekr.20080121105837.909"><vh>_hit_from_citdl</vh></v>
<v t="ekr.20080121105837.910"><vh>_hit_from_first_part</vh></v>
<v t="ekr.20080121105837.911"><vh>_hit_from_getattr</vh></v>
<v t="ekr.20080121105837.912"><vh>_inherited_mods_and_pkgs_from_pkg</vh></v>
<v t="ekr.20080121105837.913"><vh>_hit_from_elem_imports</vh></v>
<v t="ekr.20080121105837.914"><vh>_hit_from_variable_type_inference</vh></v>
<v t="ekr.20080121105837.915"><vh>_hit_from_type_inference</vh></v>
</v>
</v>
<v t="ekr.20080121105837.916"><vh>tree_php.py</vh>
<v t="ekr.20080121105837.917"><vh>tree_php declarations</vh></v>
<v t="ekr.20080121105837.918"><vh>class PHPTreeEvaluator</vh>
<v t="ekr.20080121105837.919"><vh>langintel</vh></v>
<v t="ekr.20080121105837.920"><vh>libs</vh></v>
<v t="ekr.20080121105837.921"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.922"><vh>eval_calltips</vh></v>
<v t="ekr.20080121105837.923"><vh>eval_defns</vh></v>
<v t="ekr.20080121105837.924"><vh>_return_with_hit</vh></v>
<v t="ekr.20080121105837.925"><vh>_element_names_from_scope_starting_with_expr</vh></v>
<v t="ekr.20080121105837.926"><vh>_variables_from_scope</vh></v>
<v t="ekr.20080121105837.927"><vh>_constants_from_scope</vh></v>
<v t="ekr.20080121105837.928"><vh>_functions_from_scope</vh></v>
<v t="ekr.20080121105837.929"><vh>_classes_from_scope</vh></v>
<v t="ekr.20080121105837.930"><vh>_interfaces_from_scope</vh></v>
<v t="ekr.20080121105837.931"><vh>_calltips_from_hit</vh></v>
<v t="ekr.20080121105837.932"><vh>_calltip_from_class</vh></v>
<v t="ekr.20080121105837.933"><vh>_members_from_elem</vh></v>
<v t="ekr.20080121105837.934"><vh>_isElemInsideScoperef</vh></v>
<v t="ekr.20080121105837.935"><vh>_members_from_hit</vh></v>
<v t="ekr.20080121105837.936"><vh>_hit_from_citdl</vh></v>
<v t="ekr.20080121105837.937"><vh>_elem_from_scoperef</vh></v>
<v t="ekr.20080121105837.938"><vh>_hit_from_first_part</vh></v>
<v t="ekr.20080121105837.939"><vh>_hit_from_elem_imports</vh></v>
<v t="ekr.20080121105837.940"><vh>_hit_from_getattr</vh></v>
<v t="ekr.20080121105837.941"><vh>_hit_from_call</vh></v>
<v t="ekr.20080121105837.942"><vh>_hit_from_variable_type_inference</vh></v>
<v t="ekr.20080121105837.943"><vh>parent_scoperef_from_scoperef</vh></v>
<v t="ekr.20080121105837.944"><vh>built_in_blob</vh></v>
<v t="ekr.20080121105837.945"><vh>built_in_cache</vh></v>
<v t="ekr.20080121105837.946"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.947"><vh>_join_citdl_expr</vh></v>
<v t="ekr.20080121105837.948"><vh>_calltip_from_func</vh></v>
<v t="ekr.20080121105837.949"><vh>_get_global_scoperef</vh></v>
<v t="ekr.20080121105837.950"><vh>_convertListToCitdl</vh></v>
<v t="ekr.20080121105837.951"><vh>_make_shortname_lookup_citdl_dict</vh></v>
<v t="ekr.20080121105837.952"><vh>_get_all_children_with_details</vh></v>
<v t="ekr.20080121105837.953"><vh>_get_import_blob_with_module_name</vh></v>
<v t="ekr.20080121105837.954"><vh>_get_all_import_blobs_dict_for_elem</vh></v>
<v t="ekr.20080121105837.955"><vh>_get_all_import_blobs_for_elem</vh></v>
<v t="ekr.20080121105837.956"><vh>_php_cache_from_elem</vh></v>
<v t="ekr.20080121105837.957"><vh>variable_names_from_elem</vh></v>
<v t="ekr.20080121105837.958"><vh>constant_names_from_elem</vh></v>
<v t="ekr.20080121105837.959"><vh>constant_shortnames_from_elem</vh></v>
<v t="ekr.20080121105837.960"><vh>function_names_from_elem</vh></v>
<v t="ekr.20080121105837.961"><vh>function_shortnames_from_elem</vh></v>
<v t="ekr.20080121105837.962"><vh>class_names_from_elem</vh></v>
<v t="ekr.20080121105837.963"><vh>interface_names_from_elem</vh></v>
</v>
</v>
<v t="ekr.20080121105837.988"><vh>tree_ruby.py</vh>
<v t="ekr.20080121105837.989"><vh>tree_ruby declarations</vh></v>
<v t="ekr.20080121105837.990"><vh>class HitHelper</vh>
<v t="ekr.20080121105837.991"><vh>get_name</vh></v>
<v t="ekr.20080121105837.992"><vh>get_type</vh></v>
<v t="ekr.20080121105837.993"><vh>is_class</vh></v>
<v t="ekr.20080121105837.994"><vh>is_compound</vh></v>
<v t="ekr.20080121105837.995"><vh>is_function</vh></v>
<v t="ekr.20080121105837.996"><vh>is_namespace</vh></v>
<v t="ekr.20080121105837.997"><vh>is_variable</vh></v>
</v>
<v t="ekr.20080121105837.998"><vh>class TreeEvaluatorHelper</vh>
<v t="ekr.20080121105837.999"><vh>_elem_from_scoperef</vh></v>
<v t="ekr.20080121105837.1000"><vh>_calltip_from_func</vh></v>
<v t="ekr.20080121105837.1001"><vh>langintel</vh></v>
<v t="ekr.20080121105837.1002"><vh>libs</vh></v>
</v>
<v t="ekr.20080121105837.1003"><vh>class RubyTreeEvaluator</vh>
<v t="ekr.20080121105837.1004"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1005"><vh>_rec_check_inc_getattr</vh></v>
<v t="ekr.20080121105837.1006"><vh>_rec_check_dec_getattr</vh></v>
<v t="ekr.20080121105837.1007"><vh>_skip_common_ref</vh></v>
<v t="ekr.20080121105837.1008"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.1009"><vh>eval_cplns</vh></v>
<v t="ekr.20080121105837.1010"><vh>_filter_by_prefix</vh></v>
<v t="ekr.20080121105837.1011"><vh>eval_calltips</vh></v>
<v t="ekr.20080121105837.1012"><vh>eval_defns</vh></v>
<v t="ekr.20080121105837.1013"><vh>_flatten</vh></v>
<v t="ekr.20080121105837.1014"><vh>_calc_base_scoperefs</vh></v>
<v t="ekr.20080121105837.1015"><vh>_is_rails_application_controller</vh></v>
<v t="ekr.20080121105837.1016"><vh>_is_alias</vh></v>
<v t="ekr.20080121105837.1017"><vh>_calltips_from_hits</vh></v>
<v t="ekr.20080121105837.1018"><vh>_uniqify</vh></v>
<v t="ekr.20080121105837.1019"><vh>_find_first_scoperef</vh></v>
<v t="ekr.20080121105837.1020"><vh>_elem_classification</vh></v>
<v t="ekr.20080121105837.1021"><vh>_cplns_from_hits</vh></v>
<v t="ekr.20080121105837.1022"><vh>_members_from_elem</vh></v>
<v t="ekr.20080121105837.1023"><vh>_hits_from_classref</vh></v>
<v t="ekr.20080121105837.1024"><vh>_hits_from_citdl</vh></v>
<v t="ekr.20080121105837.1025"><vh>_hits_from_getattr</vh></v>
<v t="ekr.20080121105837.1026"><vh>_hits_from_getattr_aux</vh></v>
<v t="ekr.20080121105837.1027"><vh>_hit_from_elem_imports</vh></v>
<v t="ekr.20080121105837.1028"><vh>_hit_from_type_inference</vh></v>
<v t="ekr.20080121105837.1029"><vh>_get_kernel_hit</vh></v>
<v t="ekr.20080121105837.1030"><vh>_hits_from_first_part</vh></v>
<v t="ekr.20080121105837.1031"><vh>_append_hits_from_name</vh></v>
<v t="ekr.20080121105837.1032"><vh>_get_imported_blob</vh></v>
<v t="ekr.20080121105837.1033"><vh>_get_imported_blob_from_name</vh></v>
<v t="ekr.20080121105837.1034"><vh>_get_included_modules</vh></v>
<v t="ekr.20080121105837.1035"><vh>_get_required_modules</vh></v>
<v t="ekr.20080121105837.1036"><vh>_hits_from_variable_type_inference</vh></v>
<v t="ekr.20080121105837.1037"><vh>built_in_blob</vh></v>
<v t="ekr.20080121105837.1038"><vh>parent_scoperef_from_scoperef</vh></v>
<v t="ekr.20080121105837.1039"><vh>post_process_cplns</vh></v>
<v t="ekr.20080121105837.1040"><vh>post_process_calltips</vh></v>
</v>
</v>
</v>
<v t="ekr.20080121105837.1041"><vh>lang_xxx.py</vh>
<v t="ekr.20080121105837.1042"><vh>lang_css.py</vh>
<v t="ekr.20080121105837.1043"><vh>lang_css declarations</vh></v>
<v t="ekr.20080121105837.1044"><vh>class CSSLexer</vh>
<v t="ekr.20080121105837.1045"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1046"><vh>class _StraightCSSStyleClassifier</vh>
<v t="ekr.20080121105837.1047"><vh>is_css_style</vh></v>
<v t="ekr.20080121105837.1048"><vh>is_default</vh></v>
<v t="ekr.20080121105837.1049"><vh>is_comment</vh></v>
<v t="ekr.20080121105837.1050"><vh>is_string</vh></v>
<v t="ekr.20080121105837.1051"><vh>is_operator</vh></v>
<v t="ekr.20080121105837.1052"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.1053"><vh>is_value</vh></v>
<v t="ekr.20080121105837.1054"><vh>is_tag</vh></v>
<v t="ekr.20080121105837.1055"><vh>is_class</vh></v>
<v t="ekr.20080121105837.1056"><vh>is_number</vh></v>
<v t="ekr.20080121105837.1057"><vh>default_styles</vh></v>
<v t="ekr.20080121105837.1058"><vh>comment_styles</vh></v>
<v t="ekr.20080121105837.1059"><vh>string_styles</vh></v>
<v t="ekr.20080121105837.1060"><vh>operator_styles</vh></v>
<v t="ekr.20080121105837.1061"><vh>identifier_styles</vh></v>
<v t="ekr.20080121105837.1062"><vh>value_styles</vh></v>
<v t="ekr.20080121105837.1063"><vh>tag_styles</vh></v>
<v t="ekr.20080121105837.1064"><vh>class_styles</vh></v>
<v t="ekr.20080121105837.1065"><vh>number_styles</vh></v>
<v t="ekr.20080121105837.1066"><vh>ignore_styles</vh></v>
</v>
<v t="ekr.20080121105837.1067"><vh>class _UDLCSSStyleClassifier</vh>
<v t="ekr.20080121105837.1068"><vh>is_css_style</vh></v>
<v t="ekr.20080121105837.1069"><vh>_is_html_style_attribute</vh></v>
<v t="ekr.20080121105837.1070"><vh>is_identifier</vh></v>
<v t="ekr.20080121105837.1071"><vh>is_class</vh></v>
<v t="ekr.20080121105837.1072"><vh>is_tag</vh></v>
<v t="ekr.20080121105837.1073"><vh>default_styles</vh></v>
<v t="ekr.20080121105837.1074"><vh>comment_styles</vh></v>
<v t="ekr.20080121105837.1075"><vh>string_styles</vh></v>
<v t="ekr.20080121105837.1076"><vh>operator_styles</vh></v>
<v t="ekr.20080121105837.1077"><vh>identifier_styles</vh></v>
<v t="ekr.20080121105837.1078"><vh>value_styles</vh></v>
<v t="ekr.20080121105837.1079"><vh>tag_styles</vh></v>
<v t="ekr.20080121105837.1080"><vh>number_styles</vh></v>
<v t="ekr.20080121105837.1081"><vh>ignore_styles</vh></v>
</v>
<v t="ekr.20080121105837.1082"><vh>class CSSLangIntel</vh>
<v t="ekr.20080121105837.1083"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1084"><vh>_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1085"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1086"><vh>_async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1087"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1088"><vh>_get_all_anchors_names_in_project</vh></v>
<v t="ekr.20080121105837.1089"><vh>_is_ident_of_length</vh></v>
<v t="ekr.20080121105837.1090"><vh>_extract_css_declaration</vh></v>
</v>
<v t="ekr.20080121105837.1091"><vh>class CSSBuffer</vh></v>
<v t="ekr.20080121105837.1092"><vh>_isident_first_char</vh></v>
<v t="ekr.20080121105837.1093"><vh>_isident</vh></v>
<v t="ekr.20080121105837.1094"><vh>_isdigit</vh></v>
<v t="ekr.20080121105837.1095"><vh>_is_udl_css_ident</vh></v>
<v t="ekr.20080121105837.1096"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1097"><vh>lang_django.py</vh>
<v t="ekr.20080121105837.1098"><vh>lang_django declarations</vh></v>
<v t="ekr.20080121105837.1099"><vh>class DjangoLexer</vh></v>
<v t="ekr.20080121105837.1100"><vh>class DjangoBuffer</vh></v>
<v t="ekr.20080121105837.1101"><vh>class DjangoCILEDriver</vh></v>
<v t="ekr.20080121105837.1102"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1103"><vh>lang_html.py</vh>
<v t="ekr.20080121105837.1104"><vh>lang_html declarations</vh></v>
<v t="ekr.20080121105837.1105"><vh>class HTMLLexer</vh></v>
<v t="ekr.20080121105837.1106"><vh>class HTMLLangIntel</vh></v>
<v t="ekr.20080121105837.1107"><vh>class HTMLBuffer</vh></v>
<v t="ekr.20080121105837.1108"><vh>class HTMLCILEDriver</vh></v>
<v t="ekr.20080121105837.1109"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1110"><vh>lang_javascript.py</vh>
<v t="ekr.20080121105837.1111"><vh>lang_javascript declarations</vh></v>
<v t="ekr.20080121105837.1112"><vh>class JavaScriptLexer</vh>
<v t="ekr.20080121105837.1113"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1114"><vh>class PureJavaScriptStyleClassifier</vh>
<v t="ekr.20080121105837.1115"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1116"><vh>class UDLJavaScriptStyleClassifier</vh>
<v t="ekr.20080121105837.1117"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1118"><vh>class JavaScriptLangIntel</vh>
<v t="ekr.20080121105837.1119"><vh>cb_variable_data_from_elem</vh></v>
<v t="ekr.20080121105837.1120"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1121"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1122"><vh>_extra_dirs_from_env</vh></v>
<v t="ekr.20080121105837.1123"><vh>libs_from_buf</vh></v>
<v t="ekr.20080121105837.1124"><vh>_invalidate_cache</vh></v>
<v t="ekr.20080121105837.1125"><vh>_invalidate_cache_and_rescan_extra_dirs</vh></v>
<v t="ekr.20080121105837.1126"><vh>lpaths_from_blob</vh></v>
</v>
<v t="ekr.20080121105837.1127"><vh>class JavaScriptBuffer</vh>
<v t="ekr.20080121105837.1128"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1129"><vh>libs</vh></v>
<v t="ekr.20080121105837.1130"><vh>stdlib</vh></v>
<v t="ekr.20080121105837.1131"><vh>scoperef_from_blob_and_line</vh></v>
</v>
<v t="ekr.20080121105837.1132"><vh>class JavaScriptImportHandler</vh>
<v t="ekr.20080121105837.1133"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1134"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1135"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.1136"><vh>find_importables_in_dir</vh></v>
</v>
<v t="ekr.20080121105837.1137"><vh>class JavaScriptCILEDriver</vh>
<v t="ekr.20080121105837.1138"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.1139"><vh>scan_multilang</vh></v>
<v t="ekr.20080121105837.1140"><vh>scan_csl_tokens</vh></v>
</v>
<v t="ekr.20080121105837.1141"><vh>_sortByLineCmp</vh></v>
<v t="ekr.20080121105837.1142"><vh>sortByLine</vh></v>
<v t="ekr.20080121105837.1143"><vh>class JSArgs</vh>
<v t="ekr.20080121105837.1144"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1145"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1146"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1147"><vh>class JSObject</vh>
<v t="ekr.20080121105837.1148"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1149"><vh>addVariable</vh></v>
<v t="ekr.20080121105837.1150"><vh>addMemberVariable</vh></v>
<v t="ekr.20080121105837.1151"><vh>getReturnType</vh></v>
<v t="ekr.20080121105837.1152"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1153"><vh>outline</vh></v>
<v t="ekr.20080121105837.1154"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1155"><vh>class JSVariable</vh>
<v t="ekr.20080121105837.1156"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1157"><vh>class JSFunction</vh>
<v t="ekr.20080121105837.1158"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1159"><vh>addReturnType</vh></v>
</v>
<v t="ekr.20080121105837.1160"><vh>class JSClass</vh>
<v t="ekr.20080121105837.1161"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1162"><vh>class JSFile</vh>
<v t="ekr.20080121105837.1163"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1164"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1165"><vh>outline</vh></v>
<v t="ekr.20080121105837.1166"><vh>_findScopeWithName</vh></v>
<v t="ekr.20080121105837.1167"><vh>_lookupVariableType</vh></v>
<v t="ekr.20080121105837.1168"><vh>_lookupVariableTypes</vh></v>
<v t="ekr.20080121105837.1169"><vh>_updateClassConstructors</vh></v>
<v t="ekr.20080121105837.1170"><vh>updateAllScopeNames</vh></v>
<v t="ekr.20080121105837.1171"><vh>addVariable</vh></v>
<v t="ekr.20080121105837.1172"><vh>convertToElementTreeModule</vh></v>
<v t="ekr.20080121105837.1173"><vh>convertToElementTreeFile</vh></v>
</v>
<v t="ekr.20080121105837.1174"><vh>class JavaScriptCiler</vh>
<v t="ekr.20080121105837.1175"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1176"><vh>setStyleValues</vh></v>
<v t="ekr.20080121105837.1177"><vh>_logVariables</vh></v>
<v t="ekr.20080121105837.1178"><vh>incBlock</vh></v>
<v t="ekr.20080121105837.1179"><vh>decBlock</vh></v>
<v t="ekr.20080121105837.1180"><vh>_findInScope</vh></v>
<v t="ekr.20080121105837.1181"><vh>_locateScopeForName</vh></v>
<v t="ekr.20080121105837.1182"><vh>_lookupVariableTypeFromScope</vh></v>
<v t="ekr.20080121105837.1183"><vh>addFunction</vh></v>
<v t="ekr.20080121105837.1184"><vh>addClassFunction</vh></v>
<v t="ekr.20080121105837.1185"><vh>_addClassPart</vh></v>
<v t="ekr.20080121105837.1186"><vh>addClass</vh></v>
<v t="ekr.20080121105837.1187"><vh>addAnonymousClass</vh></v>
<v t="ekr.20080121105837.1188"><vh>addClassOrVariableMember</vh></v>
<v t="ekr.20080121105837.1189"><vh>addClassParent</vh></v>
<v t="ekr.20080121105837.1190"><vh>addGetter</vh></v>
<v t="ekr.20080121105837.1191"><vh>addSetter</vh></v>
<v t="ekr.20080121105837.1192"><vh>_convertFunctionToClassContructor</vh></v>
<v t="ekr.20080121105837.1193"><vh>_convertFunctionToClass</vh></v>
<v t="ekr.20080121105837.1194"><vh>_convertFunctionToClosureVariable</vh></v>
<v t="ekr.20080121105837.1195"><vh>_findOrCreateScope</vh></v>
<v t="ekr.20080121105837.1196"><vh>addVariable</vh></v>
<v t="ekr.20080121105837.1197"><vh>addObjectVariable</vh></v>
<v t="ekr.20080121105837.1198"><vh>addReturnObject</vh></v>
<v t="ekr.20080121105837.1199"><vh>addFunctionReturnType</vh></v>
<v t="ekr.20080121105837.1200"><vh>_getParenArguments</vh></v>
<v t="ekr.20080121105837.1201"><vh>_skipOverParenArguments</vh></v>
<v t="ekr.20080121105837.1202"><vh>_skipToEndOfVariableAssignment</vh></v>
<v t="ekr.20080121105837.1203"><vh>_getArgumentsFromPos</vh></v>
<v t="ekr.20080121105837.1204"><vh>_getIdentifiersFromPos</vh></v>
<v t="ekr.20080121105837.1205"><vh>_getCitdlTypeInfo</vh></v>
<v t="ekr.20080121105837.1206"><vh>_getVariableType</vh></v>
<v t="ekr.20080121105837.1207"><vh>_unquoteJsString</vh></v>
<v t="ekr.20080121105837.1208"><vh>_getVariableDetail</vh></v>
<v t="ekr.20080121105837.1209"><vh>_variableHandler</vh></v>
<v t="ekr.20080121105837.1210"><vh>createObjectArgument</vh></v>
<v t="ekr.20080121105837.1211"><vh>createFunctionArgument</vh></v>
<v t="ekr.20080121105837.1212"><vh>_addCodePiece</vh></v>
<v t="ekr.20080121105837.1213"><vh>_chooseBestVariable</vh></v>
<v t="ekr.20080121105837.1214"><vh>_copyObjectToAnother</vh></v>
<v t="ekr.20080121105837.1215"><vh>_handleYAHOOExtension</vh></v>
<v t="ekr.20080121105837.1216"><vh>_removeObjectFromScope</vh></v>
<v t="ekr.20080121105837.1217"><vh>_handleFunctionApply</vh></v>
<v t="ekr.20080121105837.1218"><vh>_handleFunctionWithArguments</vh></v>
<v t="ekr.20080121105837.1219"><vh>_resetState</vh></v>
<v t="ekr.20080121105837.1220"><vh>_popPreviousState</vh></v>
<v t="ekr.20080121105837.1221"><vh>_pushAndSetState</vh></v>
<v t="ekr.20080121105837.1222"><vh>_endOfScanReached</vh></v>
<v t="ekr.20080121105837.1223"><vh>token_next</vh></v>
<v t="ekr.20080121105837.1224"><vh>scan_puretext</vh></v>
<v t="ekr.20080121105837.1225"><vh>convertToElementTreeFile</vh></v>
<v t="ekr.20080121105837.1226"><vh>convertToElementTreeModule</vh></v>
</v>
<v t="ekr.20080121105837.1227"><vh>_isident</vh></v>
<v t="ekr.20080121105837.1228"><vh>_isdigit</vh></v>
<v t="ekr.20080121105837.1229"><vh>_walk_js_scopes</vh></v>
<v t="ekr.20080121105837.1230"><vh>_walk_js_symbols</vh></v>
<v t="ekr.20080121105837.1231"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1232"><vh>lang_mason.py</vh>
<v t="ekr.20080121105837.1233"><vh>lang_mason declarations</vh></v>
<v t="ekr.20080121105837.1234"><vh>class MasonLexer</vh></v>
<v t="ekr.20080121105837.1235"><vh>class MasonBuffer</vh></v>
<v t="ekr.20080121105837.1236"><vh>class MasonCILEDriver</vh></v>
<v t="ekr.20080121105837.1237"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1238"><vh>lang_perl.py</vh>
<v t="ekr.20080121105837.1239"><vh>lang_perl declarations</vh></v>
<v t="ekr.20080121105837.1240"><vh>class PerlLexer</vh>
<v t="ekr.20080121105837.1241"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1242"><vh>class PerlImportsEvaluator</vh>
<v t="ekr.20080121105837.1243"><vh>__str__</vh></v>
<v t="ekr.20080121105837.1244"><vh>eval</vh></v>
</v>
<v t="ekr.20080121105837.1245"><vh>class PerlLangIntel</vh>
<v t="ekr.20080121105837.1246"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1247"><vh>citdl_expr_and_prefix_filter_from_trg</vh></v>
<v t="ekr.20080121105837.1248"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1249"><vh>libs_from_buf</vh></v>
<v t="ekr.20080121105837.1250"><vh>_perl_from_env</vh></v>
<v t="ekr.20080121105837.1251"><vh>_perl_info_from_perl</vh></v>
<v t="ekr.20080121105837.1252"><vh>_extra_dirs_from_env</vh></v>
<v t="ekr.20080121105837.1253"><vh>_buf_indep_libs_from_env</vh></v>
<v t="ekr.20080121105837.1254"><vh>_invalidate_cache</vh></v>
<v t="ekr.20080121105837.1255"><vh>_invalidate_cache_and_rescan_extra_dirs</vh></v>
<v t="ekr.20080121105837.1256"><vh>cb_import_data_from_elem</vh></v>
</v>
<v t="ekr.20080121105837.1257"><vh>class PerlBuffer</vh>
<v t="ekr.20080121105837.1258"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1259"><vh>libs</vh></v>
<v t="ekr.20080121105837.1260"><vh>stdlib</vh></v>
</v>
<v t="ekr.20080121105837.1261"><vh>class PerlImportHandler</vh>
<v t="ekr.20080121105837.1262"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1263"><vh>_shellOutForPath</vh></v>
<v t="ekr.20080121105837.1264"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1265"><vh>findModule</vh></v>
<v t="ekr.20080121105837.1266"><vh>findModuleOnDisk</vh></v>
<v t="ekr.20080121105837.1267"><vh>findSubImportsOnDisk</vh></v>
<v t="ekr.20080121105837.1268"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1269"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.1270"><vh>find_importables_in_dir</vh></v>
</v>
<v t="ekr.20080121105837.1271"><vh>class PerlCILEDriver</vh>
<v t="ekr.20080121105837.1272"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1273"><vh>scan</vh></v>
<v t="ekr.20080121105837.1274"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.1275"><vh>scan_multilang</vh></v>
</v>
<v t="ekr.20080121105837.1276"><vh>_is_perl_var_char</vh></v>
<v t="ekr.20080121105837.1277"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1278"><vh>lang_php.py (error)</vh>
<v t="ekr.20080121105837.1279"><vh>lang_php declarations</vh></v>
<v t="ekr.20080121105837.1280"><vh>class PHPLexer</vh></v>
<v t="ekr.20080121105837.1281"><vh>class PHPLangIntel</vh>
<v t="ekr.20080121105837.1282"><vh>cb_variable_data_from_elem</vh></v>
<v t="ekr.20080121105837.1283"><vh>_functionCalltipTrigger</vh></v>
<v t="ekr.20080121105837.1284"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1285"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1286"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1287"><vh>_citdl_expr_from_pos</vh></v>
<v t="ekr.20080121105837.1288"><vh>citdl_expr_from_trg</vh></v>
<v t="ekr.20080121105837.1289"><vh>citdl_expr_under_pos</vh></v>
<v t="ekr.20080121105837.1290"><vh>libs_from_buf</vh></v>
<v t="ekr.20080121105837.1291"><vh>_php_from_env</vh></v>
<v t="ekr.20080121105837.1292"><vh>_php_info_from_php</vh></v>
<v t="ekr.20080121105837.1293"><vh>_extra_dirs_from_env</vh></v>
<v t="ekr.20080121105837.1294"><vh>_buf_indep_libs_from_env</vh></v>
<v t="ekr.20080121105837.1295"><vh>_invalidate_cache</vh></v>
<v t="ekr.20080121105837.1296"><vh>_invalidate_cache_and_rescan_extra_dirs</vh></v>
<v t="ekr.20080121105837.1297"><vh>cb_import_data_from_elem</vh></v>
</v>
<v t="ekr.20080121105837.1298"><vh>class PHPBuffer</vh>
<v t="ekr.20080121105837.1299"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1300"><vh>libs</vh></v>
<v t="ekr.20080121105837.1301"><vh>stdlib</vh></v>
</v>
<v t="ekr.20080121105837.1302"><vh>class PHPImportHandler</vh>
<v t="ekr.20080121105837.1303"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1304"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1305"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.1306"><vh>find_importables_in_dir</vh></v>
</v>
<v t="ekr.20080121105837.1307"><vh>class PHPCILEDriver</vh>
<v t="ekr.20080121105837.1308"><vh>XXXscan_purelang</vh></v>
<v t="ekr.20080121105837.1309"><vh>scan_multilang</vh></v>
</v>
<v t="ekr.20080121105837.1310"><vh>_sortByLineCmp</vh></v>
<v t="ekr.20080121105837.1311"><vh>sortByLine</vh></v>
<v t="ekr.20080121105837.1312"><vh>class PHPArgs</vh>
<v t="ekr.20080121105837.1313"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1314"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1315"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1316"><vh>class PHPVariable</vh>
<v t="ekr.20080121105837.1317"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1318"><vh>addType</vh></v>
<v t="ekr.20080121105837.1319"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1320"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1321"><vh>class PHPConstant</vh>
<v t="ekr.20080121105837.1322"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1323"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1324"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1325"><vh>class PHPFunction</vh>
<v t="ekr.20080121105837.1326"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1327"><vh>addReturnType</vh></v>
<v t="ekr.20080121105837.1328"><vh>__str__</vh></v>
<v t="ekr.20080121105837.1329"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1330"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1331"><vh>class PHPInterface</vh>
<v t="ekr.20080121105837.1332"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1333"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1334"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1335"><vh>class PHPClass</vh>
<v t="ekr.20080121105837.1336"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1337"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1338"><vh>toElementTree</vh></v>
</v>
<v t="ekr.20080121105837.1339"><vh>class PHPFile</vh>
<v t="ekr.20080121105837.1340"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1341"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1342"><vh>convertToElementTreeModule</vh></v>
<v t="ekr.20080121105837.1343"><vh>convertToElementTreeFile</vh></v>
</v>
<v t="ekr.20080121105837.1344"><vh>class PHPcile</vh>
<v t="ekr.20080121105837.1345"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1346"><vh>_clearindex</vh></v>
<v t="ekr.20080121105837.1347"><vh>clear</vh></v>
<v t="ekr.20080121105837.1348"><vh>__repr__</vh></v>
<v t="ekr.20080121105837.1349"><vh>convertToElementTreeModule</vh></v>
<v t="ekr.20080121105837.1350"><vh>convertToElementTreeFile</vh></v>
</v>
<v t="ekr.20080121105837.1351"><vh>class PHPParser</vh>
<v t="ekr.20080121105837.1352"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1353"><vh>idfunc</vh></v>
<v t="ekr.20080121105837.1354"><vh>include_file</vh></v>
<v t="ekr.20080121105837.1355"><vh>incBlock</vh></v>
<v t="ekr.20080121105837.1356"><vh>decBlock</vh></v>
<v t="ekr.20080121105837.1357"><vh>addFunction</vh></v>
<v t="ekr.20080121105837.1358"><vh>addReturnType</vh></v>
<v t="ekr.20080121105837.1359"><vh>addClass</vh></v>
<v t="ekr.20080121105837.1360"><vh>addClassMember</vh></v>
<v t="ekr.20080121105837.1361"><vh>addClassConstant</vh></v>
<v t="ekr.20080121105837.1362"><vh>addInterface</vh></v>
<v t="ekr.20080121105837.1363"><vh>addVariable</vh></v>
<v t="ekr.20080121105837.1364"><vh>addConstant</vh></v>
<v t="ekr.20080121105837.1365"><vh>_getArgumentsFromPos</vh></v>
<v t="ekr.20080121105837.1366"><vh>_getIdentifiersFromPos</vh></v>
<v t="ekr.20080121105837.1367"><vh>_skipPastParenArguments</vh></v>
<v t="ekr.20080121105837.1368"><vh>_getVariableType</vh></v>
<v t="ekr.20080121105837.1369"><vh>_getKeywordArguments</vh></v>
<v t="ekr.20080121105837.1370"><vh>_getExtendsArgument</vh></v>
<v t="ekr.20080121105837.1371"><vh>_getImplementsArgument</vh></v>
<v t="ekr.20080121105837.1372"><vh>_unquoteString</vh></v>
<v t="ekr.20080121105837.1373"><vh>_removeDollarSymbolFromVariableName</vh></v>
<v t="ekr.20080121105837.1374"><vh>_getIncludePath</vh></v>
<v t="ekr.20080121105837.1375"><vh>_getConstantNameAndType</vh></v>
<v t="ekr.20080121105837.1376"><vh>_addAllVariables</vh></v>
<v t="ekr.20080121105837.1377"><vh>_variableHandler</vh></v>
<v t="ekr.20080121105837.1378"><vh>_addCodePiece</vh></v>
<v t="ekr.20080121105837.1379"><vh>_resetState</vh></v>
<v t="ekr.20080121105837.1380"><vh>token_next</vh></v>
<v t="ekr.20080121105837.1381"><vh>scan_multilang_content</vh></v>
<v t="ekr.20080121105837.1382"><vh>convertToElementTreeFile</vh></v>
<v t="ekr.20080121105837.1383"><vh>convertToElementTreeModule</vh></v>
</v>
<v t="ekr.20080121105837.1384"><vh>_isident</vh></v>
<v t="ekr.20080121105837.1385"><vh>_isdigit</vh></v>
<v t="ekr.20080121105837.1386"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1423"><vh>lang_rhtml.py</vh>
<v t="ekr.20080121105837.1424"><vh>lang_rhtml declarations</vh></v>
<v t="ekr.20080121105837.1425"><vh>class RHTMLLexer</vh></v>
<v t="ekr.20080121105837.1426"><vh>class RHTMLBuffer</vh>
<v t="ekr.20080121105837.1427"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1428"><vh>class RHTMLCILEDriver</vh></v>
<v t="ekr.20080121105837.1429"><vh>_isident</vh></v>
<v t="ekr.20080121105837.1430"><vh>_isdigit</vh></v>
<v t="ekr.20080121105837.1431"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1432"><vh>lang_ruby.py (error)</vh>
<v t="ekr.20080121105837.1433"><vh>lang_ruby declarations</vh></v>
<v t="ekr.20080121105837.1434"><vh>class RubyLexer</vh>
<v t="ekr.20080121105837.1435"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1436"><vh>class RubyCitadelEvaluator</vh>
<v t="ekr.20080121105837.1437"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1438"><vh>post_process_calltips</vh></v>
<v t="ekr.20080121105837.1439"><vh>post_process_cplns</vh></v>
</v>
<v t="ekr.20080121105837.1440"><vh>class RubyImportsEvaluator</vh>
<v t="ekr.20080121105837.1441"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1442"><vh>__str__</vh></v>
<v t="ekr.20080121105837.1443"><vh>eval</vh></v>
</v>
<v t="ekr.20080121105837.1444"><vh>class RubyBuffer</vh>
<v t="ekr.20080121105837.1445"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1446"><vh>libs</vh></v>
</v>
<v t="ekr.20080121105837.1447"><vh>class _CommonStyleClassifier</vh>
<v t="ekr.20080121105837.1448"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1449"><vh>ignore_styles</vh></v>
</v>
<v t="ekr.20080121105837.1450"><vh>class _RubyStyleClassifier</vh>
<v t="ekr.20080121105837.1451"><vh>is_ruby_style_at_pos</vh></v>
<v t="ekr.20080121105837.1452"><vh>is_identifier_or_word_style</vh></v>
<v t="ekr.20080121105837.1453"><vh>is_identifier_style</vh></v>
<v t="ekr.20080121105837.1454"><vh>is_operator_style</vh></v>
<v t="ekr.20080121105837.1455"><vh>is_default_style</vh></v>
<v t="ekr.20080121105837.1456"><vh>__getattr__</vh></v>
</v>
<v t="ekr.20080121105837.1457"><vh>class _UDLStyleClassifier</vh>
<v t="ekr.20080121105837.1458"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1459"><vh>is_ruby_style_at_pos</vh></v>
<v t="ekr.20080121105837.1460"><vh>implicit_completion_skip_styles</vh></v>
<v t="ekr.20080121105837.1461"><vh>completion_skip_styles</vh></v>
<v t="ekr.20080121105837.1462"><vh>is_identifier_or_word_style</vh></v>
<v t="ekr.20080121105837.1463"><vh>is_identifier_style</vh></v>
<v t="ekr.20080121105837.1464"><vh>is_operator_style</vh></v>
<v t="ekr.20080121105837.1465"><vh>comment_styles</vh></v>
<v t="ekr.20080121105837.1466"><vh>number_styles</vh></v>
<v t="ekr.20080121105837.1467"><vh>string_styles</vh></v>
<v t="ekr.20080121105837.1468"><vh>is_default_style</vh></v>
</v>
<v t="ekr.20080121105837.1469"><vh>class RubyLangIntel</vh>
<v t="ekr.20080121105837.1470"><vh>libs_from_buf</vh></v>
<v t="ekr.20080121105837.1471"><vh>_ruby_from_env</vh></v>
<v t="ekr.20080121105837.1472"><vh>_ruby_info_from_ruby</vh></v>
<v t="ekr.20080121105837.1473"><vh>_extra_dirs_from_env</vh></v>
<v t="ekr.20080121105837.1474"><vh>_buf_indep_libs_from_env</vh></v>
<v t="ekr.20080121105837.1475"><vh>_invalidate_cache</vh></v>
<v t="ekr.20080121105837.1476"><vh>_invalidate_cache_and_rescan_extra_dirs</vh></v>
<v t="ekr.20080121105837.1477"><vh>_get_prev_token_skip_ws</vh></v>
<v t="ekr.20080121105837.1478"><vh>_get_token_before_namelist</vh></v>
<v t="ekr.20080121105837.1479"><vh>_is_completable_name</vh></v>
<v t="ekr.20080121105837.1480"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1481"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1482"><vh>citdl_expr_from_trg</vh></v>
<v t="ekr.20080121105837.1483"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1484"><vh>cb_import_data_from_elem</vh></v>
<v t="ekr.20080121105837.1485"><vh>calltip_verify_termination</vh></v>
</v>
<v t="ekr.20080121105837.1486"><vh>class RubyImportHandler</vh>
<v t="ekr.20080121105837.1487"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1488"><vh>_shellOutForPath</vh></v>
<v t="ekr.20080121105837.1489"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1490"><vh>findModule</vh></v>
<v t="ekr.20080121105837.1491"><vh>findModuleOnDisk</vh></v>
<v t="ekr.20080121105837.1492"><vh>findSubImportsOnDisk</vh></v>
<v t="ekr.20080121105837.1493"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1494"><vh>genScannableFiles</vh></v>
<v t="ekr.20080121105837.1495"><vh>find_importables_in_dir</vh></v>
</v>
<v t="ekr.20080121105837.1496"><vh>_blob_scope_from_codeintel_tree</vh></v>
<v t="ekr.20080121105837.1497"><vh>class RubyCILEDriver</vh>
<v t="ekr.20080121105837.1498"><vh>scan</vh></v>
<v t="ekr.20080121105837.1499"><vh>scan_purelang</vh></v>
<v t="ekr.20080121105837.1500"><vh>scan_multilang</vh></v>
</v>
<v t="ekr.20080121105837.1501"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1502"><vh>lang_ruby_common.py</vh>
<v t="ekr.20080121105837.1503"><vh>lang_ruby_common declarations</vh></v>
<v t="ekr.20080121105837.1504"><vh>class RubyCommonBufferMixin</vh>
<v t="ekr.20080121105837.1505"><vh>check_for_rails_app_path</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1506"><vh>lang_smarty.py</vh>
<v t="ekr.20080121105837.1507"><vh>lang_smarty declarations</vh></v>
<v t="ekr.20080121105837.1508"><vh>class SmartyLexer</vh></v>
<v t="ekr.20080121105837.1509"><vh>class SmartyBuffer</vh></v>
<v t="ekr.20080121105837.1510"><vh>class SmartyCILEDriver</vh></v>
<v t="ekr.20080121105837.1511"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1512"><vh>lang_tcl.py</vh>
<v t="ekr.20080121105837.1513"><vh>lang_tcl declarations</vh></v>
<v t="ekr.20080121105837.1514"><vh>class TclLexer</vh>
<v t="ekr.20080121105837.1515"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1516"><vh>class TclBuffer</vh></v>
<v t="ekr.20080121105837.1517"><vh>class TclLangIntel</vh>
<v t="ekr.20080121105837.1518"><vh>cb_import_data_from_elem</vh></v>
</v>
<v t="ekr.20080121105837.1519"><vh>class TclImportHandler</vh>
<v t="ekr.20080121105837.1520"><vh>_shellOutForPath</vh></v>
<v t="ekr.20080121105837.1521"><vh>setCorePath</vh></v>
<v t="ekr.20080121105837.1522"><vh>_findScannableFiles</vh></v>
<v t="ekr.20080121105837.1523"><vh>genScannableFiles</vh></v>
</v>
<v t="ekr.20080121105837.1524"><vh>class TclCILEDriverOld</vh>
<v t="ekr.20080121105837.1525"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1526"><vh>scan</vh></v>
<v t="ekr.20080121105837.1527"><vh>scan_purelang</vh></v>
</v>
<v t="ekr.20080121105837.1528"><vh>class TclCILEDriverNew</vh>
<v t="ekr.20080121105837.1529"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1530"><vh>scan</vh></v>
<v t="ekr.20080121105837.1531"><vh>scan_purelang</vh></v>
</v>
<v t="ekr.20080121105837.1532"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1533"><vh>lang_templatetoolkit.py</vh>
<v t="ekr.20080121105837.1534"><vh>lang_templatetoolkit declarations</vh></v>
<v t="ekr.20080121105837.1535"><vh>class TemplateToolkitLexer</vh></v>
<v t="ekr.20080121105837.1536"><vh>class TemplateToolkitBuffer</vh></v>
<v t="ekr.20080121105837.1537"><vh>class TemplateToolkitCILEDriver</vh></v>
<v t="ekr.20080121105837.1538"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1539"><vh>lang_xbl.py</vh>
<v t="ekr.20080121105837.1540"><vh>lang_xbl declarations</vh></v>
<v t="ekr.20080121105837.1541"><vh>class XBLLexer</vh></v>
<v t="ekr.20080121105837.1542"><vh>class XBLBuffer</vh></v>
<v t="ekr.20080121105837.1543"><vh>class XBLCILEDriver</vh></v>
<v t="ekr.20080121105837.1544"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1545"><vh>lang_xml.py (error)</vh>
<v t="ekr.20080121105837.1546"><vh>lang_xml declarations</vh></v>
<v t="ekr.20080121105837.1547"><vh>class XMLLexer</vh></v>
<v t="ekr.20080121105837.1548"><vh>class XMLLangIntel</vh>
<v t="ekr.20080121105837.1549"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1550"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1551"><vh>async_eval_at_trg</vh></v>
</v>
<v t="ekr.20080121105837.1552"><vh>class XMLBuffer</vh></v>
<v t="ekr.20080121105837.1553"><vh>register</vh></v>
<v t="ekr.20080121105837.1554"><vh>getTreeForDocument</vh></v>
<v t="ekr.20080121105837.1555"><vh>getNodeForPosition</vh></v>
<v t="ekr.20080121105837.1556"><vh>getDefaultCompletion</vh></v>
<v t="ekr.20080121105837.1557"><vh>getValidTagNames</vh></v>
<v t="ekr.20080121105837.1558"><vh>getValidAttributes</vh></v>
<v t="ekr.20080121105837.1559"><vh>getValidAttributeValues</vh></v>
<v t="ekr.20080121105837.1560"><vh>_StartTagNameAutoComplete</vh></v>
<v t="ekr.20080121105837.1561"><vh>_StartLocalTagNameAutoComplete</vh></v>
<v t="ekr.20080121105837.1562"><vh>_EndTagAutoComplete</vh></v>
<v t="ekr.20080121105837.1563"><vh>_StartAttrValueAutoComplete</vh></v>
<v t="ekr.20080121105837.1564"><vh>_StartAttrAutoComplete</vh></v>
</v>
<v t="ekr.20080121105837.1565"><vh>lang_xslt.py</vh>
<v t="ekr.20080121105837.1566"><vh>lang_xslt declarations</vh></v>
<v t="ekr.20080121105837.1567"><vh>class XSLTLexer</vh></v>
<v t="ekr.20080121105837.1568"><vh>class XSLTBuffer</vh></v>
<v t="ekr.20080121105837.1569"><vh>register</vh></v>
</v>
<v t="ekr.20080121105837.1570"><vh>lang_xul.py</vh>
<v t="ekr.20080121105837.1571"><vh>lang_xul declarations</vh></v>
<v t="ekr.20080121105837.1572"><vh>class XULLexer</vh></v>
<v t="ekr.20080121105837.1573"><vh>class XULBuffer</vh></v>
<v t="ekr.20080121105837.1574"><vh>class XULCILEDriver</vh></v>
<v t="ekr.20080121105837.1575"><vh>register</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1576"><vh>udl.py (user defined language)</vh>
<v t="ekr.20080121105837.1577"><vh>udl declarations</vh></v>
<v t="ekr.20080121105837.1578"><vh>is_udl_m_style</vh></v>
<v t="ekr.20080121105837.1579"><vh>is_udl_css_style</vh></v>
<v t="ekr.20080121105837.1580"><vh>is_udl_csl_style</vh></v>
<v t="ekr.20080121105837.1581"><vh>is_udl_ssl_style</vh></v>
<v t="ekr.20080121105837.1582"><vh>is_udl_tpl_style</vh></v>
<v t="ekr.20080121105837.1583"><vh>_lexudl_path_escape</vh></v>
<v t="ekr.20080121105837.1584"><vh>_urlescape</vh></v>
<v t="ekr.20080121105837.1585"><vh>class UDLLexer</vh>
<v t="ekr.20080121105837.1586"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1587"><vh>class UDLBuffer</vh>
<v t="ekr.20080121105837.1588"><vh>lang_from_style</vh></v>
<v t="ekr.20080121105837.1589"><vh>lang_from_pos</vh></v>
<v t="ekr.20080121105837.1590"><vh>scoperef_from_pos</vh></v>
<v t="ekr.20080121105837.1591"><vh>trg_from_pos</vh></v>
<v t="ekr.20080121105837.1592"><vh>preceding_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1593"><vh>curr_calltip_arg_range</vh></v>
<v t="ekr.20080121105837.1594"><vh>async_eval_at_trg</vh></v>
<v t="ekr.20080121105837.1595"><vh>defn_trg_from_pos</vh></v>
<v t="ekr.20080121105837.1596"><vh>libs</vh></v>
<v t="ekr.20080121105837.1597"><vh>style_names_from_style_num</vh></v>
<v t="ekr.20080121105837.1598"><vh>string_styles</vh></v>
<v t="ekr.20080121105837.1599"><vh>comment_styles</vh></v>
<v t="ekr.20080121105837.1600"><vh>number_styles</vh></v>
</v>
<v t="ekr.20080121105837.1601"><vh>class XMLParsingBufferMixin</vh>
<v t="ekr.20080121105837.1602"><vh>xml_tree</vh></v>
<v t="ekr.20080121105837.1603"><vh>xml_parse</vh></v>
</v>
<v t="ekr.20080121105837.1604"><vh>class _NotYetSet</vh></v>
<v t="ekr.20080121105837.1605"><vh>class UDLCILEDriver</vh>
<v t="ekr.20080121105837.1606"><vh>master_cile_driver</vh></v>
<v t="ekr.20080121105837.1607"><vh>scan_purelang</vh></v>
</v>
</v>
</v>
</v>
<v t="ekr.20080121105837.1608"><vh>manager.py</vh>
<v t="ekr.20080121105837.1609"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1610"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1611"><vh>upgrade</vh></v>
<v t="ekr.20080121105837.1612"><vh>initialize</vh></v>
<v t="ekr.20080121105837.1613"><vh>register_langs</vh></v>
<v t="ekr.20080121105837.1614"><vh>register_lang</vh></v>
<v t="ekr.20080121105837.1615"><vh>set_lang_info</vh></v>
<v t="ekr.20080121105837.1616"><vh>finalize</vh></v>
<v t="ekr.20080121105837.1617"><vh>batch_update</vh></v>
<v t="ekr.20080121105837.1618"><vh>is_registered_lang</vh></v>
<v t="ekr.20080121105837.1619"><vh>is_multilang</vh></v>
<v t="ekr.20080121105837.1620"><vh>is_xml_lang</vh></v>
<v t="ekr.20080121105837.1621"><vh>is_cpln_lang</vh></v>
<v t="ekr.20080121105837.1622"><vh>get_cpln_langs</vh></v>
<v t="ekr.20080121105837.1623"><vh>is_citadel_lang</vh></v>
<v t="ekr.20080121105837.1624"><vh>get_citadel_langs</vh></v>
<v t="ekr.20080121105837.1625"><vh>langintel_from_lang</vh></v>
<v t="ekr.20080121105837.1626"><vh>buf_from_koIDocument</vh></v>
<v t="ekr.20080121105837.1627"><vh>buf_from_content</vh></v>
<v t="ekr.20080121105837.1628"><vh>buf_from_path</vh></v>
<v t="ekr.20080121105837.1629"><vh>request_eval</vh></v>
<v t="ekr.20080121105837.1630"><vh>request_reeval</vh></v>
<v t="ekr.20080121105837.1631"><vh>stop</vh></v>
<v t="ekr.20080121105837.1632"><vh>run</vh></v>
<v t="ekr.20080121105837.1633"><vh>_handle_eval_sess</vh></v>
<v t="ekr.20080121105837.1634"><vh>_put</vh></v>
<v t="ekr.20080121105837.1635"><vh>_get</vh></v>
</v>
<v t="ekr.20080121105837.1636"><vh>parser_cix.py</vh>
<v t="ekr.20080121105837.1637"><vh>parser_cix declarations</vh></v>
<v t="ekr.20080121105837.1638"><vh>get_common_attrs</vh></v>
<v t="ekr.20080121105837.1639"><vh>sort_by_lines</vh></v>
<v t="ekr.20080121105837.1640"><vh>get_arguments_cix</vh></v>
<v t="ekr.20080121105837.1641"><vh>get_docstring_cix</vh></v>
<v t="ekr.20080121105837.1642"><vh>get_imports_cix</vh></v>
<v t="ekr.20080121105837.1643"><vh>get_includes_cix</vh></v>
<v t="ekr.20080121105837.1644"><vh>get_signature_cix</vh></v>
<v t="ekr.20080121105837.1645"><vh>get_var_cix</vh></v>
<v t="ekr.20080121105837.1646"><vh>_local_varname_test</vh></v>
<v t="ekr.20080121105837.1647"><vh>_local_varname_test_true</vh></v>
<v t="ekr.20080121105837.1648"><vh>_get_vars_helper</vh></v>
<v t="ekr.20080121105837.1649"><vh>get_globals_cix</vh></v>
<v t="ekr.20080121105837.1650"><vh>get_vars_cix</vh></v>
<v t="ekr.20080121105837.1651"><vh>common_module_class_cix</vh></v>
<v t="ekr.20080121105837.1652"><vh>classref_etree_cix</vh></v>
<v t="ekr.20080121105837.1653"><vh>class_etree_cix</vh></v>
<v t="ekr.20080121105837.1654"><vh>method_etree_cix</vh></v>
<v t="ekr.20080121105837.1655"><vh>module_etree_cix</vh></v>
<v t="ekr.20080121105837.1656"><vh>visit_children_get_cix</vh></v>
<v t="ekr.20080121105837.1657"><vh>produce_elementTree_cix</vh></v>
<v t="ekr.20080121105837.1658"><vh>produce_elementTree_contents_cix</vh></v>
</v>
<v t="ekr.20080121105837.1659"><vh>parser_data.py</vh>
<v t="ekr.20080121105837.1660"><vh>parser_data declarations</vh></v>
<v t="ekr.20080121105837.1661"><vh>class Name_LineNum</vh>
<v t="ekr.20080121105837.1662"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1663"><vh>class VarInfo</vh>
<v t="ekr.20080121105837.1664"><vh>__init__</vh></v>
</v>
<v t="ekr.20080121105837.1665"><vh>update_collection</vh></v>
<v t="ekr.20080121105837.1666"><vh>class Node</vh>
<v t="ekr.20080121105837.1667"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1668"><vh>append_node</vh></v>
<v t="ekr.20080121105837.1669"><vh>set_line_end_num</vh></v>
<v t="ekr.20080121105837.1670"><vh>dump_kids</vh></v>
<v t="ekr.20080121105837.1671"><vh>dump2</vh></v>
<v t="ekr.20080121105837.1672"><vh>dump_collection</vh></v>
</v>
<v t="ekr.20080121105837.1673"><vh>class ClassNode</vh>
<v t="ekr.20080121105837.1674"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1675"><vh>add_classrefs</vh></v>
<v t="ekr.20080121105837.1676"><vh>has_classref</vh></v>
<v t="ekr.20080121105837.1677"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.1678"><vh>class FileNode</vh>
<v t="ekr.20080121105837.1679"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1680"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.1681"><vh>class ArgNode</vh>
<v t="ekr.20080121105837.1682"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1683"><vh>get_full_name</vh></v>
</v>
<v t="ekr.20080121105837.1684"><vh>class MethodNode</vh>
<v t="ekr.20080121105837.1685"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1686"><vh>add_arg</vh></v>
<v t="ekr.20080121105837.1687"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.1688"><vh>class ModuleNode</vh>
<v t="ekr.20080121105837.1689"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1690"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.1691"><vh>class VariableNode</vh>
<v t="ekr.20080121105837.1692"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1693"><vh>dump</vh></v>
</v>
<v t="ekr.20080121105837.1694"><vh>class BlockNode</vh>
<v t="ekr.20080121105837.1695"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1696"><vh>dump</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1697"><vh>parseutil.py</vh>
<v t="ekr.20080121105837.1698"><vh>parseutil declarations</vh></v>
<v t="ekr.20080121105837.1699"><vh>tryEncoding</vh></v>
<v t="ekr.20080121105837.1700"><vh>getEncodedBuffer</vh></v>
<v t="ekr.20080121105837.1701"><vh>getAttrStr</vh></v>
<v t="ekr.20080121105837.1702"><vh>xmlencode</vh></v>
<v t="ekr.20080121105837.1703"><vh>cdataescape</vh></v>
<v t="ekr.20080121105837.1704"><vh>urlencode_path</vh></v>
<v t="ekr.20080121105837.1705"><vh>uncommentDocString</vh></v>
<v t="ekr.20080121105837.1706"><vh>parseDocString</vh></v>
<v t="ekr.20080121105837.1707"><vh>class recollector</vh>
<v t="ekr.20080121105837.1708"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1709"><vh>add</vh></v>
</v>
<v t="ekr.20080121105837.1710"><vh>class Lexer</vh>
<v t="ekr.20080121105837.1711"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1712"><vh>nexttok</vh></v>
<v t="ekr.20080121105837.1713"><vh>settext</vh></v>
<v t="ekr.20080121105837.1714"><vh>addmatch</vh></v>
<v t="ekr.20080121105837.1715"><vh>scan</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1716"><vh>tree.py (Important)</vh>
<v t="ekr.20080121105837.1717"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1718"><vh>tree_2_0_from_tree_0_1</vh></v>
<v t="ekr.20080121105837.1719"><vh>tree_from_cix_path</vh></v>
<v t="ekr.20080121105837.1720"><vh>tree_from_cix</vh></v>
<v t="ekr.20080121105837.1721"><vh>pretty_tree_from_tree</vh></v>
<v t="ekr.20080121105837.1722"><vh>check_tree</vh></v>
<v t="ekr.20080121105837.1723"><vh>class TreeEvaluator</vh>
<v t="ekr.20080121105837.1724"><vh>get_start_scoperef</vh></v>
<v t="ekr.20080121105837.1725"><vh>eval</vh></v>
<v t="ekr.20080121105837.1726"><vh>scope_stack_from_tree_and_linenum</vh></v>
<v t="ekr.20080121105837.1727"><vh>_tokenize_citdl_expr</vh></v>
<v t="ekr.20080121105837.1728"><vh>_join_citdl_expr</vh></v>
<v t="ekr.20080121105837.1729"><vh>str_elem</vh></v>
<v t="ekr.20080121105837.1730"><vh>str_elem_and_children</vh></v>
<v t="ekr.20080121105837.1731"><vh>str_import</vh></v>
<v t="ekr.20080121105837.1732"><vh>log_start</vh></v>
<v t="ekr.20080121105837.1733"><vh>log</vh></v>
<v t="ekr.20080121105837.1734"><vh>pre_eval</vh></v>
<v t="ekr.20080121105837.1735"><vh>_eval_citdl_expr</vh></v>
<v t="ekr.20080121105837.1736"><vh>_resolve_import</vh></v>
<v t="ekr.20080121105837.1737"><vh>_eval_import</vh></v>
<v t="ekr.20080121105837.1738"><vh>_eval_citdl_token</vh></v>
<v t="ekr.20080121105837.1739"><vh>_defn_from_hit</vh></v>
<v t="ekr.20080121105837.1740"><vh>_check_infinite_recursion</vh></v>
</v>
<v t="ekr.20080121105837.1741"><vh>_dump_element</vh></v>
</v>
<v t="ekr.20080121105837.1742"><vh>util.py</vh>
<v t="ekr.20080121105837.1743"><vh>util declarations</vh></v>
<v t="ekr.20080121105837.1744"><vh>isident</vh></v>
<v t="ekr.20080121105837.1745"><vh>isdigit</vh></v>
<v t="ekr.20080121105837.1746"><vh>safe_lang_from_lang</vh></v>
<v t="ekr.20080121105837.1747"><vh>guess_lang_from_path</vh></v>
<v t="ekr.20080121105837.1748"><vh>gen_dirs_under_dirs</vh></v>
<v t="ekr.20080121105837.1749"><vh>parseDocSummary</vh></v>
<v t="ekr.20080121105837.1750"><vh>parsePyFuncDoc</vh></v>
<v t="ekr.20080121105837.1751"><vh>unmark_text</vh></v>
<v t="ekr.20080121105837.1752"><vh>markup_text</vh></v>
<v t="ekr.20080121105837.1753"><vh>banner</vh></v>
<v t="ekr.20080121105837.1754"><vh>_dedentlines</vh></v>
<v t="ekr.20080121105837.1755"><vh>dedent</vh></v>
<v t="ekr.20080121105837.1756"><vh>indent</vh></v>
<v t="ekr.20080121105837.1757"><vh>timeit</vh></v>
<v t="ekr.20080121105837.1758"><vh>hotshotit</vh></v>
<v t="ekr.20080121105837.1759"><vh>OrdPunctLast</vh></v>
<v t="ekr.20080121105837.1760"><vh>CompareNPunctLast</vh></v>
<v t="ekr.20080121105837.1761"><vh>make_short_name_dict</vh></v>
<v t="ekr.20080121105837.1762"><vh>cachedmethod</vh></v>
<v t="ekr.20080121105837.1763"><vh>class Memoize</vh>
<v t="ekr.20080121105837.1764"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1765"><vh>__call__</vh></v>
<v t="ekr.20080121105837.1766"><vh>_getKey</vh></v>
</v>
</v>
<v t="ekr.20080121105837.1767"><vh>__init__.py (codeintel2)</vh></v>
</v>
<v t="ekr.20080121105837.1768"><vh>codeintel2/database</vh>
<v t="ekr.20080121121728.9"><vh> __init__.py (database)</vh></v>
<v t="ekr.20080121121728.1"><vh>catalog.py</vh>
<v t="ekr.20080121121842"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121121842.1"><vh>class CatalogsZone</vh>
<v t="ekr.20080121121842.2"><vh>__init__</vh></v>
<v t="ekr.20080121121842.3"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.4"><vh>_selection_from_selector</vh></v>
<v t="ekr.20080121121842.5"><vh>_res_ids_from_selections</vh></v>
<v t="ekr.20080121121842.6"><vh>get_lib</vh></v>
<v t="ekr.20080121121842.7"><vh>res_index</vh></v>
<v t="ekr.20080121121842.8"><vh>blob_index</vh></v>
<v t="ekr.20080121121842.9"><vh>toplevelname_index</vh></v>
<v t="ekr.20080121121842.10"><vh>toplevelprefix_index</vh></v>
<v t="ekr.20080121121842.11"><vh>save</vh></v>
<v t="ekr.20080121121842.12"><vh>cull_mem</vh></v>
<v t="ekr.20080121121842.13"><vh>avail_catalogs</vh></v>
<v t="ekr.20080121121842.14"><vh>update</vh></v>
<v t="ekr.20080121121842.15"><vh>_new_res_id</vh></v>
<v t="ekr.20080121121842.16"><vh>_remove_res</vh></v>
<v t="ekr.20080121121842.17"><vh>_add_res</vh></v>
<v t="ekr.20080121121842.18"><vh>res_id_from_lang_and_blobname</vh></v>
<v t="ekr.20080121121842.19"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.20"><vh>lpaths_from_lang_and_blobname</vh></v>
</v>
<v t="ekr.20080121121842.21"><vh>class CatalogLib</vh>
<v t="ekr.20080121121842.22"><vh>__init__</vh></v>
<v t="ekr.20080121121842.23"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.24"><vh>import_handler</vh></v>
<v t="ekr.20080121121842.25"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.26"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.27"><vh>get_blob_imports</vh></v>
<v t="ekr.20080121121842.28"><vh>_blobnames_from_toplevelname</vh></v>
<v t="ekr.20080121121842.29"><vh>hits_from_lpath</vh></v>
<v t="ekr.20080121121842.30"><vh>toplevel_cplns</vh></v>
</v>
<v t="ekr.20080121121842.31"><vh>_elem_from_scoperef</vh></v>
</v>
<v t="ekr.20080121105837.1769"><vh>database.py (Important)</vh>
<v t="ekr.20080121105837.1770"><vh>&lt;&lt; database.py docstring &gt;&gt; (important)</vh></v>
<v t="ekr.20080121105837.1771"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1772"><vh>&lt;&lt; version stuff &gt;&gt;</vh></v>
<v t="ekr.20080121105837.1773"><vh>__init__</vh></v>
<v t="ekr.20080121105837.1774"><vh>__del__</vh></v>
<v t="ekr.20080121105837.1775"><vh>Locks</vh>
<v t="ekr.20080121105837.1776"><vh>acquire_lock</vh></v>
<v t="ekr.20080121105837.1777"><vh>release_lock</vh></v>
</v>
<v t="ekr.20080121105837.1778"><vh>version</vh></v>
<v t="ekr.20080121105837.1779"><vh>upgrade_info</vh></v>
<v t="ekr.20080121105837.1780"><vh>create</vh></v>
<v t="ekr.20080121105837.1781"><vh>reset</vh></v>
<v t="ekr.20080121105837.1782"><vh>upgrade &amp; helpers</vh>
<v t="ekr.20080121105837.1783"><vh>_upgrade_wipe_db</vh></v>
<v t="ekr.20080121105837.1784"><vh>_upgrade_wipe_db_catalogs</vh></v>
<v t="ekr.20080121105837.1785"><vh>_upgrade_wipe_db_langzones</vh></v>
<v t="ekr.20080121105837.1786"><vh>_upgrade_wipe_db_langs</vh></v>
</v>
<v t="ekr.20080121105837.1787"><vh>report_event</vh></v>
<v t="ekr.20080121105837.1788"><vh>save</vh></v>
<v t="ekr.20080121105837.1789"><vh>cull_mem</vh></v>
<v t="ekr.20080121105837.1790"><vh>_gen_langs_in_db</vh></v>
<v t="ekr.20080121105837.1791"><vh>check &amp; helpers</vh>
<v t="ekr.20080121105837.1792"><vh>_check_catalogszone</vh></v>
<v t="ekr.20080121105837.1793"><vh>_check_proj_dir</vh></v>
<v t="ekr.20080121105837.1794"><vh>_check_langzone</vh></v>
<v t="ekr.20080121105837.1795"><vh>_check_multilangzone</vh></v>
</v>
<v t="ekr.20080121105837.1796"><vh>corruption</vh></v>
<v t="ekr.20080121105837.1797"><vh>get_catalogs_zone</vh></v>
<v t="ekr.20080121105837.1798"><vh>get_catalog_lib</vh></v>
<v t="ekr.20080121105837.1799"><vh>get_stdlibs_zone</vh></v>
<v t="ekr.20080121105837.1800"><vh>get_stdlib</vh></v>
<v t="ekr.20080121105837.1801"><vh>_get_lang_zone</vh></v>
<v t="ekr.20080121105837.1802"><vh>get_lang_lib</vh></v>
<v t="ekr.20080121105837.1803"><vh>get_proj_zone</vh></v>
<v t="ekr.20080121105837.1804"><vh>get_proj_lib</vh></v>
<v t="ekr.20080121105837.1805"><vh>load_blob</vh></v>
<v t="ekr.20080121105837.1806"><vh>load_pickle</vh></v>
<v t="ekr.20080121105837.1807"><vh>save_pickle</vh></v>
<v t="ekr.20080121105837.1808"><vh>Convenience methods</vh>
<v t="ekr.20080121105837.1809"><vh>bhash_from_blob_info</vh></v>
<v t="ekr.20080121105837.1810"><vh>dhash_from_dir</vh></v>
<v t="ekr.20080121105837.1811"><vh>get_buf_scan_time</vh></v>
<v t="ekr.20080121105837.1812"><vh>get_buf_data</vh></v>
<v t="ekr.20080121105837.1813"><vh>remove_buf_data</vh></v>
<v t="ekr.20080121105837.1814"><vh>update_buf_data</vh></v>
</v>
</v>
<v t="ekr.20080121121728.3"><vh>langlib.py</vh>
<v t="ekr.20080121121842.32"><vh>langlib declarations</vh></v>
<v t="ekr.20080121121842.33"><vh>class LangDirsLib</vh>
<v t="ekr.20080121121842.34"><vh>__init__</vh></v>
<v t="ekr.20080121121842.35"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.36"><vh>_acquire_lock</vh></v>
<v t="ekr.20080121121842.37"><vh>_release_lock</vh></v>
<v t="ekr.20080121121842.38"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.39"><vh>has_blob_in_db</vh></v>
<v t="ekr.20080121121842.40"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.41"><vh>get_blob_imports</vh></v>
<v t="ekr.20080121121842.42"><vh>hits_from_lpath</vh></v>
<v t="ekr.20080121121842.43"><vh>toplevel_cplns</vh></v>
<v t="ekr.20080121121842.44"><vh>ensure_dir_scanned</vh></v>
<v t="ekr.20080121121842.45"><vh>_importables_from_dir</vh></v>
<v t="ekr.20080121121842.46"><vh>_dbsubpath_from_blobname</vh></v>
</v>
<v t="ekr.20080121121842.47"><vh>class LangTopLevelNameIndex</vh>
<v t="ekr.20080121121842.48"><vh>__init__</vh></v>
<v t="ekr.20080121121842.49"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.50"><vh>merge</vh></v>
<v t="ekr.20080121121842.51"><vh>merge_expired</vh></v>
<v t="ekr.20080121121842.52"><vh>data</vh></v>
<v t="ekr.20080121121842.53"><vh>update</vh></v>
<v t="ekr.20080121121842.54"><vh>remove</vh></v>
<v t="ekr.20080121121842.55"><vh>_pivot_res_data</vh></v>
<v t="ekr.20080121121842.56"><vh>toplevel_cplns</vh></v>
<v t="ekr.20080121121842.57"><vh>get_blobnames</vh></v>
</v>
<v t="ekr.20080121121842.58"><vh>class LangZone</vh>
<v t="ekr.20080121121842.59"><vh>__init__</vh></v>
<v t="ekr.20080121121842.60"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.61"><vh>__del__</vh></v>
<v t="ekr.20080121121842.62"><vh>_acquire_lock</vh></v>
<v t="ekr.20080121121842.63"><vh>_release_lock</vh></v>
<v t="ekr.20080121121842.64"><vh>_check_lang</vh></v>
<v t="ekr.20080121121842.65"><vh>dhash_from_dir</vh></v>
<v t="ekr.20080121121842.66"><vh>dfb_from_dir</vh></v>
<v t="ekr.20080121121842.67"><vh>get_buf_scan_time</vh></v>
<v t="ekr.20080121121842.68"><vh>get_buf_data</vh></v>
<v t="ekr.20080121121842.69"><vh>remove_buf_data</vh></v>
<v t="ekr.20080121121842.70"><vh>update_buf_data</vh></v>
<v t="ekr.20080121121842.71"><vh>_mk_zone_skel</vh></v>
<v t="ekr.20080121121842.72"><vh>_mk_dbdir</vh></v>
<v t="ekr.20080121121842.73"><vh>load_blob</vh></v>
<v t="ekr.20080121121842.74"><vh>load_index</vh></v>
<v t="ekr.20080121121842.75"><vh>changed_index</vh></v>
<v t="ekr.20080121121842.76"><vh>save_index</vh></v>
<v t="ekr.20080121121842.77"><vh>save</vh></v>
<v t="ekr.20080121121842.78"><vh>cull_mem</vh></v>
<v t="ekr.20080121121842.79"><vh>get_lib</vh></v>
</v>
</v>
<v t="ekr.20080121121728.4"><vh>multilanglib.py</vh>
<v t="ekr.20080121121842.80"><vh>multilanglib declarations</vh></v>
<v t="ekr.20080121121842.81"><vh>class MultiLangTopLevelNameIndex</vh>
<v t="ekr.20080121121842.82"><vh>__init__</vh></v>
<v t="ekr.20080121121842.83"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.84"><vh>merge</vh></v>
<v t="ekr.20080121121842.85"><vh>merge_expired</vh></v>
<v t="ekr.20080121121842.86"><vh>data</vh></v>
<v t="ekr.20080121121842.87"><vh>update</vh></v>
<v t="ekr.20080121121842.88"><vh>remove</vh></v>
<v t="ekr.20080121121842.89"><vh>_pivot_res_data</vh></v>
<v t="ekr.20080121121842.90"><vh>toplevel_cplns</vh></v>
<v t="ekr.20080121121842.91"><vh>get_blobnames</vh></v>
</v>
<v t="ekr.20080121121842.92"><vh>class MultiLangZone</vh>
<v t="ekr.20080121121842.93"><vh>get_lib</vh></v>
<v t="ekr.20080121121842.94"><vh>dfb_from_dir</vh></v>
<v t="ekr.20080121121842.95"><vh>get_buf_data</vh></v>
<v t="ekr.20080121121842.96"><vh>remove_buf_data</vh></v>
<v t="ekr.20080121121842.97"><vh>update_buf_data</vh></v>
</v>
<v t="ekr.20080121121842.98"><vh>class MultiLangDirsLib</vh>
<v t="ekr.20080121121842.99"><vh>__init__</vh></v>
<v t="ekr.20080121121842.100"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.101"><vh>_acquire_lock</vh></v>
<v t="ekr.20080121121842.102"><vh>_release_lock</vh></v>
<v t="ekr.20080121121842.103"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.104"><vh>has_blob_in_db</vh></v>
<v t="ekr.20080121121842.105"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.106"><vh>hits_from_lpath</vh></v>
<v t="ekr.20080121121842.107"><vh>toplevel_cplns</vh></v>
<v t="ekr.20080121121842.108"><vh>ensure_dir_scanned</vh></v>
<v t="ekr.20080121121842.109"><vh>_importables_from_dir</vh></v>
<v t="ekr.20080121121842.110"><vh>_dbsubpath_from_blobname</vh></v>
</v>
</v>
<v t="ekr.20080121121728.5"><vh>projlib.py</vh>
<v t="ekr.20080121121842.111"><vh>projlib declarations</vh></v>
<v t="ekr.20080121121842.112"><vh>class ProjectZone</vh>
<v t="ekr.20080121121842.113"><vh>__init__</vh></v>
<v t="ekr.20080121121842.114"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.115"><vh>__del__</vh></v>
<v t="ekr.20080121121842.116"><vh>get_dirs_from_basename</vh></v>
<v t="ekr.20080121121842.117"><vh>set_dirs_from_basename</vh></v>
<v t="ekr.20080121121842.118"><vh>_mk_dbdir</vh></v>
<v t="ekr.20080121121842.119"><vh>save</vh></v>
<v t="ekr.20080121121842.120"><vh>update</vh></v>
<v t="ekr.20080121121842.121"><vh>_likely_filename_from_lang_and_blobname</vh></v>
<v t="ekr.20080121121842.122"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.123"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.124"><vh>_lang_lib_for_blob</vh></v>
<v t="ekr.20080121121842.125"><vh>get_lib</vh></v>
</v>
<v t="ekr.20080121121842.126"><vh>class ProjectLib</vh>
<v t="ekr.20080121121842.127"><vh>__init__</vh></v>
<v t="ekr.20080121121842.128"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.129"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.130"><vh>get_blob</vh></v>
</v>
</v>
<v t="ekr.20080121121728.6"><vh>resource.py</vh>
<v t="ekr.20080121121842.131"><vh>resource declarations</vh></v>
<v t="ekr.20080121121842.132"><vh>class Resource</vh>
<v t="ekr.20080121121842.133"><vh>__init__</vh></v>
<v t="ekr.20080121121842.134"><vh>canon_path</vh></v>
</v>
<v t="ekr.20080121121842.135"><vh>class AreaResource</vh>
<v t="ekr.20080121121842.136"><vh>area_and_subpath_from_path</vh></v>
<v t="ekr.20080121121842.137"><vh>__init__</vh></v>
<v t="ekr.20080121121842.138"><vh>__str__</vh></v>
<v t="ekr.20080121121842.139"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.140"><vh>area_path</vh></v>
<v t="ekr.20080121121842.141"><vh>path</vh></v>
</v>
</v>
<v t="ekr.20080121121728.7"><vh>stdlib.py</vh>
<v t="ekr.20080121121842.142"><vh>stdlib declarations</vh></v>
<v t="ekr.20080121121842.143"><vh>class StdLib</vh>
<v t="ekr.20080121121842.144"><vh>__init__</vh></v>
<v t="ekr.20080121121842.145"><vh>__repr__</vh></v>
<v t="ekr.20080121121842.146"><vh>import_handler</vh></v>
<v t="ekr.20080121121842.147"><vh>blob_index</vh></v>
<v t="ekr.20080121121842.148"><vh>toplevelname_index</vh></v>
<v t="ekr.20080121121842.149"><vh>toplevelprefix_index</vh></v>
<v t="ekr.20080121121842.150"><vh>has_blob</vh></v>
<v t="ekr.20080121121842.151"><vh>get_blob</vh></v>
<v t="ekr.20080121121842.152"><vh>get_blob_imports</vh></v>
<v t="ekr.20080121121842.153"><vh>hits_from_lpath</vh></v>
<v t="ekr.20080121121842.154"><vh>toplevel_cplns</vh></v>
</v>
<v t="ekr.20080121121842.155"><vh>class StdLibsZone</vh>
<v t="ekr.20080121121842.156"><vh>__init__</vh></v>
<v t="ekr.20080121121842.157"><vh>__del__</vh></v>
<v t="ekr.20080121121842.158"><vh>vers_and_names_from_lang</vh></v>
<v t="ekr.20080121121842.159"><vh>res_index</vh></v>
<v t="ekr.20080121121842.160"><vh>save</vh></v>
<v t="ekr.20080121121842.161"><vh>get_lib</vh></v>
<v t="ekr.20080121121842.162"><vh>_get_preload_zip</vh></v>
<v t="ekr.20080121121842.163"><vh>can_preload</vh></v>
<v t="ekr.20080121121842.164"><vh>preload</vh></v>
<v t="ekr.20080121121842.165"><vh>remove_lang</vh></v>
<v t="ekr.20080121121842.166"><vh>update_lang</vh></v>
<v t="ekr.20080121121842.167"><vh>_handle_res_todos</vh></v>
<v t="ekr.20080121121842.168"><vh>_remove_res</vh></v>
<v t="ekr.20080121121842.169"><vh>_add_res</vh></v>
</v>
<v t="ekr.20080121121842.170"><vh>_ver_from_ver_str</vh></v>
</v>
<v t="ekr.20080121121728.8"><vh>util.py</vh>
<v t="ekr.20080121121842.171"><vh>util declarations</vh></v>
<v t="ekr.20080121121842.172"><vh>filter_blobnames_for_prefix</vh></v>
<v t="ekr.20080121121842.173"><vh>rmdir</vh></v>
<v t="ekr.20080121121842.174"><vh>_rmtree_onerror</vh></v>
<v t="ekr.20080121121842.175"><vh>__run_log</vh></v>
<v t="ekr.20080121121842.176"><vh>run</vh></v>
<v t="ekr.20080121121842.177"><vh>run_in_dir</vh></v>
</v>
</v>
</v>
</v>
</v>
<v t="ekr.20080121143612" a="E"><vh>Komodo test script</vh>
<v t="ekr.20080121151821.1"><vh>&lt;&lt; imports &gt;&gt;</vh></v>
<v t="ekr.20080121142959.1"><vh>addKomodoPaths</vh></v>
<v t="ekr.20080121150435"><vh>openManager</vh></v>
<v t="ekr.20080121150435.1"><vh>openDatabase</vh></v>
</v>
</vnodes>
<tnodes>
<t tx="ekr.20080121105230.3"></t>
<t tx="ekr.20080121105800"># A script to create @auto nodes from all .py files in a directory.

import glob,os

reallyCreate = True

baseDir = r'c:\Python25\Lib\site-packages\pubsub'
baseDir = r'C:\Program Files\Komodo Edit 4.3\lib\mozilla\python\komodo\codeintel2'
baseDir = r'C:\Program Files\Komodo Edit 4.3\lib\mozilla\python\komodo\codeintel2\database'
baseDir = r'C:\Program Files\Komodo Edit 4.3\lib\sdk\pylib'
baseDir = r'C:\Program Files\Komodo Edit 4.3\lib\sdk\pylib\ludditelib'
dirs = ('',) #'Extensions','UserConfig',)
print '-----'

c.beginUpdate()
try:
    for theDir in dirs:
        pattern = g.os_path_join(baseDir,theDir,'*.py')
        files = glob.glob(pattern)
        print pattern
        # print g.listToString(files)
        for name in files:
            h = '@auto %s' % (name[len(baseDir) + 1:].strip())
            print 'creating',h
            if reallyCreate:
                child = p.insertAsLastChild()
                child.initHeadString(h)
finally:
    c.endUpdate()
</t>
<t tx="ekr.20080121105837"></t>
<t tx="ekr.20080121105837.1">@language rest

Most important files:

codeintel2/database/database.py
sdk/share/lang_LANG.py
</t>
<t tx="ekr.20080121105837.2">.rng files are used for validating .XML documents; uses a simple schema language
for XML that focuses on the description and validation of the structure and
content of an XML document.  Used by OpenOffice.org.

See http://www.fileinfo.net/extension/rng</t>
<t tx="ekr.20080121105837.3"></t>
<t tx="ekr.20080121105837.4"># ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
# 
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
# 
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
# 
# The Original Code is Komodo code.
# 
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
# 
# Contributor(s):
#   ActiveState Software Inc
# 
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
# 
# ***** END LICENSE BLOCK *****</t>
<t tx="ekr.20080121105837.7"></t>
<t tx="ekr.20080121105837.8"></t>
<t tx="ekr.20080121105837.9">@language python
@tabwidth -4
@others
# When run from command line
if __name__ == '__main__':
    _test()
</t>
<t tx="ekr.20080121105837.10">#!python
# ***** BEGIN LICENSE BLOCK *****

"""The Accessor interface (and implementations) for accessing scintilla
lexer-based styled buffers.
"""

from codeintel2.common import *

try:
    from xpcom.client import WeakReference
    from xpcom import COMException
except ImportError:
    pass


</t>
<t tx="ekr.20080121105837.11">class Accessor(object):
    """Virtual base class for a lexed text accessor. This defines an API
    with which lexed text data (the text content, styling info, etc.) is
    accessed by trigger/completion/etc. handling. Actual instances will
    be one of the subclasses.
    """
    @others
</t>
<t tx="ekr.20080121105837.12">def char_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.13">def style_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.14">def line_and_col_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.15">def gen_char_and_style_back(self, start, stop):
    """Generate (char, style) tuples backward from start to stop
    a la range(start, stop, -1) -- i.e. exclusive at 'stop' index.

    For SciMozAccessor this can be implemented more efficiently than
    the naive usage of char_at_pos()/style_at_pos().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.16">def gen_char_and_style(self, start, stop):
    """Generate (char, style) tuples forward from start to stop
    a la range(start, stop) -- i.e. exclusive at 'stop' index.

    For SciMozAccessor this can be implemented more efficiently than
    the naive usage of char_at_pos()/style_at_pos().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.17">def match_at_pos(self, pos, s):
    """Return True if the given string matches the text at the given
    position.
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.18">def line_from_pos(self, pos):
    """Return the 0-based line number for the given position."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.19">def line_start_pos_from_pos(self, pos):
    """Return the position of the start of the line of the given pos."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.20">def pos_from_line_and_col(self, line, col):
    """Return the position of the given line and column."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.21">@property
def text(self):
    """All buffer content (as a unicode string)."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.22">def text_range(self, start, end):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.23">def length(self):
    """Return the length of the buffer.

    Note that whether this returns a *character* pos or a *byte* pos is
    left fuzzy so that SilverCity and SciMoz implementations can be
    efficient. All that is guaranteed is that the *_at_pos() methods
    work as expected.
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.24">#def gen_pos_and_char_fwd(self, start_pos):
#    """Generate (&lt;pos&gt;, &lt;char&gt;) tuples forward from the starting
#    position until the end of the document.
#    
#    Note that whether &lt;pos&gt; is a *character* pos or a *byte* pos is
#    left fuzzy so that SilverCity and SciMoz implementations can be
#    efficient.
#    """
#    raise VirtualMethodError()
def gen_tokens(self):
    """Generator for all styled tokens in the buffer.
    
    Currently this should yield token dict a la SilverCity's
    tokenize_by_style().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121105837.25">def contiguous_style_range_from_pos(self, pos):
    """Returns a 2-tuple (start, end) giving the span of the sequence of
    characters with the style at position pos."""
    raise VirtualMethodError()


</t>
<t tx="ekr.20080121105837.26">class SilverCityAccessor(Accessor):
    @others
</t>
<t tx="ekr.20080121105837.27">def __init__(self, lexer, content):
    #XXX i18n: need encoding arg?
    self.lexer = lexer
    self.content = content #XXX i18n: this should be a unicode buffer

</t>
<t tx="ekr.20080121105837.28">def reset_content(self, content):
    """A backdoor specific to this accessor to allow the equivalent of
    updating the buffer/file/content.
    """
    self.content = content
    self.__tokens_cache = None

</t>
<t tx="ekr.20080121105837.29">__tokens_cache = None
@property
def tokens(self):
    if self.__tokens_cache is None:
        self.__tokens_cache = self.lexer.tokenize_by_style(self.content)
    return self.__tokens_cache
    
</t>
<t tx="ekr.20080121105837.30">def char_at_pos(self, pos):
    return self.content[pos]

</t>
<t tx="ekr.20080121105837.31">def _token_at_pos(self, pos):
    #XXX Locality of reference should offer an optimization here.
    # Binary search for appropriate token.
    lower, upper = 0, len(self.tokens)  # [lower-limit, upper-limit)
    sentinel = 15
    while sentinel &gt; 0:
        idx = ((upper - lower) / 2) + lower
        token = self.tokens[idx]
        #print "_token_at_pos %d: token idx=%d text[%d:%d]=%r"\
        #      % (pos, idx, token["start_index"], token["end_index"],
        #         token["text"])
        start, end = token["start_index"], token["end_index"]
        if pos &lt; token["start_index"]:
            upper = idx
        elif pos &gt; token["end_index"]:
            lower = idx + 1
        else:
            return token
        sentinel -= 1
    else:
        raise Error("style_at_pos binary search sentinel hit: there "
                    "is likely a logic problem here!")

</t>
<t tx="ekr.20080121105837.32">def style_at_pos(self, pos):
    return self._token_at_pos(pos)["style"]

</t>
<t tx="ekr.20080121105837.33">def line_and_col_at_pos(self, pos):
    #TODO: Fix this. This is busted for line 0 (at least).
    line = self.line_from_pos(pos)
    # I assume that since we got the line, __start_pos_from_line exists
    col = pos - self.__start_pos_from_line[line]
    return line, col

</t>
<t tx="ekr.20080121105837.34">#PERF: If perf is important for this accessor then could do much
#      better with smarter use of _token_at_pos() for these two.
def gen_char_and_style_back(self, start, stop):
    assert -1 &lt;= stop &lt;= start, "stop: %r, start: %r" % (stop, start)
    for pos in range(start, stop, -1):
        yield (self.char_at_pos(pos), self.style_at_pos(pos))
</t>
<t tx="ekr.20080121105837.35">def gen_char_and_style(self, start, stop):
    assert 0 &lt;= start &lt;= stop, "start: %r, stop: %r" % (start, stop)
    for pos in range(start, stop):
        yield (self.char_at_pos(pos), self.style_at_pos(pos))

</t>
<t tx="ekr.20080121105837.36">def match_at_pos(self, pos, s):
    return self.content[pos:pos+len(s)] == s

</t>
<t tx="ekr.20080121105837.37">__start_pos_from_line = None
def line_from_pos(self, pos):
    r"""
        &gt;&gt;&gt; sa = SilverCityAccessor(lexer,
        ...         #0         1           2         3
        ...         #01234567890 123456789 01234567890 12345
        ...         'import sys\nif True:\nprint "hi"\n# bye')
        &gt;&gt;&gt; sa.line_from_pos(0)
        0
        &gt;&gt;&gt; sa.line_from_pos(9)
        0
        &gt;&gt;&gt; sa.line_from_pos(10)
        0
        &gt;&gt;&gt; sa.line_from_pos(11)
        1
        &gt;&gt;&gt; sa.line_from_pos(22)
        2
        &gt;&gt;&gt; sa.line_from_pos(34)
        3
        &gt;&gt;&gt; sa.line_from_pos(35)
        3
    """
    # Lazily build the line -&gt; start-pos info.
    if self.__start_pos_from_line is None:
        self.__start_pos_from_line = [0]
        for line_str in self.content.splitlines(True):
            self.__start_pos_from_line.append(
                self.__start_pos_from_line[-1] + len(line_str))

    # Binary search for line number.
    lower, upper = 0, len(self.__start_pos_from_line)
    sentinel = 15
    while sentinel &gt; 0:
        line = ((upper - lower) / 2) + lower
        #print "LINE %d: limits=(%d, %d) start-pos=%d"\
        #      % (line, lower, upper, self.__start_pos_from_line[line])
        if pos &lt; self.__start_pos_from_line[line]:
            upper = line
        elif line+1 == upper or self.__start_pos_from_line[line+1] &gt; pos:
            return line
        else:
            lower = line
        sentinel -= 1
    else:
        raise Error("line_from_pos binary search sentinel hit: there "
                    "is likely a logic problem here!")

</t>
<t tx="ekr.20080121105837.38">def line_start_pos_from_pos(self, pos):
    token = self._token_at_pos(pos)
    return token["start_index"] - token["start_column"]
</t>
<t tx="ekr.20080121105837.39">def pos_from_line_and_col(self, line, col):
    if not self.__start_pos_from_line:
        self.line_from_pos(len(self.text)) # force init
    return self.__start_pos_from_line[line] + col

</t>
<t tx="ekr.20080121105837.40">@property
def text(self):
    return self.content
</t>
<t tx="ekr.20080121105837.41">def text_range(self, start, end):
    return self.content[start:end]
</t>
<t tx="ekr.20080121105837.42">def length(self):
    return len(self.content)
</t>
<t tx="ekr.20080121105837.43">def gen_tokens(self):
    for token in self.tokens:
        yield token
</t>
<t tx="ekr.20080121105837.44">def contiguous_style_range_from_pos(self, pos):
    token = self._token_at_pos(pos)
    return (token["start_index"], token["end_index"] + 1)


</t>
<t tx="ekr.20080121105837.45">class SciMozAccessor(Accessor):
    @others
</t>
<t tx="ekr.20080121105837.46">def __init__(self, scimoz, silvercity_lexer):
    self.scimoz = WeakReference(scimoz)
    self.style_mask = (1 &lt;&lt; scimoz.styleBits) - 1
    self.silvercity_lexer = silvercity_lexer
</t>
<t tx="ekr.20080121105837.47">def char_at_pos(self, pos):
    return self.scimoz().getWCharAt(pos)
</t>
<t tx="ekr.20080121105837.48">def style_at_pos(self, pos):
    return self.scimoz().getStyleAt(pos) &amp; self.style_mask
</t>
<t tx="ekr.20080121105837.49">def line_and_col_at_pos(self, pos):
    scimoz = self.scimoz()
    line = scimoz.lineFromPosition(pos)
    col = pos - scimoz.positionFromLine(line)
    return line, col

</t>
<t tx="ekr.20080121105837.50"># These two are *much* faster than repeatedly calling char_at_pos()
# and style_at_pos().
def gen_char_and_style_back(self, start, stop):
    if start &gt; stop:
        # For scimoz.getStyledText(), it's (inclusive, exclusive)
        styled_text = self.scimoz().getStyledText(stop+1, start+1)
        style_mask = self.style_mask
        for i in range(len(styled_text)-2, -2, -2):
            yield (styled_text[i], ord(styled_text[i+1]) &amp; style_mask)
    elif start == stop:
        pass
    else:
        raise AssertionError("start (%r) &lt; stop (%r)" % (start, stop))
</t>
<t tx="ekr.20080121105837.51">def gen_char_and_style(self, start, stop):
    if start &lt; stop:
        # For scimoz.getStyledText(), it's (inclusive, exclusive)
        styled_text = self.scimoz().getStyledText(start, stop)
        style_mask = self.style_mask
        for i in range(0, len(styled_text), 2):
            yield (styled_text[i], ord(styled_text[i+1]) &amp; style_mask)
    elif start == stop:
        pass
    else:
        raise AssertionError("start (%r) &gt; stop (%r)" % (start, stop))

</t>
<t tx="ekr.20080121105837.52">#XXX def match_at_pos(self, pos, s):...
def line_from_pos(self, pos):
    return self.scimoz().lineFromPosition(pos)
</t>
<t tx="ekr.20080121105837.53">def line_start_pos_from_pos(self, pos):
    scimoz = self.scimoz()
    return scimoz.positionFromLine(scimoz.lineFromPosition(pos))
</t>
<t tx="ekr.20080121105837.54">def pos_from_line_and_col(self, line, col):
    return self.scimoz().positionFromLine(line) + col
</t>
<t tx="ekr.20080121105837.55">@property
def text(self):
    return self.scimoz().text
</t>
<t tx="ekr.20080121105837.56">def text_range(self, start, end):
    return self.scimoz().getTextRange(start, end)
</t>
<t tx="ekr.20080121105837.57">def length(self):
    return self.scimoz().textLength
    #raise NotImplementedError(
    #    "Calculating the *character* length of a SciMoz buffer can "
    #    "be expensive. Are you sure you want to use this method? "
    #    "Try accessor.gen_pos_and_char_fwd() first.")
</t>
<t tx="ekr.20080121105837.58">def gen_tokens(self):
    #PERF: This is not a great solution but see bug 54217.
    acc = SilverCityAccessor(self.silvercity_lexer, self.text)
    for token in acc.gen_tokens():
        yield token
</t>
<t tx="ekr.20080121105837.59">def contiguous_style_range_from_pos(self, pos):
    curr_style = self.style_at_pos(pos)
    i = pos - 1
    while i &gt;= 0 and self.style_at_pos(i) == curr_style:
        i -= 1
    start_pos = i + 1
    
    last_pos = self.length()
    i = pos + 1
    while i &lt; last_pos and self.style_at_pos(i) == curr_style:
        i += 1
    end_pos = i # Point one past the end
    return (start_pos, end_pos)


</t>
<t tx="ekr.20080121105837.60">class KoDocumentAccessor(SciMozAccessor):
    """An accessor that lazily defers to the first view attached to this
    Komodo document object.
    """
    @others
</t>
<t tx="ekr.20080121105837.61">def __init__(self, doc, silvercity_lexer):
    self.doc = WeakReference(doc)
    self.silvercity_lexer = silvercity_lexer
</t>
<t tx="ekr.20080121105837.62">_scimoz_weak_ref = None

def _scimoz_proxy_from_scimoz(self, scimoz):
    from xpcom import _xpcom
    return _xpcom.getProxyForObject(1, components.interfaces.ISciMoz,
        scimoz, _xpcom.PROXY_SYNC | _xpcom.PROXY_ALWAYS)
    
</t>
<t tx="ekr.20080121105837.63">def scimoz(self):
    # Defer getting the scimoz until first need. This is required
    # because a koIDocument does not have its koIScintillaView at
    # creation time.
    # SIDE-EFFECT: Set self.style_mask on first access.
    if self._scimoz_weak_ref is None:
        try:
            view = self.doc().getView()
        except (COMException, AttributeError), ex:
            # Race conditions on file opening in Komodo can result
            # in self.doc() being None or an error in .getView().
            raise NoBufferAccessorError(str(ex))
        scimoz_proxy = self._scimoz_proxy_from_scimoz(view.scimoz)
        self.style_mask = (1 &lt;&lt; scimoz_proxy.styleBits) - 1
        self._scimoz_weak_ref = WeakReference(view.scimoz)
        return scimoz_proxy
    scimoz = self._scimoz_weak_ref()
    if scimoz:
        return self._scimoz_proxy_from_scimoz(scimoz)
    else:
        return None


</t>
<t tx="ekr.20080121105837.64">class AccessorCache:
    """Utility class used to cache buffer styling information"""
    @others
</t>
<t tx="ekr.20080121105837.65">
def __init__(self, accessor, position, fetchsize=20, debug=False):
    """Document accessor cache contructor. Will cache fetchsize style info
    pieces starting from position - 1.
    
    @param accessor {Accessor} a form of document accessor
    @param position {int} where in the document to start caching from (exclusive)
    @param fetchsize {int} how much cache is stored/retrived at a time
    """
    self._accessor = accessor
    self._cachefetchsize = fetchsize
    self._debug = debug
    #self._debug = True
    self._reset(position)

</t>
<t tx="ekr.20080121105837.66"># Private
def _reset(self, position):
    self._pos = position
    self._ch = None
    self._style = None
    # cachePos is used to store where self._pos is inside the _cache
    self._cachePos = 0
    self._chCache = []
    self._styleCache = []
    # cacheXXXBufPos is used to store where cache is relative to the buffer
    # _cacheFirstBufPos is inclusive
    self._cacheFirstBufPos = position
    # _cacheLastBufPos is exclusive
    self._cacheLastBufPos  = position

</t>
<t tx="ekr.20080121105837.67">def _extendCacheBackwards(self, byAmount=None):
    if self._cacheFirstBufPos &gt; 0:
        if byAmount is None:
            byAmount = self._cachefetchsize
        # Generate another n tuples (pos, char, style)
        start = max(0, (self._cacheFirstBufPos - byAmount))
        # Add more to the start of the cache
        extendCount = (self._cacheFirstBufPos - start)
        ch_list = []
        style_list = []
        for ch, style in self._accessor.gen_char_and_style(start, self._cacheFirstBufPos):
            ch_list.append(ch)
            style_list.append(style)
        self._chCache = ch_list + self._chCache
        self._styleCache = style_list + self._styleCache
        self._cachePos += extendCount
        self._cacheFirstBufPos = start
        if self._debug:
            print "Extended cache by %d, _cachePos: %d, len now: %d" % (
                extendCount, self._cachePos, len(self._chCache))
            print "Ch cache now: %r" % (self._chCache)
    else:
        raise IndexError("No buffer left to examine")

</t>
<t tx="ekr.20080121105837.68">def _extendCacheForwards(self, byAmount=None):
    buf_length = self._accessor.length()
    if self._cacheLastBufPos &lt; buf_length:
        if byAmount is None:
            byAmount = self._cachefetchsize
        # Generate another n tuples (pos, char, style)
        end = min(buf_length, (self._cacheLastBufPos + byAmount))
        # Add more to the end of the cache
        extendCount = end - self._cacheLastBufPos
        for ch, style in self._accessor.gen_char_and_style(self._cacheLastBufPos, end):
            self._chCache.append(ch)
            self._styleCache.append(style)
        self._cacheLastBufPos = end
        if self._debug:
            print "Extended cache by %d, _cachePos: %d, len now: %d" % (
                extendCount, self._cachePos, len(self._chCache))
            print "Ch cache now: %r" % (self._chCache)
    else:
        raise IndexError("No buffer left to examine")

</t>
<t tx="ekr.20080121105837.69"># Public
def dump(self, limit=20):
    if len(self._chCache) &gt; 0:
        print "  pos: %r, ch: %r, style: %r, cachePos: %r, cache len: %d\n  cache: %r" % (self._cachePos + self._cacheFirstBufPos,
                                                         self._chCache[self._cachePos],
                                                         self._styleCache[self._cachePos],
                                                         self._cachePos,
                                                         len(self._chCache),
                                                         self._chCache)
    else:
        print "New cache: %r" % (self._chCache[-limit:])

</t>
<t tx="ekr.20080121105837.70">def setCacheFetchSize(self, size):
    self._cachefetchsize = size

</t>
<t tx="ekr.20080121105837.71">def resetToPosition(self, position):
    if self._debug:
        print "resetToPosition: %d" % (position)
        print "self._cacheFirstBufPos: %d" % (self._cacheFirstBufPos)
        print "self._cacheLastBufPos: %d" % (self._cacheLastBufPos)
    if position &gt;= self._cacheLastBufPos:
        if position &gt;= self._cacheLastBufPos + self._cachefetchsize:
            # Clear everything
            self._reset(position)
            return
        else:
            # Just extend forwards
            if self._debug:
                print "resetToPosition: extending cache forwards"
            self._extendCacheForwards()
    elif position &lt; self._cacheFirstBufPos:
        if position &lt; self._cacheFirstBufPos - self._cachefetchsize:
            # Clear everything
            self._reset(position)
            return
        else:
            # Just extend back
            if self._debug:
                print "resetToPosition: extending cache backwards"
            self._extendCacheBackwards()
    else:
        # It's in the current cache area, we keep that then
        pass
    self._cachePos = position - self._cacheFirstBufPos
    self._ch = self._chCache[self._cachePos]
    self._style = self._styleCache[self._cachePos]
    self._pos = position
    if self._debug:
        print "self._cachePos: %d, cacheLen: %d" % (self._cachePos, len(self._chCache))
        print "resetToPosition: p: %r, ch: %r, st: %r" % (self._pos, self._ch, self._style)

</t>
<t tx="ekr.20080121105837.72">#def pushBack(self, numPushed=1):
#    """Push back the items that were recetly popped off.
#    @returns {int} Number of pushed items
#    """
#    pushItems = self._popped[-numPushed:]
#    pushItems.reverse()
#    self._cache += pushItems
#    if len(self._popped) &gt; 0:
#        self._currentTuple = self._popped[-1]
#    else:
#        self._currentTuple = (self._currentTuple[0] + numPushed, None, None)
#    return len(pushItems)

def getCurrentPosCharStyle(self):
    """Get the current buffer position information.
    @returns {tuple} with values (pos, char, style)
    """
    return (self._pos, self._ch, self._style)

</t>
<t tx="ekr.20080121105837.73">def getPrevPosCharStyle(self, ignore_styles=None, max_look_back=100):
    """Get the previous buffer position information.
    @param ignore_styles {tuple}
    @returns {tuple} with values (pos, char, style), these values will
    all be None if it exceeds the max_look_back.
    @raises IndexError can be raised when nothing left to consume.
    """
    count = 0
    while count &lt; max_look_back:
        count += 1
        self._cachePos -= 1
        if self._cachePos &lt; 0:
            self._extendCacheBackwards()
        self._style = self._styleCache[self._cachePos]
        if ignore_styles is None or self._style not in ignore_styles:
            self._ch = self._chCache[self._cachePos]
            break
    else:
        # Went too far without finding what looking for
        return (None, None, None)
    self._pos = self._cachePos + self._cacheFirstBufPos
    if self._debug:
        print "getPrevPosCharStyle:: pos:%d ch:%r style:%d" % (self._pos, self._ch, self._style)
    return (self._pos, self._ch, self._style)

</t>
<t tx="ekr.20080121105837.74">def getPrecedingPosCharStyle(self, current_style=None, ignore_styles=None,
                             max_look_back=200):
    """Go back and get the preceding style.
    @returns {tuple} with values (pos, char, style)
    Returns None for both char and style, when out of characters to look
    at and there is still no previous style found.
    """
    if current_style is None:
        current_style = self._styleCache[self._cachePos]
    try:
        new_ignore_styles = [current_style]
        if ignore_styles is not None:
            new_ignore_styles += list(ignore_styles)
        return self.getPrevPosCharStyle(new_ignore_styles, max_look_back)
    except IndexError:
        pass
    # Did not find the necessary style
    return None, None, None

</t>
<t tx="ekr.20080121105837.75">def getTextBackWithStyle(self, current_style=None, ignore_styles=None,
                         max_text_len=200):
    """Go back and get the preceding text, which is of a different style.
    @returns {tuple} with values (pos, text), pos is position of first text char
    """
    old_p = self._pos
    new_p, c, style = self.getPrecedingPosCharStyle(current_style,
                                                    ignore_styles,
                                                    max_look_back=max_text_len)
    #print "Return %d:%d" % (new_p, old_p+1)
    if style is None:   # Ran out of text to look at
        new_p = max(0, old_p - max_text_len)
        return new_p, self.text_range(new_p, old_p+1)
    else:
        # We don't eat the new styling info
        self._cachePos += 1
        return new_p+1, self.text_range(new_p+1, old_p+1)

</t>
<t tx="ekr.20080121105837.76">def getNextPosCharStyle(self, ignore_styles=None, max_look_ahead=100):
    """Get the next buffer position information.
    @param ignore_styles {tuple}
    @returns {tuple} with values (pos, char, style), these values will
    all be None if it exceeds the max_look_ahead.
    @raises IndexError can be raised when nothing left to consume.
    """
    max_pos = self._cachePos + max_look_ahead
    while self._cachePos &lt; max_pos:
        self._cachePos += 1
        if self._cachePos &gt;= len(self._chCache):
            self._extendCacheForwards()
        self._style = self._styleCache[self._cachePos]
        if ignore_styles is None or self._style not in ignore_styles:
            self._ch = self._chCache[self._cachePos]
            break
    else:
        # Went too far without finding what looking for
        return (None, None, None)
    self._pos = self._cachePos + self._cacheFirstBufPos
    if self._debug:
        print "getNextPosCharStyle:: pos:%d ch:%r style:%d" % (self._pos, self._ch, self._style)
    return (self._pos, self._ch, self._style)

</t>
<t tx="ekr.20080121105837.77">def getSucceedingPosCharStyle(self, current_style=None, ignore_styles=None,
                              max_look_ahead=200):
    """Go forward and get the next different style.
    @returns {tuple} with values (pos, char, style)
    Returns None for both char and style, when out of characters to look
    at and there is still no previous style found.
    """
    if current_style is None:
        current_style = self._styleCache[self._cachePos]
    try:
        new_ignore_styles = [current_style]
        if ignore_styles is not None:
            new_ignore_styles += list(ignore_styles)
        return self.getNextPosCharStyle(new_ignore_styles, max_look_ahead)
    except IndexError:
        pass
    # Did not find the necessary style
    return None, None, None

</t>
<t tx="ekr.20080121105837.78">def getTextForwardWithStyle(self, current_style=None, ignore_styles=None,
                            max_text_len=200):
    """Go forward and get the succeeding text, which is of a different style.
    @returns {tuple} with values (pos, text), pos is position of last text char.
    """
    old_p = self._pos
    new_p, c, style = self.getSucceedingPosCharStyle(current_style,
                                                     ignore_styles,
                                                     max_look_ahead=max_text_len)
    if style is None:   # Ran out of text to look at
        new_p = min(self._accessor.length(), old_p + max_text_len)
        return new_p, self.text_range(old_p, new_p)
    else:
        # We don't eat the new styling info
        self._cachePos -= 1
        return new_p-1, self.text_range(old_p, new_p)

</t>
<t tx="ekr.20080121105837.79">def text_range(self, start, end):
    """Return text in range buf[start:end]
    
    Note: Start position is inclusive, end position is exclusive.
    """
    if start &gt;= self._cacheFirstBufPos and end &lt;= self._cacheLastBufPos:
        cstart = start - self._cacheFirstBufPos
        cend = end - self._cacheFirstBufPos
        if self._debug:
            print "text_range:: cstart: %d, cend: %d" % (cstart, cend)
            print "text_range:: start: %d, end %d" % (start, end)
            print "text_range:: _cacheFirstBufPos: %d, _cacheLastBufPos: %d" % (self._cacheFirstBufPos, self._cacheLastBufPos)
        # It's all in the cache
        return "".join(self._chCache[cstart:cend])
    if self._debug:
        print "text_range:: using parent text_range: %r - %r" % (start, end)
    return self._accessor.text_range(start, end)

</t>
<t tx="ekr.20080121105837.80"># Test function
def _test():
    class _TestAccessor(Accessor):
        def __init__(self, content, styles):
            self.content = content
            self.style = styles
        def length(self):
            return len(self.content)
        def char_at_pos(self, pos):
            return self.content[pos]
        def style_at_pos(self, pos):
            return self.style[pos]
        def gen_char_and_style_back(self, start, stop):
            assert -1 &lt;= stop &lt;= start, "stop: %r, start: %r" % (stop, start)
            for pos in range(start, stop, -1):
                yield (self.char_at_pos(pos), self.style_at_pos(pos))
        def gen_char_and_style(self, start, stop):
            assert 0 &lt;= start &lt;= stop, "start: %r, stop: %r" % (start, stop)
            for pos in range(start, stop):
                yield (self.char_at_pos(pos), self.style_at_pos(pos))
        def text_range(self, start, end):
            return self.content[start:end]

    content = "This is my test buffer\r\nSecond   line\r\nThird line\r\n"
    styles =  "1111011011011110111111 2 21111110001111 2 21111101111 2 2".replace(" ", "")
    ta = _TestAccessor(content, map(int, styles))
    pos = len(content) - 2
    ac = AccessorCache(ta, pos)
    #ac._debug = True
    for i in range(2):
        assert(ac.getPrevPosCharStyle() == (pos-1, "e", 1))
        assert(ac.getPrecedingPosCharStyle(1) == (pos-5, " ", 0))
        assert(ac.getPrecedingPosCharStyle(0) == (pos-6, "d", 1))
        assert(ac.getPrecedingPosCharStyle(1) == (pos-11, "\n", 2))
        assert(ac.getPrecedingPosCharStyle()  == (pos-13, "e", 1))
        assert(ac.getTextBackWithStyle(1) == (pos-16, "line"))
        assert(ac.getPrevPosCharStyle() == (pos-17, " ", 0))
        assert(ac.getPrecedingPosCharStyle(0) == (pos-20, "d", 1))
        if i == 0:
            ac.resetToPosition(pos)

    assert(ac.getCurrentPosCharStyle() == (pos-20, "d", 1))

    #print pos
    #print ac.getSucceedingPosCharStyle()
    assert(ac.getNextPosCharStyle() == (pos-19, " ", 0))
    assert(ac.getSucceedingPosCharStyle() == (pos-16, "l", 1))
    assert(ac.getTextForwardWithStyle(1) == (pos-13, "line"))
    assert(ac.getNextPosCharStyle() == (pos-12, "\r", 2))
    assert(ac.getNextPosCharStyle() == (pos-11, "\n", 2))
    assert(ac.getSucceedingPosCharStyle(2) == (pos-10, "T", 1))
    assert(ac.getSucceedingPosCharStyle() == (pos-5, " ", 0))
    assert(ac.getSucceedingPosCharStyle() == (pos-4, "l", 1))
    assert(ac.getSucceedingPosCharStyle() == (pos, "\r", 2))
    assert(ac.getNextPosCharStyle() == (pos+1, "\n", 2))

    # Bug: http://bugs.activestate.com/show_bug.cgi?id=64227
    #      Ensure text_range uses correct parameters in boundary situations
    ac.resetToPosition(3)
    assert(ac.getTextBackWithStyle(1)[1] == "This")
    ac.resetToPosition(len(content) - 2)
    assert(ac.getTextForwardWithStyle(2)[1] == "\r\n")


</t>
<t tx="ekr.20080121105837.81">@language python
@tabwidth -4
@others

if __name__ == "__main__":
    _doctest()
@ignore</t>
<t tx="ekr.20080121105837.82">#!python
# ***** BEGIN LICENSE BLOCK *****

import os
from os.path import dirname, join, abspath, normpath, basename
import sys
import re
import operator
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import traceback

import SilverCity
from SilverCity import ScintillaConstants
#XXX Import only what we need
from SilverCity.ScintillaConstants import *

from codeintel2.common import *
from codeintel2.util import isident, indent, banner, markup_text

try:
    from xpcom import components
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False

#XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir




</t>
<t tx="ekr.20080121105837.83">#---- module interface

class Buffer(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelBuffer]

    # Language-specific attributes that subclasses must fill-in.
    lang = None             # language name
    cpln_fillup_chars = ""  # chars on which autocomplete UI will "fillup"
    cpln_stop_chars = ""    # chars on which autocomplete UI will stop

    # Separator btwn completions in a completion list string for the
    # Scintilla API.
    # We don't use the default, ' ', because so of our languages have
    # completions with spaces in them (e.g. Tcl).
    scintilla_cpln_sep = '\n'
    scintilla_cpln_sep_ord = ord(scintilla_cpln_sep) 

    # &lt;prefix&gt;&lt;stylename&gt;, scintilla style constants prefix for this
    # language. Most languages just have one prefix (e.g. "SCE_P_" for
    # Python), but HTML, for example, has many.
    sce_prefixes = None

    # Code Browser control. (Note: most code browser control is on the
    # relevant LangIntel).
    # 
    # Show a row for this buffer even if empty of code browser data.
    cb_show_if_empty = False

    # Lazily built cache of SCE_* style number (per language) to constant
    # name.
    _style_name_from_style_num_from_lang = {}

    @others
</t>
<t tx="ekr.20080121105837.84">def __init__(self, mgr, accessor, env=None, path=None):
    self.mgr = mgr
    self.accessor = accessor # an Accessor instance
    self._env = env
    self.path = path

    self.implicit_completion_skip_styles = dict(
        (s, True) for s in self.comment_styles() + self.string_styles())
    self.completion_skip_styles = dict(
        (s, True) for s in self.number_styles())

</t>
<t tx="ekr.20080121105837.85">def __repr__(self):
    return "&lt;%s buf '%s'&gt;" % (self.lang, basename(self.path))

</t>
<t tx="ekr.20080121105837.86">@property
def env(self):
    """The runtime Environment instance for this buffer."""
    return self._env or self.mgr.env

</t>
<t tx="ekr.20080121105837.87">_langintel_cache = None
@property
def langintel(self):
    if self._langintel_cache is None:
        self._langintel_cache = self.mgr.langintel_from_lang(self.lang)
    return self._langintel_cache

</t>
<t tx="ekr.20080121105837.88">def lang_from_pos(self, pos):
    return self.lang

</t>
<t tx="ekr.20080121105837.89">def trg_from_pos(self, pos, implicit=True):
    """If the given position is a _likely_ trigger point, return a
    relevant Trigger instance. Otherwise return the None.

        "pos" is the position at which to check for a trigger point.
        "implicit" (optional) is a boolean indicating if this trigger
            is being implicitly checked (i.e. as a side-effect of
            typing). Defaults to true.

    Implementations of this should be *fast* because editor usage will
    likely call this for most typed characters.

    The default implementation defers to the langintel for this buffer.
    This is generally a better place to implement trg_from_pos if this
    language's content can appear in a multi-language buffer (e.g. CSS).
    """
    return self.langintel.trg_from_pos(self, pos, implicit)

</t>
<t tx="ekr.20080121105837.90">def preceding_trg_from_pos(self, pos, curr_pos):
    """Look back from the given position for a trigger point within
    range.

        "pos" is the position at which to begin backtracking. (I.e. for
            the first Ctrl+J this is the cursor position, for the next
            Ctrl+J it is the position of the current
            autocomplete/calltip UI.)
        "curr_pos" is the current position -- the one to use to
            determine if within range of a found trigger. (I.e. this is
            the cursor position in Komodo.)

    Here "within range" depends on the language and the trigger. This
    is the main determinant for the "Ctrl+J" (explicitly trigger
    completion now) functionality in Komodo, for example, and the
    ultimate goal is to not surprisingly move the cursor on the user.
    Here is the algorithm:
    - Only consider a *completion* (i.e. TRG_FORM_CPLN) trigger point
      if `pos' is in range. I.e.:
            sys.pat&lt;|&gt;h         # consider the `sys.' trigger
            os.path.join("&lt;|&gt;   # do not consider the `os.path.' trigger
    - Only consider a calltip trigger point inside the argument
      region.

    I.e., "within range" means, we could show the UI for that completion
    in scintilla without having to move the cursor.

    The default implementation defers to the langintel for this buffer.

    Returns a Trigger instance or None.
    """
    return self.langintel.preceding_trg_from_pos(self, pos, curr_pos)

</t>
<t tx="ekr.20080121105837.91">def async_eval_at_trg(self, trg, ctlr):
    """Asynchronously determine completion/calltip info for the given
    trigger.

        "trg" is the trigger at which to evaluate (a Trigger instance).
        "ctlr" is the controller (a EvalController instance) used to
            relay results and status and to receive control signals.

    Rules for implementation:
    - Must call ctlr.start(buf, trg) at start.
    - Should call ctrl.set_desc(desc) near the start to provide a
      short description of the evaluation. 
    - Should log eval errors via ctlr.error(msg, args...).
    - Should log other events via ctlr.{debug|info|warn}.
    - Should respond to ctlr.abort() in a timely manner.
    - If successful, must report results via one of
      ctrl.set_cplns() or ctrl.set_calltips().
    - Must call ctlr.done(some_reason_string) when done.

    Tips for implementation:
    - The typical structure of an async_eval_at_trg() implementation is:
        ctlr.start(self, trg)  # or 'buf' if implemented on LangIntel
        if trg.id == (&lt;lang&gt;, TRG_FORM_CPLN, &lt;type&gt;):
            # handle this trigger type
        elif trg.id == (&lt;lang&gt;, TRG_FORM_CPLN, &lt;type&gt;):
            # handle this trigger type
        ...
    - If evaluation of a particular trigger type is fast (i.e. just a
      lookup in a hardcoded data structure) then it is okay to process
      asynchronously.

    The default implementation defers to the langintel for this buffer.

    Returns no value. All interaction is on the controller. This may
    raise CodeIntelError on an unexpected error condition.
    """
    #XXX xpcom UnwrapObject here?
    self.langintel.async_eval_at_trg(self, trg, ctlr)

</t>
<t tx="ekr.20080121105837.92">def cplns_from_trg(self, trg, timeout=None, ctlr=None):
    """Return completions for the given trigger point.

        "trg" is the trigger point at which to eval completions.
        "timeout" (optional) is a number of seconds after which to
            abandon completion. Raises EvalTimeout if the timeout is
            reached.
        "ctlr" (optional) is a EvalController instance to use for
            custom interaction with the evaluation.

    This is a convenience synchronous wrapper around async_eval_at_trg().
    Use the async version for any more interesting interaction.

    A "completion" is a 2-tuple -- (&lt;type&gt;, &lt;completion-string&gt;) -- where
    &lt;type&gt; is currently just a string like "variable", "class", etc.
    """
    assert timeout is None or isinstance(timeout, (float, int)),\
        "'timeout' must be None or a number"
    if ctlr is None:
        ctlr = EvalController()
    self.async_eval_at_trg(trg, ctlr)
    ctlr.wait(timeout)
    if not ctlr.is_done():
        ctlr.done("timed out")
        raise EvalTimeout("eval for %s timed-out" % trg)
    return ctlr.cplns

</t>
<t tx="ekr.20080121105837.93">def calltips_from_trg(self, trg, timeout=None, ctlr=None):
    """Return calltips for the given trigger point.

        "trg" is the trigger point at which to eval completions.
        "timeout" (optional) is a number of seconds after which to
            abandon completion. Raises EvalTimeout if the timeout is
            reached.
        "ctlr" (optional) is a EvalController instance to use for
            custom interaction with the evaluation.

    This is a convenience synchronous wrapper around async_eval_at_trg().
    Use the async version for any more interesting interaction.
    """
    assert timeout is None or isinstance(timeout, (float, int)),\
        "'timeout' must be None or a number"
    if ctlr is None:
        ctlr = EvalController()
    self.async_eval_at_trg(trg, ctlr)
    ctlr.wait(timeout)
    if not ctlr.is_done():
        ctlr.done("timed out")
        raise EvalTimeout("eval for %s timed-out" % trg)
    return ctlr.calltips

</t>
<t tx="ekr.20080121105837.94">def curr_calltip_arg_range(self, trg_pos, calltip, curr_pos, DEBUG=False):
    """Return that range in the calltip of the "current" arg.
    I.e. what argument is currently being entered.

        "trg_pos" is the trigger position.
        "calltip" is the full calltip text.
        "curr_pos" is the current position in the buffer.

    Returns a range: (start, end)
    Set `start == -1` to cancel the calltip, i.e. if the entered text
    has closed the call region.

    The default implementation uses defers to the LangIntel
    singleton for this language.
    """
    return self.langintel.curr_calltip_arg_range(self, trg_pos, calltip,
                                                 curr_pos, DEBUG=DEBUG)

</t>
<t tx="ekr.20080121105837.95">@property
def libs(self):
    """Return the ordered list libraries in which to search for blob
    imports in this buffer.

    Each "library" is an instance of a database *Lib class that
    provides the has_blob()/get_blob() API. See the
    database/database.py module docstring for details.

    Commonly a buffer (for a typical programming language) will have
    some or all of the following libs:
        curdirlib/runtimedirlib
        extradirslib (based on *ExtraPaths prefs in the buffer's env)
        envlib (e.g. from PYTHONPATH, PERL5LIB, ... if set)
        cataloglib
        sitelib
        stdlib
    """
    raise VirtualMethodError("Buffer subclass for lang '%s' should "
                             "implement the 'libs' property" % self.lang)

</t>
<t tx="ekr.20080121105837.96">def to_html(self, include_styling=False, include_html=False, title=None,
            do_trg=False, do_eval=False):
    """Return a styled HTML snippet for the current buffer.

        "include_styling" (optional, default False) is a boolean
            indicating if the CSS/JS/informational-HTML should be
            included.
        "include_html" (optional, default False) is a boolean indicating
            if the HTML output should be wrapped into a complete HTML
            document.
        "title" is the HTML document title to use if 'include_html' is
            True.
        "do_trg" (optional, default False) indicates that trigger
            handling should be done. This implies do_eval=True.
        "do_eval" (optional, default False) indicates that completion
            eval should be done.
    """
    from cStringIO import StringIO
    html = StringIO()
    
@ EKR:
    first mismatched line: 342
 &lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"\n'
@c

    if include_html:
        html.write('''\
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
&lt;title&gt;%s&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
''' % title)

    if include_styling:
        html.write('''
&lt;script type="application/x-javascript"&gt;
function show_class(span) {
    var infobox = document.getElementById("infobox");
    infobox.innerHTML = span.getAttribute("class");
}
&lt;/script&gt;

&lt;style&gt;
#infobox {
border: 4px solid #e0e0e0;
background-color: #f0f0f0;
padding: 10px;
position: fixed;
top: 5px;
right: 5px;
}

/* CSS Tooltips: http://www.communitymx.com/content/article.cfm?cid=4E2C0 */
div.code span.trg {
font: small-caption;
vertical-align: bottom;
color: green;
position: relative;
cursor: crosshair;
}
div.code span.trg-info {
display: none;
z-index: 25;
cursor: text;
min-width: 25em;
white-space: nowrap;
}
div.code span.trg:hover span.trg-info {
z-index: 26;
position: absolute;
top: 1.0em;
left: 0.0em;
display: block;
padding: 4px;
background-color: #f0f0f0;
border: 1px solid #e0e0e0;
}
span.trg-evalerror  { width: 50em; color: red !important; }
span.trg-error      { width: 50em; color: red !important; }
span.trg-notatrg    { color: blue !important; }
span.trg-noresults  { color: orange !important; }
td.trg-evallog {
color: grey;
border-left: 1px solid grey;
padding-left: 5px;
}

/* token highlighting and debugging info */
div.code span:hover {
background-color: #e0e0e0;
}

div.code span.udl-region:hover {
background-color: #f0f0f0;
}

/* language-neutral syntax coloring */
div.code {
font-family: "Courier New", Courier, monospace;
font-size: small;
}

div.code .comments    { color: grey; }
div.code .keywords    { font-weight: bold; }
div.code .identifiers { color: black; }
div.code .strings     { color: blue; }
div.code .classes,
div.code .functions   { color: green; }
div.code .stderr      { background-color: red; }
div.code .stdout      { background-color: blue; }
div.code .tags        { color: red; }

&lt;/style&gt;

&lt;div id="infobox"&gt;&lt;/div&gt;
''')

    #XXX escape lang name for CSS class
    html.write('&lt;div class="code %s"&gt;\n' % self.lang.lower())

    curr_udl_region = None
    ch = last_ch = None
    for token in self.accessor.gen_tokens():
        css_classes = self.style_names_from_style_num(token["style"])
        if css_classes and css_classes[0].startswith("SCE_UDL_"):
            udl_region = css_classes[0].split('_')[2]
            if udl_region == curr_udl_region:
                pass
            else:
                if curr_udl_region:
                    html.write('\n&lt;/span&gt;\n')
                html.write('\n&lt;span class="udl-region"&gt;\n')
                curr_udl_region = udl_region
        html.write('&lt;span class="%s" onmouseover="show_class(event.target);"&gt;'
                   % ' '.join(css_classes))
        for i, ch in enumerate(token["text"]):
            if ch == "\n" and last_ch == "\r":
                # Treat '\r\n' as one char.
                continue
            if do_trg:
                try:
                    trg = self.trg_from_pos(token["start_index"] + i)
                except CodeIntelError, ex:
                    html.write(self._html_from_trg_error(ex))
                else:
                    if trg is not None:
                        html.write(self._html_from_trg(trg,
                                                       do_eval=do_eval))
            #XXX Need to do tab expansion.
            html.write(_htmlescape(ch, quote=True, whitespace=True))
            last_ch = ch
        html.write('&lt;/span&gt;')
    if curr_udl_region:
        html.write('\n&lt;/span&gt;\n')
    html.write('&lt;/div&gt;\n')

    if include_html:
        html.write('''
&lt;/body&gt;
&lt;/html&gt;
''')

    return html.getvalue()

</t>
<t tx="ekr.20080121105837.97">def _html_from_trg_error(self, ex):
    marker = "&amp;curren;"
    classes = ["trg"]
    classes.append("trg-error")
    result = _htmlescape(traceback.format_exc(), whitespace=True)
    info_html = '&lt;div&gt;%s&lt;/div' % result
    return '&lt;span class="%s"&gt;%s&lt;span class="trg-info"&gt;%s&lt;/span&gt;&lt;/span&gt;' \
           % (' '.join(classes), marker, info_html)

</t>
<t tx="ekr.20080121105837.98">def _html_from_trg(self, trg, do_eval=False):
    marker = "&amp;curren;"
    classes = ["trg"]

    try:
        eval_log_stream = StringIO()
        hdlr = logging.StreamHandler(eval_log_stream)
        infoFmt = "%(name)s: %(message)s"
        fmtr = logging.Formatter("%(name)s: %(levelname)s: %(message)s")
        hdlr.setFormatter(fmtr)
        codeintel_logger = logging.getLogger("codeintel")
        codeintel_logger.addHandler(hdlr)
        if do_eval:
            ctlr = LogEvalController(codeintel_logger)
            try:
                if trg.form == TRG_FORM_CPLN:
                    cplns = self.cplns_from_trg(trg, ctlr=ctlr)
                else:
                    calltips = self.calltips_from_trg(trg, ctlr=ctlr)
            finally:
                codeintel_logger.removeHandler(hdlr)
    except NotATriggerError:
        classes.append("trg-notatrg")
        result = "(not a trigger point, false alarm by trg_from_pos())"
    except (EvalError, NotImplementedError,
            #XXX Eventually citdl evaluation shouldn't use
            #    codeintel2.CodeIntelError.
            CodeIntelError), ex:
        classes.append("trg-evalerror")
        result = _htmlescape(traceback.format_exc(), whitespace=True)
    else:
        if trg.form == TRG_FORM_CPLN:
            if not do_eval:
                classes.append("trg-noresults")
                result = "(eval skipped)"
            elif cplns:
                result = "&lt;br /&gt;".join(["&lt;em&gt;%s&lt;/em&gt; %s" % c
                                        for c in cplns])
            else:
                classes.append("trg-noresults")
                result = "(no completions)"
        else:
            if not do_eval:
                classes.append("trg-noresults")
                result = "(eval skipped)"
            elif calltips:
                result = _htmlescape(calltips[0], whitespace=True)
            else:
                classes.append("trg-noresults")
                result = "(no calltip)"

    eval_log = _htmlescape(str(trg), whitespace=True)
    eval_log += "&lt;hr /&gt;"
    eval_log += _htmlescape(eval_log_stream.getvalue(), whitespace=True)
    info_html = ('&lt;table&gt;&lt;tr valign="top"&gt;'
                 '&lt;td&gt;%s&lt;/td&gt;'
                 '&lt;td class="trg-evallog"&gt;%s&lt;/td&gt;'
                 '&lt;/tr&gt;&lt;/table&gt;'
                 % (result, eval_log))
    return '&lt;span class="%s"&gt;%s&lt;span class="trg-info"&gt;%s&lt;/span&gt;&lt;/span&gt;' \
           % (' '.join(classes), marker, info_html)


</t>
<t tx="ekr.20080121105837.99">#---- Scintilla style helpers.
def style_names_from_style_num(self, style_num):
    #XXX Would like to have python-foo instead of p_foo or SCE_P_FOO, but
    #    that requires a more comprehensive solution for all langs and
    #    multi-langs.
    style_names = []

    # Get the constant name from ScintillaConstants.
    if self.lang not in self._style_name_from_style_num_from_lang:
        name_from_num \
            = self._style_name_from_style_num_from_lang[self.lang] = {}
        if self.sce_prefixes is None:
            raise Error("'sce_prefixes' not set on class %s: cannot "
                        "determine style constant names"
                        % self.__class__.__name__)
        for attr in dir(ScintillaConstants):
            for sce_prefix in self.sce_prefixes:
                if attr.startswith(sce_prefix):
                    name_from_num[getattr(ScintillaConstants, attr)] = attr
    else:
        name_from_num \
            = self._style_name_from_style_num_from_lang[self.lang]
    const_name = self._style_name_from_style_num_from_lang[self.lang][style_num]
    style_names.append(const_name)

    # Get a style group from styles.py.
    if self.lang in styles.StateMap:
        for style_group, const_names in styles.StateMap[self.lang].items():
            if const_name in const_names:
                style_names.append(style_group)
                break
    else:
        log.warn("lang '%s' not in styles.StateMap: won't have "
                 "common style groups in HTML output" % self.lang)

    return style_names

</t>
<t tx="ekr.20080121105837.100">__string_styles = None
def string_styles(self):
    if self.__string_styles is None:
        state_map = styles.StateMap[self.lang]
        self.__string_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("strings", "stringeol")
            for style_name in state_map.get(style_class, [])
        ]
    return self.__string_styles

</t>
<t tx="ekr.20080121105837.101">__comment_styles = None
def comment_styles(self):
    if self.__comment_styles is None:
        state_map = styles.StateMap[self.lang]
        self.__comment_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("comments", "here documents",
                                "data sections")
            for style_name in state_map.get(style_class, [])
        ]
    return self.__comment_styles

</t>
<t tx="ekr.20080121105837.102">__number_styles = None
def number_styles(self):
    if self.__number_styles is None:
        state_map = styles.StateMap[self.lang]
        self.__number_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("numbers",)
            for style_name in state_map.get(style_class, [])
        ]
    return self.__number_styles



</t>
<t tx="ekr.20080121105837.103">#---- internal support stuff

# Recipe: htmlescape (1.0+) in C:\trentm\tm\recipes\cookbook
#         + whitespace option
def _htmlescape(s, quote=False, whitespace=False):
    """Replace special characters '&amp;', '&lt;' and '&gt;' by SGML entities.

    Also optionally replace quotes and whitespace with entities and &lt;br/&gt;
    as appropriate.
    """
    s = s.replace("&amp;", "&amp;amp;") # Must be done first!
    s = s.replace("&lt;", "&amp;lt;")
    s = s.replace("&gt;", "&amp;gt;")
    if quote:
        s = s.replace('"', "&amp;quot;")
    if whitespace:
        s = s.replace(' ', "&amp;nbsp;")
        #XXX Adding that '\n' might be controversial.
        s = re.sub(r"(\r\n|\r|\n)", "&lt;br /&gt;\n", s)
    return s



</t>
<t tx="ekr.20080121105837.104">#---- self-test

def _doctest():
    import doctest
    doctest.testmod()

</t>
<t tx="ekr.20080121105837.105">#!/usr/bin/env python
# ***** LICENSE BLOCK *****
&lt;&lt; citadel.py docstring &gt;&gt;

@language python
@tabwidth -4

#---- globals
log = logging.getLogger("codeintel.citadel")
#log.setLevel(logging.INFO)

&lt;&lt; imports &gt;&gt;
@others
</t>
<t tx="ekr.20080121105837.106">import os
from os.path import (isfile, isdir, exists, dirname, abspath, join, basename)
import sys
import logging
import time
import re
import traceback
from pprint import pprint

import ciElementTree as ET
import codeintel2
from codeintel2.buffer import Buffer
from codeintel2.common import *
from codeintel2.indexer import ScanRequest
#from codeintel2.scheduler import BatchUpdater
</t>
<t tx="ekr.20080121105837.107">#---- module interface


class CitadelBuffer(Buffer):
    &lt;&lt; class CitadelBuffer docstring &gt;&gt;
    # Local cache for buf data that is stored in the db. Each one of
    # these has a property for access.
    _scan_time_cache = None
    _scan_error_cache = None
    _blob_from_lang_cache = None

    @others
    #XXX Move citdl_expr_from_trg() here (see PythonBuffer)?



</t>
<t tx="ekr.20080121105837.108">def __init__(self, *args, **kwargs):
    Buffer.__init__(self, *args, **kwargs)
    self._scan_lock = threading.RLock()

</t>
<t tx="ekr.20080121105837.109"># Scanning can happen on different threads so access to scan data
# must be guarded.
def acquire_lock(self):
    self._scan_lock.acquire()
</t>
<t tx="ekr.20080121105837.110">def release_lock(self):
    self._scan_lock.release()

</t>
<t tx="ekr.20080121105837.111">_have_checked_db = False
def _load_buf_data_once(self):
    """Load persisted data for this buffer from the db.
    Raises NotFoundInDatabase is not there.
    """
    if not self._have_checked_db:
        self._have_checked_db = True
        self._scan_time_cache, self._scan_error_cache, \
            self._blob_from_lang_cache = self.mgr.db.get_buf_data(self)

</t>
<t tx="ekr.20080121105837.112">def defn_trg_from_pos(self, pos, lang=None):
    """Return a list of CI definitions for the CITDL expression
    at the given pos.
    """
    if lang is None:
        lang = self.lang
    return Trigger(lang, TRG_FORM_DEFN, "defn", pos, False, length=0)

</t>
<t tx="ekr.20080121105837.113">def defns_from_trg(self, trg, timeout=None, ctlr=None):
    self.async_eval_at_trg(trg, ctlr)
    ctlr.wait(timeout)
    if not ctlr.is_done():
        ctlr.done("timed out")
        raise EvalTimeout("eval for %s timed-out" % trg)
    return ctlr.defns # -&gt; list of Definition's

</t>
<t tx="ekr.20080121105837.114">@property
def scan_time(self):
    """The time of the last scan data. 
    
    This may be the time of the scan or the modification time of the
    buffer content at the last scan.  Typically this is set via the
    'mtime' optional argument to scan().

    This returns None if this file hasn't been scanned.
    """
    self.acquire_lock()
    try:
        if self._scan_time_cache is None:
            try:
                self._load_buf_data_once()
            except NotFoundInDatabase:
                pass
        return self._scan_time_cache
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.115">@property
def scan_error(self):
    "A string describing why the last scan failed, or None if it didn't."
    self.acquire_lock()
    try:
        if self._scan_error_cache is None:
            try:
                self._load_buf_data_once()
            except NotFoundInDatabase:
                pass
        return self._scan_error_cache
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.116">@property
def blob_from_lang(self):
    self.acquire_lock()
    try:
        if self._blob_from_lang_cache is None:
            try:
                self._load_buf_data_once()
            except NotFoundInDatabase:
                self.release_lock()
                try:
                    self.scan()
                finally:
                    self.acquire_lock()
        return self._blob_from_lang_cache
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.117">@property
def tree(self):
    """The CIX tree for this buffer. Will lazily scan if necessary."""
    self.acquire_lock()
    try:
        # SIDE-EFFECT: scan if necessary
        blob_from_lang = self.blob_from_lang

        tree = ET.Element("codeintel", version="2.0")
        path = self.path
        if os.sep != '/':
            path = path.replace(os.sep, '/')
        file = ET.SubElement(tree, "file", path=path,
                             lang=self.lang,
                             mtime=str(self._scan_time_cache))
        if self._scan_error_cache:
            file.set("error", self._scan_error_cache)
        if blob_from_lang:
            for lang, blob in sorted(blob_from_lang.items()):
                file.append(blob)
        return tree
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.118">@property
def cix(self):
    """The CIX for this buffer. Will lazily scan if necessary."""
    return ET.tostring(self.tree)

</t>
<t tx="ekr.20080121105837.119">def scan(self, mtime=None):
    """Scan the current buffer.

        "mtime" is the modification time of the buffer content. If
            not given the current time will be used.

    The results are stored on the buffer to be retrieved via the
    scan_time/scan_error/blob_from_lang properties.
    """
    if self.path is None:
        raise Error("cannot scan %s buffer: 'path' is not set (setting "
                    "a fake path starting with '&lt;Unsaved&gt;' is okay)"
                    % self.lang)

    cile_driver = self.mgr.citadel.cile_driver_from_lang(self.lang)
    if mtime is None:
        mtime = time.time()

    #TODO: Eventually would like the CILEDriver scan methods to have
    #      a signature more inline with
    #      blob_from_lang/scan_time/scan_error. I.e. drop
    #      &lt;file error="..."&gt; mechanism in favour of just raising
    #      CILEError.
    try:
        tree = cile_driver.scan_purelang(self)
    except CodeIntelError, ex:
        exc_info = sys.exc_info()
        exc_class, exc, tb = sys.exc_info()
        tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
        scan_error = "%s (%s:%s in %s)" % (exc, tb_path, tb_lineno, tb_func)
    except Exception, ex:
        msg = "unexpected error scanning `%s'" % basename(self.path)
        log.exception(msg)
        exc_info = sys.exc_info()
        exc_class, exc, tb = sys.exc_info()
        tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
        scan_error = "%s: %s (%s:%s in %s)"\
                     % (msg, exc, tb_path, tb_lineno, tb_func)
    else:
        scan_error = tree[0].get("error")

    self.acquire_lock()
    try:
        self._scan_time_cache = mtime
        self._scan_error_cache = scan_error
        if not scan_error: # Keep the old scan data if scan failed.
            self._blob_from_lang_cache = dict((b.get("lang"), b)
                                              for b in tree[0])
        elif self._blob_from_lang_cache is None:
            self._blob_from_lang_cache = {}
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.120">def scoperef_from_pos(self, pos):
    """Return the scoperef for the given position in this buffer.

    A "scoperef" is a 2-tuple:
        (&lt;blob&gt;, &lt;lpath&gt;)
    where &lt;blob&gt; is the ciElementTree blob for the buffer content
    and &lt;lpath&gt; is an ordered list of names into the blob
    identifying the scope.
    
    For example, given this "foo.py":

        class Foo:
            baz = 42
            def bar(self):
                print "bar bar!"

    the scoperef for the print line would be:

        (&lt;Python blob 'foo'&gt;, ["Foo", "bar"])

    If no relevant scope is found (e.g. for example, in markup
    content in PHP) then None is returned.
    """
    blob = self.blob_from_lang[self.lang]
    line = self.accessor.line_from_pos(pos) + 1 # convert to 1-based
    return self.scoperef_from_blob_and_line(blob, line)

</t>
<t tx="ekr.20080121105837.121">def scoperef_from_blob_and_line(self, blob, line): # line is 1-based
    lpath = []
    scope = blob
    while True:
        next_scope_could_be = None
        # PERF: Could make this a binary search if a scope has *lots* of
        # subscopes.
        for subscope in scope.findall("scope"):
            start = int(subscope.get("line"))
            if line &lt; start:
                break
            end = subscope.get("lineend") and int(subscope.get("lineend"))
            
            if end is not None:
                if end &lt; line:
                    next_scope_could_be = None
                else:
                    next_scope_could_be = subscope
            else:
                next_scope_could_be = subscope
        if next_scope_could_be is not None:
            lpath.append(next_scope_could_be.get("name"))
            scope = next_scope_could_be
        else:
            break
    return (blob, lpath)

</t>
<t tx="ekr.20080121105837.122"># These two are convenience methods for working with this buffer and
# the database.
def load(self, force=False):
    """Add this buffer's scan data to the database.
    
    Note: If the buffer content has changed you might need to
    manually force a scan via buf.scan(). Otherwise it is possible
    that the buffer will get the current data from the database (if
    it exists) and then turn around and update the db with that
    unchanged data. I.e. an expensive no-op.
    """
    self.mgr.db.update_buf_data(self, force=force)

</t>
<t tx="ekr.20080121105837.123">def unload(self):
    """Remove this buffer from the database."""
    self.mgr.db.remove_buf_data(self)

</t>
<t tx="ekr.20080121105837.124">class ImportHandler:
    """Virtual base class for language-specific "import"-statement handlers.
    
    The basic job of an import handler is to convert an import statement (i.e.
    a row in the 'import' table) into a row in the CIDB 'module' table. Doing
    this depends on language-specific import semantics.
    
    A fundamental part of import resolution is the search path. Here the
    search path is broken into three parts:
        - "core" path: built-in to the interpreter/compiler, generally
          dependent on the installation location.
        - "env" path: additional directories specified in a special
          environment variable, e.g. PYTHONPATH, PERL5LIB
        - "custom" path: additional "out-of-band" directories
    
    Each language-specific ImportHandler is a singleton as doled out by
    Citadel.import_handler_from_lang().
    """
    lang = None

    #DEPRECATED
    PATH_ENV_VAR = None
    corePath = None
    envPath = None
    customPath = None

    @others
</t>
<t tx="ekr.20080121105837.125">def __init__(self, mgr):
    self.mgr = mgr

</t>
<t tx="ekr.20080121105837.126">#DEPRECATED
def setCustomPath(self, path):
    """Specify some custom search directories."""
    self.customPath = path

</t>
<t tx="ekr.20080121105837.127">#DEPRECATED
def setEnvPath(self, value=None):
    """Specify the value of the PATH-style environment variable.
    
        "value" is the appropriate environment variable value, e.g.:
            "C:\trentm\mylib;C:\shared\lib-python". If value is None then
            the value will be retrieved from os.environ.

    This will lazily be called if necessary.
    """
    path = []
    if value is None:
        if self.PATH_ENV_VAR:
            path = os.environ.get(self.PATH_ENV_VAR, "").split(os.pathsep)
    else:
        path = value.split(os.pathsep)
    self.envPath = path

</t>
<t tx="ekr.20080121105837.128">#DEPRECATED
def setCorePath(self, compiler=None, extra=None):
    """Specify the data needed to determine the core search path.
    
        "compiler" is the path to the language compiler/interpreter.
            If not specified then the first appropriate
            compiler/interpreter on the path is used.
        "extra" (optional) can be used to specify required extra
            data for determining the core import path.  For example,
            the PHP-specific implementation uses this to specify the
            "php.ini"-config-file path.

    This will lazily be called if necessary.
    """
    # Sub-classes must implement this and set self.corePath as a
    # result (to [] if it could not be determined).
    raise NotImplementedError("setCorePath: pure virtual method call")

</t>
<t tx="ekr.20080121105837.129">#DEPRECATED
def _getPath(self, cwd=None):
    """Put all the path pieces together and return that list.
    
    If "cwd" is specified, it is prepended to the list. (In many languages
    the directory of the file with the import statement is first on the
    module search path.)
    """
    if self.corePath is None: self.setCorePath()
    if self.envPath is None: self.setEnvPath()
    if cwd is not None:
        path = [cwd]
    else:
        path = []
    if self.customPath:
        path += self.customPath
    path += self.envPath
    path += self.corePath
    return path

</t>
<t tx="ekr.20080121105837.130">#DEPRECATED
def findModuleOnDisk(self, module, submodule, cwd):
    """Find the full path to the given module on disk.
    
        "module" is a the module name (_can_ include dots, e.g. xml.sax)
        "submodule" is a possible sub-module to also include in the
            import path. Some languages allow you to separate the module
            and submodule tokens to control the imported symbol name. For
            example, submodule will be "sax" for this Python import:
                from xml import sax
            This kind of thing is not possible in Perl and hence the
            "submodule" argument can be ignored for a Perl
            implementation. Submodule would be "DumperX" from this Perl
            import:
                use Data::Dumper qw(DumperX);
        "cwd" is the directory of the module containing the import stmt.
    
    If successful, returns a 3-tuple:
        (&lt;module path&gt;, "module"|"submodule", &lt;scannable&gt;,
    where,
        the second element indicates if the returned module row
            corresponds to the given "module" or "submodule" argument.
        &lt;scannable&gt; is a boolean indicating if this file is likely
            scannable.

    Otherwise, returns (None, None, None).
    """
    raise NotImplementedError("findModuleOnDisk: pure virtual method call")

</t>
<t tx="ekr.20080121105837.131">#DEPRECATED
def findSubImportsOnDisk(self, module, cwd):
    """Return a list of importable submodules to the given module.
    
    The returned list is a list of strings that would be appropriate for
    direct use in the language's specific import statement. I.e.: for
    Perl:
        ["ConnCache", "Protocol", "UserAgent", ...]
    not:
        ["ConnCache.pm", "Protocol.pm", "UserAgent.pm", ...]
    For PHP, however, including the .php extension might be appropriate.
    """
    raise NotImplementedError("findSubImportsOnDisk: pure virtual method call")

</t>
<t tx="ekr.20080121105837.132">#DEPRECATED
def findModule(self, cu, factory, module, submodule, cwd=None):
    """Find the 'module' table row corresponding to the given import row.
    
        "cu" is an open CIDB cursor
        "factory" is a ThingyFactory instance to use.
        "module" is the module name (or path, e.g. "xml.sax")
        "submodule" is a possible sub-module to also include in the
            import path. Some languages allow you to separate the module
            and submodule tokens to control the imported symbol name. For
            example, submodule will be "sax" for this Python import:
                from xml import sax
            This kind of thing is not possible in Perl and hence the
            "submodule" argument can be ignored for a Perl
            implementation. Submodule would be "DumperX" from this Perl
            import:
                use Data::Dumper qw(DumperX);
        "cwd" is the directory of the module containing the import stmt.

    If successful, returns a 2-tuple:
        (&lt;module Scope instance&gt;, "module"|"submodule")
    The second element indicates if the returned module row corresponds
    to the given "module" or "submodule" argument.
    
    On failure (i.e. no entry for this module in the CIDB) a
    NoModuleEntry error is raised.
    """
    raise NotImplementedError("findModule: pure virtual method call")

</t>
<t tx="ekr.20080121105837.133">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    """Generate scannable files on the import path.
    
        "path" (optional) is an import path to load. If not specified
            the default import path is used.
        "skipRareImports" (optional, default false) is a boolean
            indicating if files unlikely to be imported/searched-for/used
            should be skipped. This can be specified to speed up, for
            example, scanning *all* files during a batch update of a
            language installation.
        "importableOnly" (optional, default false) is a boolean
            indicating if only those files that are importable from
            the given path should be included. For example a Python
            file in a subdirectory cannot be imported if that dir
            does not have a package-defining "__init__.py" file.
    """
    raise NotImplementedError("genScannableFiles: pure virtual method call")

</t>
<t tx="ekr.20080121105837.134">#---- new citree-based eval stuff

# The string that separates dir levels in import names. For example,
# this would be '.' for Python (import foo.bar), '::' for Perl
# (use Foo::Bar;), '/' for Ruby, etc. Must be set for each language.
sep = None

def find_importables_in_dir(self, dir):
    """Return a mapping of
        import-name -&gt; (path, subdir-import-name, is-dir-import)
    for all possible importable "things" in the given dir. Each part
    is explained below.
    
    The "import-name" is the string that you'd use in the particular
    language's import statement:
                    import statement        import-name     path
                    ----------------        -----------     ----
        Python:     import foo              foo             foo.py
        Perl:       use Foo;                Foo             Foo.pm
        Ruby:       require 'foo'           foo             foo.rb
        PHP:        require("foo.php")      foo.php         foo.php
                    require("foo.inc")      foo.inc         foo.inc
    
    For the simple case of a directly imported file in this dir, the
    "subdir-import-name" isn't relevant so None is used:
        Python:     "foo": ("foo.py", None, ...)
        Perl:       "Foo": ("Foo.pm", None, ...)
        Ruby:       "foo": ("foo.rb", None, ...)
        PHP:        "foo.php": ("foo.php", None, ...)
                    "foo.inc": ("foo.inc", None, ...)

    In addition to importable files in the given dir, this function
    must also provide the link to imports in *sub-directories*.  In
    Python a special "__init__.py" in subdirs is actually imported
    when a dir is specified. Here the "subdir-import-name" becomes
    relevant:
        Python:     "bar": ("bar/__init__.py", "__init__", False)

    In most languages there isn't a special file to indicate this.
    However the dir name *can* appear as part of an import
    statement. The "is-dir-import" boolean is used to indicate that
    the "import-name" can be used as part of a multi-level import
    statement:
        Perl:       "Bar": (None, None, True)
        Ruby:       "bar": (None, None, True)
        PHP:        "bar": (None, None, True)

    Some of these latter languages occassionally have an importable
    file *and* a sub-directory of the same name.
        Perl:       LWP.pm and LWP/... in the stdlib
        Ruby:       shell.rb and shell/... in the stdlib
    In these cases:
        Perl:       "LWP": ("LWP.pm", None, True)
        Ruby:       "shell": ("shell.rb", None, True)

    """
    raise NotImplementedError("find_importables_in_dir: virtual method")

</t>
<t tx="ekr.20080121105837.135">def import_blob_name(self, import_name, libs, ctlr):
    """Return the blob tree for the given import name and libs.

        "import_name" is the name used in the language's
            import/use/require statement under which blob
            information is generally keyed in the database.
        "libs" is an order list of libraries in which to search for
            the blob. See database/database.py's module docstring
            for info on the Library API.
        "ctlr" is the EvalController instance. Logging is done
            on this, and ctlr.is_aborted() may be used to abort
            processing.
    """
    #TODO: Will have to add "submodule" arg a la findModule() above
    for lib in libs:
        blob = lib.get_blob(import_name)
        if blob is not None:
            ctlr.info("is blob '%s' from %s? yes", import_name, lib)
            return blob
        else:
            ctlr.info("is blob '%s' from %s? no", import_name, lib)
    else:
        raise CodeIntelError("could not find data for %s blob '%s'"
                             % (self.lang, import_name))



</t>
<t tx="ekr.20080121105837.136">class CitadelEvaluator(Evaluator):
    """A Citadel evaluator -- i.e. the guy that knows how to translate
    a CITDL expression into a list of completions or a calltip.
    """
    citadel = None
    have_requested_reeval_already = False # sentinel to trap infinite loop

    @others
</t>
<t tx="ekr.20080121105837.137">def __init__(self, ctlr, buf, trg, expr, line):
    Evaluator.__init__(self, ctlr, buf, trg)
    self.lang = buf.lang #XXX should use trg.lang instead (multi-lang differs)
    self.path = buf.path
    self.cwd = dirname(self.path)
    self.expr = expr #XXX should be rigorous and use citdl_expr
    self.line = line # 0-based

</t>
<t tx="ekr.20080121105837.138">def __str__(self):
    return "'%s' at %s#%s" % (self.expr, basename(self.path), self.line+1)

</t>
<t tx="ekr.20080121105837.139">def post_process_cplns(self, cplns):
    """Hook for sub-classes to post-process the list of completions.
    
    Implementations may modify the list in place.
    
    Note that a common operation that all implementations should
    generally do (and the default impl. *does*) is to sort the list
    of completions case-insensitively by value. Sorting is necessary
    to have type-ahead-find work properly in Scintilla's autocomplete
    UI and case-insensitive sorting is necessary if using Scintilla's
    SCI_AUTOCSETIGNORECASE(true) -- which Komodo is. To do this:
            cplns.sort(key=lambda c: c[1].upper())
    """
    cplns.sort(key=lambda c: c[1].upper())
    return cplns

</t>
<t tx="ekr.20080121105837.140">def post_process_calltips(self, calltips):
    """Hook for sub-classes to post-process the list of calltips.
    
    Implementations may modify the list in place.
    """
    return calltips

</t>
<t tx="ekr.20080121105837.141">def post_process_defns(self, defns):
    """Hook for sub-classes to post-process the list of defns.
    
    Implementations may modify the list in place.
    """
    return defns

</t>
<t tx="ekr.20080121105837.142">def request_reeval(self):
    """Used for an on_complete callback to CitadelBuffer.scan_and_load()."""
    assert not self.have_requested_reeval_already, \
        "invalid eval usage: cannot request re-eval more than once"
    self.have_requested_reeval_already = True

    if self.ctlr.is_aborted():
        self.ctlr.done("aborting")
        return
    self.ctlr.info("request re-eval of %s", self)
    self.mgr.request_reeval(self)

</t>
<t tx="ekr.20080121105837.143">def import_resolution_failure(self, name, path):
    """Called by import-resolution code to offer ability to react to
    a module import not resolving in the CIDB.
    
    The nice-to-have plan was to request a scan of this module and then
    re-evaluate at this trigger when that was finished. If well behaved
    this would give the best completion GOOBE to the user: the first
    time may be slow, but it just works.

    PUNTing on that for now because (1) of fear of this not being
    well-behaved: repeated (and hence performance intensive) attempted
    scanning of a module that doesn't quite make it into to the CIDB.
    Could monitor that with a "3 strikes" rule or something. Also (2),
    the *real* solution should involve re-scanning of modules that
    are newer than our scan info. This logic belongs on a Buffer for
    that module (or something). Revisit when/if refactoring codeintel
    the next time through.
    """
    self.ctlr.warn("no info on import '%s'", name)
    #log.warn("XXX Currently not reacting to import resolution failure. "
    #         "Try to do that later. (path=%s)" % path)


</t>
<t tx="ekr.20080121105837.144">#---- the guts of the evaluation

def debug(self, msg, *args):
    self.ctlr.debug(msg, *args)
</t>
<t tx="ekr.20080121105837.145">def info(self, msg, *args):
    self.ctlr.info(msg, *args)
</t>
<t tx="ekr.20080121105837.146">def warn(self, msg, *args):
    self.ctlr.warn(msg, *args) #XXX why was this "info"?
</t>
<t tx="ekr.20080121105837.147">def error(self, msg, *args):
    self.ctlr.error(msg, *args)


</t>
<t tx="ekr.20080121105837.148">class Citadel(object):
    """The manager of Citadel-parts of the CodeIntel system. This is a
    singleton canonically available from Manager.citadel.
    
    Usage
    -----

    Typically all interaction with a Citadel is done via a Manager instance.
    Here is what the Manager should be doing.

        citadel = Citadel(mgr, ...)
        
        #XXX Obsolete
        # Upgrade the CIDB, if necessary via appropriate usage of:
        #   .cidb_upgrade_info()
        #   .upgrade_cidb()
        #   .reset_cidb()

        citadel.initialize()

        # Use the citadel. The most common methods are:
        #   .{add|stage}_scan_request()
        # and making batch updates (described below).

        # Must be finalized to ensure no thread hangs.
        citadel.finalize()

    Making Batch Updates
    --------------------
    
        citadel.batch_update_request(...) # make one or more request
        citadel.batch_update_start(...)   # start the update

    By default .batch_update_start() will block until the update is complete.
    This (and other control of the update process) can be customized by
    passing in your own controller.
    """
    MIN_CIDB_VERSION = (1, 0)  # minimum supported database version

    @others
</t>
<t tx="ekr.20080121105837.149">def __init__(self, mgr):
    self.mgr = mgr

    self._import_handler_from_lang = {}
    self._cile_driver_from_lang = {}
    self._is_citadel_cpln_from_lang = {}

    self._scheduler = None # the scheduler thread, started as required
    self.batch_updater = None
    # Boolean indicating if a late-created main scheduler should NOT be
    # started immediately (because a BatchScheduler is already running).
    self._wait_to_start_scheduler = False

</t>
<t tx="ekr.20080121105837.150">def set_lang_info(self, lang, cile_driver_class, is_cpln_lang=False):
    self._cile_driver_from_lang[lang] = cile_driver_class(self.mgr)
    if is_cpln_lang:
        self._is_citadel_cpln_from_lang[lang] = True

</t>
<t tx="ekr.20080121105837.151">def cile_driver_from_lang(self, lang):
    """Return the CILE driver for this language.
    
    Raises KeyError if there isn't one registered.
    """
    return self._cile_driver_from_lang[lang]

</t>
<t tx="ekr.20080121105837.152">def is_citadel_cpln_lang(self, lang):
    """Return true if the given lang is a Citadel-based completion
    lang.
    """
    return lang in self._is_citadel_cpln_from_lang
</t>
<t tx="ekr.20080121105837.153">def get_citadel_cpln_langs(self):
    return self._is_citadel_cpln_from_lang.keys()

</t>
<t tx="ekr.20080121105837.154">def finalize(self):
    pass

</t>
<t tx="ekr.20080121105837.155">def batch_update(self, join=True, updater=None):
    """Do a batch update.
    
        "join" (optional, default True) indicates if this should
            block until complete. If False this will return immediately
            and you must manually .join() on the updater.
        "updater" (optional) is an BatchUpdater instance (generally
            a customized subclass of) used to do the update process.
    """
    if self.batch_updater is not None:
        raise CodeIntelError("cannot start batch update: another batch "
                             "update is in progress")

    assert(join or updater is not None,
           "cannot specify join=False and updater=None because "
           "you must manually wait on the updater if join is False.")
    if updater is None:
        updater = BatchUpdater()
    assert (isinstance(updater, BatchUpdater),
            "given controller is not an instance of "
            "BatchUpdater: %r" % updater)

    if self._scheduler is not None:
        self._scheduler.pause()
    else:
        self._wait_to_start_scheduler = True

    self.batch_updater = updater
    updater.start(self, on_complete=self._batch_update_completed)
    if join:
        updater.join()

</t>
<t tx="ekr.20080121105837.156">def _batch_update_completed(self):
    self._wait_to_start_scheduler = False
    if self._scheduler is not None:
        if self._scheduler.isAlive():
            self._scheduler.resume()
        else:
            self._scheduler.start()
    self.batch_updater = None

</t>
<t tx="ekr.20080121105837.157">#_SHOW_PROGRESS_ON_ONE_LINE = True
#def batchUpdateProgress(self, stage, obj):
#    """Called when progress is made on a set of batch update requests.
#    
#        "stage" is a string defining the current processing stage.
#        "obj" is some object relevant to a particular stage to describe
#            is state of progress.
#    
#    Subclasses can override this for custom handling.
#    """
#    if self._batchProgressQuiet:
#        return
#
#    cache = self._batchProgressCache or {}
#    if stage == "Preparing database": # a.k.a. removing db indices
#        name, current, total = obj
#        line = "%s: %s" % (stage, name)
#    elif stage == "Restoring indices":
#        name, current, total = obj
#        line = "%s: %s" % (stage, name)
#    elif stage == "Gathering files":
#        line = "Gathering files: %s files" % obj
#    elif stage == "Scanning": # 'obj' is a request object
#        # Scanning: [#####        ] (1/12) ...tel\xsltcile.py ETA: 5 min
#        remaining = self._batch_scheduler.getNumFilesToProcess()+1
#        total = cache.setdefault("total_files", remaining)
#        # Progress meter section
#        percent = float(total-remaining)/float(total)
#        METER_WIDTH = 20
#        meterTemplate = "%%-%ds" % METER_WIDTH
#        meter = meterTemplate % ("#"*int(METER_WIDTH*percent))
#        # Count and file section
#        # 79: display width; 25: other stuff, e.g. "Scanning", "ETA: ..."
#        file = obj.path
#        COUNT_AND_FILE_WIDTH = 79 - 25 - METER_WIDTH
#        count = "(%d/%d)" % (total-remaining+1, total)
#        FILE_WIDTH = COUNT_AND_FILE_WIDTH - len(count) - 1
#        if len(file) &gt; FILE_WIDTH:
#            file = "..."+file[-FILE_WIDTH+3:]
#        countAndFile = "%s %s" % (count, file)
#        # ETA section
#        now = time.time()
#        if "starttime" in cache:
#            elapsedsecs = now - cache["starttime"]
#            totalsecs = elapsedsecs / percent
#            remainsecs = totalsecs - elapsedsecs
#            if remainsecs &lt; 60.0:
#                eta = "ETA: %d sec" % int(remainsecs)
#            elif (remainsecs/60.0 &lt; 60.0):
#                eta = "ETA: %d min" % int(remainsecs/60.0)
#            else:
#                eta = "ETA: %d hr" % int(remainsecs/3600.0)
#        else:
#            cache["starttime"] = now
#            eta = ""
#        # Put sections together
#        line_template = "Scanning: [%%s] %%-%ds %%s" % COUNT_AND_FILE_WIDTH
#        line = line_template % (meter, countAndFile, eta)
#    else:
#        line = "%s: %s" % (stage, obj)
#    if self._SHOW_PROGRESS_ON_ONE_LINE and "last_line" in cache:
#        length = len(cache["last_line"])
#        sys.stdout.write( "\b \b"*length )
#    sys.stdout.write(line)
#    if not self._SHOW_PROGRESS_ON_ONE_LINE:
#        sys.stdout.write('\n')
#    cache["last_line"] = line
#    self._batchProgressCache = cache
#
#def batchUpdateCompleted(self, reason):
#    """Called when a set of batch update requests are completed.
#    
#    Subclasses can override this for custom handling.
#    """
#    if self._batchProgressQuiet:
#        return
#
#    cache = self._batchProgressCache or {}
#    if "starttime" in cache:
#        totalsecs = time.time() - cache["starttime"]
#        if totalsecs &lt; 60.0:
#            elapsed = "%d seconds" % int(totalsecs)
#        elif (totalsecs/60.0 &lt; 60.0):
#            elapsed = "%d minute(s)" % int(totalsecs/60.0)
#        else:
#            elapsed = "%d hour(s)" % int(totalsecs/3600.0)
#    else:
#        elapsed = None
#    errors = self._lastBatchUpdateErrors
#    if self._SHOW_PROGRESS_ON_ONE_LINE and "last_line" in cache:
#        length = len(cache["last_line"])
#        sys.stdout.write( "\b \b"*length )
#    if reason == "completed":
#        sys.stdout.write("Batch update completed.")
#    elif reason == "stopped":
#        sys.stdout.write("Batch update was cancelled.")
#    elif reason == "error":
#        sys.stdout.write("Batch update errored out.")
#    else:
#        sys.stdout.write("Batch update completed (%s)." % reason)
#    if elapsed: sys.stdout.write(" Running time: %s." % elapsed)
#    if errors: sys.stdout.write(" There were %d errors:" % len(errors))
#    sys.stdout.write("\n")
#    if errors:
#        print "\t"+"\n\t".join(errors)

def import_handler_from_lang(self, lang):
    """Return an "import"-handler for the given language.

    Returns None if don't know how to handle imports for this language.
    Each language-specific ImportHandler object is a singleton.

    TODO: move this to Manager class.
    """
    if lang not in self._import_handler_from_lang:
        try:
            self._import_handler_from_lang[lang] \
                = self.mgr.import_handler_class_from_lang[lang](self.mgr)
        except KeyError:
            raise CodeIntelError("there is no registered ImportHandler "
                                 "class for language '%s'" % lang)
    return self._import_handler_from_lang[lang]


</t>
<t tx="ekr.20080121105837.158">@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;
@others
</t>
<t tx="ekr.20080121105837.159"># ***** BEGIN LICENSE BLOCK *****

"""Common definitions for the Citadel parts of codeintel."""

import os
import sys
import md5
import re
import stat
import time
import threading
import logging

from codeintel2.common import *

log = logging.getLogger("codeintel.citadel")



</t>
<t tx="ekr.20080121105837.160">class ScanRequest:
    """A request to scan a file for code intel.
    
    A ScanRequest has the following properties:
        "id" is a unique ID for this request. It is assigned by the
            scheduler when the request is made.
        "path" is the full canonicalized path to the file to scan. The path
            is canonicalized when set in the constructor.
        "language" is the content-type of the file. This determines what
            "Language Engine(s)" are used to scan it. (XXX Specify allowable
            range of languages.)
        "priority" must be one of the PRIORITY_* priorities.
        "force" is a boolean indicating if a scan should be run even if
            the database is already up-to-date for this content.
        "content" is the file content. This can be explicitly given in the
            constructor. This is useful if the current content is not
            saved to disk or if it is difficult to retrieve the content.
            If not specified the loadContent() method will be used to
            get it from the filename.  Subclasses can override
            loadContent() if necessary.
        "md5sum" is the MD5 hexdigest of the content.  If already
            calculated it may be specified in the constructor. Otherwise
            this can be calculated as needed via the calculateMD5()
            method.
        "mtime" is the modified time of the file/content. If this is not
            given, it is determined lazily (if content is NOT specified) or
            defaults to the current time (if content IS specified).
        "scan_imports" is a boolean (default true) indicating that
            imports should be scheduled for scanning when this file is
            loaded into the database.
        "on_complete" (optional) is a callable to call when the scan
            and load is complete.
    """
    @others
</t>
<t tx="ekr.20080121105837.161">def __init__(self, path, language, priority, force=0, content=None,
             md5sum=None, mtime=None, scan_imports=True,
             on_complete=None):
    self.id = None
    self.path = path
    self.language = language
    self.priority = priority
    self.force = force
    self.content = content
    if mtime:
        self.mtime = mtime
    elif content is not None:
        # Presumably if the content is being specified rather than having
        # the request's loadContent() determine it, then it is from an
        # editor buffer and may have changed just recently.
        self.mtime = int(time.time())
    else:
        self.mtime = None # determine lazily
    self.md5sum = md5sum
    self.scan_imports = scan_imports
    self.on_complete = on_complete
    self.complete_event = threading.Event() #XXX use a pool
</t>
<t tx="ekr.20080121105837.162">def __repr__(self):
    return "&lt;ScanRequest id:%r, path:'%s'&gt;" % (self.id, self.path)
</t>
<t tx="ekr.20080121105837.163">def __str__(self):
    return "scan request '%s' (prio %s)" % (self.path, self.priority)
</t>
<t tx="ekr.20080121105837.164">def complete(self):
    """Called by scheduler when this scan is complete (whether or
    not it was successful/skipped/whatever).
    """
    log.info("complete %s", self)
    self.complete_event.set()
    if self.on_complete:
        try:
            self.on_complete()
        except:
            log.exception("ignoring exception in ScanRequest "
                          "on_complete callback")
</t>
<t tx="ekr.20080121105837.165">def wait(self, timeout=None):
    """Can be called by code requesting a scan to wait for completion
    of this particular scan.
    """
    self.complete_event.wait(timeout)
</t>
<t tx="ekr.20080121105837.166">def loadContent(self):
    """If self.content is not set, load it from self.path.
    
    This also sets self.mtime, if necessary.
    This can raise an EnvironmentError if the file is not accessible.
    """
    if self.content is None:
        self.mtime = os.stat(self.path)[stat.ST_MTIME]
        fin = open(self.path, "r")
        try:
            self.content = fin.read()
        finally:
            fin.close()
</t>
<t tx="ekr.20080121105837.167">def calculateMD5(self):
    """Calculate and set self.md5sum if is it not already set."""
    if self.md5sum is None:
        self.loadContent()
        self.md5sum = md5.new(self.content).hexdigest()
</t>
<t tx="ekr.20080121105837.168">def getCanonicalPath(self):
    return canonicalizePath(self.path)

</t>
<t tx="ekr.20080121105837.169">@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;
&lt;&lt; globals &gt;&gt;

@others

#---- self-test code

if __name__ == '__main__':
    def _test():
        import doctest, common
        return doctest.testmod(common)
    _test()
</t>
<t tx="ekr.20080121105837.170">#!python

"""Code Intelligence: common definitions"""
# Dev Notes:
# - XXX Need some good top-level logging control functions for this package.
# - XXX Rationalize exceptions.
# - XXX Coding style name changes.

#XXX Use cog to fill out __all__.
#__all__ = []

import os
from os.path import dirname, join, normpath, exists, basename
import sys
import md5
import re
import stat
import time
import threading
import logging

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

try:
    from xpcom import components
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False

#XXX Should only do this hack for non-Komodo local codeintel usage.
#XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir


#---- general codeintel pragmas

# Allow the CILEs to generate type guesses based on type names (e.g.
# "event" is an Event in JS).
ENABLE_HEURISTICS = True 



</t>
<t tx="ekr.20080121105837.171">#---- globals

# Trigger forms.
TRG_FORM_CPLN, TRG_FORM_CALLTIP, TRG_FORM_DEFN = range(3)

# Priorities at which scanning requests can be scheduled.
PRIORITY_CONTROL = 0        # Special sentinal priority to control scheduler
PRIORITY_IMMEDIATE = 1      # UI is requesting info on this file now
PRIORITY_CURRENT = 2        # UI requires info on this file soon
PRIORITY_OPEN = 3           # UI will likely require info on this file soon
PRIORITY_BACKGROUND = 4     # info may be needed sometime

# CIDB base type constants
BT_CLASSREF, BT_INTERFACEREF = range(2)

# CIDB symbol type constants
(ST_FUNCTION, ST_CLASS, ST_INTERFACE, ST_VARIABLE, ST_ARGUMENT) = range(5)
_symbolType2Name = {
    ST_FUNCTION: "function",
    ST_CLASS: "class",
    ST_INTERFACE: "interface",
    ST_VARIABLE: "variable",
    ST_ARGUMENT: "argument"
}

</t>
<t tx="ekr.20080121105837.172"></t>
<t tx="ekr.20080121105837.173">#---- exceptions

class CodeIntelError(Exception):
    """Base Code Intelligence system error."""
    pass
</t>
<t tx="ekr.20080121105837.174">Error = CodeIntelError #XXX Remove uses of this in favour of CodeIntelError.

class NotATriggerError(CodeIntelError):
    pass
</t>
<t tx="ekr.20080121105837.175">class EvalError(CodeIntelError):
    pass
</t>
<t tx="ekr.20080121105837.176">class EvalTimeout(EvalError):
    pass

</t>
<t tx="ekr.20080121105837.177">class VirtualMethodError(CodeIntelError):
    #TODO: pull out the method and class name from the stack for errmsg
    #      tell user what needs to be implemented
    pass

</t>
<t tx="ekr.20080121105837.178">class CitadelError(CodeIntelError):
    pass

</t>
<t tx="ekr.20080121105837.179">class NoBufferAccessorError(CodeIntelError):
    """The accessor has no buffer/content to access."""
    pass

</t>
<t tx="ekr.20080121105837.180">class CILEError(CitadelError):
    """CILE processing error."""
    #XXX Should add some relevant data to the exception. Perhaps
    #    the request should be passed in and this c'tor can extract
    #    data it wants to keep.  This could be used to facilitate
    #    submitting bug reports on our Language Engines.
    pass


</t>
<t tx="ekr.20080121105837.181">class CIXError(CitadelError):
    """Code Intelligence XML error."""
    pass

</t>
<t tx="ekr.20080121105837.182">class CIDBError(CitadelError):
    """Code Intelligence Database error."""
    #TODO: Transition to DatabaseError and ensure that the change in
    #      base class doesn't cause problems.
    pass

</t>
<t tx="ekr.20080121105837.183">class DatabaseError(CodeIntelError):
    pass

</t>
<t tx="ekr.20080121105837.184">class CorruptDatabase(DatabaseError):
    """Corruption in some part of the database was found."""
    #XXX Should add attributes that indicate which part
    #    was corrupt and/or one of a known set of possible corrupts.
    #    Then add a Database.recover() function that could attempt
    #    to recover with that argument.
    pass

</t>
<t tx="ekr.20080121105837.185">class NotFoundInDatabase(DatabaseError):
    """No data for the buffer was found in the database."""
    pass


</t>
<t tx="ekr.20080121105837.186">class CITDLError(CitadelError):  #XXX Just drop in favour of CitadelError?
    """CITDL syntax error."""
    pass


</t>
<t tx="ekr.20080121105837.187">class NoModuleEntry(CIDBError):
    """There is no entry for this module in the CIDB.
    
    The "module_path" second constructor argument (possibly None) is required
    to allow completion handling (which will be trapping these errors) to use
    that path to kick off a scan for it. This shouldn't be a burden as the
    import handlers that raise this will just have looked for this path.
    """
    @others
</t>
<t tx="ekr.20080121105837.188">def __init__(self, module_name, module_path):
    CIDBError.__init__(self)
    self.module_name = module_name # the module name
    self.module_path = module_path
</t>
<t tx="ekr.20080121105837.189">def __str__(self):
    path_info = ""
    if self.module_path:
        path_info = " (%s)" % os.path.basename(self.module_path)
    return "no module entry for '%s'%s in CIDB"\
           % (self.module_name, path_info)

</t>
<t tx="ekr.20080121105837.190">class NoCIDBModuleEntry(CIDBError): #XXX change name to NoModuleEntryForPath
    """There is no module entry for the given path in the CIDB."""
    @others
</t>
<t tx="ekr.20080121105837.191">def __init__(self, path):
    CIDBError.__init__(self)
    self.path = path
</t>
<t tx="ekr.20080121105837.192">def __str__(self):
    return "no module entry for '%s' in CIDB"\
           % os.path.basename(self.path)



</t>
<t tx="ekr.20080121105837.193">#---- common codeintel base classes</t>
<t tx="ekr.20080121105837.194">
class Trigger(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelTrigger]

    lang = None  # e.g. "Python", "CSS"
    form = None  # TRG_FORM_CPLN or TRG_FORM_CALLTIP
    type = None  # e.g. "object-members"
    pos = None
    implicit = None
    # The number characters of the trigger. For most (but not all) triggers
    # there is a clear distinction between a trigger token and a preceding
    # context token. For example:
    #       foo.&lt;|&gt;         # trigger token is '.', length = 1
    #       Foo::Bar-&gt;&lt;|&gt;   # trigger token is '-&gt;', length = 2
    # This default to 1.
    length = None

    @others
</t>
<t tx="ekr.20080121105837.195">def __init__(self, lang, form, type, pos, implicit, length=1,
             **extra):
    self.lang = lang
    self.form = form
    self.type = type
    self.pos = pos
    self.implicit = implicit
    self.length = length
    self.extra = extra # Trigger-specific extra data, if any

</t>
<t tx="ekr.20080121105837.196">@property
def id(self):
    return (self.lang, self.form, self.type)

</t>
<t tx="ekr.20080121105837.197">__name = None
@property
def name(self):
    """A more user-friendly name for this trigger, e.g.
    'python-complete-object-members'
    """
    if self.__name is None:
        form_str = {TRG_FORM_CPLN: "complete",
                    TRG_FORM_DEFN: "defn",
                    TRG_FORM_CALLTIP: "calltip"}[self.form]
        self.__name = "%s-%s-%s" % (self.lang.lower(), form_str,
                                    self.type)
    return self.__name

</t>
<t tx="ekr.20080121105837.198">def __repr__(self):
    explicit_str = (not self.implicit) and " (explicit)" or ""
    return "&lt;Trigger '%s' at %d%s&gt;" % (self.name, self.pos, explicit_str)

</t>
<t tx="ekr.20080121105837.199">def is_same(self, trg):
    """Return True iff the given trigger is (effectively) the same
    as this one.
    
    Dev Note: "Effective" is currently left a little fuzzy. Just
    comparing enough to fix Komodo Bug 55378.
    """
    if _xpcom_:
        trg = UnwrapObject(trg)
    if (self.pos == trg.pos
        and self.type == trg.type
        and self.form == trg.form
        and self.lang == trg.lang):
        return True
    else:
        return False


</t>
<t tx="ekr.20080121105837.200">class Definition(object):
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelDefinition]

    lang = None        # e.g. "Python", "CSS"
    path = None        # e.g. "/usr/local/..."
    blobname = None    # e.g. "sys"
    lpath = None       # lookup tuple in blob, e.g. ["MyClass", "afunc"]
    name = None        # e.g. "path"
    line = None        # e.g. 345
    ilk = None         # e.g. "function"
    citdl = None       # e.g. "int"
    signature = None   # e.g. "function xyz(...)"
    doc = None         # e.g. "Xyz is just nasty stuff..."
    attributes = None  # e.g. "local private"
    returns = None     # e.g. "int"

    @others
</t>
<t tx="ekr.20080121105837.201">def __init__(self, lang, path, blobname, lpath, name, line, ilk,
             citdl, doc, signature=None, attributes=None,
             returns=None):
    self.lang = lang
    self.path = path
    self.blobname = blobname
    self.lpath = lpath
    self.name = name
    self.line = line
    self.ilk = ilk
    self.citdl = citdl
    self.doc = doc
    self.signature = signature
    self.attributes = attributes
    self.returns = returns

</t>
<t tx="ekr.20080121105837.202">def __repr__(self):
    if self.path is None:
        return "&lt;Definition: %s '%s' at %s#%s&gt;"\
                % (self.ilk, self.name, self.blobname, self.line)
    else:
        return "&lt;Definition: %s '%s' at %s#%s in %s&gt;"\
                % (self.ilk, self.name, self.blobname, self.line,
                   basename(self.path))


</t>
<t tx="ekr.20080121105837.203">class CILEDriver(object):
    """Base class for all CILE drivers.
    
    CILE stands for "CodeIntel Language Engine". A CILE is the thing that
    knows how to convert content of a specific language to CIX (the XML data
    loaded into the CIDB, then used for completion, code browsers, etc.)
    
    A CILE *driver* is a class that implements this interface on top of a
    language's CILE. A CILE might be a Python module, a separate executable,
    whatever.
    """
    @others
</t>
<t tx="ekr.20080121105837.204">def __init__(self, mgr):
    self.mgr = mgr

</t>
<t tx="ekr.20080121105837.205">#DEPRECATED
def scan(self, request):
    """Scan the given file and return data as a CIX document.

        "request" is a ScanRequest instance.

    This method MUST be re-entrant. The scheduler typically runs a pool
    of scans simultaneously so individual drivers can be called into from
    multiple threads.
    
    If the scan was successful, returns a CIX document (XML). Note: the
    return value should be unicode string, i.e. NOT an encoded byte
    string -- encoding to UTF-8 is done as necessary elsewhere.
    
    Raises a CILEError if there was a problem scanning. I.e. a driver
    should be resistant to CILE hangs and crashes.
    """
    raise VirtualMethodError("CILEDriver.scan")

</t>
<t tx="ekr.20080121105837.206">def scan_purelang(self, buf):
    """Scan the given buffer and return a CIX element tree.

        "buf" is an instance of this language's Buffer class.
    """
    raise VirtualMethodError("CILEDriver.scan_purelang")

</t>
<t tx="ekr.20080121105837.207">def scan_multilang(self, buf, csl_cile_driver=None):
    """Scan the given multilang (UDL-based) buffer and return a CIX
    element tree.

        "buf" is the multi-lang UDLBuffer instance (e.g.
            lang_rhtml.RHTMLBuffer for RHTML).
        "csl_cile_driver" (optional) is the CSL (client-side language)
            CILE driver. While scanning, CSL tokens should be gathered and,
            if any, passed to the CSL scanner like this:
                csl_cile_driver.scan_csl_tokens(
                    file_elem, blob_name, csl_tokens)
            The CSL scanner will append a CIX &lt;scope ilk="blob"&gt;
            element to the &lt;file&gt; element.

    A language that supports being part of a multi-lang document
    must implement this method.
    """
    raise VirtualMethodError("CILEDriver.scan_multilang")

</t>
<t tx="ekr.20080121105837.208">def scan_csl_tokens(self, file_elem, blob_name, csl_tokens):
    """Generate a CIX &lt;scope ilk="blob"&gt; tree for the given CSL
    (client-side language) tokens and append the blob to the given
    file element.

    A language that supports being a client-side language in a
    multi-lang document must implement this method. Realistically
    this just means JavaScript for now, but could eventually include
    Python for the new Mozilla DOM_AGNOSTIC work.
    """
    raise VirtualMethodError("CILEDriver.scan_csl_tokens")


</t>
<t tx="ekr.20080121105837.209">class EvalController(object):
    """A class for interaction with an asynchronous evaluation of completions
    or calltips. Typically for "interesting" interaction on would subclass
    this and pass an instance of that class to Buffer.async_eval_at_trg().
    """
    if _xpcom_:
        _com_interfaces_ = [components.interfaces.koICodeIntelEvalController]

    @others
</t>
<t tx="ekr.20080121105837.210">def __init__(self):
    self.complete_event = threading.Event() # use a pool?
    self._done = False
    self._aborted = False
    self.buf = None
    self.trg = None
    self.cplns = None
    self.calltips = None
    self.defns = None
    self.desc = None

</t>
<t tx="ekr.20080121105837.211">def start(self, buf, trg):
    """Called by the evaluation engine to indicate the beginning of
    evaluation and to pass in data the controller might need.
    """
    self.buf = buf
    self.trg = trg

</t>
<t tx="ekr.20080121105837.212">def set_desc(self, desc):
    self.desc = desc

</t>
<t tx="ekr.20080121105837.213">def done(self, reason):
    """Called by the evaluation engine to indicate completion handling
    has finished."""
    self.info("done eval: %s", reason)
    self._done = True
    self.buf = None
    self.trg = None
    self.complete_event.set()
</t>
<t tx="ekr.20080121105837.214">def is_done(self):
    return self._done

</t>
<t tx="ekr.20080121105837.215">def abort(self):
    """Signal to completion handling system to abort the current
    completion session.
    """
    self._aborted = True
</t>
<t tx="ekr.20080121105837.216">def is_aborted(self):
    return self._aborted

</t>
<t tx="ekr.20080121105837.217">def wait(self, timeout=None):
    """Block until this completion session is done or
    until the timeout is reached.
    """
    self.complete_event.wait(timeout)

</t>
<t tx="ekr.20080121105837.218">def debug(self, msg, *args): pass
</t>
<t tx="ekr.20080121105837.219">def info(self, msg, *args): pass
</t>
<t tx="ekr.20080121105837.220">def warn(self, msg, *args): pass
</t>
<t tx="ekr.20080121105837.221">def error(self, msg, *args): pass

</t>
<t tx="ekr.20080121105837.222">#XXX Perhaps this capturing should be in a sub-class used only for
#    testing. Normal IDE behaviour is to fwd the data in set_*().
def set_cplns(self, cplns):
    self.cplns = cplns
</t>
<t tx="ekr.20080121105837.223">def set_calltips(self, calltips):
    self.calltips = calltips
</t>
<t tx="ekr.20080121105837.224">def set_defns(self, defns):
    self.defns = defns


</t>
<t tx="ekr.20080121105837.225">class LogEvalController(EvalController):
    @others
</t>
<t tx="ekr.20080121105837.226">def __init__(self, logger_or_log_name=None):
    if isinstance(logger_or_log_name, logging.getLoggerClass()):
        self.logger = logger_or_log_name
    else:
        self.logger = logging.getLogger(logger_or_log_name)
    EvalController.__init__(self)

</t>
<t tx="ekr.20080121105837.227">def debug(self, msg, *args):
    self.logger.debug(msg, *args)
</t>
<t tx="ekr.20080121105837.228">def info(self, msg, *args):
    self.logger.info(msg, *args)
</t>
<t tx="ekr.20080121105837.229">def warn(self, msg, *args):
    self.logger.warn(msg, *args)
</t>
<t tx="ekr.20080121105837.230">def error(self, msg, *args):
    self.logger.error(msg, *args)


</t>
<t tx="ekr.20080121105837.231">class Evaluator(object):
    """To do asynchronous autocomplete/calltip evaluation you create an
    Evaluator instance (generally a specialized subclass of) and pass it
    to Manager.request_eval() and/or Manager.request_reeval().
    
    At a minimum a subclass must implement the eval() method making sure
    that the rules described for Buffer.async_eval_at_trg() are followed
    (see buffer.py). Typically this just means:
    - ensuring ctlr.done() is called,
    - reacting to ctrl.is_aborted(), and
    - optionally calling the other EvalController methods as appropriate.

    A subclass should also implement readable __str__ output.

    The manager handles:
    - co-ordinating a queue of evaluation requests
    - only ever running one evaluation at a time (because it only makes sense
      in an IDE to have one on the go)
    - calling the evaluator's eval() method in a subthread
    - calling ctlr.done(&lt;reason&gt;) if the eval terminates with an exception
    
    One important base class is the CitadelEvaluator (see citadel.py) that
    knows how to do CITDL evaluation using the CIDB. Citadel languages
    (e.g. Perl, Python, ...) will generally use CitadelEvaluators for most
    of their triggers.
    """
    @others
</t>
<t tx="ekr.20080121105837.232">def __init__(self, ctlr, buf, trg):
    assert isinstance(ctlr, EvalController)
    self.ctlr = ctlr
    #assert isinstance(buf, Buffer) # commented out to avoid circular dep
    self.buf = buf
    assert isinstance(trg, Trigger)
    self.trg = trg

</t>
<t tx="ekr.20080121105837.233">def eval(self):
    self.ctlr.done("eval not implemented")
    raise VirtualMethodError("Evaluator.eval")



</t>
<t tx="ekr.20080121105837.234">#---- helper methods</t>
<t tx="ekr.20080121105837.235">def symbolType2Name(st):
    return _symbolType2Name[st]

</t>
<t tx="ekr.20080121105837.236"># match 0x00-0x1f except TAB(0x09), LF(0x0A), and CR(0x0D)
_encre = re.compile('([\x00-\x08\x0b\x0c\x0e-\x1f])')
if sys.version_info &gt;= (2, 3):
    charrefreplace = 'xmlcharrefreplace'
else:
    # Python 2.2 doesn't have 'xmlcharrefreplace'. Fallback to a
    # literal '?' -- this is better than failing outright.
    charrefreplace = 'replace'

def xmlencode(s):
    """Encode the given string for inclusion in a UTF-8 XML document.
    
    Specifically, illegal or unpresentable characters are encoded as
    XML character entities.
    """
    # As defined in the XML spec some of the character from 0x00 to 0x19
    # are not allowed in well-formed XML. We replace those with entity
    # references here.
    #   http://www.w3.org/TR/2000/REC-xml-20001006#charsets
    # (XXX It would be nice if Python has a codec for this. Perhaps we
    # should write one.)
    return _encre.sub(
               # replace with XML decimal char entity, e.g. '&amp;#7;'
               lambda m: '&amp;#%d;'%ord(m.group(1)),
               s.encode('utf-8', charrefreplace))

</t>
<t tx="ekr.20080121105837.237">def xmlattrstr(attrs):
    """Construct an XML-safe attribute string from the given attributes
    
        "attrs" is a dictionary of attributes
    
    The returned attribute string includes a leading space, if necessary,
    so it is safe to use the string right after a tag name.
    """
    #XXX Should this be using 
    from xml.sax.saxutils import quoteattr
    s = ''
    names = attrs.keys()
    names.sort() # dump attrs sorted by key, not necessary but is more stable
    for name in names:
        s += ' %s=%s' % (name, quoteattr(str(attrs[name])))
    return s


</t>
<t tx="ekr.20080121105837.238">def isUnsavedPath(path):
    """Return true if the given path is a special &lt;Unsaved&gt;\sub\path file."""
    tag = "&lt;Unsaved&gt;"
    length = len(tag)
    if path.startswith(tag) and (len(path)==length or path[length] in "\\/"):
        return True
    else:
        return False

</t>
<t tx="ekr.20080121105837.239">_uriMatch = re.compile("^\w+://")
def canonicalizePath(path, normcase=True):
    r"""Return what CodeIntel considers a canonical version of the given path.
    
        "path" is the path to canonicalize.
        "normcase" (optional, default True) is a boolean indicating if the
            case should be normalized.
    
    "Special" paths are ones of the form "&lt;Tag&gt;\sub\path". Supported special
    path tags:
        &lt;Unsaved&gt;       Used when the given path isn't a real file: e.g.
                        unsaved document buffers.

    Raises a ValueError if it cannot be converted to a canonical path.
    
    &gt;&gt;&gt; canonicalizePath(r"C:\Python22\Lib\os.py")  # normcase on Windows
    'c:\\python22\\lib\\os.py'
    &gt;&gt;&gt; canonicalizePath(r"&lt;Unsaved&gt;\Python-1.py")
    '&lt;Unsaved&gt;\\python-1.py'
    &gt;&gt;&gt; canonicalizePath("&lt;Unsaved&gt;")
    '&lt;Unsaved&gt;'
    &gt;&gt;&gt; canonicalizePath("&lt;Unsaved&gt;\\")
    '&lt;Unsaved&gt;'
    &gt;&gt;&gt; canonicalizePath("ftp://ftp.ActiveState.com/pub")
    'ftp://ftp.ActiveState.com/pub'
    """
    if path is None:
        raise ValueError("cannot canonicalize path, path is None")
    if path.startswith('&lt;'):  # might be a special path
        first, rest = None, None
        for i in range(1, len(path)):
            if path[i] in "\\/":
                first, rest = path[:i], path[i+1:]
                break
        else:
            first, rest = path, None
        if first.endswith('&gt;'):
            tag = first
            subpath = rest
            if tag == "&lt;Unsaved&gt;":
                pass # leave tag unchanged
            else:
                raise ValueError("unknown special path tag: %s" % tag)
            cpath = tag
            if subpath:
                subpath = os.path.normpath(subpath)
                if normcase:
                    subpath = os.path.normcase(subpath)
                cpath = os.path.join(cpath, subpath)
            return cpath
    if _uriMatch.match(path): # ftp://, koremote://
        #XXX Should we normcase() a UR[LI]
        return path
    else:
        cpath = os.path.normpath(os.path.abspath(path))
        if normcase:
            cpath = os.path.normcase(cpath)
        return cpath

</t>
<t tx="ekr.20080121105837.240">def parseAttributes(attrStr=None):
    """Parse the given attributes string (from CIX) into an attribute dict."""
    attrs = {}
    if attrStr is not None:
        for token in attrStr.split():
            if '=' in token:
                key, value = token.split('=', 1)
            else:
                key, value = token, 1
            attrs[key] = value
    return attrs



</t>
<t tx="ekr.20080121105837.241">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.242"># ***** BEGIN LICENSE BLOCK *****

import textwrap

CSS_ATTR_DICT = {
    'azimuth'   : [
            'behind',
            'center',
            'center-left',
            'center-right',
            'far-left',
            'far-right',
            'inherit',
            'left',
            'leftwards',
            'left-side',
            'right',
            'rightwards',
            'right-side',
            '!important',
        ],
    'background': [
            'bottom',
            'center',
            'fixed',
            'inherit',
            'left',
            'none',
            'no-repeat',
            'repeat',
            'repeat-x',
            'repeat-y',
            'rgb(',
            'right',
            'scroll',
            'top',
            'transparent',
            'url(',
            '!important',
            '#',
        ],
    'background-attachment': [
            'fixed',
            'inherit',
            'scroll',
            '!important',
        ],
    'background-color': [
            'inherit',
            'rgb(',
            'transparent',
            '!important',
            '#',
        ],
    'background-image': [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'background-position': [
            'bottom',
            'center',
            'inherit',
            'left',
            'right',
            'top',
            '!important',
        ],
    'background-repeat': [
            'inherit',
            'no-repeat',
            'repeat',
            'repeat-x',
            'repeat-y',
            '!important',
        ],
    'border'    : [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-bottom': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-bottom-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-bottom-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-bottom-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-collapse': [
            'collapse',
            'inherit',
            'separate',
            '!important',
        ],
    'border-color': [
            'inherit',
            'rgb(',
            'transparent',
            '!important',
            '#',
        ],
    'border-left': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-left-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-left-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-left-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-right': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-right-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-right-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-right-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-spacing': [
            'inherit',
            '!important',
        ],
    'border-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-top': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'border-top-color': [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'border-top-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'border-top-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'border-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'bottom'    : [
            'auto',
            'inherit',
            '!important',
        ],
    'caption-side': [
            'bottom',
            'inherit',
            'left',
            'right',
            'top',
            '!important',
        ],
    'clear'     : [
            'both',
            'inherit',
            'left',
            'none',
            'right',
            '!important',
        ],
    'clip'      : [
            'auto',
            'inherit',
            'rect(',
            '!important',
        ],
    'color'     : [
            'inherit',
            'rgb(',
            '!important',
            '#',
        ],
    'content'   : [
            'close-quote',
            'counter(',
            'inherit',
            'no-close-quote',
            'no-open-quote',
            'open-quote',
            'url(',
            '!important',
            "",
            '',
        ],
    'counter-increment': [
            'inherit',
            'none',
            '!important',
        ],
    'counter-reset': [
            'inherit',
            'none',
            '!important',
        ],
    'cue'       : [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'cue-after' : [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'cue-before': [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'cursor'    : [
            'auto',
            'crosshair',
            'default',
            'e-resize',
            'help',
            'inherit',
            'move',
            'ne-resize',
            'nw-resize',
            'n-resize',
            'pointer',
            'se-resize',
            'sw-resize',
            's-resize',
            'text',
            'url(',
            'wait',
            'w-resize',
            '!important',
        ],
    'direction' : [
            'inherit',
            'ltr',
            'rtl',
            '!important',
        ],
    'display'   : [
            'block',
            'compact',
            'inherit',
            'inline',
            'inline-table',
            'list-item',
            'marker',
            'none',
            'run-in',
            'table',
            'table-caption',
            'table-cell',
            'table-column',
            'table-column-group',
            'table-footer-group',
            'table-header-group',
            'table-row',
            'table-row-group',
            '!important',
        ],
    'elevation' : [
            'above',
            'below',
            'higher',
            'inherit',
            'level',
            'lower',
            '!important',
        ],
    'empty-cells': [
            'hide',
            'inherit',
            'show',
            '!important',
        ],
    'float'     : [
            'inherit',
            'left',
            'none',
            'right',
            '!important',
        ],
    'font'      : [
            '100',
            '200',
            '300',
            '400',
            '500',
            '600',
            '700',
            '800',
            '900',
            'bold',
            'bolder',
            'caption',
            'cursive',
            'fantasy',
            'icon',
            'inherit',
            'italic',
            'large',
            'larger',
            'lighter',
            'medium',
            'menu',
            'message-box',
            'monospace',
            'normal',
            'oblique',
            'sans-serif',
            'serif',
            'small',
            'smaller',
            'small-caps',
            'small-caption',
            'status-bar',
            'xx-large',
            'xx-small',
            'x-large',
            'x-small',
            '!important',
        ],
    'font-family': [
            'cursive',
            'fantasy',
            'inherit',
            'monospace',
            'sans-serif',
            'serif',
            '!important',
        ],
    'font-size' : [
            'inherit',
            'large',
            'larger',
            'medium',
            'small',
            'smaller',
            'xx-large',
            'xx-small',
            'x-large',
            'x-small',
            '!important',
        ],
    'font-size-adjust': [
            'inherit',
            'none',
            '!important',
        ],
    'font-stretch': [
            'condensed',
            'expanded',
            'extra-condensed',
            'extra-expanded',
            'inherit',
            'narrower',
            'normal',
            'semi-condensed',
            'semi-expanded',
            'ultra-condensed',
            'ultra-expanded',
            'wider',
            '!important',
        ],
    'font-style': [
            'inherit',
            'italic',
            'normal',
            'oblique',
            '!important',
        ],
    'font-variant': [
            'inherit',
            'normal',
            'small-caps',
            '!important',
        ],
    'font-weight': [
            '100',
            '200',
            '300',
            '400',
            '500',
            '600',
            '700',
            '800',
            '900',
            'bold',
            'bolder',
            'inherit',
            'lighter',
            'normal',
            '!important',
        ],
    'height'    : [
            'auto',
            'inherit',
            '!important',
        ],
    'left'      : [
            'auto',
            'inherit',
            '!important',
        ],
    'letter-spacing': [
            'inherit',
            'normal',
            '!important',
        ],
    'line-height': [
            'inherit',
            'normal',
            '!important',
        ],
    'list-style': [
            'armenian',
            'circle',
            'cjk-ideographic',
            'decimal',
            'decimal-leading-zero',
            'disc',
            'georgian',
            'hebrew',
            'hiragana',
            'hiragana-iroha',
            'inherit',
            'inside',
            'katakana',
            'katakana-iroha',
            'lower-alpha',
            'lower-greek',
            'lower-latin',
            'lower-roman',
            'none',
            'outside',
            'square',
            'upper-alpha',
            'upper-latin',
            'upper-roman',
            'url(',
            '!important',
        ],
    'list-style-image': [
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'list-style-position': [
            'inherit',
            'inside',
            'outside',
            '!important',
        ],
    'list-style-type': [
            'armenian',
            'circle',
            'cjk-ideographic',
            'decimal',
            'decimal-leading-zero',
            'disc',
            'georgian',
            'hebrew',
            'hiragana',
            'hiragana-iroha',
            'inherit',
            'katakana',
            'katakana-iroha',
            'lower-alpha',
            'lower-greek',
            'lower-latin',
            'lower-roman',
            'none',
            'square',
            'upper-alpha',
            'upper-latin',
            'upper-roman',
            '!important',
        ],
    'margin'    : [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-bottom': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-left': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-right': [
            'auto',
            'inherit',
            '!important',
        ],
    'margin-top': [
            'auto',
            'inherit',
            '!important',
        ],
    'marker-offset': [
            'auto',
            'inherit',
            '!important',
        ],
    'marks'     : [
            'crop',
            'cross',
            'inherit',
            'none',
            '!important',
        ],
    'max-height': [
            'inherit',
            'none',
            '!important',
        ],
    'max-width' : [
            'inherit',
            'none',
            '!important',
        ],
    'min-height': [
            'inherit',
            '!important',
        ],
    'min-width' : [
            'inherit',
            '!important',
        ],
    'orphans'   : [
            'inherit',
            '!important',
        ],
    'outline'   : [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'invert',
            'medium',
            'none',
            'outset',
            'rgb(',
            'ridge',
            'solid',
            'thick',
            'thin',
            '!important',
            '#',
        ],
    'outline-color': [
            'inherit',
            'invert',
            'rgb(',
            '!important',
            '#',
        ],
    'outline-style': [
            'dashed',
            'dotted',
            'double',
            'groove',
            'hidden',
            'inherit',
            'inset',
            'none',
            'outset',
            'ridge',
            'solid',
            '!important',
        ],
    'outline-width': [
            'inherit',
            'medium',
            'thick',
            'thin',
            '!important',
        ],
    'overflow'  : [
            'auto',
            'hidden',
            'inherit',
            'scroll',
            'visible',
            '!important',
        ],
    'padding'   : [
            'inherit',
            '!important',
        ],
    'padding-bottom': [
            'inherit',
            '!important',
        ],
    'padding-left': [
            'inherit',
            '!important',
        ],
    'padding-right': [
            'inherit',
            '!important',
        ],
    'padding-top': [
            'inherit',
            '!important',
        ],
    'page'      : [
            'auto',
        ],
    'page-break-after': [
            'always',
            'auto',
            'avoid',
            'inherit',
            'left',
            'right',
            '!important',
        ],
    'page-break-before': [
            'always',
            'auto',
            'avoid',
            'inherit',
            'left',
            'right',
            '!important',
        ],
    'page-break-inside': [
            'auto',
            'avoid',
            'inherit',
            '!important',
        ],
    'pause'     : [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pause-after': [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pause-before': [
            'inherit',
            'ms',
            's',
            '!important',
        ],
    'pitch'     : [
            'high',
            'Hz',
            'inherit',
            'kHz',
            'low',
            'medium',
            'x-high',
            'x-low',
            '!important',
        ],
    'pitch-range': [
            'inherit',
            '!important',
        ],
    'play-during': [
            'auto',
            'inherit',
            'none',
            'url(',
            '!important',
        ],
    'position'  : [
            'absolute',
            'fixed',
            'inherit',
            'relative',
            'static',
            '!important',
        ],
    'quotes'    : [
            'inherit',
            'none',
            '!important',
            "",
            '',
        ],
    'richness'  : [
            'inherit',
            '!important',
        ],
    'right'     : [
            'auto',
            'inherit',
            '!important',
        ],
    'size'      : [
            'auto',
            'inherit',
            'landscape',
            'portrait',
            '!important',
        ],
    'speak'     : [
            'inherit',
            'none',
            'normal',
            'spell-out',
            '!important',
        ],
    'speak-header': [
            'always',
            'inherit',
            'once',
            '!important',
        ],
    'speak-numeral': [
            'continuous',
            'digits',
            'inherit',
            '!important',
        ],
    'speak-punctuation': [
            'code',
            'inherit',
            'none',
            '!important',
        ],
    'speech-rate': [
            'fast',
            'faster',
            'inherit',
            'medium',
            'slow',
            'slower',
            'x-fast',
            'x-slow',
            '!important',
        ],
    'stress'    : [
            'inherit',
            '!important',
        ],
    'table-layout': [
            'auto',
            'fixed',
            'inherit',
            '!important',
        ],
    'text-align': [
            'center',
            'inherit',
            'justify',
            'left',
            'right',
            '!important',
            "",
            '',
        ],
    'text-decoration': [
            'blink',
            'inherit',
            'line-through',
            'none',
            'overline',
            'underline',
            '!important',
        ],
    'text-indent': [
            'inherit',
            '!important',
        ],
    'text-shadow': [
            'inherit',
            'none',
            'rgb(',
            '!important',
            '#',
        ],
    'text-transform': [
            'capitalize',
            'inherit',
            'lowercase',
            'none',
            'uppercase',
            '!important',
        ],
    'top'       : [
            'auto',
            'inherit',
            '!important',
        ],
    'unicode-bidi': [
            'bidi-override',
            'embed',
            'inherit',
            'normal',
            '!important',
        ],
    'vertical-align': [
            'baseline',
            'bottom',
            'inherit',
            'middle',
            'sub',
            'super',
            'text-bottom',
            'text-top',
            'top',
            '!important',
        ],
    'visibility': [
            'collapse',
            'hidden',
            'inherit',
            'visible',
            '!important',
        ],
    'voice-family': [
            'child',
            'female',
            'inherit',
            'male',
            '!important',
        ],
    'volume'    : [
            'inherit',
            'loud',
            'medium',
            'silent',
            'soft',
            'x-loud',
            'x-soft',
            '!important',
        ],
    'white-space': [
            'inherit',
            'normal',
            'nowrap',
            'pre',
            '!important',
        ],
    'widows'    : [
            'inherit',
            '!important',
        ],
    'width'     : [
            'auto',
            'inherit',
            '!important',
        ],
    'word-spacing': [
            'inherit',
            'normal',
            '!important',
        ],
    'z-index'   : [
            'auto',
            'inherit',
            '!important',
        ],
}

CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT = {
    'azimuth'               : """Audio: Spatial audio property for aural presentation""",
    'background'            : """Shorthand for setting the individual background properties""",
    'background-attachment' : """If background image is specified, this specifies whether it is fixed with regard to the viewport ('fixed') or scrolls along with the document ('scroll').""",
    'background-color'      : """Sets the background color of an element, either a &lt;color&gt; value or the keyword 'transparent', to make the underlying colors shine through""",
    'background-image'      : """Sets the background image of an element. When setting a background image, authors should also specify a background color that will be used when the image is unavailable. When the image is available, it is rendered on top of the background color""",
    'background-position'   : """If a background image has been specified, this property specifies its initial position""",
    'background-repeat'     : """If a background image is specified, this property specifies whether the image is repeated (tiled), and how""",
    'border'                : """Shorthand for border-width, border-style and border-color affecting all 4 borders""",
    'border-bottom'         : """Shorthand for border-width, border-style and border-color affecting the bottom border""",
    'border-bottom-color'   : """Sets the color of the bottom border""",
    'border-bottom-style'   : """Specifies the line style of a box's bottom border (solid, double, dashed, hidden, etc.)""",
    'border-bottom-width'   : """Sets the width of the bottom border of a box""",
    'border-collapse'       : """This property selects a table's border model.""",
    'border-color'          : """Sets the color of the four borders""",
    'border-left'           : """Shorthand for border-width, border-style and border-color affecting the left border""",
    'border-left-color'     : """Sets the color of the left border""",
    'border-left-style'     : """Specifies the line style of a box's left border (solid, double, dashed, hidden, etc.)""",
    'border-left-width'     : """Sets the width of the left border of a box""",
    'border-right'          : """Shorthand for border-width, border-style and border-color affecting the right border""",
    'border-right-color'    : """Sets the color of the right border""",
    'border-right-style'    : """Specifies the line style of a box's right border (solid, double, dashed, hidden, etc.)""",
    'border-right-width'    : """Sets the width of the right border of a box""",
    'border-spacing'        : """The lengths specify the distance that separates adjacent cell borders. If one length is specified, it gives both the horizontal and vertical spacing. If two are specified, the first gives the horizontal spacing and the second the vertical spacing. Lengths may not be negative.""",
    'border-style'          : """Specifies the line style of a box's four borders (solid, double, dashed, hidden, etc.)""",
    'border-top'            : """Shorthand for border-width, border-style and border-color affecting the top border""",
    'border-top-color'      : """Sets the color of the top border""",
    'border-top-style'      : """Specifies the line style of a box's top border (solid, double, dashed, hidden, etc.)""",
    'border-top-width'      : """Sets the width of the top border of a box""",
    'border-width'          : """Shorthand for setting 'border-top-width', 'border-right-width', 'border-bottom-width', and 'border-left-width' at the same place in the style sheet. If there is only one value, it applies to all sides. If there are two values, the top and bottom borders are set to the first value and the right and left are set to the second. If there are three values, the top is set to the first value, the left and right are set to the second, and the bottom is set to the third. If there are four values, they apply to the top, right, bottom, and left, respectively.""",
    'bottom'                : """Specifies how far a box's bottom content edge is offset above the bottom of the box's containing block""",
    'caption-side'          : """Specifies the position of the caption box with respect to the table box""",
    'clear'                 : """Indicates which sides of an element's box(es) may not be adjacent to an earlier floating box""",
    'clip'                  : """A clipping region defines what portion of an element's rendered content is visible""",
    'color'                 : """This property describes the foreground color of an element's text content""",
    'content'               : """This property is used with the :before and :after pseudo-elements to generate content in a document""",
    'counter-increment'     : """Indicates by how much the counter is incremented for every occurrence of the element. The default increment is 1. Zero and negative integers are allowed.""",
    'counter-reset'         : """Specifies the value that the counter is set to on each occurrence of the element""",
    'cue'                   : """Audio: Shorthand for setting 'cue-before' and 'cue-after'. If two values are given, the first value is 'cue-before' and the second is 'cue-after'. If only one value is given, it applies to both properties.""",
    'cue-after'             : """Audio: Sound to be played after the element to delimit it""",
    'cue-before'            : """Audio: Sound to be played before the element to delimit it""",
    'cursor'                : """Specifies the type of cursor to be displayed for the pointing device""",
    'direction'             : """Specifies the base writing direction of blocks and the direction of embeddings and overrides (see 'unicode-bidi') for the Unicode bidirectional algorithm.""",
    'display'               : """How the element is to be displayed, denotes the box type format""",
    'elevation'             : """Audio: Spatial elevation direction for aural presentation.""",
    'empty-cells'           : """Controls the rendering of borders around cells that have no visible content""",
    'float'                 : """Specifies whether a box should float to the left, right, or not at all""",
    'font'                  : """Shorthand for setting 'font-style', 'font-variant', 'font-weight', 'font-size', 'line-height', and 'font-family', at the same place in the style sheet""",
    'font-family'           : """Specifies a prioritized list of font family names and/or generic family names""",
    'font-size'             : """Describes the size of the font when set solid""",
    'font-size-adjust'      : """Specifies an aspect value for an element that will preserve the x-height of the first choice font in the substitute font""",
    'font-stretch'          : """Selects a normal, condensed, or extended face from a font family""",
    'font-style'            : """Sets normal (sometimes referred to as "roman" or "upright"), italic, and oblique faces within a font family""",
    'font-variant'          : """Can be used to select font casing 'normal' or 'small-caps'""",
    'font-weight'           : """Specifies the weight of the font""",
    'height'                : """Specifies the content height of boxes generated by block-level and replaced elements""",
    'left'                  : """This property specifies how far a box's left content edge is offset to the right of the left edge of the box's containing block""",
    'letter-spacing'        : """Specifies spacing behavior between text characters""",
    'line-height'           : """Specifies the minimal height of each generated inline box""",
    'list-style'            : """Shorthand notation for setting the three properties 'list-style-type', 'list-style-image', and 'list-style-position' at the same place in the style sheet""",
    'list-style-image'      : """Sets the image that will be used as the list item marker""",
    'list-style-position'   : """Specifies the position of the marker box in the principal block box""",
    'list-style-type'       : """Specifies appearance of the list item marker if 'list-style-image' has the value 'none' or if the image pointed to by the URI cannot be displayed""",
    'margin'                : """Shorthand for setting 'margin-top', 'margin-right', 'margin-bottom', and 'margin-left' at the same place in the style sheet""",
    'margin-bottom'         : """Specifies the width of the bottom margin area of a box""",
    'margin-left'           : """Specifies the width of the left margin area of a box""",
    'margin-right'          : """Specifies the width of the right margin area of a box""",
    'margin-top'            : """Specifies the width of the top margin area of a box""",
    'marker-offset'         : """Specifies the distance between the nearest border edges of a marker box and its associated principal box""",
    'marks'                 : """Specifies whether cross marks or crop marks or both should be rendered just outside the page box edge. Crop marks indicate where the page should be cut. Cross marks (also known as register marks or registration marks) are used to align sheets""",
    'max-height'            : """Maximum height of the containing box""",
    'max-width'             : """Maximum width of the containing box""",
    'min-height'            : """Minimum height of the containing box""",
    'min-width'             : """Minimum width of the containing box""",
    'orphans'               : """Specifies the minimum number of lines of a paragraph that must be left at the bottom of a page""",
    'outline'               : """Shorthand for setting 'outline-style', 'outline-width', and 'outline-color' at the same place in the style sheet""",
    'outline-color'         : """Outline color around visual object""",
    'outline-style'         : """Specifies the line style of the outline (solid, double, dashed, etc.)""",
    'outline-width'         : """Specifies the width of the outline around the element""",
    'overflow'              : """Specifies whether the content of a block-level element is clipped when it overflows the element's box (which is acting as a containing block for the content)""",
    'padding'               : """Shorthand for setting 'padding-top', 'padding-right', 'padding-bottom', and 'padding-left' at the same place in the style sheet""",
    'padding-bottom'        : """Sets the bottom width of the containing box""",
    'padding-left'          : """Sets the left width of the containing box""",
    'padding-right'         : """Sets the right width of the containing box""",
    'padding-top'           : """Sets the top width of the containing box""",
    'page'                  : """Specifies a particular type of page where an element should be displayed""",
    'page-break-after'      : """Indicate the user agent should break the page after here""",
    'page-break-before'     : """Indicate the user agent should break the page before here""",
    'page-break-inside'     : """Indicate the user agent should break the page within here""",
    'pause'                 : """Audio: Shorthand for setting 'pause-before' and 'pause-after'. If two values are given, the first value is 'pause-before' and the second is 'pause-after'. If only one value is given, it applies to both properties""",
    'pause-after'           : """Audio: Specifies a pause to be observed after speaking an element's content""",
    'pause-before'          : """Audio: Specifies a pause to be observed before speaking an element's content""",
    'pitch'                 : """Audio: Specifies the average pitch (a frequency) of the speaking voice""",
    'pitch-range'           : """Audio: Specifies variation in average pitch""",
    'play-during'           : """Audio: Similar to the 'cue-before' and 'cue-after' properties, this property specifies a sound to be played as a background while an element's content is spoken""",
    'position'              : """Specifies which of the CSS2 positioning algorithms is used to calculate the position of a box""",
    'quotes'                : """Specifies quotation marks for any number of embedded quotations""",
    'richness'              : """Audio: Specifies the richness, or brightness, of the speaking voice. A rich voice will "carry" in a large room, a smooth voice will not""",
    'right'                 : """This property specifies how far a box's right content edge is offset to the left of the right edge of the box's containing block""",
    'size'                  : """Specifies the size and orientation of a page box""",
    'speak'                 : """Audio: Specifies whether text will be rendered aurally and if so, in what manner""",
    'speak-header'          : """Audio: Specifies whether table headers are spoken before every cell, or only before a cell when that cell is associated with a different header than the previous cell""",
    'speak-numeral'         : """Audio: Controls how numerals are spoken""",
    'speak-punctuation'     : """Audio: Specifies how punctuation is spoken""",
    'speech-rate'           : """Audio: Specifies the speaking rate. Note that both absolute and relative keyword values are allowed""",
    'stress'                : """Audio: Specifies the height of "local peaks" in the intonation contour of a voice""",
    'table-layout'          : """Specifies the algorithm used to lay out the table cells, rows, and columns""",
    'text-align'            : """Specifies how inline content of a block is aligned""",
    'text-decoration'       : """Specifies decorations that are added to the text of an element""",
    'text-indent'           : """Specifies the indentation of the first line of text in a block""",
    'text-shadow'           : """A comma-separated list of shadow effects to be applied to the text of the element""",
    'text-transform'        : """Specifies capitalization effects of an element's text""",
    'top'                   : """This property specifies how far a box's top content edge is offset below the top edge of the box's containing block""",
    'unicode-bidi'          : """Specifies the level of embedding with respect to the bidirectional algorithm""",
    'uri'                   : """An internet reference string.""",
    'vertical-align'        : """Affects the vertical positioning inside a line box of the boxes generated by an inline-level element""",
    'visibility'            : """Specifies whether the boxes generated by an element are rendered. Invisible boxes still affect layout (set the 'display' property to 'none' to suppress box generation altogether)""",
    'voice-family'          : """Audio: Value is a comma-separated, prioritized list of voice family names""",
    'volume'                : """Audio: Refers to the median volume of the audio""",
    'white-space'           : """Specifies how whitespace inside the element is handled""",
    'widows'                : """Specifies the minimum number of lines of a paragraph that must be left at the top of a page""",
    'width'                 : """Specifies the content width of boxes generated by block-level and replaced elements""",
    'word-spacing'          : """Specifies spacing behavior between words""",
    'z-index'               : """For a positioned box, specifies the stack level of the box in the current stacking context and also whether the box establishes a local stacking context.""",
}
for property, calltip in CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT.items():
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[property] = "\n".join(textwrap.wrap(calltip, 40))
</t>
<t tx="ekr.20080121105837.243">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.244">#!/usr/bin/env python

"""Runtime environment handling for codeintel

"Environment" here means more than just the environment variables (i.e.
os.environ). It also means preferences/settings/conditions that are part
of the running environment for a codeintel Manager or Buffer.

Generally the relevant environment is used to get data such environment
variables and preferences (e.g., what Python interpreter is relevant,
what level of JS DOM APIs should be considered).

The Manager has an 'env' attribute (by default, an Environment instance)
and, optionally, a buffer can have a custom environment (also the 'env'
attribute). The latter is useful for sharing a project environment
across all buffers part of the same project.

For example, Buffers created for files in Komodo currently have a
KoCodeIntelEnvironment instance. All buffers belonging to the same project
share a single such instance that incorporates project settings. Buffers
not part of a project share a default instance that just uses global
Komodo settings.

Read the base Environment class for details on the API.
"""

import os
import logging


log = logging.getLogger("codeintel.environment")
</t>
<t tx="ekr.20080121105837.245">#log.setLevel(logging.DEBUG)



class Environment(object):
    """The base Environment class. It defines the API that all types
    of "environments" in codeintel must implement and provides a base
    implementation that:
    - has no prefs
    - maps envvars to os.environ, and
    - has some basic file associations for 'assoc_patterns_from_lang()'.

    Every environment must have a 'cache' attribute that is a wide open
    dictionary. Various parts of the codeintel system can (and do) use
    this cache for maintain runtime calculated date.
    """
    @others
</t>
<t tx="ekr.20080121105837.246">def __init__(self):
    self.cache = {}
</t>
<t tx="ekr.20080121105837.247">def __del__(self):
    self.remove_all_pref_observers()
</t>
<t tx="ekr.20080121105837.248">def __repr__(self):
    return "&lt;Environment&gt;"

</t>
<t tx="ekr.20080121105837.249">def has_envvar(self, name):
    """Return True if the named envvar exists."""
    return name in os.environ
</t>
<t tx="ekr.20080121105837.250">def get_envvar(self, name, default=None):
    """Return the value of the named envvar, if it exists. Otherwise
    return the given default, if any, or None.
    """
    return os.environ.get(name, default)
</t>
<t tx="ekr.20080121105837.251">def get_all_envvars(self):
    """Return a dictionary of all environment variables."""
    return dict(os.environ)

</t>
<t tx="ekr.20080121105837.252">def has_pref(self, name):
    """Return True if the named pref exists."""
    return False
</t>
<t tx="ekr.20080121105837.253">def get_pref(self, name, default=None):
    """Return the value of the named pref, if it exists. Otherwise
    return the given default, if any, or None.
    """
    return default
</t>
<t tx="ekr.20080121105837.254">def get_all_prefs(self, name, default=None):
    """Return a list with the value of the named pref at each
    "pref-level". If not defined at a particular level the 'default'
    value will be placed at that index.
    
    Note: This was added to support Komodo's multi-level pref system.
    Most simple Environment classes only support one level.
    """
    return [self.get_pref(name, default)]
</t>
<t tx="ekr.20080121105837.255">def add_pref_observer(self, name, callback):
    pass
</t>
<t tx="ekr.20080121105837.256">def remove_pref_observer(self, name, callback):
    pass
</t>
<t tx="ekr.20080121105837.257">def remove_all_pref_observers(self):
    pass

</t>
<t tx="ekr.20080121105837.258">_default_assoc_patterns_from_lang = {
    "Python": ["*.py"],
    "JavaScript": ["*.js"],
    "PHP": ["*.php", "*.inc", "*.module"],
    "Perl": ["*.pm", "*.pl"],
    "Tcl": ["*.tcl"],
    "Ruby": ["*.rb"],
}
def assoc_patterns_from_lang(self, lang):
    """Return a list of filename patterns identifying the given
    language. Returns the empty list if don't have any info for that
    lang.
    """
    return self._default_assoc_patterns_from_lang.get(lang, [])

</t>
<t tx="ekr.20080121105837.259">def get_proj_base_dir(self):
    """Return the full path to the project base dir, or None if this
    environment does not represent a project.
    """
    return None


</t>
<t tx="ekr.20080121105837.260">class SimplePrefsEnvironment(Environment):
    """A simple environment that supports basic key/value prefs and
    pref change observation.

    Whenever a pref changes, any registered callbacks for that pref name
    will be called as follows:
        callback(&lt;env&gt;, &lt;pref-name&gt;)

    Note: There is no support for *deleting* a pref. Just set it to
    None.  The reason for not supporting this is that it would require
    complicating pref observer notification to be able to distinguish
    setting pref to None and deleting it.
    """
    @others
</t>
<t tx="ekr.20080121105837.261">def __init__(self, **prefs):
    Environment.__init__(self)
    self._prefs = prefs
    self._pref_observer_callbacks_from_name = {}

</t>
<t tx="ekr.20080121105837.262">def set_pref(self, name, value):
    self._prefs[name] = value
    self._notify_pref_observers(name)
</t>
<t tx="ekr.20080121105837.263">def has_pref(self, name):
    return name in self._prefs
</t>
<t tx="ekr.20080121105837.264">def get_pref(self, name, default=None):
    if name not in self._prefs:
        return default
    return self._prefs[name]
</t>
<t tx="ekr.20080121105837.265">def get_all_prefs(self, name, default=None):
    return [self.get_pref(name, default)]

</t>
<t tx="ekr.20080121105837.266">#TODO: Add ability to be able to call add_pref_observer() without
#      having to worry if have already done so for this name.
def add_pref_observer(self, name, callback):
    if name not in self._pref_observer_callbacks_from_name:
        self._pref_observer_callbacks_from_name[name] = []
    self._pref_observer_callbacks_from_name[name].append(callback)
</t>
<t tx="ekr.20080121105837.267">def remove_pref_observer(self, name, callback):
    self._pref_observer_callbacks_from_name[name].remove(callback)
</t>
<t tx="ekr.20080121105837.268">def remove_all_pref_observers(self):
    self._pref_observer_callbacks_from_name = {}
</t>
<t tx="ekr.20080121105837.269">def _notify_pref_observers(self, name):
    for callback in self._pref_observer_callbacks_from_name.get(name, []):
        try:
            callback(self, name)
        except:
            log.exception("error in pref observer for pref '%s' change",
                          name)


</t>
<t tx="ekr.20080121105837.270">class DefaultEnvironment(SimplePrefsEnvironment):
    """The default environment used by the Manager if no environment is
    provided.
    """
    _default_prefs = {
        "codeintel_selected_catalogs": ["yui", "pywin32"],
        "codeintel_max_recursive_dir_depth": 10,
    }

    @others
</t>
<t tx="ekr.20080121105837.271">def __init__(self):
    SimplePrefsEnvironment.__init__(self, **self._default_prefs)


</t>
<t tx="ekr.20080121105837.272">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.273">#!/usr/bin/env python

"""Shared CIX tools for Code Intelligence

    CIX helpers for codeintel creation. Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html#xml-based-import-export-syntax-cix
"""

import os
import sys
import re
import shutil
from cStringIO import StringIO
import warnings

from ciElementTree import Element, ElementTree, SubElement
from codeintel2.util import parseDocSummary

# Dictionary of known js types and what they map to
known_javascript_types = {
    "object":       "Object",
    "obj":          "Object",
    "function":     "Function",
    "array":        "Array",
    "string":       "String",
    "text":         "String",
    "int":          "Number",
    "integer":      "Number",
    "number":       "Number",
    "numeric":      "Number",
    "decimal":      "Number",
    "short":        "Number",
    "unsigned short": "Number",
    "long":         "Number",
    "unsigned long":"Number",
    "float":        "Number",
    "bool":         "Boolean",
    "boolean":      "Boolean",
    "true":         "Boolean",
    "false":        "Boolean",
    "date":         "Date",
    "regexp":       "RegExp",
    # Dom elements
    "element":      "Element",
    "node":         "Node",
    "domnode":      "DOMNode",
    "domstring":    "DOMString",
    "widget":       "Widget",
    "domwidget":    "DOMWidget",
    "htmlelement":  "HTMLElement",
    "xmldocument":  "XMLDocument",
    "htmldocument": "HTMLDocument",
    # Special
    "xmlhttprequest": "XMLHttpRequest",
    "void":          "",
    # Mozilla special
    "UTF8String":    "String",
    "AString":       "String",
}

</t>
<t tx="ekr.20080121105837.274">def standardizeJSType(vartype):
    """Return a standardized name for the given type if it is a known type.

    Example1: given vartype of "int", returns "Number"
    Example2: given vartype of "YAHOO.tool", returns "YAHOO.tool"
    """

    if vartype:
        typename = known_javascript_types.get(vartype.lower(), None)
        if typename is None:
            #print "Unknown type: %s" % (vartype)
            return vartype
        return typename

</t>
<t tx="ekr.20080121105837.275">spacere = re.compile(r'\s+')
def condenseSpaces(s):
    """Remove any line enedings and condense multiple spaces"""

    s = s.replace("\n", " ")
    s = spacere.sub(' ', s)
    return s.strip()

</t>
<t tx="ekr.20080121105837.276">def remove_directory(dirpath):
    """ Recursively remove the directory path given """

    if os.path.exists(dirpath):
        shutil.rmtree(dirpath, ignore_errors=True)

</t>
<t tx="ekr.20080121105837.277">def getText(elem):
    """Return the internal text for the given ElementTree node"""

    l = []
    for element in elem.getiterator():
        if element.text:
            l.append(element.text)
        if element.tail:
            l.append(element.tail)
    return " ".join(l)

</t>
<t tx="ekr.20080121105837.278">def getAllTextFromSubElements(elem, subelementname):
    descnodes = elem.findall(subelementname)
    if len(descnodes) == 1:
        return getText(descnodes[0])
    return None

</t>
<t tx="ekr.20080121105837.279">def setCixDoc(cixelement, doctext, parse=False):
    if parse:
        doclines = parseDocSummary(doctext.splitlines(0))
        doctext = "\n".join(doclines)
    elif sys.platform.startswith("win"):
        doctext = doctext.replace("\r\n", "\n")
    #TODO: By default clip doc content down to a smaller set -- just
    #      enough for a good calltip. By then also want an option to
    #      *not* clip, for use in documentation generation.
    #if len(doctext) &gt; 1000:
    #    warnings.warn("doctext for cixelement: %r has length: %d" % (
    #                    cixelement.get("name"), len(doctext)))
    cixelement.attrib["doc"] = doctext

</t>
<t tx="ekr.20080121105837.280">def setCixDocFromNodeChildren(cixelement, node, childnodename):
    doctext = getAllTextFromSubElements(node, childnodename)
    if doctext:
        setCixDoc(cixelement, condenseSpaces(doctext), parse=True)

</t>
<t tx="ekr.20080121105837.281">def addCixArgument(cixelement, argname, argtype=None, doc=None):
    cixarg = SubElement(cixelement, "variable", ilk="argument", name=argname)
    if argtype:
        addCixType(cixarg, argtype)
    if doc:
        setCixDoc(cixarg, doc)
    return cixarg

</t>
<t tx="ekr.20080121105837.282">def addCixReturns(cixelement, returntype=None):
    if returntype and returntype != "void":
        cixelement.attrib["returns"] = returntype

</t>
<t tx="ekr.20080121105837.283">def addCixType(cixobject, vartype):
    if vartype:
        cixobject.attrib["citdl"] = vartype

</t>
<t tx="ekr.20080121105837.284">def addCixAttribute(cixobject, attribute):
    attrs = cixobject.get("attributes")
    if attrs:
        sp = attrs.split()
        if attribute not in sp:
            attrs = "%s %s" % (attrs, attribute)
    else:
        attrs = attribute
    cixobject.attrib["attributes"] = attrs

</t>
<t tx="ekr.20080121105837.285">def addClassRef(cixclass, name):
    refs = cixclass.get("classrefs", None)
    if refs:
        if name not in refs.split(" "):
            cixclass.attrib["classrefs"] = "%s %s" % (refs, name)
    else:
        cixclass.attrib["classrefs"] = "%s" % (name)

</t>
<t tx="ekr.20080121105837.286">def addInterfaceRef(cixinterface, name):
    refs = cixinterface.get("interfacerefs", None)
    if refs:
        if name not in refs.split(" "):
            cixinterface.attrib["interfacerefs"] = "%s %s" % (refs, name)
    else:
        cixinterface.attrib["interfacerefs"] = "%s" % (name)

</t>
<t tx="ekr.20080121105837.287">def setCixSignature(cixelement, signature):
    cixelement.attrib["signature"] = signature

</t>
<t tx="ekr.20080121105837.288">def createCixVariable(cixobject, name, vartype=None, attributes=None):
    if attributes:
        v = SubElement(cixobject, "variable", name=name,
                       attributes=attributes)
    else:
        v = SubElement(cixobject, "variable", name=name)
    if vartype:
        addCixType(v, vartype)
    return v

</t>
<t tx="ekr.20080121105837.289">def createCixFunction(cixmodule, name, attributes=None):
    if attributes:
        return SubElement(cixmodule, "scope", ilk="function", name=name,
                          attributes=attributes)
    else:
        return SubElement(cixmodule, "scope", ilk="function", name=name)

</t>
<t tx="ekr.20080121105837.290">def createCixInterface(cixmodule, name):
    return SubElement(cixmodule, "scope", ilk="interface", name=name)

</t>
<t tx="ekr.20080121105837.291">def createCixClass(cixmodule, name):
    return SubElement(cixmodule, "scope", ilk="class", name=name)

</t>
<t tx="ekr.20080121105837.292">def createCixModule(cixfile, name, lang, src=None):
    if src is None:
        return SubElement(cixfile, "scope", ilk="blob", name=name, lang=lang)
    else:
        return SubElement(cixfile, "scope", ilk="blob", name=name, lang=lang, src=src)

</t>
<t tx="ekr.20080121105837.293">def createOrFindCixModule(cixfile, name, lang, src=None):
    for module in cixfile.findall("./scope"):
        if module.get("ilk") == "blob" and module.get("name") == name and \
           module.get("lang") == lang:
            return module
    return createCixModule(cixfile, name, lang, src)

</t>
<t tx="ekr.20080121105837.294">def createCixFile(cix, path, lang="JavaScript", mtime="1102379523"):
    return SubElement(cix, "file",
                        lang=lang,
                        #mtime=mtime,
                        path=path)

</t>
<t tx="ekr.20080121105837.295">def createCixRoot(version="2.0", name=None, description=None):
    cixroot = Element("codeintel", version=version)
    if name is not None:
        cixroot.attrib["name"] = name
    if description is not None:
        cixroot.attrib["description"] = description
    return cixroot

</t>
<t tx="ekr.20080121105837.296"># Add .text and .tail values to make the CIX output pretty. (Only have
# to avoid "doc" tags: they are the only ones with text content.)
def prettify(elem, level=0, indent='  ', youngestsibling=0):
    if elem and elem.tag != "doc":
        elem.text = '\n' + (indent*(level+1))
    for i in range(len(elem)):
        prettify(elem[i], level+1, indent, i==len(elem)-1)
    elem.tail = '\n' + (indent*(level-youngestsibling))

</t>
<t tx="ekr.20080121105837.297">def get_cix_string(cix, prettyFormat=True):
    # Get the CIX.
    if prettyFormat:
        prettify(cix)
    cixstream = StringIO()
    cixtree = ElementTree(cix)
    cixstream.write('&lt;?xml version="1.0" encoding="UTF-8"?&gt;\n')
    cixtree.write(cixstream)
    cixcontent = cixstream.getvalue()
    cixstream.close()
    return cixcontent

</t>
<t tx="ekr.20080121105837.298">def remove_cix_line_numbers_from_tree(tree):
    for node in tree.getiterator():
        node.attrib.pop("line", None)
        node.attrib.pop("lineend", None)
</t>
<t tx="ekr.20080121105837.299">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.300">#!python
# ***** BEGIN LICENSE BLOCK *****

"""The codeintel indexer is a thread that handles scanning files and
loading them into the database. There is generally one indexer on the
Manager instance.

    mgr.idxr = Indexer(mgr)

XXX A separate indexer instance may be used for batch updates of the db.
"""
# TODO:
# - How are scan errors handled? do we try to keep from re-scanning over
#   and over? Perhaps still use mtime to only try again on new content.
#   Could still have a "N strikes in the last 1 minute" rule or
#   something.
# - batch updating (still wanted? probably)

import os, sys
import threading
import time
import bisect
import Queue
import md5
import traceback

import logging

from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.database.langlib import LangDirsLib
from codeintel2.database.multilanglib import MultiLangDirsLib

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

log = logging.getLogger("codeintel.indexer")
</t>
<t tx="ekr.20080121105837.301">#log.setLevel(logging.DEBUG)



#---- internal support

class _PriorityQueue(Queue.Queue):
    """A thread-safe priority queue.

    In order to use this the inserted items should be tuples with the
    priority first. Note that subsequent elements of the item tuples will
    be used for secondary sorting. As a result, it is often desirable to
    make the second tuple index be a timestamp so that the queue is a
    FIFO for elements with the same priority, e.g.:
        item = (PRIORITY, time.time(), element)

    Usage:
        q = _PriorityQueue(0)  # unbounded queue
        q.put( (2, time.time(), "second") )
        q.put( (1, time.time(), "first") )
        q.put( (3, time.time(), "third") )
        priority, timestamp, value = q.get()
    """
    @others
</t>
<t tx="ekr.20080121105837.302">def _put(self, item):
    bisect.insort(self.queue, item)

</t>
<t tx="ekr.20080121105837.303"># The following are to ensure a *list* is being used as the internal
# Queue data structure. Python 2.4 switched to using a deque
# internally which doesn't have the insert() method that
# bisect.insort() uses.
def _init(self, maxsize):
    self.maxsize = maxsize
    self.queue = []
</t>
<t tx="ekr.20080121105837.304">def _get(self):
    return self.queue.pop(0)


</t>
<t tx="ekr.20080121105837.305">class _Request(object):
    """Base class for a queue-able thing.

    A request object must have an 'id'. This is used for "staging"
    requests on the queue. A staged request will sit around for 'delay'
    amount of time before actually being put on the processing queue.
    During that wait, a subsequent stage request with the same 'id' will
    replace the first one -- including resetting the delay. This is
    useful for staging relatively expensive processing in the background
    for content that is under ongoing changes (e.g. for processing an
    editor buffer while it is being editted).
    """
    #XXX PERF: use a slot?
    id = None
    @others
</t>
<t tx="ekr.20080121105837.306">def __init__(self, id=None):
    if id is not None:
        self.id = id


</t>
<t tx="ekr.20080121105837.307">class _UniqueRequestPriorityQueue(_PriorityQueue):
    """A thread-safe priority queue for '_Request' objects.

    This queue class extends _PriorityQueue with the condition that:
    When adding a _Request to the queue, if a _Request with the same id
    already exists in the queue, then the new _Request inherits the
    higher priority and the earlier timestamp of the two and _replaces_
    the older _Request.

    This condition is added because there is no point in scanning file
    contents from time T1 when a scan of the file contents at time T2
    (more recent) is being requested. It is important to adopt the
    higher priority (and earlier timestamp) to ensure the requestor does
    not starve.

    Note: This presumes that an "item" is this 3-tuple:
        (&lt;priority-number&gt;, &lt;timestamp&gt;, &lt;_Request instance&gt;)
    """
    @others
</t>
<t tx="ekr.20080121105837.308">def __init__(self, maxsize=0):
    _PriorityQueue.__init__(self, maxsize)
    self._item_from_id = {}

</t>
<t tx="ekr.20080121105837.309">def _put(self, item):
    # Remove a possible existing request for the same file (there can
    # be only one).
    priority, timestamp, request = item
    id = request.id
    if id in self._item_from_id:
        i = self._item_from_id[id]
        self.queue.remove(i)
        p, t, r = i
        item = (min(priority, p), t, request)
    # Add the (possibly updated) item to the queue.
    self._item_from_id[id] = item
    _PriorityQueue._put(self, item)

</t>
<t tx="ekr.20080121105837.310">def _get(self):
    item = _PriorityQueue._get(self)
    del self._item_from_id[item[-1].id]
    return item


</t>
<t tx="ekr.20080121105837.311">class _StagingRequestQueue(_UniqueRequestPriorityQueue):
    """A thread-safe priority queue for '_Request' objects with delayed
    staging support.

    This queue class extends _UniqueRequestPriorityQueue by adding the
    .stage() method. This method is like the regular .put() method
    except that staged requests are only actually placed on the queue if
    a certain period of inactivity passes without subsequent stage
    requests for the same request id.

    This is to support reasonable performance for live updating while a
    document is being edited. Rather than executing a scan for every
    intermediate edited state, scanning is only  after a period of
    relative inactivity.

    One additional burden is that a "staging thread" is involved so one must
    call this queue's .finalize() method to properly shut it down.

    As with the _ScanRequestQueue this queue presumes that and item is this
    3-tuple:
            (&lt;priority-number&gt;, &lt;timestamp&gt;, &lt;ScanRequest instance&gt;)
    """
    DEFAULT_STAGING_DELAY = 1.5 # default delay from on deck -&gt; on queue (s)

    @others
</t>
<t tx="ekr.20080121105837.312">def __init__(self, maxsize=0, stagingDelay=None):
    """Create a staging scan request queue.

        "maxsize" (optional) is an upperbound limit on the number of
            items in the queue (&lt;= 0 means the queue is unbounded).
        "stagingDelay" (optional) is a number of seconds to use as a
            delay from being staged to being placed on the queue.
    """
    _UniqueRequestPriorityQueue.__init__(self, maxsize)
    if stagingDelay is None:
        self._stagingDelay = self.DEFAULT_STAGING_DELAY
    else:
        self._stagingDelay = stagingDelay
    self._onDeck = {
        # &lt;request-id&gt; : (&lt;time when due&gt;, &lt;priority&gt;, &lt;queue item&gt;)
    }
    self._nothingOnDeck = threading.Lock()
    self._nothingOnDeck.acquire()
    self._terminate = 0 # boolean telling "staging thread" to terminate
    self._stager = threading.Thread(target=self._stagingThread,
                                    name="request staging thread")
    self._stager.start()

</t>
<t tx="ekr.20080121105837.313">def finalize(self):
    if self._stager:
        self._terminate = 1
        # Make sure staging thread isn't blocked so it can terminate.
        self.mutex.acquire()
        try:
            if not self._onDeck:
                self._nothingOnDeck.release()
        finally:
            self.mutex.release()
        # Don't bother join'ing because there is no point waiting for
        # up to self._stagingDelay while the staging thread shuts down.
        #self._stager.join()

</t>
<t tx="ekr.20080121105837.314">def stage(self, item, delay=None):
    if delay is None:
        delay = self._stagingDelay
    self.mutex.acquire()
    try:
        priority, timestamp, request = item
        wasEmpty = not self._onDeck
        if request.id not in self._onDeck \
           or self._onDeck[request.id][1] != PRIORITY_IMMEDIATE:
            self._onDeck[request.id] = (timestamp + delay, priority, item)
            if wasEmpty:
                self._nothingOnDeck.release()
    finally:
        self.mutex.release()

</t>
<t tx="ekr.20080121105837.315">def _stagingThread(self):
    """Thread that handles moving requests on-deck to the queue."""
    log.debug("staging thread: start")
    while 1:
        # If nothing is on-deck, wait until there is.
        #log.debug("staging thread: acquire self._nothingOnDeck")
        self._nothingOnDeck.acquire()
        #log.debug("staging thread: acquired self._nothingOnDeck")
        if self._terminate:
            break

        # Place any "due" items on the queue.
        self.mutex.acquire()
        somethingStillOnDeck = 1
        currTime = time.time()
        toQueue = []
        try:
            for id, (timeDue, priority, item) in self._onDeck.items():
                if currTime &gt;= timeDue:
                    toQueue.append(item)
                    del self._onDeck[id]
            if not self._onDeck:
                somethingStillOnDeck = 0
        finally:
            if somethingStillOnDeck:
                self._nothingOnDeck.release()
            self.mutex.release()
        if toQueue:
            log.debug("staging thread: queuing %r", toQueue)
            for item in toQueue:
                self.put(item)

        # Sleep for a bit.
        #XXX If the latency it too large we may want to sleep for some
        #    fraction of the staging delay.
        log.debug("staging thread: sleep for %.3fs", self._stagingDelay)
        time.sleep(self._stagingDelay)
    log.debug("staging thread: end")



</t>
<t tx="ekr.20080121105837.316">#---- public classes

class XMLParseRequest(_Request):
    """A request to re-parse and XML-y/HTML-y file

    (For XML completion and Komodo's DOMViewer.)
    """
    @others
</t>
<t tx="ekr.20080121105837.317">def __init__(self, buf, priority, force=False):
    if _xpcom_:
        buf = UnwrapObject(buf)
    self.buf = buf
    self.id = buf.path + "#xml-parse"
    self.priority = priority
    self.force = force
</t>
<t tx="ekr.20080121105837.318">def __repr__(self):
    return "&lt;XMLParseRequest %r&gt;" % self.id
</t>
<t tx="ekr.20080121105837.319">def __str__(self):
    return "xml parse '%s' (prio %s)" % (self.buf.path, self.priority)


</t>
<t tx="ekr.20080121105837.320">class ScanRequest(_Request):
    """A request to scan a file for codeintel.

    A ScanRequest has the following properties:
        "buf" is the CitadelBuffer instance.
        "priority" must be one of the PRIORITY_* priorities.
        "force" is a boolean indicating if a scan should be run even if
            the database is already up-to-date for this content.
        "mtime" is the modified time of the file/content. If not given
            it defaults to the current time.
        "on_complete" (optional) is a callable to call when the scan
            and load is complete. (XXX: Is this being used by anyone?)

        "status" is set on completion. See .complete() docstring for details.
    """
    status = None
    @others
</t>
<t tx="ekr.20080121105837.321">def __init__(self, buf, priority, force=False, mtime=None, on_complete=None):
    if _xpcom_:
        buf = UnwrapObject(buf)
    self.buf = buf
    self.id = buf.path
    self.priority = priority
    self.force = force
    if mtime is None:
        self.mtime = time.time()
    else:
        self.mtime = mtime
    self.on_complete = on_complete
    self.complete_event = threading.Event() #XXX use a pool
</t>
<t tx="ekr.20080121105837.322">def __repr__(self):
    return "&lt;ScanRequest %r&gt;" % self.id
</t>
<t tx="ekr.20080121105837.323">def __str__(self):
    return "scan request '%s' (prio %s)" % (self.buf.path, self.priority)
</t>
<t tx="ekr.20080121105837.324">def complete(self, status):
    """Called by scheduler when this scan is complete (whether or
    not it was successful/skipped/whatever).

        "status" is one of the following:
            changed     The scan was done and (presumably) something
                        changed. PERF: Eventually want to be able to
                        detect when an actual change is made to be
                        used elsewhere to know not to update.
            skipped     The scan was skipped.
    """
    log.debug("complete %s", self)
    self.status = status
    self.complete_event.set()
    if self.on_complete:
        try:
            self.on_complete()
        except:
            log.exception("ignoring exception in ScanRequest "
                          "on_complete callback")
</t>
<t tx="ekr.20080121105837.325">def wait(self, timeout=None):
    """Can be called by code requesting a scan to wait for completion
    of this particular scan.
    """
    self.complete_event.wait(timeout)


</t>
<t tx="ekr.20080121105837.326">class PreloadBufLibsRequest(_Request):
    priority = PRIORITY_BACKGROUND    
    @others
</t>
<t tx="ekr.20080121105837.327">def __init__(self, buf):
    if _xpcom_:
        buf = UnwrapObject(buf)
    self.buf = buf
    self.id = buf.path + "#preload-libs"
</t>
<t tx="ekr.20080121105837.328">def __repr__(self):
    return "&lt;PreloadBufLibsRequest %r&gt;" % self.id
</t>
<t tx="ekr.20080121105837.329">def __str__(self):
    return "pre-load libs for '%s'" % self.buf.path

</t>
<t tx="ekr.20080121105837.330">class PreloadLibRequest(_Request):
    priority = PRIORITY_BACKGROUND    
    @others
</t>
<t tx="ekr.20080121105837.331">def __init__(self, lib):
    self.lib = lib
    self.id = "%s %s with %s dirs#preload-lib" \
              % (lib.lang, lib.name, len(lib.dirs))
</t>
<t tx="ekr.20080121105837.332">def __repr__(self):
    return "&lt;PreloadLibRequest %r&gt;" % self.id
</t>
<t tx="ekr.20080121105837.333">def __str__(self):
    return "pre-load %s %s (%d dirs)" \
           % (self.lib.lang, self.lib.name, len(self.lib.dirs))


</t>
<t tx="ekr.20080121105837.334">class IndexerStopRequest(_Request):
    id = "indexer stop request"
    priority = PRIORITY_CONTROL
    @others
</t>
<t tx="ekr.20080121105837.335">def __repr__(self):
    return '&lt;'+self.id+'&gt;'

</t>
<t tx="ekr.20080121105837.336">class IndexerPauseRequest(_Request):
    id = "indexer pause request"
    priority = PRIORITY_CONTROL
    @others
</t>
<t tx="ekr.20080121105837.337">def __repr__(self):
    return '&lt;'+self.id+'&gt;'


</t>
<t tx="ekr.20080121105837.338">class Indexer(threading.Thread):
    """A codeintel indexer thread.

    An indexer is mainly responsible for taking requests to scan
    (Citadel) buffers and load the data into the appropriate LangZone of
    the database.

#XXX Only needed when/if batch updating is redone.
##    This thread manages a queue of ScanRequest's, scheduling the scans in
##    priority order. It has two modes of usage:
##        MODE_DAEMON
##            The scheduler remains running until it is explicitly stopped with
##            the .stop() method.
##        MODE_ONE_SHOT
##            All added requests are processed and then the scheduler
##            terminates. Note that the .stageRequest() method is not
##            allowed in this mode.

    Usage:
        from codeintel.indexer import Indexer
        idxr = Indexer(mgr)
        idxr.start()
        try:
            # idxr.stage_request(&lt;request&gt;)
            # idxr.add_request(&lt;request&gt;)
        finally:
            idxr.finalize()

    Dev Notes:
    - The intention is the indexer will grow to handle other requests as
      well (saving and culling cached parts of the database).
    - There is a potential race condition on request id generation
      if addRequest/stageRequest calls are made from multiple threads.
    """
    MODE_DAEMON, MODE_ONE_SHOT = range(2)
    mode = MODE_DAEMON

    @others
</t>
<t tx="ekr.20080121105837.339">class StopIndexing(Exception):
    """Used to signal that indexer iteration should stop.

    Dev Note: I *could* use StopIteration here, but I don't want to
    possibly misinterpret a real StopIteration.
    """
    pass

</t>
<t tx="ekr.20080121105837.340">def __init__(self, mgr, on_scan_complete=None):
    """
        "on_scan_complete" (optional), if specified, is called when
            a ScanRequest is completed.

    TODO: add back the requestStartCB and completedCB (for batch updates)
    """
    threading.Thread.__init__(self, name="codeintel indexer")
    self.mgr = mgr 
    self.on_scan_complete = on_scan_complete
    if self.mode == self.MODE_DAEMON:
        self._requests = _StagingRequestQueue()
    else:
        self._requests = _UniqueRequestPriorityQueue()
    self._stopping = False
    self._resumeEvent = None

</t>
<t tx="ekr.20080121105837.341">def finalize(self):
    """Shutdown the indexer.

    This must be done even if the the indexer thread was never
    .start()'ed -- because of the thread used for the
    _StagingRequestQueue.
    """
    self._stopping = True
    if isinstance(self._requests, _StagingRequestQueue):
        self._requests.finalize()
    if self.isAlive():
        self.add_request(IndexerStopRequest())
        try:
            self.join()
        except AssertionError:
            pass # thread was not started

</t>
<t tx="ekr.20080121105837.342">def pause(self):
    self._resumeEvent = threading.Event()
    self._pauseEvent = threading.Event()
    self.addRequest(IndexerPauseRequest())
    self._pauseEvent.wait() # wait until the Scheduler is actually paused
    log.debug("indexer: paused")

</t>
<t tx="ekr.20080121105837.343">def resume(self):
    if self._resumeEvent:
        self._resumeEvent.set()
        self._resumeEvent = None
    log.debug("indexer: resumed")

</t>
<t tx="ekr.20080121105837.344">def stage_request(self, request, delay=None):
    log.debug("stage %r", request)
    if self.mode == self.MODE_ONE_SHOT:
        raise CodeIntelError("cannot call stage requests on a "
                             "MODE_ONE_SHOT indexer")
    #self._abortMatchingRunner(request.buf.path, request.buf.lang)
    self._requests.stage( (request.priority, time.time(), request), delay )
</t>
<t tx="ekr.20080121105837.345">def add_request(self, request):
    log.debug("add %r", request)
    #self._abortMatchingRunner(request.buf.path, request.buf.lang)
    self._requests.put( (request.priority, time.time(), request) )

#XXX re-instate for batch updating (was getNumRequests)
##    def num_requests(self):
##        return self._requests.qsize()
</t>
<t tx="ekr.20080121105837.346">def run(self):    # the scheduler thread run-time
    log.debug("indexer: start")
##        reason = "failed"
    try:
        while 1:
            try:
                self._iteration()
            except Queue.Empty: # for mode=MODE_ONE_SHOT only
##                    reason = "completed"
                break
            except self.StopIndexing:
##                    reason = "stopped"
                break
            except:
                log.exception("unexpected internal error in indexer: "
                              "ignoring and continuing")
    finally:
##            try:
##                if self._completedCB:
##                    self._completedCB(reason)
##            except:
##                log.exception("unexpected error in completion callback")
        log.debug("indexer thread: stopped")

</t>
<t tx="ekr.20080121105837.347">def _iteration(self):
    """Handle one request on the queue.

    Raises StopIndexing exception if iteration should stop.
    """
    #log.debug("indexer: get request")
    if self.mode == self.MODE_DAEMON:
        priority, timestamp, request = self._requests.get()
    else: # mode == self.MODE_ONE_SHOT
        priority, timestamp, request = self._requests.get_nowait()
    #log.debug("indexer: GOT request")

    try:
        if request.priority == PRIORITY_CONTROL: # sentinel
            if isinstance(request, IndexerStopRequest):
                raise self.StopIndexing()
            elif isinstance(request, IndexerPauseRequest):
                self._pauseEvent.set() # tell .pause() that Indexer has paused
                self._resumeEvent.wait()
                return
            else:
                raise CodeIntelError("unexpected indexer control "
                                     "request: %r" % request)

        if isinstance(request, ScanRequest):
            # Drop this request if the database is already up-to-date.
            db = self.mgr.db
            buf = request.buf
            status = "changed"
            if not request.force:
                scan_time_in_db = db.get_buf_scan_time(buf)
                if scan_time_in_db is not None \
                   and scan_time_in_db &gt; request.mtime:
                    log.debug("indexer: drop %s: have up-to-date data for "
                              "%s in the db", request, buf)
                    status = "skipped"
                    return

            buf.scan(mtime=request.mtime)
            db.update_buf_data(buf)

        elif isinstance(request, XMLParseRequest):
            request.buf.xml_parse()

        # Currently these two are somewhat of a DB zone-specific hack.
        #TODO: The standard DB "lib" iface should grow a
        #      .preload() (and perhaps .can_preload()) with a
        #      ctlr arg. This should be unified with the current
        #      StdLib.preload().
        elif isinstance(request, PreloadBufLibsRequest):
            for lib in request.buf.libs:
                if isinstance(lib, (LangDirsLib, MultiLangDirsLib)):
                    for dir in lib.dirs:
                        lib.ensure_dir_scanned(dir)
        elif isinstance(request, PreloadLibRequest):
            lib = request.lib
            assert isinstance(lib, (LangDirsLib, MultiLangDirsLib))
            for dir in lib.dirs:
                lib.ensure_dir_scanned(dir)

    finally:
        if isinstance(request, ScanRequest):
            request.complete(status)
            if self.on_scan_complete:
                try:
                    self.on_scan_complete(request)
                except:
                    log.exception("ignoring exception in Indexer "
                                  "on_scan_complete callback")


</t>
<t tx="ekr.20080121105837.348">class BatchUpdater(threading.Thread):
    """A scheduler thread for batch updates to the CIDB.

    Usage:

        # May want to have a subclass of BatchUpdater for fine control.
        updater = BatchUpdater()
        updater.add_request(...)  # Make one or more requests.

        mgr.batch_update(updater=updater)  # This will start the updater.

        # Optionally use/override methods on the updater to control/monitor
        # the update.
        # Control methods:
        #   abort()                 Abort the update.
        #   join(timeout=None)      Wait for the update to complete.
        #
        # Query methods:
        #   num_files_to_process()
        #   is_aborted()
        #
        # Monitoring methods (need to override these in subclass to catch):
        #   debug(msg, *args)
        #   info(msg, *args)
        #   warn(msg, *args)
        #   error(msg, *args)
        #   progress(stage, obj)
        #   done(reason)            Called when complete.

    Dev Notes:
    - Yes, there are two ways to get code run on completion:
        .start(..., on_complete=None)   intended for the controlling Citadel
        .done()                         intended for the sub-classing user
    """
    citadel = None
    on_complete = None
    _aborted = None

    @others
</t>
<t tx="ekr.20080121105837.349">def __init__(self):
    XXX
    threading.Thread.__init__(self, name="CodeIntel Batch Scheduler")

    self._requests = Queue.Queue()
    self.mode = None # "upgrade", "non-upgrade" or None
    self._scheduler = None # lazily created (if necessary) Scheduler

    #XXX Need these two anymore?
    self._completion_reason = None
    self._had_errors = False

</t>
<t tx="ekr.20080121105837.350">def start(self, citadel, on_complete=None):
    self.citadel = citadel
    self.on_complete = on_complete
    threading.Thread.start(self)

</t>
<t tx="ekr.20080121105837.351">def abort(self):
    """Abort the batch update.

    XXX The scheduler.stop() call will *block* until the scheduler is
        done. Don't want that, but need to rationalize with other
        calls to Scheduler.stop().
    """
    self._aborted = True
    if self._scheduler:
        self._scheduler.stop()
</t>
<t tx="ekr.20080121105837.352">def is_aborted(self):
    return self._aborted

</t>
<t tx="ekr.20080121105837.353">def done(self, reason):
    """Called when the update is complete.

        "reason" is a short string indicating how the batch update
            completed. Currently expected values are (though this
            may not be rigorous):
                aborted
                error
                success
                failed      (from Scheduler)
                completed   (from Scheduler)
                stopped     (from Scheduler)
            XXX Might be helpful to rationalize these.
    """
    self.info("done: %s", reason)

</t>
<t tx="ekr.20080121105837.354">def add_request(self, type, path, language=None, extra=None):
    """Add a batch request

        "type" is one of:
            language    scan a language installation
            cix         import a CIX file
            directory   scan a source directory
            upgrade     upgrade a CIDB file to the current version
        "path", depending on "type" is the full path to:
            language    a language installation
            cix         a CIX file
            directory   a source directory
            upgrade     a CIDB file
        "language", depending on "type" is:
            language    the language of the language installation
            cix         (not relevant, should be None)
            directory   the language of the source directory
            upgrade     (not relevant, should be None)
        "extra" is an optional (null if not used) extra value depending
            on the type, path and/or language of the request that may be
            request for processing it. For example, a PHP language batch
            update request uses the "extra" field to specify the
            "php.ini"-config-file path.
    """
    if self.isAlive():
        raise CodeIntelError("cannot add a batch update request while "
                             "the batch scheduler is alive")
    if type in ("language", "cix", "directory", "upgrade"):
        if type in ("language", "cix", "directory"):
            if self.mode == "upgrade":
                raise CodeIntelError("cannot mix 'upgrade' batch requests "
                                     "with other types: (%s, %s, %s, %s)"
                                     % (type, path, language, extra))
            self.mode = "non-upgrade"
        elif type == "upgrade":
            if self.mode == "non-upgrade":
                raise CodeIntelError("cannot mix 'upgrade' batch requests "
                                     "with other types: (%s, %s, %s, %s)"
                                     % (type, path, language, extra))
            self.mode = "upgrade"
        self._requests.put( (type, path, language, extra) )
    else:
        raise CodeIntelError("unknown batch update request type: '%s'"
                             % type)

</t>
<t tx="ekr.20080121105837.355">def num_files_to_process(self):
    """Return the number of files remaining to process."""
    #XXX Might want to do something for "upgrade" mode here.
    if self._scheduler:
        return self._scheduler.getNumRequests()
    else:
        return 0

</t>
<t tx="ekr.20080121105837.356">def progress(self, msg, data):
    """Report progress.

        "msg" is some string, generally used to indicate a stage of
            processing
        "data" is some object dependent on the value of "msg".
    """
    self.info("progress: %s %r", msg, data)
</t>
<t tx="ekr.20080121105837.357">def debug(self, msg, *args):
    log.debug(msg, *args)
</t>
<t tx="ekr.20080121105837.358">def info(self, msg, *args):
    log.info(msg, *args)
</t>
<t tx="ekr.20080121105837.359">def warn(self, msg, *args):
    log.warn(msg, *args)
</t>
<t tx="ekr.20080121105837.360">def error(self, msg, *args):
    log.error(msg, *args)

</t>
<t tx="ekr.20080121105837.361">def _subscheduler_request_started(self, request):
    """Callback from sub-Scheduler thread."""
    self.progress("scanning", request)

</t>
<t tx="ekr.20080121105837.362">def _subscheduler_completed(self, reason):
    """Callback from sub-Scheduler thread."""
    self._completion_reason = reason

</t>
<t tx="ekr.20080121105837.363">def _get_scheduler(self):
    if not self._scheduler:
        self._scheduler = Scheduler(Scheduler.MODE_ONE_SHOT,
                                    self.citadel,
                                    None,
                                    self._subscheduler_request_started,
                                    self._subscheduler_completed)
    return self._scheduler

</t>
<t tx="ekr.20080121105837.364">def run(self):
    log.debug("batch scheduler thread: start")
    self.errors = []
    try:
        while 1:
            if self._aborted:
                self._completion_reason = "aborted"
                break

            try:
                type_, path, lang, extra = self._requests.get_nowait()
                self.debug("handle %r batch update request: "
                           "path=%r, language=%r, extra=%r",
                           type_, path, lang, extra)
                if type_ == "upgrade":
                    self._handle_upgrade_request(path)
                elif type_ == "language":
                    self._handle_lang_request(path, lang, extra)
                elif type_ == "cix":
                    self._handle_cix_request(path)
                elif type_ == "directory":
                    self._handle_directory_request(path, lang)
                else:
                    raise CitadelError(
                        "unexpected batch request type: '%s'" % type_)
            except Queue.Empty:
                break
            except Exception, ex:
                self._had_errors = True
                self.error("unexpected error handling batch update:\n%s",
                           _indent(traceback.format_exc()))
                break

        if self._had_errors:
            log.debug("batch scheduler thread: error out")
            self._completion_reason = "error"
        elif self.mode == "upgrade":
            self._completion_reason = "success"
        elif self._scheduler: # No Scheduler for "upgrade" batch mode.
            # Phase 2: start the scheduler and wait for it to complete.
            self._scheduler.start()
            self._scheduler.join()
            if self._had_errors:
                self._completion_reason = "error"
            else:
                self._completion_reason = "success"
    finally:
        log.debug("batch scheduler thread: stop scheduler")
        if self._scheduler:
            self._scheduler.stop()
        log.debug("batch scheduler thread: scheduler stopped, call on_complete")
        if self.on_complete:
            try:
                self.on_complete()
            except:
                log.exception("error in batch scheduler on_complete "
                              "(ignoring)")
        log.debug("batch scheduler thread: on_complete called, call done")
        self.done(self._completion_reason)
        log.debug("batch scheduler thread: done called")
    log.debug("batch scheduler thread: end")

</t>
<t tx="ekr.20080121105837.365">def _cidb_upgrade_progress_callback(self, stage, percent):
    self.progress("upgrade", (stage, percent))

</t>
<t tx="ekr.20080121105837.366">def _handle_upgrade_request(self, dbPath):
    db = Database(self.citadel)
    starttime = time.time()
    try:
        currVer = db.upgrade(dbPath, self._cidb_upgrade_progress_callback)
    except CodeIntelError, ex:
        self._had_errors = True
        self.error("Error upgrading CIDB: %s\n%s",
                   ex, _indent(traceback.format_exc()))
        return

    #XXX Re-evaluate this. Might make more sense in the Komodo-specific
    #    batch update controller now.
    # Komodo-specific HACK: Allow for a more pleasing user experience
    # by making sure the "Upgrading Database" dialog is up for at
    # least 2 seconds, rather than flashing for a quick upgrade.
    endtime = time.time()
    elapsed = endtime - starttime
    if elapsed &lt; 2.0:
        time.sleep(2.0-elapsed)

</t>
<t tx="ekr.20080121105837.367">def _handle_cix_request(self, path):
    self.progress("importing", path)
    #XXX Consider not bothering if MD5 of file is already in DB.
    #       md5sum = md5.new(cix).hexdigest()
    #    c.f. "Can an MD5 for a CIX file be added?" in my notes.
    try:
        fin = open(path, 'r')
        try:
            cix = fin.read()
        finally:
            fin.close()
    except EnvironmentError, ex:
        self._had_errors = True
        self.error("Error importing CIX file '%s': %s\n%s",
                   path, ex, _indent(traceback.format_exc()))
        return
    db = Database(self.citadel)
    try:
        db.update(cix, recover=0, scan_imports=False)
    except CodeIntelError, ex:
        self._had_errors = True
        self.error("Error importing CIX file '%s': %s\n%s",
                   path, ex, _indent(traceback.format_exc()))
        return

</t>
<t tx="ekr.20080121105837.368">def _handle_lang_request(self, path, lang, extra):
    if lang == "*":
        langs = self.citadel.get_supported_langs()
    else:
        langs = [lang]

    for lang in langs:
        # See if have any pre-created CIX files for this language to use
        # instead of or in addition to actually scanning the core
        # library.
        stdcix = os.path.join(os.path.dirname(__file__),
                              lang.lower()+".cix")
        if os.path.exists(stdcix):
            self._handle_cix_request(stdcix)

        try:
            importer = self.citadel.import_handler_from_lang(lang)
        except CodeIntelError, ex:
            if lang != "*":
                self._had_errors = True
                self.error("cannot handle 'language' batch update "
                           "request for %s: %s", lang, ex)
            continue
        try:
            importer.setCorePath(path, extra)
            UPDATE_EVERY = 50
            n = 0
            scheduler = self._get_scheduler()
            for file in importer.genScannableFiles(skipRareImports=True,
                                                   importableOnly=True):
                if n % UPDATE_EVERY == 0:
                    self.progress("gathering files", n)
                    if self._aborted:
                        break
                r = ScanRequest(file, lang, PRIORITY_IMMEDIATE,
                                scan_imports=False)
                scheduler.addRequest(r)
                n += 1
        except CodeIntelError, ex:
            self._had_errors = True
            self.error("error handling %s request: %s\n%s",
                       lang, ex, _indent(traceback.format_exc()))

</t>
<t tx="ekr.20080121105837.369">def _handle_directory_request(self, path, lang):
    if lang == "*":
        langs = self.citadel.mgr.get_citadel_langs()
    else:
        langs = [lang]

    for lang in langs:
        try:
            importer = self.citadel.import_handler_from_lang(lang)
        except CodeIntelError, ex:
            if lang == "*":
                continue
            else:
                raise CodeIntelError("cannot handle 'directory' batch "
                                     "update request for '%s': %s"
                                     % (lang, ex))
        UPDATE_EVERY = 10
        n = 0
        scheduler = self._get_scheduler()
        for file in importer.genScannableFiles([path]):
            if n % UPDATE_EVERY == 0:
                self.progress("gathering files", n)
                if self._aborted:
                    break
            r = ScanRequest(file, lang, PRIORITY_IMMEDIATE,
                            scan_imports=False)
            scheduler.addRequest(r)
            n += 1



</t>
<t tx="ekr.20080121105837.370">#---- internal support stuff

# Recipe: indent (0.2.1) in C:\trentm\tm\recipes\cookbook
def _indent(s, width=4, skip_first_line=False):
    """_indent(s, [width=4]) -&gt; 's' indented by 'width' spaces

    The optional "skip_first_line" argument is a boolean (default False)
    indicating if the first line should NOT be indented.
    """
    lines = s.splitlines(1)
    indentstr = ' '*width
    if skip_first_line:
        return indentstr.join(lines)
    else:
        return indentstr + indentstr.join(lines)


</t>
<t tx="ekr.20080121105837.371">@language python
@tabwidth -4
@others
# When run from command line
if __name__ == '__main__':
    main()
</t>
<t tx="ekr.20080121105837.372">#!/usr/bin/env python

""" Utility class used for the parsing of Javascript comments.

This uses the JavaSciptDoc style (JSDoc) "http://jsdoc.sourceforge.net/" for
allowing comments to specify specific information about the file structure.

The TAGS we use for JavaScript is based upon what JSDoc
supplies and what YAHOO has done. A YAHOO example is:

/**
 * Method for creating a slider
 *
 * @private
 * @param s {String} the name of the slider.
 * @param id {String} element id to place the silder within
 * @param {int} leftPadding is the size of the padding field on the left
 * @param rightPadding {int} optional field for setting the size of the padding
 * field on the right.
 * @return {Slider} a horizontal slider control
 */

Notes:
* comments and type information "{...}" are optional
* {} type field can be either the first or second position after the field.
* field comments can span multiple lines.
"""

# JSDoc tags and the help (calltip) for the tag.
# Note: Not all of these have a meaning for the javascript ciler.
jsdoc_tags = {
    "addon":        "This is an addon to an external JS class or component.\n"
                    "Example: /** @addon */",

    "argument":     "Provide information about a function parameter.\n"
                    "Note: Same as @param.\n"
                    "Example: /** @argument arg1 {string}  The first argument */",

    "author":       "The author of this component.\n"
                    "Example: /** @author John Smith jsmith@jsmith.com.mars */",

    "base":         "The base class this class extends.\n"
                    "Note: Same as @extends.\n"
                    "Example: /** @base MyParentClass */",

    "class":        "This tag is used in a constructor's documentation block\n"
                    "to provide information about the actual class.\n"
                    "Example: /** @class MyClass */",

    "constructor":  "The constructor for the class.\n"
                    "Example: /** @constructor MyClass */",

    "deprecated":   "Mark as not being supported anymore.\n"
                    "Deprecated components should not be used, as they\n"
                    "will usually be removed in some future version.\n"
                    "Example: /** @deprecated */",

    "exception":    "Method call may throw this type of exception.\n"
                    "Note: Same as @throws.\n"
                    "Example: /** @exception MyException  Text of when thrown */",

    "extends":      "The base class this class extends.\n"
                    "Note: Same as @base.\n"
                    "Example: /** @extends ParentClass */",

    "fileoverview": "This documentation block will be used to provide\n"
                    "an overview for the current file.\n"
                    "Example: /** @fileoverview */",

    "final":        "Constant variable.\n"
                    "Example: /** @final */",

    "ignore":       "Item will be ignored by JSDoc.\n"
                    "Example: /** @ignore */",

    "member":       "This is a member of the named class.\n"
                    "Example: /** @member MyClass */",

    "namespace":    "Namespace where the element resides.\n"
                    "Example: /** @namespace code.util */",

    "param":        "Provide information about a function parameter.\n"
                    "Note: Same as @argument.\n"
                    "Example: /** @param arg1 {string}  The first argument */",

    "private":      "Member is private.\n"
                    "This means it will not be shown in any documentation.\n"
                    "Komodo's Code Browser shows this with a locked image.\n"
                    "Example: /** @private */",

    "requires":     "Define a dependency upon another class.\n"
                    "Example: /** @requires OtherClass  Because it does! */",

    "returns":      "Provide information about the return value of a function.\n"
                    "Example: /** @returns {array} An array of items. */",

    "static":       "Static member, only one instance ever defined.\n"
                    "Example: /** @static */",

    "see":          "Link to another class or function.\n"
                    "Example: /** @see ClassName#methodName */",

    "tags":         "User defined tag names.\n"
                    "Example: /** @tags testcase,knownfailure */",

    "throws":       "Method call may throw this type of exception.\n"
                    "Note: Same as @exception.\n"
                    "Example: /** @throws MyException  Text of when thrown */",

    "type":         "Variable type.\n"
                    "Example: /** @type String */",

    "version":      "Version number of the current file or class.\n"
                    "Example: /** @version 1.0.8 */",

}

</t>
<t tx="ekr.20080121105837.373">class JSDocParameter:
    @others
</t>
<t tx="ekr.20080121105837.374">def __init__(self, paramname, paramtype=None, doc=None):
    self.paramname = paramname
    self.paramtype = paramtype
    self.doc = doc
</t>
<t tx="ekr.20080121105837.375">def __repr__(self):
    return "JSDocParameter: %r (%r) - %r" % (self.paramname, self.paramtype,
                                             self.doc)

</t>
<t tx="ekr.20080121105837.376">class JSDoc:
    A_CLASS = 0x01
    A_CONSTRUCTOR = 0x02
    A_PRIVATE = 0x04
    A_STATIC = 0x08
    A_CONSTANT = 0x10
    A_DEPRECATED = 0x20

    @others
</t>
<t tx="ekr.20080121105837.377">def __init__(self, comment=None):
    self._reset()
    if comment:
        # Full comment initially given
        #print "JSDoc comment: %r" % (comment)
        self.parse(comment)

</t>
<t tx="ekr.20080121105837.378">def __repr__(self):
    result = []
    if self.attributes:
        attrs = []
        if self.attributes &amp; self.A_CLASS:
            if self.classname:
                result.append("Classname:  %s" % (self.classname))
            else:
                attrs.append("class")
        elif self.attributes &amp; self.A_CONSTRUCTOR:
            attrs.append("constructor")
        elif self.attributes &amp; self.A_PRIVATE:
            attrs.append("private")
        elif self.attributes &amp; self.A_STATIC:
            attrs.append("static")
        elif self.attributes &amp; self.A_CONSTANT:
            attrs.append("constant")
        elif self.attributes &amp; self.A_DEPRECATED:
            attrs.append("deprecated")
        if len(attrs) &gt; 0:
            result.append(" ".join(attrs))
    if self.namespace:
        result.append("Namespace:  %s" % (self.namespace))
    if self.baseclass:
        result.append("Baseclass:  %s" % (self.baseclass))
    for cp in self.params:
        result.append(str(cp))
    if self.type:
        result.append("Type:  %s" % (self.type))
    if self.tags:
        result.append("Tags:  %s" % (self.tags))
    if self.returns:
        result.append("Returns:  %s" % (str(self.returns)))
    if self.doc:
        result.append("Doc:\n" + self.doc)
    return "JSDoc:\n  %s" % ("\n  ".join(result))

</t>
<t tx="ekr.20080121105837.379">def _reset(self):
    self.comment = None
    self.baseclass = None
    self.doc = None
    self.classname = None
    self.namespace = None
    self.type = None
    self.tags = None
    self.attributes = 0
    # params is a list of JSDocParameter's
    self.params = []
    # returns is a JSDocParameter (does not have a paramname though)
    self.returns = None

</t>
<t tx="ekr.20080121105837.380">def _getTypeField(self, value):
    # Examples:
    #  'int'
    #  '{String}'
    #  'boolean|Object'
    #  'Array[](Number[])'
    # YUI Example:
    #   * @param {&lt;a href="http://www.w3.org/TR/2000/WD-DOM-Level-1-20000929/level-one-
    #   * html.html#ID-22445964"&gt;HTMLDivElement&lt;/a&gt;} p_oElement Object specifying the 
    #   * &lt;code&gt;&amp;#60;div&amp;#62;&lt;/code&gt; element of the context menu.
    if not value:
        return value

    # Only take first field if multiples are given
    pipePos = value.find('|')
    if pipePos &gt; 0:
        value = value[:pipePos]

    value = value.strip()
    if value[-1] == "}":
        value = value[:-1]
        sp = value.split("{", 1)
        if len(sp) &gt; 1:
            value = sp[1]
            sp = value.split(":", 1)
            if len(sp) &gt; 1:
                value = sp[1]
    # Added to remove YUI's href docs from the citdl type
    href_pos = value.find('&lt;a href="')
    if href_pos &gt;= 0:
        # We only want the href link text
        end_a_tag_pos = value.find('&lt;/a&gt;')
        if end_a_tag_pos:
            value = value[:end_a_tag_pos]
            # Find matching close tag &gt;
            href_pos = value.rfind('&gt;')
            if href_pos &gt;= 0:
                value = value[href_pos+1:]

    # If a brace is in the value, it's an array
    bracePos = value.find("[")
    if bracePos &gt;= 0:
        value = "Array"
    return value.strip()

</t>
<t tx="ekr.20080121105837.381"># Examples:
#  "{Boolean}       true if the date is OOM"
#  "el {HTMLElement} the element to animate"
#  "{string}  sCategory  The log category for the message."
def _getTypeFieldFromString(self, value):
    """Return tuple (type, rest of string)"""

    sp = value.split("{", 1)
    if len(sp) &gt; 1:
        before = sp[0]
        value = sp[1]
        sp = value.split("}", 1)
        value = sp[0]
        if len(sp) &gt; 1:
            after = sp[1]
            return (self._getTypeField(value), before + after)
    return (None, value)

</t>
<t tx="ekr.20080121105837.382">def _handle_base(self, value):
    self.baseclass = value

</t>
<t tx="ekr.20080121105837.383"># Same as base
def _handle_extends(self, value):
    self._handle_base(value)

</t>
<t tx="ekr.20080121105837.384">def _handle_class(self, value):
    self.attributes |= self.A_CLASS
    self.classname = value

</t>
<t tx="ekr.20080121105837.385">def _handle_constructor(self, value):
    self.attributes |= self.A_CONSTRUCTOR

</t>
<t tx="ekr.20080121105837.386">def _handle_namespace(self, value):
    self.namespace = value

</t>
<t tx="ekr.20080121105837.387">def _handle_private(self, value):
    self.attributes |= self.A_PRIVATE

</t>
<t tx="ekr.20080121105837.388">def _handle_static(self, value):
    self.attributes |= self.A_STATIC

</t>
<t tx="ekr.20080121105837.389">def _handle_final(self, value):
    self.attributes |= self.A_CONSTANT

</t>
<t tx="ekr.20080121105837.390">def _handle_deprecated(self, value):
    self.attributes |= self.A_DEPRECATED

</t>
<t tx="ekr.20080121105837.391">def _handle_param(self, value):
    paramname = None
    paramtype = None
    doc = None
    sp = value.split(None, 2)
    for s in sp[:2]:
        if paramtype is None and s and s[0] == '{':
            # type information
            paramtype = self._getTypeField(s)
        elif paramname is None:
            paramname = s
    # Should have at least the paramname by now
    if paramname and paramtype:
        if len(sp) &gt; 2:
            doc = sp[2]
        else:
            doc = None
    else:
        doc = " ".join(sp[1:3])
    cp = JSDocParameter(paramname, paramtype, doc)
    self.params.append(cp)

</t>
<t tx="ekr.20080121105837.392">def _handle_tags(self, value):
    self.tags = value

</t>
<t tx="ekr.20080121105837.393">def _handle_type(self, value):
    self.type = self._getTypeField(value)

</t>
<t tx="ekr.20080121105837.394">def _handle_return(self, value):
    returntype, doc = self._getTypeFieldFromString(value)
    if returntype:
        self.returns = JSDocParameter(None, returntype, doc)
</t>
<t tx="ekr.20080121105837.395"># Same as return
def _handle_returns(self, value):
    return self._handle_return(value)

</t>
<t tx="ekr.20080121105837.396">def parse(self, comment):
    self._reset()
    self.comment = comment
    if not comment:
        return False
    in_doc = True
    doc = []
    lines = self.comment.splitlines(0)
    # Check to see if it's an actual javadoc
    isJSDoc = False
    # Once we reach the tags we don't add to the doc anymore, only
    # to the tags
    tagElements = []
    for line in lines:
        line = line.strip()
        #print "line: %r" % (line)
        if not isJSDoc:
            # Note: "*//**" style comes from the ciler using two comments
            # See bug: http://bugs.activestate.com/show_bug.cgi?id=68727
            if line == "/**" or line.endswith("*//**"):
                # It looks like a javadoc from here
                isJSDoc = True
        else:
            # It's a javadoc, so parse up the fields
            if line == "*/":
                isJSDoc = False
            elif line.endswith("*//**"):
                self._reset()
                self.comment = comment
            elif line == "*":
                doc.append("")
            elif len(line) &gt; 2 and line[:2] == "* ":
                sp = line.split(None, 1)
                #print sp
                if len(sp) &gt; 1:
                    if sp[1][0] == '@':
                        # It's a javadoc field
                        #print sp
                        docfield = sp[1][1:]
                        sp = docfield.split(None, 1)
                        #print sp
                        #print "Tag: %r" % (sp[0])
                        if sp[0] == "description":
                            if len(sp) &gt; 1:
                                doc.append(sp[1])
                            in_doc = True
                        else:
                            tagElements.append(sp)
                            in_doc = False
                    elif tagElements and doc and not in_doc: # This is a continued param field
                        tagData = tagElements[-1]
                        if len(tagData) == 1:
                            tagData.append(sp[1])
                        else:
                            tagData[1] += "\n%s" % (sp[1])
                    else: # This is still the main doc string
                        doc.append(sp[1])
                        in_doc = True
    self.doc = "\n".join(doc).rstrip()
    # Parse the tags now
    for tagData in tagElements:
        handle_call = getattr(self, "_handle_%s" % (tagData[0]), None)
        if handle_call is not None:
            if len(tagData) == 1:
                value = ""
            else:
                value = tagData[1].strip()
            handle_call(value)
        # else: # We don't handle this param

</t>
<t tx="ekr.20080121105837.397">def isClass(self):
    return self.attributes &amp; self.A_CLASS

</t>
<t tx="ekr.20080121105837.398">def isConstructor(self):
    return self.attributes &amp; self.A_CONSTRUCTOR

</t>
<t tx="ekr.20080121105837.399">def isPrivate(self):
    return self.attributes &amp; self.A_PRIVATE

</t>
<t tx="ekr.20080121105837.400">def isStatic(self):
    return self.attributes &amp; self.A_STATIC

</t>
<t tx="ekr.20080121105837.401">def isConstant(self):
    return self.attributes &amp; self.A_CONSTANT

</t>
<t tx="ekr.20080121105837.402">def isDeprecated(self):
    return self.attributes &amp; self.A_DEPRECATED


</t>
<t tx="ekr.20080121105837.403">############################################################
#                       Test code                          #
############################################################

def _test():
    sample_comment = """/**
 * Utility to set up the prototype, constructor and superclass properties to
 * support an inheritance strategy that can chain constructors and methods.
 *
 * @param {function} subclass   the object to modify
 * @param {function} superclass the object to inherit.
 *  Second line of param superclass doc.
 * @tags these,are,my,tags
 */
"""

    # Test the general usage of the class
    jd = JSDoc(sample_comment)
    assert(len(jd.params) == 2)
    assert(jd.params[0].paramname == "subclass")
    assert(jd.params[0].paramtype == "function")
    assert(jd.params[0].doc == "the object to modify")
    assert(jd.params[1].paramname == "superclass")
    assert(jd.params[1].paramtype == "function")
    assert(jd.params[1].doc == "the object to inherit.\nSecond line of param superclass doc.")
    assert(jd.tags == "these,are,my,tags")
    #print jd

    # Test specific internal functions of the class
    paramtype, doc = jd._getTypeFieldFromString("el {HTMLElement} the element to animate")
    assert(paramtype == "HTMLElement")
    assert(doc == "el  the element to animate")
    paramtype = jd._getTypeField("Array[](Number[])")
    assert(paramtype == "Array")
    paramtype = jd._getTypeField("Number|Array[])")
    assert(paramtype == "Number")

    jd._reset()
    jd._handle_param("{string}  sSource    The source of the the message (opt)")
    assert(len(jd.params) == 1 and \
           jd.params[0].paramname == "sSource" and \
           jd.params[0].paramtype == "string")

    jd._reset()
    jd._handle_param("oParent {Node} this node's parent node")
    assert(len(jd.params) == 1 and \
           jd.params[0].paramname == "oParent" and \
           jd.params[0].paramtype == "Node")

    jd._reset()
    jd._handle_returns("{array} Array of result objects")
    assert(jd.returns and \
           not jd.returns.paramname and \
           jd.returns.paramtype == "array")

    jd._reset()
    jd._handle_class("The superclass of all menu containers.")
    assert(jd.attributes &amp; jd.A_CLASS)
    assert(jd.isClass())

    jd._reset()
    jd._handle_private("")
    assert(jd.attributes &amp; jd.A_PRIVATE)
    assert(jd.isPrivate())

    jd._reset()
    jd._handle_static("")
    assert(jd.attributes &amp; jd.A_STATIC)
    assert(jd.isStatic())

    jd._reset()
    jd._handle_constructor("")
    assert(jd.attributes &amp; jd.A_CONSTRUCTOR)
    assert(jd.isConstructor())

    jd._reset()
    jd._handle_deprecated("")
    assert(jd.attributes &amp; jd.A_DEPRECATED)
    assert(jd.isDeprecated())

    jd._reset()
    jd._handle_base("YAHOO.widget.Menu")
    assert(jd.baseclass == "YAHOO.widget.Menu")
    jd._reset()
    jd._handle_extends("YAHOO.util.DragDrop")
    assert(jd.baseclass == "YAHOO.util.DragDrop")

    jd._reset()
    jd._handle_type("YAHOO.widget.MenuModuleItem")
    assert(jd.type == "YAHOO.widget.MenuModuleItem")
    jd._reset()
    jd._handle_type("{HTMLImageElement}")
    assert(jd.type == "HTMLImageElement")

</t>
<t tx="ekr.20080121105837.404"># Main function
def main():
    _test()

</t>
<t tx="ekr.20080121105837.405">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.406">#!/usr/bin/env python
# ***** LICENSE BLOCK *****
&lt;&lt; LangIntel docstring &gt;&gt;

import operator
from pprint import pformat

from codeintel2.common import *
from codeintel2.util import banner, indent, markup_text, isident, isdigit
from codeintel2.udl import is_udl_ssl_style

</t>
<t tx="ekr.20080121105837.407">class LangIntel(object):
    """Smarts about a given language.
    
    Note: Currently there aren't any std attributes common to all
    languages here. However, there probably eventually will be. Also
    note that common Buffer implementations defer to a language's
    LangIntel for handling various things.

    Also, see the mixins below.
    """
    @others
</t>
<t tx="ekr.20080121105837.408">def __init__(self, mgr):
    self.mgr = mgr

</t>
<t tx="ekr.20080121105837.409"># Code Browser integration.
cb_import_group_title = "Imports"
cb_globalvar_group_title = "Global Variables"
cb_group_global_vars = True

def cb_blob_detail_from_elem_and_buf(self, elem, buf):
    if elem.get("lang") != buf.lang: # multi-lang doc
        return "%s Code in %s" % (elem.get("lang"), buf.path)
    else:
        dir, base = os.path.split(buf.path)
        if dir:
            return "%s (%s)" % (base, dir)
        else:
            return base

</t>
<t tx="ekr.20080121105837.410">def cb_import_data_from_elem(self, elem):
    # Python form by default.
    alias = elem.get("alias")
    symbol = elem.get("symbol")
    module = elem.get("module")
    if alias:
        if symbol:
            name = "%s (%s.%s)" % (alias, module, symbol)
            detail = "from %(module)s import %(symbol)s as %(alias)s" % locals()
        else:
            name = "%s (%s)" % (alias, module)
            detail = "import %(module)s as %(alias)s" % locals()
    elif symbol:
        name = '.'.join([module, symbol])
        detail = "from %(module)s import %(symbol)s" % locals()
    else:
        name = module
        detail = "import %(module)s" % locals()
    return {"name": name, "detail": detail}

</t>
<t tx="ekr.20080121105837.411">def cb_variable_data_from_elem(self, elem):
    attrs = elem.get("attributes", "").split()
    if elem.get("ilk") == "argument":
        img = "argument"
    elif "__instancevar__" in attrs:
        img = "instance-variable"
    else:
        img = "variable"
    if "private" in attrs:
        img += "-private"
    elif "protected" in attrs:
        img += "-protected"
    #TODO: Add 'detail'. C.f. cb.py::getDescForSymbol().
    return {"name": elem.get("name"),
            "img": img}

</t>
<t tx="ekr.20080121105837.412">def cb_function_detail_from_elem(self, elem):
    # by default (some languages may choose to override)
    sig = elem.get("signature")
    if sig:
        return sig
    else:
        return elem.get("name")+"(...)"

</t>
<t tx="ekr.20080121105837.413">def cb_class_detail_from_elem(self, elem):
    classrefs = elem.get("classrefs")
    if classrefs:
        return elem.get("name") + "(" + classrefs + ")"
    return elem.get("name")+"()"

</t>
<t tx="ekr.20080121105837.414">def cb_interface_detail_from_elem(self, elem):
    interfacerefs = elem.get("interfacerefs")
    if interfacerefs:
        return elem.get("name") + "(" + interfacerefs + ")"
    return elem.get("name")+"()"

</t>
<t tx="ekr.20080121105837.415">def cb_namespace_detail_from_elem(self, elem):
    return elem.get("name")

</t>
<t tx="ekr.20080121105837.416">def cb_data_from_elem_and_buf(self, elem, buf):
    """Return a dict of info for a code browser row for this element.
    
    - Should define "name" key.
    - Can define "detail" key. This is the string displayed when
      hovering over the image in the code browser.
    - Can define "img" key. This is string used to identify the
      image type. The following are common values:
        argument, variable, class, function, import, interface, namespace
      The symbol-types have -protected and -private versions, e.g.:
        variable-private, variable-protected, class-private, ...
      As well, many of the languages have associated icons:
        Perl, Python, JavaScript, Ruby, ...
      A few special ones for class instance vars:
        instance-variable, instance-variable-protected,
        instance-variable-private
      Some special ones:
        container, scanning, error
    """
    if elem.tag == "import":
        data = {"img": "import"}
        data.update( self.cb_import_data_from_elem(elem) )
        return data

    elif elem.tag == "variable":
        return self.cb_variable_data_from_elem(elem)

    elif elem.tag == "scope":
        ilk = elem.get("ilk")
        if ilk == "blob":
            img = elem.get("lang")
            detail = self.cb_blob_detail_from_elem_and_buf(elem, buf)
        else:
            img = ilk
            attrs = elem.get("attributes", "").split()
            if "private" in attrs:
                img += "-private"
            elif "protected" in attrs:
                img += "-protected"
            if ilk == "function":
                detail = self.cb_function_detail_from_elem(elem)
            elif ilk == "class":
                detail = self.cb_class_detail_from_elem(elem)
            elif ilk == "interface":
                detail = self.cb_interface_detail_from_elem(elem)
            elif ilk == "namespace":
                detail = self.cb_namespace_detail_from_elem(elem)
            else: # what else could it be?
                log.warn("don't know how to get cb detail for '%s' elem",
                         ilk)
                detail = elem.get("name")

        return {"name": elem.get("name"),
                "img": img,
                "detail": detail}
    else:
        return {"name": repr(elem)}



</t>
<t tx="ekr.20080121105837.417">class ParenStyleCalltipIntelMixin(object):
    """A mixin class to implement `curr_calltip_arg_range' for languages
    with parenthesis-style call signatures.
    """
    # A sequence of terminator characters for a calltip region.
    calltip_region_terminators = tuple(']});')

    @others
</t>
<t tx="ekr.20080121105837.418">def calltip_verify_termination(self, accessor, ch, trg_pos, curr_pos):
    """Hook to allow language-specific, context-specific checking."""
    return True

</t>
<t tx="ekr.20080121105837.419">_parsed_calltip_cache = (None, None) # (&lt;last-calltip&gt;, &lt;last-parsed-calltip&gt;)
def curr_calltip_arg_range(self, buf, trg_pos, calltip, curr_pos,
                           DEBUG=False):
    """Return that range in the calltip of the "current" arg.
    I.e. what argument is currently being entered.
    
        "buf" is the buffer object on which this is being done.
        "trg_pos" is the trigger position.
        "calltip" is the full calltip text.
        "curr_pos" is the current position in the buffer.
        
    Returns a range: (start, end)
    Set `start == -1` to cancel the calltip, i.e. if the entered text
    has closed the call region.

    The default implementation uses:
        self.calltip_region_terminators
    to handle languages with calltip signatures with the following
    characteristics:
    - uses '(' and ')' to bound the argument list (though because of
      support for ';' statement termination, this isn't absolutely
      required)
    - uses a comma to separate arguments
    - basic block delimiters are {}, (), and []

    For example:
        foo()
        blam(a, b)
        range([start,] stop[, step]) -&gt; list of integers
        bar(arg1, *args, **kwargs)
        flash(boom, bang=42)
    """
    # Dev Notes:
    # - Eventually should pass in the trigger to aid in processing.
    # - TODO figure out dependence on buf.comment_styles() and
    #   buf.string_styles()
    accessor = buf.accessor
    if DEBUG:
        print banner("curr_calltip_arg_range")
        print "calltip:\n%s" % indent(calltip)
        print "buffer:\n%s" % indent(markup_text(accessor.text,
                                                 trg_pos=trg_pos,
                                                 pos=curr_pos))
        
    # Start from the trigger position and walk forward to the current
    # pos: counting args and looking for termination of the calltip
    # region.
    skip_styles = dict(
        (s, True) for s in buf.comment_styles() + buf.string_styles())
    if accessor.style_at_pos(trg_pos-1) in skip_styles:
        skip_styles = {}
    comma_count = 0
    blocks = {
        # Map a block start token to its block end token.
        '(': ')', '[': ']', '{': '}',
    }
    block_stack = []
    p = trg_pos
    for ch, style in accessor.gen_char_and_style(trg_pos, curr_pos):
        if DEBUG: print "pos %2d: %r (%2s) --" % (p, ch, style),
        if style in skip_styles:
            if DEBUG: print "skip"
        elif ch in blocks:
            if DEBUG: print "open block"
            block_stack.append(blocks[ch])
        elif block_stack:
            if ch == block_stack[-1]:
                if DEBUG: print "close block"
                block_stack.pop()
            elif ch in self.calltip_region_terminators:
                if DEBUG: print "end of call region: (-1, -1)"
                return (-1, -1)
            elif DEBUG:
                print "ignore (in block)"
        elif ch == ',':
            if DEBUG: print "next arg"
            comma_count += 1
        elif ch in self.calltip_region_terminators and \
             self.calltip_verify_termination(accessor, ch, trg_pos, curr_pos):
            if DEBUG: print "end of call region: (-1, -1)"
            return (-1, -1)
        elif DEBUG:
            print "ignore"
        p += 1

    # Parse the signature from the calltip. If there is no signature
    # then we default to not indicating any arg range.
    if self._parsed_calltip_cache[0] == calltip:
        parsed = self._parsed_calltip_cache[1]
    else:
        parsed = _parse_calltip(calltip, DEBUG)
        self._parsed_calltip_cache = (calltip, parsed)
    if parsed is None:
        if DEBUG: print "couldn't parse any calltip: (0, 0)"
        return (0, 0)
    signature, name, args = parsed
    if DEBUG:
        print "parsed calltip:\n  signature:\n%s\n  name:\n%s\n  args:\n%s"\
              % (indent(signature), indent(name), indent(pformat(args)))

    if not args:
        if DEBUG: print "no args in signature: (0, 0)"
        return (0, 0)
    elif comma_count &gt;= len(args):
        #XXX ellipsis
        if DEBUG: print "more commas than args: ellipsis?"
        span = args[-1].span # default to last arg
    else:
        span = args[comma_count].span

    if DEBUG:
        print "curr calltip range (%s, %s):" % (span[0], span[1])
        print indent(signature)
        print "    %s%s" % (' '*span[0], '-'*(span[1]-span[0]))
    return span



</t>
<t tx="ekr.20080121105837.420">class ProgLangTriggerIntelMixin(object):
    """A mixin class to implement `preceding_trg_from_pos' for
    programming languages.

    How do you know if this is appropriate for your language? Write
    some test cases using assertPrecedingTriggerMatches() and see
    if this mixin works for those tests. It works fine for Python and
    Perl, for example.
    """
    # A sequence of characters at which all triggers occur.
    trg_chars = tuple('.(')

    # A sequence of characters at which all calltip triggers occur.
    calltip_trg_chars = tuple('(')

    # A dict of chars at which to always stop backtracking looking
    # for a preceding trigger point.  If no style is given the
    # character alone is sufficient.  Otherwise trigger if the
    # style matches.
    preceding_trg_terminators = {';': None}

    @others
</t>
<t tx="ekr.20080121105837.421">def preceding_trg_from_pos(self, buf, pos, curr_pos,
                           preceding_trg_terminators=None, DEBUG=False):
    accessor = buf.accessor
    if preceding_trg_terminators is None:
        preceding_trg_terminators = self.preceding_trg_terminators
    if DEBUG:
        print banner("preceding_trg_from_pos(pos=%r, curr_pos=%r)"
                      % (pos, curr_pos))
        print indent(markup_text(accessor.text, pos=curr_pos,
                                 start_pos=pos))
        print banner(None, '-')

    # Skip over comments and strings in our checking, unless we are
    # in one of these styles for the whole range. This is so an explicit
    # trigger in a comment (or, e.g., a doc string) will work, but
    # the appearance of small comments or strings in code will not mess
    # things up.
    comment_and_string_styles = dict(
        (s, True) for s in buf.comment_styles() + buf.string_styles())
    skip_styles = {}
    start_style = accessor.style_at_pos(pos-1)
    EOL_CHARS = tuple("\n\r")

    # Limiting simplification: Only backtrack a max of 200 chars.
    # Can increase that if necessary. The problem is detecting a
    # statement boundary backwards in langs like Python and Ruby
    # where you can't rely on ';' (actually
    # `preceding_trg_terminators').
    limit = max(1, pos - 200)
    
    # First stage. We only consider autocomplete trigger (i.e.
    # trg.form==TRG_FORM_COMPLETION) if within range of the
    # curr_pos. Here "within range" means you don't have to more the
    # cursor to show the autocomplete UI.
    first_stage_limit = curr_pos
    for (char, style) in accessor.gen_char_and_style_back(curr_pos-1,
                                                          limit-1):
        if not isident(char):
            break
        first_stage_limit -= 1
    if DEBUG:
        print "[stage 1] first_stage_limit=%d (prev_ch=%r)"\
              % (first_stage_limit,
                 (first_stage_limit &gt; 0
                  and accessor.char_at_pos(first_stage_limit-1)
                  or None))
    p = pos
    if p &gt;= first_stage_limit:
        for (prev_ch, prev_style) in accessor.gen_char_and_style_back(p-1,
                                                      first_stage_limit-2):
            if (not skip_styles and prev_style != start_style
                # EOLs in comments seem to always be style 0. Don't count
                # them.
                and prev_ch not in EOL_CHARS):
                if DEBUG:
                    print "[stage 1] have seen a style change (%d -&gt; %d), " \
                          "now skipping strings and comments" \
                          % (start_style, prev_style)
                skip_styles = comment_and_string_styles
            if DEBUG:
                print "[stage 1] consider pos %2d: prev_ch=%r (%d) --"\
                      % (p, prev_ch, prev_style),
            if prev_style in skip_styles:
                if DEBUG: print "comment or string, skip it"
            elif self._is_terminating_char(prev_ch, prev_style,
                                           preceding_trg_terminators):
                if DEBUG: print "in `preceding_trg_terminators': break"
                return None
            elif prev_ch in self.trg_chars:
                if DEBUG: print "trigger char, try it"
                trg = buf.trg_from_pos(p, implicit=False)
                if trg:
                    if DEBUG: print "[stage 1] %s" % trg
                    return trg
                p -= 1
                break
            elif DEBUG:
                print "not a trigger char, skip it"
            p -= 1
    if DEBUG:
        print "[stage 1] end of possible autocomplete trigger range"

    # Second stage. We only consider calltip triggers now
    # (self.calltip_trg_chars).
    # 
    # As well, ignore enclosed paren sections to make sure we are
    # in-range. For example, we shouldn't trigger on "bar(" here:
    #   foo(bar("skip", "this", "arg", "list"), &lt;|&gt;)
    close_paren_count = 0
    for (prev_ch, prev_style) in accessor.gen_char_and_style_back(p-1, limit-2):
        if (not skip_styles and prev_style != start_style
            # EOLs in comments seem to always be style 0. Don't count
            # them.
            and prev_ch not in EOL_CHARS):
            if DEBUG:
                print "[stage 2] seen a style change (%d -&gt; %d), now " \
                      "skipping strings and comments" \
                      % (start_style, prev_style)
            skip_styles = comment_and_string_styles

        if DEBUG:
            print "[stage 2] consider pos %2d: prev_ch=%r (%d) --"\
                  % (p, prev_ch, prev_style),
        if prev_style in skip_styles:
            if DEBUG: print "comment or string, skip it"
        elif prev_ch == ')':
            close_paren_count += 1
            if DEBUG: print "close paren: count=%d" % close_paren_count
        elif close_paren_count and prev_ch == '(':
            close_paren_count -= 1
            if DEBUG: print "open paren: count=%d" % close_paren_count
        elif self._is_terminating_char(prev_ch, prev_style,
                                       preceding_trg_terminators):
            if DEBUG: print "in `preceding_trg_terminators': break"
            return None
        elif prev_ch in self.calltip_trg_chars:
            if DEBUG: print "trigger char, try it"
            trg = buf.trg_from_pos(p, implicit=False)
            if trg:
                if DEBUG: print "[stage 2] %s" % trg
                return trg
        elif DEBUG:
            print "not a trigger char, skip it"
        p -= 1

    return None

</t>
<t tx="ekr.20080121105837.422">def _is_terminating_char(self, ch, style, preceding_trg_terminators):
    terminating_style = preceding_trg_terminators.get(ch, -1)
    return terminating_style is None or terminating_style == style

</t>
<t tx="ekr.20080121105837.423">class PythonCITDLExtractorMixin(object):
    """A LangIntel mixin class for
        citdl_expr_from_trg()
    for Python-like syntax.
    """

    # Dictionary of literal types to specific language citdl type
    # Note: The default values are Python specific
    citdl_from_literal_type = {"string": "str"}

    @others
</t>
<t tx="ekr.20080121105837.424">def _citdl_expr_from_pos(self, buf, pos, implicit=False,
                         include_forwards=False, DEBUG=False):

    #PERF: Would dicts be faster for all of these?
    WHITESPACE = tuple(" \t\n\r\v\f")
    EOL = tuple("\r\n")
    BLOCKCLOSES = tuple(")}]")
    STOPOPS = tuple("({[,&amp;+-=!^|%/&lt;&gt;;:#@")
    EXTRA_STOPOPS_PRECEDING_IDENT = BLOCKCLOSES # Might be others.

    #TODO: clean this up for LangIntel-usage
    if implicit:
        skip_styles = buf.implicit_completion_skip_styles
    else:
        skip_styles = buf.completion_skip_styles
    string_styles = buf.string_styles()
    comment_styles = buf.comment_styles()

    #XXX Add sentinel num chars?
    citdl_expr = []
    accessor = buf.accessor
    i = pos

    # Move ahead to include forward chars as well
    # We stop when we go out of the expression or when the expression is
    # becomes a multiple fragment, i.e.
    #  'sys.pa&lt;|&gt;th.expanduser' -&gt; 'sys.path'
    if include_forwards:
        buf_length = accessor.length()
        if i &lt; buf_length:
            max_look_ahead = min(buf_length, i+100)
            lastch_was_whitespace = False
            while i &lt; max_look_ahead:
                ch = accessor.char_at_pos(i)
                style = accessor.style_at_pos(i)
                if ch in WHITESPACE:
                    lastch_was_whitespace = True
                elif ch in ".)}]" or ch in STOPOPS:
                    break
                elif lastch_was_whitespace:
                    break
                else:
                    lastch_was_whitespace = False
                i += 1
            # Move back to last valid char
            i -= 1
        else:
            i = buf_length - 1
        if DEBUG:
            if i &gt; pos:
                print "Including chars from pos %d up to %d" % (pos, i)
            else:
                print "No valid chars forward from pos %d, i now: %d" % (pos, i)

    # Be careful here, we cannot move from code into a comment, but we
    # can be in a comment to begin with.
    first_citdl_expr_style = None
    first_citdl_expr_style_is_comment = False
    while i &gt;= 0:
        ch = accessor.char_at_pos(i)
        style = accessor.style_at_pos(i)
        if ch in WHITESPACE:
            # drop all whitespace
            while i &gt;= 0:
                ch = accessor.char_at_pos(i)
                if ch in WHITESPACE \
                   or (ch == '\\' and accessor.char_at_pos(i+1) in EOL):
                    if DEBUG:
                        print "drop whitespace: %r" % accessor.char_at_pos(i)
                else:
                    break
                i -= 1
            # If there are two whitespace-separated words with no .
            # in between we're changing expressions:
            #   if foo&lt;|&gt; and ...
            #   def foo&lt;|&gt;(...
            if i &gt;= 0 and citdl_expr and isident(citdl_expr[-1]) \
               and ch != '.':
                if DEBUG: 
                    print "stop at non-dot: %r" % ch
                break
        elif style in string_styles: # Convert to string
            citdl_type = self.citdl_from_literal_type.get("string")
            if DEBUG:
                print "found string style, converting to: %s and now " \
                      "finished" % (citdl_type)
            if citdl_type:
                citdl_expr += reversed(citdl_type)
            break
        elif style in skip_styles: # drop styles to ignore
            while i &gt;= 0 and accessor.style_at_pos(i) in skip_styles:
                if DEBUG:
                    print "drop char of style to ignore: %r"\
                          % accessor.char_at_pos(i)
                i -= 1
        elif ch in STOPOPS or (
             # This check ensures that, for example, we get "foo" instead
             # of "bar()foo" in the following:
             #      bar()
             #      foo&lt;|&gt;.
             citdl_expr and citdl_expr[-1] != '.'
             and ch in EXTRA_STOPOPS_PRECEDING_IDENT):
            if DEBUG:
                print "stop at stop-operator %d: %r" % (i, ch)
            break
        elif ch in BLOCKCLOSES:
            if DEBUG:
                print "found block at %d: %r" % (i, ch)
            citdl_expr.append(ch)

            BLOCKS = { # map block close char to block open char
                ')': '(',
                ']': '[',
                '}': '{',
            }
            stack = [] # stack of blocks: (&lt;block close char&gt;, &lt;style&gt;)
            stack.append( (ch, style, BLOCKS[ch], i) )
            i -= 1
            num_lines = 0
            while i &gt;= 0:
                ch = accessor.char_at_pos(i)
                style = accessor.style_at_pos(i)
                if DEBUG:
                    print "finding matching brace: ch %r (%s), stack %r"\
                          % (ch, ', '.join(buf.style_names_from_style_num(style)), stack)
                if ch in EOL:
                    num_lines += 1
                if num_lines &gt;= 3:
                    if DEBUG: print "stop search for matching brace at 3 line sentinel"
                    break
                elif ch in BLOCKS and style not in skip_styles:
                    stack.append( (ch, style, BLOCKS[ch]) )
                elif ch == stack[-1][2] and style not in skip_styles:
                    #XXX Replace the second test with the following
                    #    when LexPython+SilverCity styling bugs are fixed
                    #    (spurious 'stderr' problem):
                    #       and style == stack[-1][1]:
                    stack.pop()
                    if not stack:
                        if DEBUG:
                            print "jump to matching brace at %d: %r" % (i, ch)
                        citdl_expr.append(ch)
                        i -= 1
                        break
                i -= 1
            else:
                # Didn't find the matching brace.
                if DEBUG:
                    print "couldn't find matching brace"
                raise EvalError("could not find matching brace for "
                                "'%s' at position %d"
                                % (stack[-1][0], stack[-1][3]))

        else:
            if DEBUG:
                style_names = buf.style_names_from_style_num(style)
                print "add char: %r (%s)" % (ch, ', '.join(style_names))
            if first_citdl_expr_style is None:
                # Remember the first citdl style we found
                first_citdl_expr_style = style
                first_citdl_expr_style_is_comment = style in comment_styles
            elif first_citdl_expr_style != style and \
                 (first_citdl_expr_style_is_comment or
                  style in comment_styles):
                # We've moved into or out of a comment, let's leave now
                # Fixes: http://bugs.activestate.com/show_bug.cgi?id=65672
                break
            citdl_expr.append(ch)
            i -= 1

    citdl_expr.reverse()
    citdl_expr = ''.join(citdl_expr)
    if DEBUG:
        print "return: %r" % citdl_expr
        print banner("done")
    return citdl_expr

</t>
<t tx="ekr.20080121105837.425">def citdl_expr_from_trg(self, buf, trg):
    """Return a Python CITDL expression preceding the given trigger.
    
    The expression drops newlines, whitespace, and function call
    arguments -- basically any stuff that is not used by the codeintel
    database system for determining the resultant object type of the
    expression. For example (in which &lt;|&gt; represents the given position):
    
        GIVEN                       RETURN
        -----                       ------
        foo&lt;|&gt;.                     foo
        foo(bar&lt;|&gt;.                 bar
        foo(bar,blam)&lt;|&gt;.           foo()
        foo(bar,                    foo()
            blam)&lt;|&gt;.
        @foo&lt;|&gt;(                    foo

    If (trg.form == TRG_FORM_DEFN), then it's similar to above, except it
    looks forward to grab additional characters.

        GIVEN                       RETURN
        -----                       ------
        foo&lt;|&gt;.                     foo
        f&lt;|&gt;oo.bar                  foo.bar
        foo(bar&lt;|&gt;.                 bar
        foo(bar,blam)&lt;|&gt;.           foo()
        foo(bar,                    foo().bar
            blam).b&lt;|&gt;ar
    """
    DEBUG = False
    if DEBUG:
        print banner("Python-style citdl_expr_from_trg @ %d" % trg.pos)
    if trg.form == TRG_FORM_DEFN:
        pos = trg.pos
        expr = self._citdl_expr_from_pos(buf, pos, implicit=True,
                                         include_forwards=True, DEBUG=DEBUG)
        if expr:
            # Chop off any trailing "." characters
            return expr.rstrip(".")
        return expr
    else:
        pos = trg.pos - 2   # skip ahead of the trigger char
        return self._citdl_expr_from_pos(buf, pos, trg.implicit, DEBUG)


</t>
<t tx="ekr.20080121105837.426">#---- internal calltip parsing support

class Arg(object):
    @others
</t>
<t tx="ekr.20080121105837.427">def __init__(self):
    self.start = None
    self.end = None
    self.name_chs = []
    self.default_chs = []

</t>
<t tx="ekr.20080121105837.428">def done(self, p):
    self.end = p

</t>
<t tx="ekr.20080121105837.429">def append_ch(self, p, ch):
    if not self.name_chs:
        self.start = p
    self.name_chs.append(ch)

</t>
<t tx="ekr.20080121105837.430">def append_default_ch(self, p, ch):
    self.default_chs.append(ch)

</t>
<t tx="ekr.20080121105837.431">def __nonzero__(self):
    return operator.truth(self.name_chs)

</t>
<t tx="ekr.20080121105837.432">def __repr__(self):
    default_str = (self.default
                   and ', default=%r'%self.default
                   or '')
    return "Arg(%r, %s, %s%s)" \
           % (self.name, self.start, self.end, default_str)

</t>
<t tx="ekr.20080121105837.433">@property
def name(self):
    return ''.join(self.name_chs)

</t>
<t tx="ekr.20080121105837.434">@property
def default(self):
    if self.default_chs:
        return ''.join(self.default_chs)
    else:
        return None

</t>
<t tx="ekr.20080121105837.435">@property
def span(self):
    return (self.start, self.end)

</t>
<t tx="ekr.20080121105837.436">def _parse_calltip(calltip, DEBUG=False):
    r"""Parse the given calltip text as follows:

        &gt;&gt;&gt; _parse_calltip('foo(a)\nblam')
        ('foo(a)', 'foo', [Arg('a', 4, 5)])
        &gt;&gt;&gt; _parse_calltip('foo(a, b)')
        ('foo(a, b)', 'foo', [Arg('a', 4, 5), Arg('b', 7, 8)])
        &gt;&gt;&gt; _parse_calltip('foo(a=42)')
        ('foo(a=42)', 'foo', [Arg('a', 4, 8, default='42')])
        &gt;&gt;&gt; _parse_calltip('flash(boom, bang=42)')
        ('flash(boom, bang=42)', 'flash', [Arg('boom', 6, 10), Arg('bang', 12, 19, default='42')])

    Not currently doing anything magical for calltips like these:
        range([start,] stop[, step]) -&gt; list of integers
    """
    signature = calltip.splitlines(0)[0]
    arg_start_pos = signature.find('(')
    if arg_start_pos == -1 or ')' not in signature:
        if DEBUG:
            print "no '(' and ')' in first line of calltip"
        return None
    name = calltip[:arg_start_pos].strip()

    #XXX Should add block skipping.
    #skip_blocks = {
    #    '"': '"',
    #    "'": "'",
    #    "/*": "*/",  # JavaScript comments
    #}

    length = len(signature)
    p = arg_start_pos + 1
    args = [Arg()]
    OPERATOR, ARGUMENT, DEFAULT = range(3)
    WHITESPACE = tuple(" \t[]")
    state = OPERATOR
    while p &lt; length:
        ch = signature[p]
        if ch == ')':
            break # end of argument region
        elif state == OPERATOR:
            if ch in WHITESPACE:
                pass
            elif ch == ',':
                args[-1].done(p)
                args.append(Arg())
            else:
                state = ARGUMENT
                continue # do this char again
        elif state == ARGUMENT:
            if ch == ',':
                state = OPERATOR
                continue
            elif ch == '=':
                state = DEFAULT
            else:
                args[-1].append_ch(p, ch)
        elif state == DEFAULT:
            if ch == ',':
                state = OPERATOR
                continue
            else:
                args[-1].append_default_ch(p, ch)
        p += 1
    if not args[-1]:
        del args[-1]
    else:
        args[-1].done(p)
    return (signature, name, args)

</t>
<t tx="ekr.20080121105837.437"></t>
<t tx="ekr.20080121105837.438"></t>
<t tx="ekr.20080121105837.439">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    sys.exit(main(sys.argv))


</t>
<t tx="ekr.20080121105837.440">#!/usr/bin/env python

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    perlcile - a Code Intelligence Language Engine for the Perl language

    Module Usage:
        from perlcile import scan
        mtime = os.stat("foo.pl")[stat.ST_MTIME]
        content = open("foo.pl", "r").read()
        scan(content, "foo.pl", mtime=mtime)
    
    Command-line Usage:
        perlcile.py [&lt;options&gt;...] [&lt;Perl file&gt;]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename &lt;path&gt;   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted &lt;file&gt; tag.
        --md5=&lt;string&gt;      md5 hash for the input
        --mtime=&lt;secs&gt;      modification time for output info, in #secs since
                            1/1/70.
        -L, --language &lt;name&gt;
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Perl files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .pl files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.activestate.com/Komodo_3.0/func/code_intelligence.html
        http://specs.tl.activestate.com/kd/kd-0100.html
    
    The command-line interface will return non-zero iff the scan failed.
"""

import os
import os.path
import sys
import getopt
import md5
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import perl_lexer, perl_parser, util
from codeintel2.tree import pretty_tree_from_tree
from codeintel2.common import CILEError
from codeintel2 import parser_cix

#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("perlcile")
#log.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

gProvideFullDocs = False


</t>
<t tx="ekr.20080121105837.441">#---- internal support
# This code has intimate knowledge of the code objects defined in
# perl_parser.py

def scan(content, filename, md5sum=None, mtime=None):
    log.info("scan '%s'", filename)
    content = content.expandtabs(8)
    tokenizer = perl_lexer.PerlLexer(content, gProvideFullDocs)
    parser = perl_parser.Parser(tokenizer, provide_full_docs=gProvideFullDocs)
    parse_tree = parser.parse()
    tree = parser.produce_CIX()
    tree = pretty_tree_from_tree(tree)
    return tostring(tree)


</t>
<t tx="ekr.20080121105837.442">def scan_purelang(buf):
    content = buf.accessor.text.expandtabs(8)
    tokenizer = perl_lexer.PerlLexer(content, gProvideFullDocs)
    parser = perl_parser.Parser(tokenizer, provide_full_docs=gProvideFullDocs)
    parser.moduleName = buf.path
    parse_tree = parser.parse()
    tree = parser.produce_CIX()
    return tree

</t>
<t tx="ekr.20080121105837.443">def scan_multilang(tokens, module_elem):
    """Build the Perl module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the &lt;module&gt; element of a CIX element tree on
            which the Perl module should be built.

    This should return a list of the CSL tokens in the token stream.
    """
        
    tokenizer = perl_lexer.PerlMultiLangLexer(tokens)
    # "PerlHTML" is about all we need for whichever Perl-based
    # template language is being used.  This could just as easily be a
    # boolean that indicates whether we're processing a pure language
    # or a multi-lang one.
    
    parser = perl_parser.Parser(tokenizer, lang="PerlHTML", provide_full_docs=gProvideFullDocs)
    parser.moduleName = "" #Unknown
    parser.parse()
    parse_tree = parser.produce_CIX_NoHeader(module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens, tokenizer.has_perl_code()

</t>
<t tx="ekr.20080121105837.444">#---- mainline

def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
            ["version", "verbose", "help", "filename=", "md5=", "mtime=",
             "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `perlcile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Perl"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "perlcile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "&lt;stdin&gt;"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if os.path.isfile(path):
                filenames.append(path)
            elif os.path.isdir(path):
                perlfiles = [os.path.join(path, n) for n in os.listdir(path)
                             if os.path.splitext(n)[1] in (".pl", ".pm")]
                perlfiles = [f for f in perlfiles if os.path.isfile(f)]
                filenames += perlfiles

    if 1:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan(content, filename, md5sum=md5sum, mtime=mtime, lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    try:
        pass
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1

</t>
<t tx="ekr.20080121105837.445">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Trent Mick (TrentM@ActiveState.com)

@language python
@tabwidth -4

&lt;&lt; docstring &gt;&gt;
&lt;&lt; dev notes &gt;&gt;
&lt;&lt; globals &gt;&gt;

@others
if __name__ == "__main__":
    sys.exit( main(sys.argv) )

</t>
<t tx="ekr.20080121105837.446">@nocolor

"""
    pythoncile - a Code Intelligence Language Engine for the Python language

    Module Usage:
        from pythoncile import scan
        mtime = os.stat("foo.py")[stat.ST_MTIME]
        content = open("foo.py", "r").read()
        scan(content, "foo.py", mtime=mtimthoncile.pye)
    
    Command-line Usage:
        pythoncile.py [&lt;options&gt;...] [&lt;Python files&gt;...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename &lt;path&gt;   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted &lt;file&gt; tag.
        --md5=&lt;string&gt;      md5 hash for the input
        --mtime=&lt;secs&gt;      modification time for output info, in #secs since
                            1/1/70.
        -L, --language &lt;name&gt;
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Python files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .py files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.activestate.com/Komodo_3.0/func/code_intelligence.html
    
    The command-line interface will return non-zero iff the scan failed.
"""


</t>
<t tx="ekr.20080121105837.447"># Dev Notes:
# &lt;none&gt;
#
#TODO:
# - type inferencing: asserts
# - type inferencing: return statements
# - type inferencing: calls to isinstance
# - special handling for None may be required
# - Comments and doc strings. What format?
#   - JavaDoc - type hard to parse and not reliable
#     (http://java.sun.com/j2se/javadoc/writingdoccomments/).
#   - PHPDoc? Possibly, but not that rigorous.
#   - Grouch (http://www.mems-exchange.org/software/grouch/) -- dunno yet.
#     - Don't like requirement for "Instance attributes:" landmark in doc
#       strings.
#     - This can't be a full solution because the requirement to repeat
#       the argument name doesn't "fit" with having a near-by comment when
#       variable is declared.
#     - Two space indent is quite rigid
#     - Only allowing attribute description on the next line is limiting.
#     - Seems focussed just on class attributes rather than function
#       arguments.
#   - Perhaps what PerlCOM POD markup uses?
#   - Home grown? My own style? Dunno
# - make type inferencing optional (because it will probably take a long
#   time to generate), this is tricky though b/c should the CodeIntel system
#   re-scan a file after "I want type inferencing now" is turned on? Hmmm.
# - [lower priority] handle staticmethod(methname) and
#   classmethod(methname). This means having to delay emitting XML until
#   end of class scope and adding .visitCallFunc().
# - [lower priority] look for associated comments for variable
#   declarations (as per VS.NET's spec, c.f. "Supplying Code Comments" in
#   the VS.NET user docs)</t>
<t tx="ekr.20080121105837.448">import os
import sys
import getopt
import md5
import re
import logging
import pprint
import glob
import time
import stat
import types
from cStringIO import StringIO

import compiler
from compiler import ast
from compiler.visitor import dumpNode, ExampleASTVisitor
import parser

from codeintel2.common import CILEError
from codeintel2 import util
from codeintel2.parseutil import xmlencode, getAttrStr, cdataescape
</t>
<t tx="ekr.20080121105837.449">#---- global data

_version_ = (0, 3, 0)
log = logging.getLogger("pythoncile")
#log.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned



</t>
<t tx="ekr.20080121105837.450">#---- exceptions

class PythonCILEError(CILEError):
    pass



</t>
<t tx="ekr.20080121105837.451">#---- internal routines and classes

def _isclass(namespace):
    return (len(namespace["types"]) == 1
            and "class" in namespace["types"])

</t>
<t tx="ekr.20080121105837.452">def _isfunction(namespace):
    return (len(namespace["types"]) == 1
            and "function" in namespace["types"])


</t>
<t tx="ekr.20080121105837.453">class AST2CIXVisitor:
    """Generate Code Intelligence XML (CIX) from walking a Python AST tree.
    
    This just generates the CIX content _inside_ of the &lt;file/&gt; tag. The
    prefix and suffix have to be added separately.
    """
    DEBUG = 0
    @others
</t>
<t tx="ekr.20080121105837.454">def __init__(self, moduleName=None, content=None):
    if self.DEBUG is None:
        self.DEBUG = log.isEnabledFor(logging.DEBUG)
    self.moduleName = moduleName
    if content:
        self.lines = content.splitlines(0)
    else:
        self.lines = None
    # Symbol Tables (dicts) are built up for each scope. The namespace
    # stack to the global-level is maintain in self.nsstack.
    self.st = { # the main module symbol table
        # &lt;scope name&gt;: &lt;namespace dict&gt;
    }
    self.nsstack = []
    self.cix = []

</t>
<t tx="ekr.20080121105837.455">def emit(self, s, level):
    indent = '    '*level
    if self.DEBUG:
        sys.stdout.write(indent+s)
    self.cix.extend([indent, s])

</t>
<t tx="ekr.20080121105837.456">def cix_module(self, node, level):
    """Emit CIX for the given module namespace."""
    #log.debug("cix_module(%s, level=%r)", '.'.join(node["nspath"]), level)
    assert len(node["types"]) == 1 and "module" in node["types"]
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    self.emit('&lt;module%s&gt;\n' % getAttrStr(attrs), level)
    doc = node.get("doc")
    if doc:
        doc = cdataescape(xmlencode(doc))
        self.emit('&lt;doc&gt;&lt;![CDATA['+doc+']]&gt;&lt;/doc&gt;\n', level+1)
    for import_ in node.get("imports", []):
        self.cix_import(import_, level+1)
    self.cix_symbols(node["symbols"], level+1)
    self.emit('&lt;/module&gt;\n', level)

</t>
<t tx="ekr.20080121105837.457">def cix_import(self, node, level):
    #log.debug("cix_import(%s, level=%r)", node["module"], level)
    attrs = node
    self.emit('&lt;import%s/&gt;\n' % getAttrStr(attrs), level)

</t>
<t tx="ekr.20080121105837.458">def cix_symbols(self, node, level, parentIsClass=0):
    vars = node.values()
    # Sort variables by line order. This provide the most naturally
    # readable comparison of document with its associate CIX content.
    vars.sort(lambda a,b: cmp(a.get("line"), b.get("line")))
    for var in vars:
        self.cix_symbol(var, level, parentIsClass)

</t>
<t tx="ekr.20080121105837.459">def cix_symbol(self, node, level, parentIsClass=0):
    if _isclass(node):
        self.cix_class(node, level)
    elif _isfunction(node):
        self.cix_function(node, level)
    else:
        self.cix_variable(node, level, parentIsClass)

</t>
<t tx="ekr.20080121105837.460">def cix_types(self, guesses, level):
    """'guesses' is a types dict: {&lt;type guess&gt;: &lt;score&gt;, ...} """
    typesAndScores = guesses.items()
    typesAndScores.sort(lambda a,b: cmp(b[1], a[1])) # highest score first
    for type_, score in typesAndScores:
        if ' ' in type_:
            #XXX Drop the &lt;start-scope&gt; part of CITDL for now.
            type_ = type_.split(None, 1)[0]
        # Don't emit None types, it does not help us. Fix for bug:
        #  http://bugs.activestate.com/show_bug.cgi?id=71989
        if type_ != "None":
            tattrs = {"type": type_, "score": score}
            self.emit('&lt;type%s/&gt;\n' % getAttrStr(tattrs), level)

</t>
<t tx="ekr.20080121105837.461">def cix_variable(self, node, level, parentIsClass=0):
    #log.debug("cix_variable(%s, level=%r, parentIsClass=%r)",
    #          '.'.join(node["nspath"]), level, parentIsClass)
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    if node.get("attributes"): attrs["attributes"] = node["attributes"]
    if parentIsClass and "is-class-var" not in node:
        # Special CodeIntel &lt;variable&gt; attribute to distinguish from the
        # usual class variables.
        if "attributes" in attrs:
            attrs["attributes"] += " __instancevar__"
        else:
            attrs["attributes"] = "__instancevar__"
    if not node.get("doc") and not node["types"]:
        self.emit('&lt;variable%s/&gt;\n' % getAttrStr(attrs), level)
    else:
        self.emit('&lt;variable%s&gt;\n' % getAttrStr(attrs), level)
        doc = node.get("doc")
        if doc:
            doc = cdataescape(xmlencode(doc))
            self.emit('&lt;doc&gt;&lt;![CDATA['+doc+']]&gt;&lt;/doc&gt;\n', level+1)
        self.cix_types(node["types"], level+1)
        self.emit('&lt;/variable&gt;\n', level)

</t>
<t tx="ekr.20080121105837.462">def cix_classref(self, node, level):
    #log.debug("cix_classref(%s, level=%r)", '.'.join(node["nspath"]), level)
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    if not node["types"]:
        self.emit('&lt;classref%s/&gt;\n' % getAttrStr(attrs), level)
    else:
        self.emit('&lt;classref%s&gt;\n' % getAttrStr(attrs), level)
        self.cix_types(node["types"], level+1)
        self.emit('&lt;/classref&gt;\n', level)

</t>
<t tx="ekr.20080121105837.463">def cix_class(self, node, level):
    #log.debug("cix_class(%s, level=%r)", '.'.join(node["nspath"]), level)
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    if "lineend" in node: attrs["lineend"] = node["lineend"]
    if node.get("attributes"): attrs["attributes"] = node["attributes"]
    self.emit('&lt;class%s&gt;\n' % getAttrStr(attrs), level)
    if "signature" in node:
        signature = cdataescape(xmlencode(node["signature"]))
        self.emit('&lt;signature&gt;&lt;![CDATA['+signature+']]&gt;&lt;/signature&gt;\n',
                  level+1)
    for classref in node["classrefs"]:
        self.cix_classref(classref, level+1)
    doc = node.get("doc")
    if doc:
        doc = cdataescape(xmlencode(doc))
        self.emit('&lt;doc&gt;&lt;![CDATA['+doc+']]&gt;&lt;/doc&gt;\n', level+1)
    for import_ in node.get("imports", []):
        self.cix_import(import_, level+1)
    self.cix_symbols(node["symbols"], level+1, parentIsClass=1)
    self.emit('&lt;/class&gt;\n', level)

</t>
<t tx="ekr.20080121105837.464">def cix_argument(self, node, level):
    #log.debug("cix_argument(%s, level=%r)", '.'.join(node["nspath"]), level)
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    if "attributes" in node: attrs["attributes"] = node["attributes"]
    if not node.get("doc") and not node["types"]:
        self.emit('&lt;argument%s/&gt;\n' % getAttrStr(attrs), level)
    else:
        self.emit('&lt;argument%s&gt;\n' % getAttrStr(attrs), level)
        doc = node.get("doc")
        if doc:
            doc = cdataescape(xmlencode(doc))
            self.emit('&lt;doc&gt;&lt;![CDATA['+doc+']]&gt;&lt;/doc&gt;\n', level+1)
        self.cix_types(node["types"], level+1)
        self.emit('&lt;/argument&gt;\n', level)

</t>
<t tx="ekr.20080121105837.465">def cix_function(self, node, level):
    #log.debug("cix_function(%s, level=%r)", '.'.join(node["nspath"]), level)
    attrs = {"name": node["name"]}
    if "line" in node: attrs["line"] = node["line"]
    if "lineend" in node: attrs["lineend"] = node["lineend"]
    if node.get("attributes"): attrs["attributes"] = node["attributes"]

    # Determine the best return type.
    best_citdl = None
    max_count = 0
    for citdl, count in node["returns"].items():
        if count &gt; max_count:
            best_citdl = citdl
    if best_citdl:
        attrs["returns"] = best_citdl

    self.emit('&lt;function%s&gt;\n' % getAttrStr(attrs), level)

    if "signature" in node:
        signature = cdataescape(xmlencode(node["signature"]))
        self.emit('&lt;signature&gt;&lt;![CDATA['+signature+']]&gt;&lt;/signature&gt;\n',
                  level+1)
    doc = node.get("doc")
    if doc:
        doc = cdataescape(xmlencode(doc))
        self.emit('&lt;doc&gt;&lt;![CDATA['+doc+']]&gt;&lt;/doc&gt;\n', level+1)

    for import_ in node.get("imports", []):
        self.cix_import(import_, level+1)
    argNames = []
    for arg in node["arguments"]:
        argNames.append(arg["name"])
        self.cix_argument(arg, level+1)
    symbols = {} # don't re-emit the function arguments
    for symbolName, symbol in node["symbols"].items():
        if symbolName not in argNames:
            symbols[symbolName] = symbol
    self.cix_symbols(symbols, level+1)
    #XXX &lt;returns/&gt; if one is defined
    self.emit('&lt;/function&gt;\n', level)

</t>
<t tx="ekr.20080121105837.466">def getCIX(self, level=0):
    """Return CIX content for parsed data."""
    log.debug("getCIX")
    moduleNS = self.st[()]
    self.cix_module(moduleNS, level)
    return "".join(self.cix)

</t>
<t tx="ekr.20080121105837.467">def visitModule(self, node):
    log.info("visitModule")
    nspath = ()
    namespace = {"name": self.moduleName,
                 "nspath": nspath,
                 "types": {"module": 1},
                 "symbols": {}}
    if node.doc:
        summarylines = util.parseDocSummary(node.doc.splitlines(0))
        namespace["doc"] = "\n".join(summarylines)
    if node.lineno: namespace["line"] = node.lineno
    self.st[nspath] = namespace
    self.nsstack.append(namespace)
    self.visit(node.node)
    self.nsstack.pop()

</t>
<t tx="ekr.20080121105837.468">def visitReturn(self, node):
    log.info("visitReturn: %r", node.value)
    citdl_types = self._guessTypes(node.value)
    for citdl in citdl_types:
        if citdl:
            citdl = citdl.split(None, 1)[0]
            if citdl and citdl not in ("None", "NoneType"):
                if citdl in ("False", "True"):
                    citdl = "bool"
                func_node = self.nsstack[-1]
                t = func_node["returns"]
                t[citdl] = t.get(citdl, 0) + 1

</t>
<t tx="ekr.20080121105837.469">def visitClass(self, node):
    log.info("visitClass:%d: %r", node.lineno,
             self.lines and self.lines[node.lineno-1])
    locals = self.nsstack[-1]
    name = node.name
    nspath = locals["nspath"] + (name,)
    namespace = {
        "nspath": nspath,
        "name": name,
        "types": {"class": 1},
        #XXX Example of a base class that might surprise: the
        #    __metaclass__ class in
        #    c:\python22\lib\site-packages\ctypes\com\automation.py
        #    Should this be self._getCITDLExprRepr()???
        "classrefs": [],
        "symbols": {},
    }
    namespace["declaration"] = namespace

    if node.lineno: namespace["line"] = node.lineno
    lastNode = node
    while lastNode.getChildNodes():
        lastNode = lastNode.getChildNodes()[-1]
    if lastNode.lineno: namespace["lineend"] = lastNode.lineno

    attributes = []
    if name.startswith("__") and name.endswith("__"):
        pass
    elif name.startswith("__"):
        attributes.append("private")
    elif name.startswith("_"):
        attributes.append("protected")
    namespace["attributes"] = ' '.join(attributes)

    if node.bases:
        for baseNode in node.bases:
            baseName = self._getExprRepr(baseNode)
            classref = {"name": baseName, "types": {}}
            for t in self._guessTypes(baseNode):
                if t not in classref["types"]:
                    classref["types"][t] = 0
                classref["types"][t] += 1
            namespace["classrefs"].append(classref)
    if node.doc:
        siglines, desclines = util.parsePyFuncDoc(node.doc)
        if siglines:
            namespace["signature"] = "\n".join(siglines)
        if desclines:
            namespace["doc"] = "\n".join(desclines)
    self.st[nspath] = locals["symbols"][name] = namespace

    self.nsstack.append(namespace)
    self.visit(node.code)
    self.nsstack.pop()

</t>
<t tx="ekr.20080121105837.470">def visitFunction(self, node):
    log.info("visitFunction:%d: %r", node.lineno,
             self.lines and self.lines[node.lineno-1])
    parent = self.nsstack[-1]
    parentIsClass = _isclass(parent)
    name = node.name
    if parentIsClass and name == "__init__":
        fallbackSig = parent["name"]
    else:
        fallbackSig = name
    nspath = parent["nspath"] + (name,)
    namespace = {
        "nspath": nspath,
        "name": name,
        "types": {"function": 1},
        "returns": {},
        "arguments": [],
        "symbols": {},
    }
    namespace["declaration"] = namespace
    if node.lineno: namespace["line"] = node.lineno
    lastNode = node
    while lastNode.getChildNodes():
        lastNode = lastNode.getChildNodes()[-1]
    if lastNode.lineno: namespace["lineend"] = lastNode.lineno

    # Determine attributes
    attributes = []
    if name.startswith("__") and name.endswith("__"):
        pass
    elif name.startswith("__"):
        attributes.append("private")
    elif name.startswith("_"):
        attributes.append("protected")
    if name == "__init__" and parentIsClass:
        attributes.append("__ctor__")
    namespace["attributes"] = ' '.join(attributes)

    # Handle arguments. The format of the relevant Function attributes
    # makes this a little bit of pain.
    defaultArgsBaseIndex = len(node.argnames) - len(node.defaults)
    if node.kwargs:
        defaultArgsBaseIndex -= 1
        if node.varargs:
            defaultArgsBaseIndex -= 1
            varargsIndex = len(node.argnames)-2
        else:
            varargsIndex = None
        kwargsIndex = len(node.argnames)-1
    elif node.varargs:
        defaultArgsBaseIndex -= 1
        varargsIndex = len(node.argnames)-1
        kwargsIndex = None
    else:
        varargsIndex = kwargsIndex = None
    sigArgs = []
    for i in range(len(node.argnames)):
        argOrArgTuple = node.argnames[i]

        if isinstance(argOrArgTuple, tuple):
            # If it is a tuple arg with a default assignment, then we
            # drop that info (except for the sig): too hard and too rare
            # to bother with.
            sigArg = str(argOrArgTuple)
            if i &gt;= defaultArgsBaseIndex:
                defaultNode = node.defaults[i-defaultArgsBaseIndex]
                try:
                    default = self._getExprRepr(defaultNode)
                except PythonCILEError, ex:
                    raise PythonCILEError("unexpected default argument node "
                                          "type for Function '%s': %s"
                                          % (node.name, ex))
                sigArg += "="+default
            sigArgs.append(sigArg)
            arguments = []
            for argName in argOrArgTuple:
                argument = {"name": argName,
                            "nspath": nspath+(argName,),
                            "doc": None,
                            "types": {},
                            "symbols": {}}
                arguments.append(argument)
        else:
            argName = argOrArgTuple
            argument = {"name": argName,
                        "nspath": nspath+(argName,),
                        "doc": None,
                        "types": {},
                        "symbols": {}}
            if i == kwargsIndex:
                argument["attributes"] = "kwargs"
                sigArgs.append("**"+argName)
            elif i == varargsIndex:
                argument["attributes"] = "varargs"
                sigArgs.append("*"+argName)
            elif i &gt;= defaultArgsBaseIndex:
                defaultNode = node.defaults[i-defaultArgsBaseIndex]
                try:
                    argument["default"] = self._getExprRepr(defaultNode)
                except PythonCILEError, ex:
                    raise PythonCILEError("unexpected default argument node "
                                          "type for Function '%s': %s"
                                          % (node.name, ex))
                sigArgs.append(argName+'='+argument["default"])
                for t in self._guessTypes(defaultNode):
                    log.info("guessed type: %s ::= %s", argName, t)
                    if t not in argument["types"]:
                        argument["types"][t] = 0
                    argument["types"][t] += 1
            else:
                sigArgs.append(argName)

            if i == 0 and parentIsClass:
                # If this is a class method, then the first arg is the class
                # instance.
                className = self.nsstack[-1]["nspath"][-1]
                argument["types"][className] = 1
                argument["declaration"] = self.nsstack[-1]
            arguments = [argument]
            
        for argument in arguments:
            if "declaration" not in argument:
                argument["declaration"] = argument # namespace dict of the declaration
            namespace["arguments"].append(argument)
            namespace["symbols"][argument["name"]] = argument
    # Drop first "self" argument from class method signatures.
    # - This is a little bit of a compromise as the "self" argument
    #   should *sometimes* be included in a method's call signature.
    if _isclass(parent) and sigArgs:
        del sigArgs[0]
    fallbackSig += "(%s)" % (", ".join(sigArgs))
    if node.doc:
        siglines, desclines = util.parsePyFuncDoc(node.doc, [fallbackSig])
        namespace["signature"] = "\n".join(siglines)
        if desclines:
            namespace["doc"] = "\n".join(desclines)
    else:
        namespace["signature"] = fallbackSig
    self.st[nspath] = parent["symbols"][name] = namespace

    self.nsstack.append(namespace)
    self.visit(node.code)
    self.nsstack.pop()

</t>
<t tx="ekr.20080121105837.471">def visitImport(self, node):
    log.info("visitImport:%d: %r", node.lineno,
             self.lines and self.lines[node.lineno-1])
    imports = self.nsstack[-1].setdefault("imports", [])
    for module, alias in node.names:
        import_ = {"module": module}
        if node.lineno: import_["line"] = node.lineno
        if alias: import_["alias"] = alias
        imports.append(import_)

</t>
<t tx="ekr.20080121105837.472">def visitFrom(self, node):
    log.info("visitFrom:%d: %r", node.lineno,
             self.lines and self.lines[node.lineno-1])
    imports = self.nsstack[-1].setdefault("imports", [])
    for symbol, alias in node.names:
        import_ = {"module": node.modname, "symbol": symbol}
        if node.lineno: import_["line"] = node.lineno
        if alias: import_["alias"] = alias
        imports.append(import_)

</t>
<t tx="ekr.20080121105837.473">#XXX
#def visitReturn(self, node):
#    # set __rettypes__ on Functions
#    pass
#def visitGlobal(self, node):
#    # note for future visitAssign to control namespace
#    pass
#def visitYield(self, node):
#    # modify the Function into a generator??? what are the implications?
#    pass
#def visitAssert(self, node):
#    # support the assert hints that Wing does
#    pass

def _assignVariable(self, varName, namespace, rhsNode, line,
                    isClassVar=0):
    """Handle a simple variable name assignment.

        "varName" is the variable name being assign to.
        "namespace" is the namespace dict to which to assign the variable.
        "rhsNode" is the ast.Node of the right-hand side of the
            assignment.
        "line" is the line number on which the variable is being assigned.
        "isClassVar" (optional) is a boolean indicating if this var is
            a class variable, as opposed to an instance variable
    """
    log.debug("_assignVariable(varName=%r, namespace %s, rhsNode=%r, "
              "line, isClassVar=%r)", varName,
              '.'.join(namespace["nspath"]), rhsNode, isClassVar)
    variable = namespace["symbols"].get(varName, None)
    if variable is None:
        variable = {"name": varName,
                    "nspath": namespace["nspath"]+(varName,),
                    # Could try to parse documentation from a near-by
                    # string.
                    "doc": None,
                    # 'types' is a dict mapping a type name to the number
                    # of times this was guessed as the variable type.
                    "types": {},
                    "symbols": {}}
        # Determine attributes
        attributes = []
        if varName.startswith("__") and varName.endswith("__"):
            pass
        elif varName.startswith("__"):
            attributes.append("private")
        elif varName.startswith("_"):
            attributes.append("protected")
        variable["attributes"] = ' '.join(attributes)

        variable["declaration"] = variable
        if line: variable["line"] = line
        namespace["symbols"][varName] = variable
    if isClassVar and not "is-class-var" in variable:
        variable["is-class-var"] = 1
        # line number of first class-level assignment wins
        if line: variable["line"] = line

    varTypes = variable["types"]
    for t in self._guessTypes(rhsNode, namespace):
        log.info("guessed type: %s ::= %s", varName, t)
        if t not in varTypes:
            varTypes[t] = 0
        varTypes[t] += 1

</t>
<t tx="ekr.20080121105837.474">def _visitSimpleAssign(self, lhsNode, rhsNode, line):
    """Handle a simple assignment: assignment to a symbol name or to
    an attribute of a symbol name. If the given left-hand side (lhsNode)
    is not an node type that can be handled, it is dropped.
    """
    log.debug("_visitSimpleAssign(lhsNode=%r, rhsNode=%r)", lhsNode,
              rhsNode)
    if isinstance(lhsNode, ast.AssName):
        # E.g.:  foo = ...
        # Assign this to the local namespace, unless there was a
        # 'global' statement. (XXX Not handling 'global' yet.)
        ns = self.nsstack[-1]
        self._assignVariable(lhsNode.name, ns, rhsNode, line,
                             isClassVar=_isclass(ns))
    elif isinstance(lhsNode, ast.AssAttr):
        # E.g.:  foo.bar = ...
        # If we can resolve "foo", then we update that namespace.
        variable, citdl = self._resolveObjectRef(lhsNode.expr)
        if variable:
            self._assignVariable(lhsNode.attrname,
                                 variable["declaration"], rhsNode, line)
    else:
        log.debug("could not handle simple assign (module '%s'): "
                  "lhsNode=%r, rhsNode=%r", self.moduleName, lhsNode,
                  rhsNode)

</t>
<t tx="ekr.20080121105837.475">def visitAssign(self, node):
    log.info("visitAssign:%d: %r", node.lineno,
             self.lines and self.lines[node.lineno-1])
    lhsNode = node.nodes[0]
    rhsNode = node.expr
    if isinstance(lhsNode, (ast.AssName, ast.AssAttr)):
        # E.g.:
        #   foo = ...       (AssName)
        #   foo.bar = ...   (AssAttr)
        self._visitSimpleAssign(lhsNode, rhsNode, node.lineno)
    elif isinstance(lhsNode, (ast.AssTuple, ast.AssList)):
        # E.g.:
        #   foo, bar = ...
        #   [foo, bar] = ...
        # If the RHS is a sequence with the same number of elements,
        # then we update each assigned-to variable. Otherwise, bail.
        if isinstance(rhsNode, (ast.Tuple, ast.List)):
            if len(lhsNode.nodes) == len(rhsNode.nodes):
                for i in range(len(lhsNode.nodes)):
                    self._visitSimpleAssign(lhsNode.nodes[i],
                                            rhsNode.nodes[i],
                                            node.lineno)
        elif isinstance(rhsNode, ast.Dict):
            if len(lhsNode.nodes) == len(rhsNode.items):
                for i in range(len(lhsNode.nodes)):
                    self._visitSimpleAssign(lhsNode.nodes[i],
                                            rhsNode.items[i][0],
                                            node.lineno)
    elif isinstance(lhsNode, ast.Slice):
        # E.g.:  bar[1:2] = "foo"
        # We don't bother with these: too hard.
        pass
    elif isinstance(lhsNode, ast.Subscript):
        # E.g.:  bar[1] = "foo"
        # We don't bother with these: too hard.
        pass
    else:
        raise PythonCILEError("unexpected type of LHS of assignment: %r"
                              % lhsNode)

</t>
<t tx="ekr.20080121105837.476">def _resolveObjectRef(self, expr):
    """Try to resolve the given expression to a variable namespace.
    
        "expr" is some kind of ast.Node instance.
    
    Returns the following 2-tuple for the object:
        (&lt;variable dict&gt;, &lt;CITDL string&gt;)
    where,
        &lt;variable dict&gt; is the defining dict for the variable, e.g.
                {'name': 'classvar', 'types': {'int': 1}}.
            This is None if the variable could not be resolved.
        &lt;CITDL string&gt; is a string of CITDL code (see the spec) describing
            how to resolve the variable later. This is None if the
            variable could be resolved or if the expression is not
            expressible in CITDL (CITDL does not attempt to be a panacea).
    """
    log.debug("_resolveObjectRef(expr=%r)", expr)
    if isinstance(expr, ast.Name):
        name = expr.name
        nspath = self.nsstack[-1]["nspath"]
        for i in range(len(nspath), -1, -1):
            ns = self.st[nspath[:i]]
            if name in ns["symbols"]:
                return (ns["symbols"][name], None)
            else:
                log.debug("_resolveObjectRef: %r not in namespace %r", name,
                          '.'.join(ns["nspath"]))
    elif isinstance(expr, ast.Getattr):
        obj, citdl = self._resolveObjectRef(expr.expr)
        decl = obj and obj["declaration"] or None # want the declaration
        if (decl #and "symbols" in decl #XXX this "and"-part necessary?
            and expr.attrname in decl["symbols"]):
            return (decl["symbols"][expr.attrname], None)
        elif isinstance(expr.expr, ast.Const):
            # Special case: specifically refer to type object for
            # attribute access on constants, e.g.:
            #   ' '.join
            citdl = "__builtins__.%s.%s"\
                    % ((type(expr.expr.value).__name__), expr.attrname)
            return (None, citdl)
            #XXX Could optimize here for common built-in attributes. E.g.,
            #    we *know* that str.join() returns a string.
    elif isinstance(expr, ast.Const):
        # Special case: specifically refer to type object for constants.
        return (None, "__builtins__.%s" % type(expr.value).__name__)
    elif isinstance(expr, ast.CallFunc):
        #XXX Would need flow analysis to have an object dict for whatever
        #    a __call__ would return.
        pass

    # Fallback: return CITDL code for delayed resolution.
    log.debug("_resolveObjectRef: could not resolve %r", expr)
    scope = '.'.join(self.nsstack[-1]["nspath"])
    exprrepr = self._getCITDLExprRepr(expr)
    if exprrepr:
        if scope:
            citdl = "%s %s" % (exprrepr, scope)
        else:
            citdl = exprrepr
    else:
        citdl = None
    return (None, citdl)

</t>
<t tx="ekr.20080121105837.477">def _guessTypes(self, expr, curr_ns=None):
    log.debug("_guessTypes(expr=%r)", expr)
    ts = []
    if isinstance(expr, ast.Const):
        ts = [type(expr.value).__name__]
    elif isinstance(expr, ast.Tuple):
        ts = [tuple.__name__]
    elif isinstance(expr, (ast.List, ast.ListComp)):
        ts = [list.__name__]
    elif isinstance(expr, ast.Dict):
        ts = [dict.__name__]
    elif isinstance(expr, (ast.Add, ast.Sub, ast.Mul, ast.Div, ast.Mod,
                           ast.Power)):
        order = ["int", "bool", "long", "float", "complex", "string",
                 "unicode"]
        possibles = self._guessTypes(expr.left)+self._guessTypes(expr.right)
        ts = []
        highest = -1
        for possible in possibles:
            if possible not in order:
                ts.append(possible)
            else:
                highest = max(highest, order.index(possible))
        if not ts and highest &gt; -1:
            ts = [order[highest]]
    elif isinstance(expr, (ast.FloorDiv, ast.Bitand, ast.Bitor,
                           ast.Bitxor, ast.RightShift, ast.LeftShift)):
        ts = [int.__name__]
    elif isinstance(expr, (ast.Or, ast.And)):
        ts = []
        for node in expr.nodes:
            for t in self._guessTypes(node):
                if t not in ts:
                    ts.append(t)
    elif isinstance(expr, (ast.Compare, ast.Not)):
        ts = [type(1==2).__name__]
    elif isinstance(expr, (ast.UnaryAdd, ast.UnarySub, ast.Invert,
                           ast.Not)):
        ts = self._guessTypes(expr.expr)
    elif isinstance(expr, ast.Slice):
        ts = [list.__name__]
    elif isinstance(expr, ast.Backquote):
        ts = [str.__name__]

    elif isinstance(expr, (ast.Name, ast.Getattr)):
        variable, citdl = self._resolveObjectRef(expr)
        if variable:
            if _isclass(variable) or _isfunction(variable):
                ts = [ '.'.join(variable["nspath"]) ]
            else:
                ts = variable["types"].keys()
        elif citdl:
            ts = [citdl]
    elif isinstance(expr, ast.CallFunc):
        variable, citdl = self._resolveObjectRef(expr.node)
        if variable:
            #XXX When/if we support &lt;returns/&gt; and if we have that
            #    info for this 'variable' we can return an actual
            #    value here.
            # Optmizing Shortcut: If the variable is a class then just
            # call its type that class definition, i.e. 'mymodule.MyClass'
            # instead of 'type(call(mymodule.MyClass))'.

            # Remove the common leading namespace elements.
            scope_parts = list(variable["nspath"])
            if curr_ns is not None:
                for part in curr_ns["nspath"]:
                    if scope_parts and part == scope_parts[0]:
                        scope_parts.pop(0)
                    else:
                        break
            scope = '.'.join(scope_parts)
            if _isclass(variable):
                ts = [ scope ]
            else:
                ts = [scope+"()"]
        elif citdl:
            # For code like this:
            #   for line in lines:
            #       line = line.rstrip()
            # this results in a type guess of "line.rstrip &lt;funcname&gt;".
            # That sucks. Really it should at least be line.rstrip() so
            # that runtime CITDL evaluation can try to determine that
            # rstrip() is a _function_ call rather than _class creation_,
            # which is the current resuilt. (c.f. bug 33493)
            # XXX We *could* attempt to guess based on where we know
            #     "line" to be a module import: the only way that
            #     'rstrip' could be a class rather than a function.
            # TW: I think it should always use "()" no matter if it's
            #     a class or a function. The codeintel handler can work
            #     out which one it is. This gives us the ability to then
            #     distinguish between class methods and instance methods,
            #     as class methods look like:
            #       MyClass.staticmethod()
            #     and instance methods like:
            #       MyClass().instancemethod()
            # Updated to use "()".
            # Ensure we only add the "()" to the type part, not to the
            # scope (if it exists) part, which is separated by a space. Bug:
            #   http://bugs.activestate.com/show_bug.cgi?id=71987
            # citdl in this case looks like "string.split myfunction"
            ts = citdl.split(None, 1)
            ts[0] += "()"
            ts = [" ".join(ts)]
    elif isinstance(expr, (ast.Subscript, ast.Lambda)):
        pass
    else:
        log.info("don't know how to guess types from this expr: %r" % expr)
    return ts

</t>
<t tx="ekr.20080121105837.478">def _getExprRepr(self, node):
    """Return a string representation for this Python expression.
    
    Raises PythonCILEError if can't do it.
    """
    s = None
    if isinstance(node, ast.Name):
        s = node.name
    elif isinstance(node, ast.Const):
        s = repr(node.value)
    elif isinstance(node, ast.Getattr):
        s = '.'.join([self._getExprRepr(node.expr), node.attrname])
    elif isinstance(node, ast.List):
        items = [self._getExprRepr(c) for c in node.getChildren()]
        s = "[%s]" % ", ".join(items)
    elif isinstance(node, ast.Tuple):
        items = [self._getExprRepr(c) for c in node.getChildren()]
        s = "(%s)" % ", ".join(items)
    elif isinstance(node, ast.Dict):
        items = ["%s: %s" % (self._getExprRepr(k), self._getExprRepr(v))
                 for (k, v) in node.items]
        s = "{%s}" % ", ".join(items)
    elif isinstance(node, ast.CallFunc):
        s = self._getExprRepr(node.node)
        s += "("
        allargs = []
        for arg in node.args:
            allargs.append( self._getExprRepr(arg) )
        if node.star_args:
            for arg in node.star_args:
                allargs.append( "*" + self._getExprRepr(arg) )
        if node.dstar_args:
            for arg in node.dstar_args:
                allargs.append( "**" + self._getExprRepr(arg) )
        s += ",".join( allargs )
        s += ")"
    elif isinstance(node, ast.Subscript):
        s = "[%s]" % self._getExprRepr(node.expr)
    elif isinstance(node, ast.Backquote):
        s = "`%s`" % self._getExprRepr(node.expr)
    elif isinstance(node, ast.Slice):
        dumpNode(node)
        s = self._getExprRepr(node.expr)
        s += "["
        if node.lower:
            s += self._getExprRepr(node.lower)
        s += ":"
        if node.upper:
            s += self._getExprRepr(node.upper)
        s += "]"
    elif isinstance(node, ast.UnarySub):
        s = "-" + self._getExprRepr(node.expr)
    elif isinstance(node, ast.UnaryAdd):
        s = "+" + self._getExprRepr(node.expr)
    elif isinstance(node, ast.Add):
        s = self._getExprRepr(node.left) + "+" + self._getExprRepr(node.right)
    elif isinstance(node, ast.Sub):
        s = self._getExprRepr(node.left) + "-" + self._getExprRepr(node.right)
    elif isinstance(node, ast.Mul):
        s = self._getExprRepr(node.left) + "*" + self._getExprRepr(node.right)
    elif isinstance(node, ast.Div):
        s = self._getExprRepr(node.left) + "/" + self._getExprRepr(node.right)
    elif isinstance(node, ast.FloorDiv):
        s = self._getExprRepr(node.left) + "//" + self._getExprRepr(node.right)
    elif isinstance(node, ast.Mod):
        s = self._getExprRepr(node.left) + "%" + self._getExprRepr(node.right)
    elif isinstance(node, ast.Power):
        s = self._getExprRepr(node.left) + "**" + self._getExprRepr(node.right)
    elif isinstance(node, ast.LeftShift):
        s = self._getExprRepr(node.left) + "&lt;&lt;" + self._getExprRepr(node.right)
    elif isinstance(node, ast.RightShift):
        s = self._getExprRepr(node.left) + "&gt;&gt;"+ self._getExprRepr(node.right)
    elif isinstance(node, ast.Keyword):
        s = node.name + "=" + self._getExprRepr(node.expr)
    elif isinstance(node, ast.Bitor):
        creprs = []
        for cnode in node.nodes:
            if isinstance(cnode, (ast.Const, ast.Name)):
                crepr = self._getExprRepr(cnode)
            else:
                crepr = "(%s)" % self._getExprRepr(cnode)
            creprs.append(crepr)
        s = "|".join(creprs)
    elif isinstance(node, ast.Bitand):
        creprs = []
        for cnode in node.nodes:
            if isinstance(cnode, (ast.Const, ast.Name)):
                crepr = self._getExprRepr(cnode)
            else:
                crepr = "(%s)" % self._getExprRepr(cnode)
            creprs.append(crepr)
        s = "&amp;".join(creprs)
    elif isinstance(node, ast.Bitxor):
        creprs = []
        for cnode in node.nodes:
            if isinstance(cnode, (ast.Const, ast.Name)):
                crepr = self._getExprRepr(cnode)
            else:
                crepr = "(%s)" % self._getExprRepr(cnode)
            creprs.append(crepr)
        s = "^".join(creprs)
    elif isinstance(node, ast.Lambda):
        s = "lambda"
        defaultArgsBaseIndex = len(node.argnames) - len(node.defaults)
        if node.kwargs:
            defaultArgsBaseIndex -= 1
            if node.varargs:
                defaultArgsBaseIndex -= 1
                varargsIndex = len(node.argnames)-2
            else:
                varargsIndex = None
            kwargsIndex = len(node.argnames)-1
        elif node.varargs:
            defaultArgsBaseIndex -= 1
            varargsIndex = len(node.argnames)-1
            kwargsIndex = None
        else:
            varargsIndex = kwargsIndex = None
        args = []
        for i in range(len(node.argnames)):
            argOrArgTuple = node.argnames[i]
            if isinstance(argOrArgTuple, tuple):
                arg = "(%s)" % ','.join(argOrArgTuple)
                if i &gt;= defaultArgsBaseIndex:
                    defaultNode = node.defaults[i-defaultArgsBaseIndex]
                    try:
                        arg += "="+self._getExprRepr(defaultNode)
                    except PythonCILEError:
                        #XXX Work around some trouble cases.
                        arg += arg+"=..."
            else:
                argname = node.argnames[i]
                if i == kwargsIndex:
                    arg = "**"+argname
                elif i == varargsIndex:
                    arg = "*"+argname
                elif i &gt;= defaultArgsBaseIndex:
                    defaultNode = node.defaults[i-defaultArgsBaseIndex]
                    try:
                        arg = argname+"="+self._getExprRepr(defaultNode)
                    except PythonCILEError:
                        #XXX Work around some trouble cases.
                        arg = argname+"=..."
                else:
                    arg = argname
            args.append(arg)
        if args:
            s += " " + ",".join(args)
        try:
            s += ": " + self._getExprRepr(node.code)
        except PythonCILEError:
            #XXX Work around some trouble cases.
            s += ":..."
    else:
        raise PythonCILEError("don't know how to get string repr "
                              "of expression: %r" % node)
    return s

</t>
<t tx="ekr.20080121105837.479">def _getCITDLExprRepr(self, node, _level=0):
    """Return a string repr for this expression that CITDL processing
    can handle.
    
    CITDL is no panacea -- it is meant to provide simple delayed type
    determination. As a result, many complicated expressions cannot
    be handled. If the expression is not with CITDL's scope, then None
    is returned.
    """
    s = None
    if isinstance(node, ast.Name):
        s = node.name
    elif isinstance(node, ast.Const):
        s = repr(node.value)
    elif isinstance(node, ast.Getattr):
        exprRepr = self._getCITDLExprRepr(node.expr, _level+1)
        if exprRepr is None:
            pass
        else:
            s = '.'.join([exprRepr, node.attrname])
    elif isinstance(node, ast.List):
        s = "[]"
    elif isinstance(node, ast.Tuple):
        s = "()"
    elif isinstance(node, ast.Dict):
        s = "{}"
    elif isinstance(node, ast.CallFunc):
        # Only allow CallFunc at the top-level. I.e. this:
        #   spam.ham.eggs()
        # is in scope, but this:
        #   spam.ham().eggs
        # is not.
        if _level != 0:
            pass
        else:
            s = self._getCITDLExprRepr(node.node, _level+1)
            if s is not None:
                s += "()"
    return s


</t>
<t tx="ekr.20080121105837.480">def _quietCompilerParse(content):
    oldstderr = sys.stderr
    sys.stderr = StringIO()
    try:
        return compiler.parse(content)
    finally:
        sys.stderr = oldstderr

</t>
<t tx="ekr.20080121105837.481">def _quietCompile(source, filename, kind):
    oldstderr = sys.stderr
    sys.stderr = StringIO()
    try:
        return compile(source, filename, kind)
    finally:
        sys.stderr = oldstderr


</t>
<t tx="ekr.20080121105837.482">def _getAST(content):
    """Return an AST for the given Python content.
    
    If cannot, raise an error describing the problem.
    """
    # EOL issues:
    # compiler.parse() can't handle '\r\n' EOLs on Mac OS X and can't
    # handle '\r' EOLs on any platform. Let's just always normalize.
    # Unfortunately this is work only for the exceptional case. The
    # problem is most acute on the Mac.
    content = '\n'.join(content.splitlines(0))
    # Is this faster?
    #   content = content.replace('\r\n', '\n').replace('\r', '\n')

    errlineno = None # line number of a SyntaxError
    ast_ = None
    try:
        ast_ = _quietCompilerParse(content)
    except SyntaxError, ex:
        errlineno = ex.lineno
        log.debug("compiler parse #1: syntax error on line %d", errlineno)
    except parser.ParserError, ex:
        log.debug("compiler parse #1: parse error")
        # Try to get the offending line number.
        # compile() only likes LFs for EOLs.
        lfContent = content.replace("\r\n", "\n").replace("\r", "\n")
        try:
            _quietCompile(lfContent, "dummy.py", "exec")
        except SyntaxError, ex2:
            errlineno = ex2.lineno
        except:
            pass
        if errlineno is None:
            raise # Does this re-raise 'ex' (as we want) or 'ex2'?

    if errlineno is not None:
        # There was a syntax error at this line: try to recover by effectively
        # nulling out the offending line.
        lines = content.splitlines(1)
        offender = lines[errlineno-1]
        log.info("syntax error on line %d: %r: trying to recover",
                 errlineno, offender)
        indent = ''
        for i in range(0, len(offender)):
            if offender[i] in " \t":
                indent += offender[i]
            else:
                break
        lines[errlineno-1] = indent+"pass"+"\n"
        newContent = ''.join(lines)

        errlineno2 = None
        try:
            ast_ = _quietCompilerParse(newContent)
        except SyntaxError, ex:
            errlineno2 = ex.lineno
            log.debug("compiler parse #2: syntax error on line %d", errlineno)
        except parser.ParserError, ex:
            log.debug("compiler parse #2: parse error")
            # Try to get the offending line number.
            # compile() only likes LFs for EOLs.
            lfContent = newContent.replace("\r\n", "\n").replace("\r", "\n")
            try:
                _quietCompile(lfContent, "dummy.py", "exec")
            except SyntaxError, ex2:
                errlineno2 = ex2.lineno
            except:
                pass
            if errlineno2 is None:
                raise

        if ast_ is not None:
            pass
        elif errlineno2 == errlineno:
            raise ValueError("cannot recover from syntax error: line %d"
                             % errlineno)
        else:
            raise ValueError("cannot recover from multiple syntax errors: "
                             "line %d and then %d" % (errlineno, errlineno2))
    return ast_


</t>
<t tx="ekr.20080121105837.483">#---- public module interface

def scan(content, filename, md5sum=None, mtime=None, lang="Python"):
    """Scan the given Python content and return Code Intelligence data
    conforming the the Code Intelligence XML format.
    
        "content" is the Python content to scan
        "filename" is the source of the Python content (used in the
            generated output).
        "md5sum" (optional) if the MD5 hexdigest has already been calculated
            for the content, it can be passed in here. Otherwise this
            is calculated.
        "mtime" (optional) is a modified time for the file (in seconds since
            the "epoch"). If it is not specified the _current_ time is used.
            Note that the default is not to stat() the file and use that
            because the given content might not reflect the saved file state.
        "lang" (optional) is the language of the given file content.
            Typically this is "Python" (i.e. a pure Python file), but it
            may also be "DjangoHTML" or similar for Python embedded in
            other documents.
        XXX Add an optional 'eoltype' so that it need not be
            re-calculated if already known.
    
    This can raise one of SyntaxError, PythonCILEError or parser.ParserError
    if there was an error processing. Currently this implementation uses the
    Python 'compiler' package for processing, therefore the given Python
    content must be syntactically correct.
    """
    log.info("scan '%s'", filename)
    if md5sum is None:
        md5sum = md5.new(content).hexdigest()
    if mtime is None:
        mtime = int(time.time())
    # 'compiler' both (1) wants a newline at the end and (2) can fail on
    # funky *whitespace* at the end of the file.
    content = content.rstrip() + '\n'

    if type(filename) == types.UnicodeType:
        filename = filename.encode('utf-8')
    # The 'path' attribute must use normalized dir separators.
    if sys.platform.startswith("win"):
        path = filename.replace('\\', '/')
    else:
        path = filename
    fileAttrs = {"language": "Python",
                 "generator": "Python",
                 "path": path}

    try:
        ast_ = _getAST(content)
        if _gClockIt: sys.stdout.write(" (ast:%.3fs)" % (_gClock()-_gStartTime))
    except Exception, ex:
        fileAttrs["error"] = str(ex)
        file = '    &lt;file%s/&gt;' % getAttrStr(fileAttrs)
    else:
        if ast_ is None:
            # This happens, for example, with:
            #   foo(bar, baz=1, blam)
            fileAttrs["error"] = "could not generate AST"
            file = '    &lt;file%s/&gt;' % getAttrStr(fileAttrs)
        else:
            fileAttrs["md5"] = md5sum
            fileAttrs["mtime"] = mtime
            moduleName = os.path.splitext(os.path.basename(filename))[0]
            visitor = AST2CIXVisitor(moduleName, content=content)
            if log.isEnabledFor(logging.DEBUG):
                walker = ExampleASTVisitor()
                walker.VERBOSE = 1
            else:
                walker = None
            compiler.walk(ast_, visitor, walker)
            if _gClockIt: sys.stdout.write(" (walk:%.3fs)" % (_gClock()-_gStartTime))
            if log.isEnabledFor(logging.INFO):
                # Dump a repr of the gathering info for debugging
                # - We only have to dump the module namespace because
                #   everything else should be linked from it.
                for nspath, namespace in visitor.st.items():
                    if len(nspath) == 0: # this is the module namespace
                        pprint.pprint(namespace)
            file = '    &lt;file%s&gt;\n\n%s\n    &lt;/file&gt;'\
                   % (getAttrStr(fileAttrs), visitor.getCIX(level=2))
            if _gClockIt: sys.stdout.write(" (getCIX:%.3fs)" % (_gClock()-_gStartTime))

    cix = u'''\
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;codeintel version="0.1"&gt;
%s
&lt;/codeintel&gt;
''' % file

    return cix



</t>
<t tx="ekr.20080121105837.484">#---- mainline

def main(argv):
    logging.basicConfig()

    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
            ["version", "verbose", "help", "filename=", "md5=", "mtime=",
             "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `pythoncile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Python"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "pythoncile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            import time
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "&lt;stdin&gt;"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if os.path.isfile(path):
                filenames.append(path)
            elif os.path.isdir(path):
                pyfiles = [os.path.join(path, n) for n in os.listdir(path)
                           if os.path.splitext(n)[1] == ".py"]
                pyfiles = [f for f in pyfiles if os.path.isfile(f)]
                filenames += pyfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                fin = open(filename, 'r')
                try:
                    content = fin.read()
                finally:
                    fin.close()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan(content, filename, md5sum=md5sum, mtime=mtime,
                        lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except PythonCILEError, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1


</t>
<t tx="ekr.20080121105837.485">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    sys.exit(main(sys.argv))

</t>
<t tx="ekr.20080121105837.486">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    rubycile - a Code Intelligence Language Engine for the Ruby language

    Module Usage:
        from rubycile import scan
        mtime = os.stat("foo.rb")[stat.ST_MTIME]
        content = open("foo.rb", "r").read()
        scan(content, "foo.rb", mtime=mtime)
    
    Command-line Usage:
        rubycile.py [&lt;options&gt;...] [&lt;Ruby files&gt;...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename &lt;path&gt;   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted &lt;file&gt; tag.
        --md5=&lt;string&gt;      md5 hash for the input
        --mtime=&lt;secs&gt;      modification time for output info, in #secs since
                            1/1/70.
        -L, --language &lt;name&gt;
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Ruby files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .rb files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html
    
    The command-line interface will return non-zero iff the scan failed.
"""

import os
from os.path import abspath, basename, dirname, splitext, isfile, isdir, join
import sys
import getopt
import md5
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import ruby_lexer, ruby_parser, util
from codeintel2.parseutil import getAttrStr, xmlencode, cdataescape
from codeintel2.common import CILEError
from codeintel2 import parser_cix


</t>
<t tx="ekr.20080121105837.487">#---- exceptions

class RubyCILEError(CILEError):
    pass


</t>
<t tx="ekr.20080121105837.488">#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("rubycile")
#log.setLevel(logging.DEBUG)

dcLog = logging.getLogger("rubycile.dircache")
#dcLog.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

gProduceOldCIX = False  #XXX Temporary -- the old format should be pulled out.

# from codeintel2.util import hotshotit

class _DirInfo:
    """
    This class stats a directory to determine when files have
    been added to or removed from it.  Update times are
    platform-dependent.  For example, the Python docs state
    that on Windows update resolution on the st_mtime
    attribute is 2-seconds, but I've observed it to be closer to
    30 seconds.
    """
    @others
</t>
<t tx="ekr.20080121105837.489">def __init__(self, ptn):
    self._data = {}
    self._ptn = ptn

</t>
<t tx="ekr.20080121105837.490">def get_files(self, dirname):
    if not self._data.has_key(dirname):
        self._create(dirname)
    else:
        new_time = self._changed(dirname)
        if new_time:
            self._update(dirname, new_time)
            dcLog.debug("==&gt; " + "\t\n".join(self._data[dirname]['flist']))
    return self._data[dirname]['flist']

</t>
<t tx="ekr.20080121105837.491">def _changed(self, dirname):
    new_time = self._mtime(dirname)
    if new_time &gt; self._data[dirname]['mtime']:
        return new_time
    return 0

</t>
<t tx="ekr.20080121105837.492">def _create(self, dirname):
    self._data[dirname] = {'mtime' : self._mtime(dirname),
                           'flist' : self._files(dirname),
                           }

</t>
<t tx="ekr.20080121105837.493">def _files(self, dirname):
    return glob.glob(join(dirname, self._ptn))

</t>
<t tx="ekr.20080121105837.494">def _mtime(self, dirname):
    try:
        return os.stat(dirname)[stat.ST_MTIME]
    except OSError:
        return 0

</t>
<t tx="ekr.20080121105837.495">def _update(self, dirname, mtime):
    self._data[dirname]['mtime'] = mtime
    self._data[dirname]['flist'] = self._files(dirname)

</t>
<t tx="ekr.20080121105837.496">_modelDirInfo = _DirInfo("*.rb")

def rails_role_from_path(path):
    apath = abspath(path)
    aplist = apath.split(os.path.sep)
    # Allow for someone to built a rails app at root...
    if len(aplist) &lt; 3:
        return None
    elif (aplist[-3] == "app" and
        (aplist[-2] == "controllers" and aplist[-1].endswith(".rb")
         or aplist[-2] == "helpers" and aplist[-1].endswith("_helper.rb")
         or aplist[-2] == "models" and aplist[-1].endswith(".rb"))):
        role_parts = aplist[-3:]
    elif (len(aplist) &gt;= 4
          and aplist[-4] == "app" and aplist[-3] == "views"
          and aplist[-1].endswith(".rhtml")):
        role_parts = aplist[-4:]
    elif (aplist[-3] == "db" and
          aplist[-2] == "migrate" and
          aplist[-1].endswith(".rb") and
          aplist[-1][0].isdigit()):
        role_parts = aplist[-3:]
    elif (aplist[-3] == "test" and
          aplist[-2] in ("functional", "integration", "unit") and
          aplist[-1].endswith(".rb")):
        role_parts = aplist[-3:]
    else:
        return None
    return role_parts

</t>
<t tx="ekr.20080121105837.497">def check_insert_rails_env(path, blob_scope):
    role_parts = rails_role_from_path(path)
    if role_parts is None:
        return
    add_models = False
    if len(role_parts) &gt; 1 and role_parts[0] == "app":
        if role_parts[1] == "views":
            # This stuff only works if the evaluator will load class names as well
            # as namespace names.
            blob_scope.insert(0, Element("import", symbol="ActionView::Base"))
        elif len(role_parts) &gt; 2:
            if role_parts[1] in ("controllers", "models"):
                if role_parts[1] == "controllers":
                    if role_parts[2] != "application.rb":
                        blob_scope.insert(0, Element("import", module="./application", symbol='*'))
                    # For loading models
                    apath = abspath(path)
                    add_models = True
                    models_dir = join(dirname(dirname(apath)), "models")
                    rel_part = "../"
                    # For loading migrations
                    modelName = "*"
                else:
                    # add requires for each migration file
                    # Here's how it works:
                    # If the file is app/models/my_thing.rb,
                    # For each file foo in ../../db/migrate/*.rb,
                    # Try to load module=foo, symbol=inflector.camelcase(drop_ext(basename(filename)))
                    modelName = ruby_parser.get_inflector().camelize(splitext(basename(path))[0])
                # Load the migration modules
                apath = abspath(path)
                migration_dir = join(dirname(dirname(dirname(apath))), "db", "migrate")
                migration_files = _modelDirInfo.get_files(migration_dir)
                idx = 0
                for migration_file in migration_files:
                    idx += 1
                    base_part = "../../db/migrate/" + splitext(basename(migration_file))[0]
                    blob_class = blob_scope.find("scope")
                    assert blob_class.get('ilk') == 'class'
                    blob_class.insert(idx, Element("import", module=base_part, symbol=modelName))
    elif (len(role_parts) &gt; 2
          and ((role_parts[0] == "db" and role_parts[1] == "migrate"
                and role_parts[2][0].isdigit())
                or role_parts[0] == "test")):
        apath = abspath(path)
        add_models = True
        models_dir = join(dirname(dirname(dirname(apath))), "app", "models")
        rel_part = "../../app/"
        if role_parts[0] == "test" and role_parts[1] == 'functional':
            # Each file functional/foo_controller_test.rb will contain a line reading
            # require 'foo'
            # but codeintel won't know where to look for this foo, so we'll tell it explicitly
            # Use 'index' to throw an exception because
            # RubyCommonBufferMixin.check_for_rails_app_path specified this pattern.
            end_part = role_parts[2].index("_test.rb")
            controller_file = rel_part + "controllers/" + role_parts[2][0:end_part]
            blob_scope.insert(0, Element("import", module=controller_file, symbol='*'))
            modelName = '*'
        #XXX - tests can't see migration dirs yet.
        #migration_dir = join(dirname(dirname(dirname(apath))), "db", "migrate")

    if add_models:
        model_files = _modelDirInfo.get_files(models_dir)
        idx = 0
        for model_file in model_files:
            idx += 1
            base_part = rel_part + "models/" + splitext(basename(model_file))[0]
            blob_scope.insert(idx, Element("import", module=base_part, symbol='*'))

</t>
<t tx="ekr.20080121105837.498">def scan(content, filename, md5sum=None, mtime=None, lang="Ruby"):
    log.info("scan '%s'", filename)
    content = content.expandtabs(8)
    tokenizer = ruby_lexer.RubyLexer(content)
    parser = ruby_parser.Parser(tokenizer, lang)
    if 1:
        parse_tree = parser.parse()
        if mtime is None:
            actual_mtime = int(time.time())
        else:
            actual_mtime = mtime
        return parser_cix.produce_cix(parse_tree, filename, actual_mtime, "Ruby", "Ruby")
    if 0: #except Exception, e:
        print "Error: " + e
        sys.exit(1)   

</t>
<t tx="ekr.20080121105837.499"># @hotshotit
def scan_purelang(content, filename):
    content = content.expandtabs(8)
    tokenizer = ruby_lexer.RubyLexer(content)
    parser = ruby_parser.Parser(tokenizer, "Ruby")
    parse_tree = parser.parse()
    tree = parser_cix.produce_elementTree_cix(parse_tree, filename,
                                              "Ruby", "Ruby")
    rails_migration_class_nodes = parser.rails_migration_class_tree()
    if rails_migration_class_nodes:
        blob_node = tree.getchildren()[0].getchildren()[0]
        for parse_tree_node in rails_migration_class_nodes:
            assert parse_tree_node.class_name == "Class"
            parser_cix.common_module_class_cix(parse_tree_node, blob_node, class_ref_fn=None, attributes="__fabricated__")
            # parser_cix.class_etree_cix(rails_migration_class_tree, blob_node)
    return tree


</t>
<t tx="ekr.20080121105837.500">def scan_multilang(tokens, module_elem):
    """Build the Ruby module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the &lt;module&gt; element of a CIX element tree on
            which the Ruby module should be built.

    This should return a tuple of:
    * the list of the CSL tokens in the token stream,
    * whether or not the document contains any Ruby tokens (style UDL_SSL...)
    """
        
    tokenizer = ruby_lexer.RubyMultiLangLexer(tokens)
    parser = ruby_parser.Parser(tokenizer, "RHTML")
    parse_tree = parser.parse()
    parser_cix.produce_elementTree_contents_cix(parse_tree, module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens, tokenizer.has_ruby_code()


</t>
<t tx="ekr.20080121105837.501">#---- mainline

def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
            ["version", "verbose", "help", "filename=", "md5=", "mtime=",
             "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `rubycile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Ruby"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "rubycile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "&lt;stdin&gt;"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if isfile(path):
                filenames.append(path)
            elif isdir(path):
                rbfiles = [join(path, n) for n in os.listdir(path)
                           if splitext(n)[1] == ".rb"]
                rbfiles = [f for f in rbfiles if isfile(f)]
                filenames += rbfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = scan_purelang(content, filename)
            # data = scan(content, filename, md5sum, mtime, lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1
    if 0: #except Exception, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1

</t>
<t tx="ekr.20080121105837.502">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    sys.exit(main(sys.argv))

</t>
<t tx="ekr.20080121105837.503">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
    tclcile - a Code Intelligence Language Engine for the Tcl language

    Module Usage:
        from tclcile import scan
        mtime = os.stat("foo.rb")[stat.ST_MTIME]
        content = open("foo.rb", "r").read()
        scan(content, "foo.rb", mtime=mtime)
    
    Command-line Usage:
        tclcile.py [&lt;options&gt;...] [&lt;Tcl files&gt;...]

    Options:
        -h, --help          dump this help and exit
        -V, --version       dump this script's version and exit
        -v, --verbose       verbose output, use twice for more verbose output
        -f, --filename &lt;path&gt;   specify the filename of the file content
                            passed in on stdin, this is used for the "path"
                            attribute of the emitted &lt;file&gt; tag.
        --md5=&lt;string&gt;      md5 hash for the input
        --mtime=&lt;secs&gt;      modification time for output info, in #secs since
                            1/1/70.
        -L, --language &lt;name&gt;
                            the language of the file being scanned
        -c, --clock         print timing info for scans (CIX is not printed)

    One or more Tcl files can be specified as arguments or content can be
    passed in on stdin. A directory can also be specified, in which case
    all .rb files in that directory are scanned.

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html
    
    The command-line interface will return non-zero iff the scan failed.
"""

import os
from os.path import basename, splitext, isfile, isdir, join
import sys
import getopt
import md5
import re
import logging
import glob
import time
import stat

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants

from codeintel2 import tcl_lexer, tcl_parser
from codeintel2.parseutil import getAttrStr, xmlencode, cdataescape
from codeintel2.common import CILEError
from codeintel2 import parser_cix

</t>
<t tx="ekr.20080121105837.504">#---- exceptions

class TclCILEError(CILEError):
    pass


</t>
<t tx="ekr.20080121105837.505">#---- global data

_version_ = (0, 1, 0)
log = logging.getLogger("tclcile")
#log.setLevel(logging.DEBUG)

_gClockIt = 0   # if true then we are gathering timing data
_gClock = None  # if gathering timing data this is set to time retrieval fn
_gStartTime = None   # start time of current file being scanned

def scan(content, filename, md5sum=None, mtime=None, lang="Tcl"):
    log.info("scan '%s'", filename)
    content = content.expandtabs(8)
    tokenizer = tcl_lexer.TclLexer(content)
    parser = tcl_parser.Parser(tokenizer, lang)
    if 1:
        parse_tree = parser.parse()
        if mtime is None:
            actual_mtime = int(time.time())
        else:
            actual_mtime = mtime
        if md5sum is None:
            actual_md5 = md5.new(content).hexdigest()
        else:
            actual_md5 = md5sum
        return parser_cix.produce_cix(parse_tree, filename, actual_md5, actual_mtime, "Tcl", "tclcile")


</t>
<t tx="ekr.20080121105837.506">def scan_purelang(content, filename):
    content = content.expandtabs(8)
    tokenizer = tcl_lexer.TclLexer(content)
    parser = tcl_parser.Parser(tokenizer, "Tcl")
    parse_tree = parser.parse()
    #XXX Change last arg from "Tcl" to "tclcile"?
    tree = parser_cix.produce_elementTree_cix(parse_tree, filename, "Tcl",
                                              "Tcl")
    return tree


</t>
<t tx="ekr.20080121105837.507">def scan_multilang(tokens, module_elem):
    """Build the Tcl module CIX element tree.

        "tokens" is a generator of UDL tokens for this UDL-based
            multi-lang document.
        "module_elem" is the &lt;module&gt; element of a CIX element tree on
            which the Tcl module should be built.

    This should return a list of the CSL tokens in the token stream.
    """
        
    tokenizer = tcl_lexer.TclMultiLangLexer(tokens)
    parser = tcl_parser.Parser(tokenizer, "AOL")
    parse_tree = parser.parse()
    parser_cix.produce_elementTree_contents_cix(parse_tree, module_elem)
    csl_tokens = tokenizer.get_csl_tokens()
    return csl_tokens


</t>
<t tx="ekr.20080121105837.508">#---- mainline

def main(argv):
    logging.basicConfig()
    # Parse options.
    try:
        opts, args = getopt.getopt(argv[1:], "Vvhf:cL:",
            ["version", "verbose", "help", "filename=", "md5=", "mtime=",
             "clock", "language="])
    except getopt.GetoptError, ex:
        log.error(str(ex))
        log.error("Try `tclcile --help'.")
        return 1
    numVerboses = 0
    stdinFilename = None
    md5sum = None
    mtime = None
    lang = "Tcl"
    global _gClockIt
    for opt, optarg in opts:
        if opt in ("-h", "--help"):
            sys.stdout.write(__doc__)
            return
        elif opt in ("-V", "--version"):
            ver = '.'.join([str(part) for part in _version_])
            print "tclcile %s" % ver
            return
        elif opt in ("-v", "--verbose"):
            numVerboses += 1
            if numVerboses == 1:
                log.setLevel(logging.INFO)
            else:
                log.setLevel(logging.DEBUG)
        elif opt in ("-f", "--filename"):
            stdinFilename = optarg
        elif opt in ("-L", "--language"):
            lang = optarg
        elif opt in ("--md5",):
            md5sum = optarg
        elif opt in ("--mtime",):
            mtime = optarg
        elif opt in ("-c", "--clock"):
            _gClockIt = 1
            global _gClock
            if sys.platform.startswith("win"):
                _gClock = time.clock
            else:
                _gClock = time.time

    if len(args) == 0:
        contentOnStdin = 1
        filenames = [stdinFilename or "&lt;stdin&gt;"]
    else:
        contentOnStdin = 0
        paths = []
        for arg in args:
            paths += glob.glob(arg)
        filenames = []
        for path in paths:
            if isfile(path):
                filenames.append(path)
            elif isdir(path):
                rbfiles = [join(path, n) for n in os.listdir(path)
                           if splitext(n)[1] == ".rb"]
                rbfiles = [f for f in rbfiles if isfile(f)]
                filenames += rbfiles

    try:
        for filename in filenames:
            if contentOnStdin:
                log.debug("reading content from stdin")
                content = sys.stdin.read()
                log.debug("finished reading content from stdin")
                if mtime is None:
                    mtime = int(time.time())
            else:
                if mtime is None:
                    mtime = int(os.stat(filename)[stat.ST_MTIME])
                content = open(filename, 'r').read()

            if _gClockIt:
                sys.stdout.write("scanning '%s'..." % filename)
                global _gStartTime
                _gStartTime = _gClock()
            data = tostring(scan_purelang(content, filename))
            # data = scan(content, filename, md5sum, mtime, lang=lang)
            if _gClockIt:
                sys.stdout.write(" %.3fs\n" % (_gClock()-_gStartTime))
            elif data:
                sys.stdout.write(data)
    except KeyboardInterrupt:
        log.debug("user abort")
        return 1
    if 0: #except Exception, ex:
        log.error(str(ex))
        if log.isEnabledFor(logging.DEBUG):
            print
            import traceback
            traceback.print_exception(*sys.exc_info())
        return 1

</t>
<t tx="ekr.20080121105837.509"></t>
<t tx="ekr.20080121105837.510">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, PerlLexer)
@ignore ### &lt;&lt; &gt;&gt; causes problems</t>
<t tx="ekr.20080121105837.511"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
Perl lexing support for codeintel/perlcile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Perl pseudo-parser).

Usage:
import perl_lexer
lexer = lex_wrapper.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import copy
import re
import sys
import string

import SilverCity
from SilverCity import Perl, ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE

pod_markings = re.compile('^=(?:head|item|cut)', re.M)

</t>
<t tx="ekr.20080121105837.512">class PerlLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""    
    @others
</t>
<t tx="ekr.20080121105837.513">
def is_comment(self, ttype):
    return ttype in (ScintillaConstants.SCE_PL_COMMENTLINE,
                     ScintillaConstants.SCE_PL_POD)
    
</t>
<t tx="ekr.20080121105837.514">@property
def style_comment(self):
    return ScintillaConstants.SCE_PL_COMMENTLINE
    
</t>
<t tx="ekr.20080121105837.515">@property
def style_default(self):
    return ScintillaConstants.SCE_PL_DEFAULT

</t>
<t tx="ekr.20080121105837.516">@property
def style_operator(self):
    return ScintillaConstants.SCE_PL_OPERATOR


</t>
<t tx="ekr.20080121105837.517">class _CommonLexer(shared_lexer.Lexer):
    @others
</t>
<t tx="ekr.20080121105837.518">def __init__(self):
    shared_lexer.Lexer.__init__(self)
    self.q = []
    self.multi_char_ops = self.build_dict('-&gt; ++ -- ** =~ !~ &lt;&lt; &gt;&gt; &lt;= &gt;= == != &lt;=&gt; &amp;&amp; || ... .. =&gt; &lt;&lt;= &gt;&gt;= &amp;&amp;= ||= ~*= /= %= += -= .= &amp;= |= ^= ::')

</t>
<t tx="ekr.20080121105837.519">class PerlLexer(_CommonLexer):
    @others
</t>
<t tx="ekr.20080121105837.520">def __init__(self, code, provide_full_docs=True):
    _CommonLexer.__init__(self)
    self.q = []
    self.classifier = PerlLexerClassifier()
    self._provide_full_docs = provide_full_docs
    Perl.PerlLexer().tokenize_by_style(code, self._fix_token_list)
    # self._fix_token_list(q_tmp) # Updates self.q in place
    self.string_types = [ScintillaConstants.SCE_PL_STRING,
                     ScintillaConstants.SCE_PL_CHARACTER,
                     ScintillaConstants.SCE_PL_HERE_Q,
                     ScintillaConstants.SCE_PL_HERE_QQ,
                     ScintillaConstants.SCE_PL_STRING_QW,
                     ScintillaConstants.SCE_PL_STRING_Q,
                     ScintillaConstants.SCE_PL_STRING_QQ,
                     ScintillaConstants.SCE_PL_STRING_QX
                     ]
    
</t>
<t tx="ekr.20080121105837.521">def _fix_token_list(self, **tok):
    """ SilverCity doesn't know much about Perl, and breaks in two ways:
    1. It doesn't know how to separate sequences of characters into
    separate tokens.
    2. It doesn't know how to map DATASECTIONs into POD sequences.
    
    It's easier to do this once before processing tokens individually.
    
    This should all be done in silvercity.  Doing this has leaked the
    whole silvercity abstraction into this module, and it doesn't
    belong here.  This routine works with SilverCity tokens, not
    shared_lexer Tokens.
    """
    if tok['start_column'] &gt; shared_lexer.MAX_REASONABLE_LIMIT:
        return
    ttype = tok['style']
    tval = tok['text']
    if ttype in (ScintillaConstants.SCE_PL_OPERATOR,
                 ScintillaConstants.SCE_PL_VARIABLE_INDEXER) and len(tok['text']) &gt; 1:
        # Scineplex doesn't know how to split some sequences of styled characters
        # into syntactically different tokens, so we do it here.
        # A sequence of characters might need to be split into more than one token.
        # Push all but the last token on the pending block.
        self.append_split_tokens(tok, self.multi_char_ops, self.q)
    elif ttype == ScintillaConstants.SCE_PL_IDENTIFIER:
        tok['text'] = tok['text'].strip()
        self.q.append(tok)
    elif (not self._provide_full_docs) and \
            ttype in (ScintillaConstants.SCE_PL_DATASECTION,
                      ScintillaConstants.SCE_PL_POD):
        pass
    elif ttype == ScintillaConstants.SCE_PL_DATASECTION:
        if pod_markings.search(tval):
            # putback (KWD package), (ID main), (OP ;), (POD this)
            col = tok['start_column']
            for new_vals in ((ScintillaConstants.SCE_PL_WORD, "package"),
                             (ScintillaConstants.SCE_PL_IDENTIFIER, "main"),
                             (ScintillaConstants.SCE_PL_OPERATOR, ";")):
                new_type, new_text = new_vals
                new_tok = copy.copy(tok)
                new_tok['text'] = new_text
                new_tok['style'] = new_type
                new_tok['start_column'] = col
                new_tok['end_column'] = col + len(new_text) - 1
                col = new_tok['end_column'] + 1
                self.q.append(new_tok)
            tok['style'] = ScintillaConstants.SCE_PL_POD
            tok['text'] = tval;
            tok['start_column'] = col
            if tok['start_line'] == tok['end_line']:
                tok['end_column'] = tok['start_line'] + len(tok['text']) - 1
            self.q.append(tok)
        else:
            # End of the queue =&gt; EOF
            pass
    else:
        self.q.append(tok)

</t>
<t tx="ekr.20080121105837.522">class PerlMultiLangLexer(_CommonLexer):
    @others
</t>
<t tx="ekr.20080121105837.523">def __init__(self, token_source):
    _CommonLexer.__init__(self)
    self.csl_tokens = []
    # http://www.mozilla.org/js/language/grammar14.html
    self.js_multi_char_ops = self.build_dict('++ -- &lt;&lt; &gt;&gt; &gt;&gt;&gt; &lt;= &gt;= == != === !== &amp;&amp; || *= /= %= += -= &lt;&lt;= &gt;&gt;= &gt;&gt;&gt;= &amp;= ^= |=')
    self.string_types = [ScintillaConstants.SCE_UDL_SSL_STRING
            ]
    self.classifier = shared_lexer.UDLLexerClassifier()
    self._contains_ssl = False
    self._build_tokens(token_source)

</t>
<t tx="ekr.20080121105837.524">def _build_tokens(self, token_source):
    while True:
        try:
            tok = token_source.next()
            self._fix_token_list(tok)
        except StopIteration:
            break

</t>
<t tx="ekr.20080121105837.525">def _fix_token_list(self, tok):
    """See perl_lexer.py for details on what this routine does."""
    ttype = tok['style']
    tval = tok['text']
    if self.is_udl_csl_family(ttype):
        if ttype == ScintillaConstants.SCE_UDL_CSL_OPERATOR and len(tval) &gt; 1:
            # Point the token splitter to the correct token queue
            self.append_split_tokens(tok, self.js_multi_char_ops,
                                     self.csl_tokens)
        else:
            self.csl_tokens.append(tok)
    elif self.is_udl_ssl_family(ttype):
        if tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR and len(tok['text']) &gt; 1:
            self.append_split_tokens(tok, self.multi_char_ops, self.q)
        else:
            self.q.append(tok)
        self._contains_ssl = True
    # See comment in RubyMultiLangLexer._fix_token_list
    # on why we probably don't need this code.
    #elif self.is_udl_tpl_family(ttype):
    #    self._contains_ssl = True

</t>
<t tx="ekr.20080121105837.526">def get_csl_tokens(self):
    return self.csl_tokens

</t>
<t tx="ekr.20080121105837.527">def has_perl_code(self):
    return self._contains_ssl

</t>
<t tx="ekr.20080121105837.528">def provide_sample_code():
    return r"""use LWP::UserAgent;

# full-line comment
# comment at start of line
 # comment at col 1
  # comment at col 2

{
package Foo;

sub new {
   my ($class, %args) = @_;
   my $self = {count =&gt; 0, list = [] };
   bless $self, (ref $class || $class);
}

sub m {
    my ($self, $arg) = @_;
    push @{$self-&gt;{list}}, $arg;
    $self-&gt;{count} += 1;
    $arg;
}

sub no_paren {
  my ($a, $b,
     $c) = $_;
  print "blah";
}

sub our_generate { my $self = shift; my $file_info = shift;
  $self-&gt;{info} = info;
  $self-&gt;{files} = [];
  $self-&gt;{classes} = [];
  $self-&gt;{hyperlinks} = {};
  #comment on what test_fn does
  # more...

  sub test_fn {
        my ($a, $b, $c, $d, $e) = @_;
        $b |= 'val1';
        $c |= f(3);
       print "nothing\n";   # end-of-line comment
       print qq(percent string\n);
    }

   }
   }
"""


</t>
<t tx="ekr.20080121105837.529">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = perl_lexer.provide_sample_code()
        fs = None
        closefs = False
        modulePath = "__main__"
        mtime = time.time()
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
        modulePath = "stdin"
        mtime = time.time()
    else:
        modulePath = sys.argv[1]
        mtime = os.stat(modulePath).st_mtime
        fs = open(modulePath, "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    # Don't show the data
    elementTreeRepn = main(sample_code, modulePath, mtime, showWarnings, False)
    sys.stdout.write(tostring(elementTreeRepn))
    sys.stdout.write("\n")

    #pp(elementTreeRepn, sys.stdout)
    #import hotshot, hotshot.stats
    #profiler = hotshot.Profile("%s.prof" % (__file__))
    #profiler.runcall(main, sample_code, modulePath, mtime, showWarnings)
    #regex_data = REGEXEN.items()
    #regex_data.sort(lambda a, b: -cmp(a[1], b[1]))
    #for x in regex_data[:20]:
    #    print x[1], x[0]

</t>
<t tx="ekr.20080121105837.530"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Perl parsing support for codeintel/perlcile.py"""

import copy
import md5
import os.path
import string
import sys
import re
import textwrap
import time
import cPickle
import logging

from ciElementTree import Element, SubElement, tostring
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import (
    SCE_PL_DEFAULT, SCE_PL_ERROR, SCE_PL_COMMENTLINE, SCE_PL_POD,
    SCE_PL_NUMBER, SCE_PL_WORD, SCE_PL_STRING, SCE_PL_CHARACTER,
    SCE_PL_PUNCTUATION, SCE_PL_PREPROCESSOR, SCE_PL_OPERATOR,
    SCE_PL_IDENTIFIER, SCE_PL_SCALAR, SCE_PL_ARRAY, SCE_PL_HASH,
    SCE_PL_SYMBOLTABLE, SCE_PL_VARIABLE_INDEXER, SCE_PL_REGEX,
    SCE_PL_REGSUBST, SCE_PL_LONGQUOTE, SCE_PL_BACKTICKS, SCE_PL_DATASECTION,
    SCE_PL_HERE_DELIM, SCE_PL_HERE_Q, SCE_PL_HERE_QQ, SCE_PL_HERE_QX,
    SCE_PL_STRING_Q, SCE_PL_STRING_QQ, SCE_PL_STRING_QX, SCE_PL_STRING_QR,
    SCE_PL_STRING_QW, SCE_PL_POD_VERB, SCE_PL_SUB, SCE_PL_SUB_ARGS,
    SCE_PL_UNKNOWN_FIELD, SCE_PL_STDIN, SCE_PL_STDOUT, SCE_PL_STDERR,
    SCE_PL_FORMAT, SCE_PL_UPPER_BOUND)

from codeintel2.common import CILEError
from codeintel2 import perl_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser

SCE_PL_UNUSED = shared_lexer.EOF_STYLE

log = logging.getLogger("perlcile")
#log.setLevel(logging.DEBUG)

#----  memoize from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/496879

TIMING = False # set to true to capture timing data from regexen
REGEXEN = {} # unused if TIMING is not True

</t>
<t tx="ekr.20080121105837.531">def memoize(function, limit=None):
    if isinstance(function, int):
        def memoize_wrapper(f):
            return memoize(f, function)

        return memoize_wrapper

    dict = {}
    list = []
    def memoize_wrapper(*args, **kwargs):
        key = cPickle.dumps((args, kwargs))
        try:
            list.append(list.pop(list.index(key)))
        except ValueError:
            dict[key] = function(*args, **kwargs)
            list.append(key)
            if limit is not None and len(list) &gt; limit:
                del dict[list.pop(0)]

        return dict[key]

    memoize_wrapper._memoize_dict = dict
    memoize_wrapper._memoize_list = list
    memoize_wrapper._memoize_limit = limit
    memoize_wrapper._memoize_origfunc = function
    memoize_wrapper.func_name = function.func_name
    return memoize_wrapper


</t>
<t tx="ekr.20080121105837.532">class TimingRe:
    "A wrapper around compiled regexen that keeps track of timing data"
    @others
</t>
<t tx="ekr.20080121105837.533">def __init__(self, re, orig_re):
    self._re = re
    self._orig_re = orig_re
</t>
<t tx="ekr.20080121105837.534">def sub(self, *args):
    return self._timing_operation('sub', *args)
</t>
<t tx="ekr.20080121105837.535">def match(self, *args):
    return self._timing_operation('match', *args)
</t>
<t tx="ekr.20080121105837.536">def search(self, *args):
    return self._timing_operation('search', *args)
</t>
<t tx="ekr.20080121105837.537">def split(self, *args):
    return self._timing_operation('split', *args)
</t>
<t tx="ekr.20080121105837.538">def findall(self, *args):
    return self._timing_operation('findall', *args)

</t>
<t tx="ekr.20080121105837.539">def _timing_operation(self, methodname, *args):
    start = time.time()
    retval = getattr(self._re, methodname)(*args)
    end = time.time()
    delta = end-start
    #if delta &gt; 0.01:
    #    print delta,'\t', self._orig_re, str(args)[:80]
    if self._orig_re not in REGEXEN:
        REGEXEN[self._orig_re] = 0.0
    REGEXEN[self._orig_re] += delta
    return retval

</t>
<t tx="ekr.20080121105837.540">@memoize
def re_compile(regex, *args):
    """A version of re.compile which memoizes and optionally keeps track of timing
    data"""
    if TIMING:
        return TimingRe(re.compile(regex, *args), regex)
    else:
        return re.compile(regex, *args)

</t>
<t tx="ekr.20080121105837.541">def re_sub(*args):
    """a version of re.sub which deals with TimingRe objects and prints out
    details of slow regexen"""
    if TIMING:
        start = time.time()
        if isinstance(args[0], TimingRe):
            retval = args[0].sub(*args[1:])
        else:
            retval = re.sub(*args)
        end = time.time()
        delta = end-start
        if delta &gt; 0.01: #adjust as needed.
            print delta,'\t',args
    else:
        retval = re.sub(*args)
    return retval

</t>
<t tx="ekr.20080121105837.542">class PerlCommonClassifier:
    """Mixin class containing classifier callbacks"""
    @others
</t>
<t tx="ekr.20080121105837.543">
def is_array_cb(self, tok):
    tval = tok.text
    return len(tval) &gt;= 2 and tval[0] == '@' and tval[1] != '$'
    # @$name is more like an expression -- don't return it

</t>
<t tx="ekr.20080121105837.544">def is_scalar_cb(self, tok):
    tval = tok.text
    return len(tval) &gt; 1 and tval[0] == '$' and (tval[1].isalnum or tval[1] == "_")

</t>
<t tx="ekr.20080121105837.545">def is_pod_cb(self, tok):
    return tok.text[0] == '=' and tok.text[1].isalnum and tok.text.find("\n=cut", 5) &gt; 0

</t>
<t tx="ekr.20080121105837.546">def is_string_qw_cb(self, tok):
    return re_compile(r'^qw\s*[^\w\d_]').match(tok.text)
                                               

</t>
<t tx="ekr.20080121105837.547"># Used for stripping the quotes off a string
_quote_patterns = {SCE_PL_STRING : re.compile('^[\'\"](.*)[\'\"]$'),
                   SCE_PL_CHARACTER : re.compile('^\'(.*)\'$'),
                   SCE_PL_STRING_Q : re.compile(r'^q\s*.(.*).$'),
                   SCE_PL_STRING_QQ : re.compile(r'^q\w\s*.(.*).$'),
                   SCE_PL_DEFAULT : re.compile('^.(.*).$'), #fallback
                   }

def quote_patterns_cb(self, tok):
    # Caller wants an array.
    return [self.quote_patterns_cb_aux(tok)]

</t>
<t tx="ekr.20080121105837.548">def quote_patterns_cb_aux(self, tok):
    tval = tok.text
    if tval[0] == '"':
        return self._quote_patterns[SCE_PL_STRING]
    elif tval[0] == '\'':
        return self._quote_patterns[SCE_PL_CHARACTER]
    elif tval.startswith("Q"):
        return self._quote_patterns[SCE_PL_STRING_QQ]
    elif tval.startswith("q"):
        return self._quote_patterns[SCE_PL_STRING_Q]
    else:
        return self._quote_patterns[SCE_PL_DEFAULT] # Fallback

</t>
<t tx="ekr.20080121105837.549">class UDLClassifier(PerlCommonClassifier, shared_parser.UDLClassifier):
    pass

</t>
<t tx="ekr.20080121105837.550">class PerlClassifier(PerlCommonClassifier, shared_parser.CommonClassifier):
    @others
</t>
<t tx="ekr.20080121105837.551">def get_builtin_type(self, tok, callback):
    raise CILEError("Unexpected call to perl_parser.get_builtin_type")
    
</t>
<t tx="ekr.20080121105837.552">def is_any_operator(self, tok):
    return tok.style == ScintillaConstants.SCE_PL_OPERATOR

</t>
<t tx="ekr.20080121105837.553">def is_comment(self, tok):
    return tok.style in (ScintillaConstants.SCE_PL_COMMENT,
                         ScintillaConstants.SCE_PL_POD)

</t>
<t tx="ekr.20080121105837.554">def is_comment_structured(self, tok, callback):
    return tok.style == ScintillaConstants.SCE_PL_POD

</t>
<t tx="ekr.20080121105837.555">def is_identifier(self, tok, allow_keywords=False):
    return (tok.style == ScintillaConstants.SCE_PL_IDENTIFIER or
        (allow_keywords and
         tok.style == ScintillaConstants.SCE_PL_WORD))

</t>
<t tx="ekr.20080121105837.556">def is_index_op(self, tok, pattern=None):
    if not (tok.style in (SCE_PL_OPERATOR, SCE_PL_VARIABLE_INDEXER)):
        return False
    elif not pattern:
        return True
    return len(tok.text) &gt; 0 and pattern.search(tok.text)

</t>
<t tx="ekr.20080121105837.557">def is_interpolating_string(self, tok, callback):
    return tok.style in [ScintillaConstants.SCE_PL_STRING,
                         ScintillaConstants.SCE_PL_REGEX,
                         ScintillaConstants.SCE_PL_HERE_QQ,
                         ScintillaConstants.SCE_PL_STRING_QQ,
                         ScintillaConstants.SCE_PL_STRING_QR,
                         ScintillaConstants.SCE_PL_STRING_QX
                         ]

</t>
<t tx="ekr.20080121105837.558">def is_keyword(self, tok, target):
    return tok.style == ScintillaConstants.SCE_PL_WORD and tok.text == target

</t>
<t tx="ekr.20080121105837.559">def is_number(self, tok):
    return tok.style == ScintillaConstants.SCE_PL_NUMBER

</t>
<t tx="ekr.20080121105837.560">def is_operator(self, tok, target):
    return tok.style == ScintillaConstants.SCE_PL_OPERATOR and tok.text == target

</t>
<t tx="ekr.20080121105837.561">def is_string(self, tok):
    return tok.style in [ScintillaConstants.SCE_PL_STRING,
                         ScintillaConstants.SCE_PL_CHARACTER,
                         ScintillaConstants.SCE_PL_HERE_Q,
                         ScintillaConstants.SCE_PL_HERE_QQ,
                         ScintillaConstants.SCE_PL_STRING_Q,
                         ScintillaConstants.SCE_PL_STRING_QQ,
                         ScintillaConstants.SCE_PL_STRING_QX,
                         ]

</t>
<t tx="ekr.20080121105837.562">def is_string_qw(self, tok, callback):
    return tok.style == ScintillaConstants.SCE_PL_STRING_QW

</t>
<t tx="ekr.20080121105837.563">def is_symbol(self, tok):
    return False

</t>
<t tx="ekr.20080121105837.564">def is_variable(self, tok):
    return SCE_PL_SCALAR &lt;= tok.style &lt;= SCE_PL_SYMBOLTABLE

</t>
<t tx="ekr.20080121105837.565"># Types of variables
def is_variable_array(self, tok, callback=None):
    return tok.style == ScintillaConstants.SCE_PL_ARRAY and \
        len(tok.text) &gt; 1 and tok.text[1] != '$'
    
</t>
<t tx="ekr.20080121105837.566">def is_variable_scalar(self, tok, callback=None):
    return tok.style == ScintillaConstants.SCE_PL_SCALAR and \
        len(tok.text) &gt; 1 and tok.text[1] != '$'
    
</t>
<t tx="ekr.20080121105837.567"># Accessors for where we'd rather work with a style than call a predicate fn

@property
def style_identifier(self):
    return ScintillaConstants.SCE_PL_IDENTIFIER

</t>
<t tx="ekr.20080121105837.568">@property
def style_word(self):
    return ScintillaConstants.SCE_PL_WORD

</t>
<t tx="ekr.20080121105837.569">def _get_classifier(lang):
    """Factory method for choosing the style classifier."""
    cls = lang == "Perl" and PerlClassifier or UDLClassifier
    return cls()

</t>
<t tx="ekr.20080121105837.570"># Parse Perl code

showWarnings = False

class ModuleInfo:
    @others
</t>
<t tx="ekr.20080121105837.571">def __init__(self, provide_full_docs):
    self.provide_full_docs = provide_full_docs

    self.modules = {}
    self.currentFunction = None
    self.currentNS = None
    self.textWrapper = textwrap.TextWrapper()
    self.textWrapper.width = 60
    self.max_doclet_low_water_mark = 80
    self.max_doclet_high_water_mark = 100
    self.pod_escape_seq = {'lt' : "&amp;lt;",
                           'gt' : "&amp;gt;",
                           'verbar' : "|",
                           'sol' : "/"}
    # Things for attrs, etc.
    self.export_string = '__exported__'
    self.export_ok_string = '__exportable__'
    self.local_string = '__local__'
    # Cached regular expressions
    self.re_bl = r'\r?\n\s*\r?\n'
    self.tryGettingDoc_Sig_re3 = re_compile(r'^=(?:item|head)\w*\s*((?:(?!\n=).)*)(?!\n=)',
                             re.M|re.S)
    self.printDocInfo_re4 = re_compile(r'^=(?:item|head)\w*\s*((?:(?!\n=).)*)(?!\n=)', re.S|re.M)
    
    self.printDocInfo_re2 = re_compile(r'^=\w+\s+DESCRIPTION%s(.*?)(?:%s|^=)' % (self.re_bl, self.re_bl), re.M)
    self.printDocInfo_re6 = re_compile(r'^=\w+\s+SYNOPSIS' + self.re_bl + '(.*?)^=',
                                       re.M|re.S)
    self.printDocInfo_bdot_re = re_compile(r'\.\s+[A-Z].*\Z')

    self._get_first_sentence_re1 = re_compile(r'\.\s+[A-Z].*\Z', re.S)

    self._simple_depod_e_re = re_compile(r'E&lt;(.*?)&gt;', re.S)
    self._simple_depod_c_re = re_compile(r'C&lt;{2,}\s*(.*?)\s*&gt;{2,}', re.S)
    self._simple_depod_ibcfsxl_re1 = re_compile(r'[IBCFSXL]&lt;[^&gt;\n]*&gt;')
    self._simple_depod_ibcfsxl_re2 = re_compile(r'[IBCFSX]&lt;(&lt;*[^&lt;&gt;]*?&gt;*)&gt;', re.S)
    self._simple_depod_l_re = re_compile(r'L&lt;\/?(.*?)&gt;')
    self._simple_depod_rest_re = re_compile(r'\w&lt;\/?(&lt;*.*?&gt;*)&gt;')

    self._depod_re1 = re_compile(r'^=begin\s+man\s+.*?^=end\s+man\s*', re.M|re.S)
    self._depod_re2 = re_compile(r'^=\w+\s*', re.M)
    self._depod_re3 = re_compile(r'\]\]&gt;')
    self._depod_re4 = re_compile(r'[\x00-\x08\x0b\x0c\x0e-\x1f]')

    self.trim_ws_re1 = re_compile(r'(?&lt;=\w[\.\!\?])\s+')
    self.trim_ws_re2 = re_compile(r'[\r\n\t]')
    self.trim_ws_re3 = re_compile(r' {2,}')

    self.printFunctions_re1 = re_compile(r'(\S)\s*\n(?:\s*\n)*\s*(\S)')

</t>
<t tx="ekr.20080121105837.572">def doStartNS(self, ns):
    name = ns.name
    if not self.modules.has_key(name):
        self.modules[name] = ns
    self.currentNS = ns
    
</t>
<t tx="ekr.20080121105837.573">def doEndNS(self, **attrInfo):
    if attrInfo.has_key('lineNo'):
        self.currentNS.lineend = attrInfo['lineNo']
    self.currentNS = None
    
</t>
<t tx="ekr.20080121105837.574">def getNS(self, name, **attrInfo):
    if self.modules.has_key(name):
        return self.modules[name]
    else:
        return NamespaceInfo(name, **attrInfo)
    
</t>
<t tx="ekr.20080121105837.575">def doSetArg(self, name):
    self.currentFunction.aArg[name] = []
    self.currentFunction.argList.append(name)
    
</t>
<t tx="ekr.20080121105837.576">def doSetParent(self, **attrInfo):
    ns = attrInfo.get('ns')
    if ns:
        self.currentNS.aParent.append(ns)
        
</t>
<t tx="ekr.20080121105837.577">def doStartFn(self, fn):
    self.currentFunction = fn
    
</t>
<t tx="ekr.20080121105837.578">def doEndFn(self, **attrInfo):
    if attrInfo.has_key('lineNo'):
        self.currentFunction.lineend = attrInfo.get('lineNo')
    self.currentNS.aFunc.append(self.currentFunction)
    self.currentFunction = None
    
</t>
<t tx="ekr.20080121105837.579">def doStartVar(self, **attrInfo):
    self.thisVar = {}
    self.thisVar['name'] = attrInfo.get('name')
    for field in ['line', 'aType', 'scope']:
        if attrInfo.has_key(field):
            self.thisVar[field] = attrInfo[field]

</t>
<t tx="ekr.20080121105837.580">def doEndVar(self, forceGlobal):
    name = self.thisVar['name']
    if (not forceGlobal) and self.currentFunction:
        if self.currentFunction.aArg.has_key(name):
            self.currentFunction.aArg[name].append(self.thisVar)
        else:
            self.set_or_append(self.currentFunction.aVar, name, self.thisVar)
    else:
        self.set_or_append(self.currentNS.aVar, name, self.thisVar)
    del self.thisVar
    
</t>
<t tx="ekr.20080121105837.581">def set_or_append(self, obj, name, val):
    if obj.has_key(name):
        obj[name].append(val)
    else:
        obj[name] = [val]
        
</t>
<t tx="ekr.20080121105837.582">def doSetVar(self, **args):
    if args.has_key('forceGlobal'):
        forceGlobal = args['forceGlobal']
        del args['forceGlobal']
    else:
        forceGlobal = False
    self.doStartVar(**args)
    self.doEndVar(forceGlobal)

</t>
<t tx="ekr.20080121105837.583">def add_imported_module(self, args, **kwargs):
    args2 = copy.copy(args)
    args2.update(kwargs)
    if self.currentFunction:
        self.currentFunction.aImports.append(args2)
    else:
        self.currentNS.aImports.append(args2)

</t>
<t tx="ekr.20080121105837.584">def printDocInfo(self, modInfo, funcInfo, currNode):
    docs = modInfo.hDocs['modules']
    modName = modInfo.name
    # These REs need rebuilding each time, as their values change on each call.
    printDocInfo_re1 = re_compile(r'^=\w+\s+NAME%s%s[\s-]+(.*?)(?:%s|^=)' %
                                  (self.re_bl, modName, self.re_bl), re.M)
        
    try:
        mainDocs = self.modules['main'].hDocs['modules'] or []
    except:
        mainDocs = []
    finalDoc = None
    if not funcInfo:
        # Just dump the module-level docs for now,
        # but favor extracting the synopsis.
        #
        # First, find the first item with a synopsis
        #
        # Otherwise, go with the first one.
        for doc in docs:
            m1 = printDocInfo_re1.search(doc)
            if m1:
                finalDoc = self.trim_ws(m1.group(1), True)
                break
            else:
                m2 = self.printDocInfo_re2.search(doc)
                if m2:
                    finalDoc = self.trim_ws(m2.group(1), True)
                    break
        if finalDoc is None:
            # Look only for a qualified name in the NAME section,
            # but don't look at the DESCRIPTION part until we can
            # select the main class in a module.
            for doc in mainDocs:
                m1 = printDocInfo_re1.search(doc)
                if m1:
                    finalDoc = self.trim_ws(m1.group(1), True)
                    break
    else:
        # First look for the function name in an item
        # Then look in the synopsis.
        # Look for a top-level synopsis first
        funcName = funcInfo.name
        # Allow for datasection-based POD\
        if docs:
            re3_s = (r'''
                            ((?:^=(?:item|head)\w*\s*\r?\n(?:\s*\r?\n)*
                            .*?(?:%s\s*::|%s\s*-&gt;|\$[\w_]+\s*-&gt;|[ \t]+)
                            %s(?![\w\d_]).*\r?\n\s*\r?\n)+)
                            # Now the description
                            # Everything up to the an equal-sign (or end)
                            ((?:\r?\n|.)*?)(?:^=|\Z)''' %
                            (modName, modName, funcName))
            printDocInfo_re3 = re_compile(re3_s, re.X|re.M)
            for doc in docs:
                # Speed up: do index before doing a reg
                if doc.find(funcName) == -1:
                    continue
                # Find a function definition in an item or head thing
                # Very general-purpose, might pick up false-positives
                # The gist:
                # Look for one or more =item/head lines,
                # separate by blank lines,
                # followed by a paragraph description
                m1 = printDocInfo_re3.search(doc)
                if m1:
                    part1 = m1.group(1)
                    finalDoc = self.trim_ws(m1.group(2), True)
                    part2 = [self.trim_ws(s, True) for s in self.printDocInfo_re4.findall(part1)]
                    finalDoc = "\n\n".join(part2) + "\n\n" + finalDoc
                    finalDoc = self._get_first_sentence(finalDoc)
                    break
        if not finalDoc:
            # Look in the __END__ section
            # XXXX VERY SLOW
            re1_s = r'''(?:^(?:item|head)\w*\s*
                       .*?
                       \b%s.*%s)+
                        # Now the description
                        # Everything up to the an equal-sign (or end)
                        ((?:\r?\n|.)*?)(?=$|^=)''' % (funcName, self.re_bl)
            printDocInfo_re1 = re_compile(re1_s, re.M|re.X)
            for doc in mainDocs:
                m1 = printDocInfo_re1.search(doc)
                if m1:
                    before_period = self.printDocInfo_bdot_re.sub('.', m1.group(1))
                    finalDoc = self.trim_ws(self._get_first_sentence(m1.group(1)), True)
                    break
        if not finalDoc:
            # Try to find a synopsis entry
            printDocInfo_re7 = re_compile(r'(.*(?:::|-&gt;|\b)%s\b.*)' % (funcName,))
            for doc in docs + mainDocs:
                m1 = self.printDocInfo_re6.search(doc)
                if m1:
                    synopsis = m1.group(1)
                    m2 = printDocInfo_re7.search(synopsis)
                    if m2:
                        finalDoc = self.trim_ws(self._get_first_sentence(m2.group(1)))
                        break
    if finalDoc:
        self.printDocString(finalDoc, currNode)
        
</t>
<t tx="ekr.20080121105837.585">def _get_first_sentence(self, s1):
    s2 = self._get_first_sentence_re1.sub('.', s1)
    return s2

</t>
<t tx="ekr.20080121105837.586">def printDocString(self, finalDoc, currNode):
    finalDoc2 = self._depod(finalDoc)
    if finalDoc2:
        currNode.set('doc', finalDoc2)
    
</t>
<t tx="ekr.20080121105837.587">def _process_e_pod(self, src):
    val = self.pod_escape_seq.get(src.lower())
    if val: return val
    if re.search(r'^\d+$', src):
        return '&amp;#%s;' % src
    m1 = re.search(r'^0[Xx]([0-9a-fA-F]+)$', src)
    if m1:
        return '&amp;#x%s;' % src
    else:
        # Assume it's an entity name of somekind,
        # and return it as an escaped representation
        # For example, pod E&lt;eacute&gt; will be encoded as
        #                  &amp;amp;eacute;
        # and will appear as
        #                  &amp;eacute;
        # Not great, but it causes no breakage.
        return '&amp;amp;%s' % src
    
</t>
<t tx="ekr.20080121105837.588">def _wrap_process_e_pod(self, m):
    return self._process_e_pod(m.group(1))
    
</t>
<t tx="ekr.20080121105837.589">def _simple_depod(self, doc):
    # Simple inline-markup removal (doesn't handle nested inlines)
    # In Perl, do this:
    # $doc =~ s/E&lt;(.*?)&gt;/_process_e_pod($1)/eg;

    doc = re_sub(self._simple_depod_e_re, self._wrap_process_e_pod, doc)

    # And handle the inline codes-- thse nest with E codes...
    
    doc = self._simple_depod_c_re.sub(r'\1', doc)

    # Above code replaces this:
    # doc = re_sub(r'C&lt;{2,}\s+(.*?)\s+&gt;{2,}', r'\1', doc)
    # doc = XmlAttrEscape(doc) -- No longer needed with ElementTree
        
    # Allow the other sequences to nest, and loop until there
    # aren't any left.
    
    old_doc = doc
    while self._simple_depod_ibcfsxl_re1.search(doc):
        # Most formatting sequences wrap a single clump of code
        doc = self._simple_depod_ibcfsxl_re2.sub(r'\1', doc)
        # Handling of links - this is more complicated.
        doc = self._simple_depod_l_re.sub(r'\1', doc)

        # We need to make sure we pull out when nothing changes.
        #XXX A log message would be useful here.
        if old_doc != doc:
            old_doc = doc
        else:
            break
    # Remove any unrecognized sequences
    doc = self._simple_depod_rest_re.sub(r'\1', doc)

    # And shrink entities back into strings.
    # This is done because we can't convert constructs like
    # E&lt;gt&gt; into "&gt;" directly, because they'll prevent
    # proper handling of outer C&lt;...&gt; in strings like 'C&lt;if (a E&lt;gt&gt; b) { ...&gt;'
    doc = doc.replace("&amp;lt;", "&lt;").replace("&amp;gt;", "&gt;")
    return doc

</t>
<t tx="ekr.20080121105837.590"># Precondition: this text is emitted inside a cdata-section

def _depod(self, doc):
    # Remove embedded man directives
    doc1 = self._depod_re1.sub('', doc)

    # Pull out leading equal signs and the directives
    doc2 = self._depod_re2.sub('', doc1)
    doc3 = self._simple_depod(doc2)
    # Handle strings that could cause the XML parser trouble
    doc4 = self._depod_re3.sub(']&lt;!&gt;]&gt;', doc3)
    doc5 = self._depod_re4.sub('?', doc4)
    return doc5
    
</t>
<t tx="ekr.20080121105837.591">def trim_ws(self, str1, truncate=False):
    # First split into sentences
    str2 = str1.strip()
    if truncate:
        sentences = self.trim_ws_re1.split(str2)
        keep_sentences = []
        sum = 0
        # Keep sentences until we pass max_doclet_high_water_mark chars.
        for s in sentences:
            thisLen = len(s)
            if sum and sum + thisLen &gt; self.max_doclet_high_water_mark:
                break
            s1 = self.trim_ws_re2.sub(' ', s)
            s2 = self.trim_ws_re3.sub(' ', s1)
            keep_sentences.append(s2)
            sum += thisLen
            if sum &gt; self.max_doclet_high_water_mark:
                break
        str2 = "  ".join(keep_sentences)
    
    if str2.find("\n") &gt;= 0 or len(str2) &gt; self.textWrapper.width * 1.1:
        str2 = "\n".join(self.textWrapper.wrap(str2))
    return str2

</t>
<t tx="ekr.20080121105837.592">def printClassParents(self, modInfo, currNode):
    if not hasattr(modInfo, 'aParent'): return
    classrefs = [info[0] for info in modInfo.aParent]
    if len(classrefs) &gt; 0:
        currNode.set('classrefs', " ".join(classrefs))
        
</t>
<t tx="ekr.20080121105837.593">def printImports(self, modInfo, currNode):
    # -- this will be correct only when there are deliberate conflicts
    # better to use object inheritance to choose methods dynamically.
    #imports = getattr(modInfo, 'aImports', [])
    #imports.reverse()
    for _import in getattr(modInfo, 'aImports', []):
        attrs = _import.keys()
        importNode = SubElement(currNode, "import")
        for k in attrs:
            importNode.set(k, str(_import[k]))
        
</t>
<t tx="ekr.20080121105837.594">def printTypeInfo(self, argInfo, currNode):
    types={}
    for type_ in argInfo:
        typeInfo = type_.get('aType')
        if not typeInfo:
            continue
        elif not typeInfo.has_key('assign'):
            continue
        tp = typeInfo['assign']
        if types.has_key(tp):
            continue
        types[tp] = None
        currNode.set('citdl', tp)
        
</t>
<t tx="ekr.20080121105837.595">def printVariables(self, modInfo, currNode):
    if not hasattr(modInfo, 'aVar'): return
    def sorter1(a,b):
        return (cmp(a[0]['line'], b[0]['line']) or
                cmp(a[0]['name'].lower(), b[0]['name'].lower()))
               
    variables = modInfo.aVar.values()
    variables.sort(sorter1)
    try:
        export_info = modInfo.export_info
    except:
        if not hasattr(self, 'default_export_info'):
            self.default_export_info = {'@EXPORT':{},'@EXPORT_OK':{}}
        export_info = self.default_export_info
    for varInfo in variables:
        var_name = varInfo[0]['name']
        varNode = SubElement(currNode, 'variable', line=str(varInfo[0]['line']),
                             name=var_name)
        attr_parts = []
        if export_info['@EXPORT'].has_key(var_name):
            attr_parts.append(self.export_string)
        if export_info['@EXPORT_OK'].has_key(var_name):
            attr_parts.append(self.export_ok_string)
        try:
            if varInfo[0]['scope'] == 'my':
                attr_parts.append(self.local_string)
        except:
            pass
        if attr_parts:
            varNode.set('attributes', ' '.join(attr_parts))
        self.printTypeInfo(varInfo, varNode)

</t>
<t tx="ekr.20080121105837.596">def printFunctions(self, modInfo, currNode):
    for funcInfo in getattr(modInfo, 'aFunc', []):
        sig, docString = self.tryGettingDoc_Sig(modInfo, funcInfo)
        funcName = funcInfo.name
        if not sig:
            sig = '%s(%s)' % (funcName, ', '.join(funcInfo.argList))
        else:
            sig = self._simple_depod(sig.strip())
            sig = self.printFunctions_re1.sub('\\1\n\\2', sig)
        funcNode = SubElement(currNode, 'scope', ilk='function', name=funcName)
        for attr_name in ['line', 'lineend']:
            ln = getattr(funcInfo, attr_name, None)
            if ln:
                funcNode.set(attr_name, str(ln))

        attr_parts = []
        if funcInfo.isConstructor:
            attr_parts.append("__ctor__")
        export_info = modInfo.export_info
        for tuple in [['@EXPORT', self.export_string],
                      ['@EXPORT_OK', self.export_ok_string]]:
            if export_info[tuple[0]].has_key(funcName):
                attr_parts.append(tuple[1])
        if attr_parts:
            funcNode.set('attributes', ' '.join(attr_parts))

        funcNode.set('signature', sig)
        
        for argName in funcInfo.argList:
            argInfo = funcInfo.aArg.get(argName)
            if argInfo:
                argNode = SubElement(funcNode, 'variable', ilk='argument', name=argInfo[0]['name'])
                self.printTypeInfo(argInfo, argNode)
        if self.provide_full_docs:
            if not docString:
                self.printDocInfo(modInfo, funcInfo, funcNode)
            else:
                self.printDocString(docString, funcNode)
        self.printImports(funcInfo, funcNode)
        self.printVariables(funcInfo, funcNode)
        
</t>
<t tx="ekr.20080121105837.597">def tryGettingDoc_Sig(self, modInfo, funcInfo):
    if not self.provide_full_docs:
        return (None, None)
    modName = modInfo.name
    funcName = funcInfo.name
    re1_s = r"""((?:^=(?:item|head)\w*\s*
                   .*?(?:%s\s*\:\:|%s\s*-&gt;|\$[\w_]+\s*-&gt;|[ \t])
                   %s(?:[^\w_]|$).*%s)+)
                  # Now the description
                  # Everything up to the an equal-sign (or end)
                  ((?:\r?\n|.)*?)(?:^=|\Z)""" % \
                     (modName, modName, funcName, self.re_bl)
    re1 = re_compile(re1_s, re.X|re.M)
    re2a = re_compile(funcName + r'\s+\w')
    re2b = re_compile(r'\s\w+\s+' + funcName + r'\b')
    re4_s = (r'''^=(?:item|head)\s*\*?\s*\r?\n
                    (?:^\s*\r?\n)*
                    ^\s*C&lt;+(.*%s.*)&gt;+\s*\r?\n
                    (?:^\s*\r?\n)*
                    # Now the description
                    # Everything up to the an equal-sign (or end)
                    ((?:.*\r?\n(?!=))+)''' % (funcName,))
    re4 = re_compile(re4_s, re.M|re.X)
    for doc in modInfo.hDocs['modules'] + self.modules['main'].hDocs['modules']:
        if doc.find(funcName) == -1:
            continue
        m1 = re1.search(doc)
        if m1:
            part1 = m1.group(1)
            # If the function name is followed by text, it's probably
            # an English description.  We need to check for a whole word
            # before the name to avoid the pod directive
            if (re2a.search(part1) or
                re2b.search(part1)):
                continue
            finalDoc = self.trim_ws(self._get_first_sentence(m1.group(2)), True)
            part2 = [s.strip() for s in self.tryGettingDoc_Sig_re3.findall(part1)]
            finalSig = (part2 and "\n\n".join(part2)) or None
            return (finalSig, finalDoc)
        else:
            m1 = re4.search(doc)
            if m1:
                finalSig = m1.group(1)
                finalDoc = self.trim_ws(self._get_first_sentence(m1.group(2)), True)
                return (finalSig, finalDoc)
    return (None, None)

</t>
<t tx="ekr.20080121105837.598">class NamespaceInfo:
    @others
</t>
<t tx="ekr.20080121105837.599">def __init__(self, name, **attrInfo):
    self.name = name
    self.line = attrInfo.get('lineNo') or 0
    self.aFunc = []
    self.aVar = {}
    self.aParent = []
    self.hDocs = {'modules':[], # hash of modules =&gt; array of docs,
                  'subs':{}     # subs =&gt; subname =&gt; array of docs
    }
    self.aImports = []
    self._isProbablyClass = False
    self.export_info = {'@EXPORT':{},
                        '@EXPORT_OK':{}}

</t>
<t tx="ekr.20080121105837.600">def isProbablyClass(self, val):
    self._isProbablyClass = val

</t>
<t tx="ekr.20080121105837.601">class FunctionInfo:
    @others
</t>
<t tx="ekr.20080121105837.602">def __init__(self, name, **attrInfo):
    self.name = name
    self.aArg = {}
    self.aVar = {}
    self.resultType = []
    self.argList = []
    self.aImports = []
    self.isConstructor = attrInfo.get('isConstructor', False)
    if attrInfo.has_key('lineNo'):
        self.line = attrInfo.get('lineNo')

</t>
<t tx="ekr.20080121105837.603">if not os.path.altsep or os.path.altsep == os.path.sep:
    def pathSplitter(s):
        return s.split(os.path.sep)
else:
    def pathSplitter(s):
        return re.split(re_compile('[' + re.escape(os.path.sep)
                                   + re.escape(os.path.altsep) + ']'), s)

class Parser:
    @others
    # end start_process_sub_definition
        
</t>
<t tx="ekr.20080121105837.604">def __init__(self, tokenizer, lang="Perl", provide_full_docs=True):
    self.tokenizer = tokenizer
    self._provide_full_docs = provide_full_docs
    self.block_stack = []
    self.bracket_matchers = {"[":"]", "{":"}", "(":")"}
    self.classifier = _get_classifier(lang)
    
    # Use simple knowledge of Perl's syntax
    # to skip quickly through code to skip.
    self.opHash = {"(" : [0, 1],
            ")" : [0, -1],
            "{" : [1, 1],
            "}" : [1, -1],
            "[" : [2, 1],
            "]" : [2, -1]}

    self.pragmaNames = {'attributes' : None,
                        'attrs' : None,
                        'autouse' : None,
                        'bigint' : None,
                        'bignum' : None,
                        'bigrat' : None,
                        'blib' : None,
                        'bytes' : None,
                        'charnames' : None,
                        'constant' : None,
                        'diagnostics' : None,
                        'encoding' : None,
                        'fields' : None,
                        'filetest' : None,
                        'if' : None,
                        'integer' : None,
                        'less' : None,
                        'lib' : None,
                        'locale' : None,
                        'open' : None,
                        'ops' : None,
                        'overload' : None,
                        're' : None,
                        'sigtrap' : None,
                        'sort' : None,
                        'strict' : None,
                        'subs' : None,
                        'threads' : None,
                        'utf8' : None,
                        'vmsish' : None,
                        'warnings' : None,
                        }
    self.find_open_indexer_re = re_compile(r'[\[{]')
    self.provide_full_docs = provide_full_docs

</t>
<t tx="ekr.20080121105837.605">def _is_stmt_end_op(self, tok):
    tval = tok.text
    if self.classifier.is_keyword(tok, 'or'):
        return True
    elif self.classifier.is_any_operator(tok):
        return tval in (';', '||')
    return False

</t>
<t tx="ekr.20080121105837.606">def _is_string(self, tok):
    return tok.style in self.tokenizer.string_types
    
    
</t>
<t tx="ekr.20080121105837.607">def printHeader(self, mtime):
    moduleName = self.moduleName
    root = Element("codeintel", version="2.0")
    fileNode = Element("file", lang="Perl",
                       path=moduleName)
    if mtime:
        fileNode.set('mtime', str(mtime))
    root.append(fileNode)
    return (root, fileNode)
    
</t>
<t tx="ekr.20080121105837.608">def printContents(self, moduleContentsName, currNode):
    name = os.path.splitext(os.path.basename(self.moduleName))[0]
    moduleNode = Element('scope', ilk='blob', lang="Perl", name=name)
    currNode.append(moduleNode)
    
    innerModules = self.moduleInfo.modules
    mainInfo = innerModules.get('main', None)
    if mainInfo:
        if self.provide_full_docs:
            self.moduleInfo.printDocInfo(mainInfo, None, moduleNode)
        self.moduleInfo.printImports(mainInfo, moduleNode)
        self.moduleInfo.printVariables(mainInfo, moduleNode)
    
    def sorter1(a,b):
        amod = innerModules.get(a)
        bmod = innerModules.get(b)
        aline = getattr(amod, 'line', None)
        if aline:
            bline = getattr(bmod, 'line', None)
            if aline and bline: return cmp(aline, bline)
        return cmp(getattr(amod, 'name', ""), getattr(bmod, 'name', ""))
    
    packages = [x for x in self.moduleInfo.modules.keys() if x != 'main']
    packages.sort(sorter1)
    for k in packages:
        if k == 'main':break
        modInfo = innerModules[k]
        classNode = Element('scope', ilk='class', name=modInfo.name, line=str(modInfo.line))
        moduleNode.append(classNode)
        if hasattr(modInfo, 'lineend'):
            classNode.set('lineend', str(modInfo.lineend))
        self.moduleInfo.printClassParents(modInfo, classNode)
        if self.provide_full_docs:
            self.moduleInfo.printDocInfo(modInfo, None, classNode)
        self.moduleInfo.printImports(modInfo, classNode)
        self.moduleInfo.printVariables(modInfo, classNode)
        self.moduleInfo.printFunctions(modInfo, classNode)

    # And do main's functions after its classes
    if mainInfo:
        self.moduleInfo.printFunctions(mainInfo, moduleNode)

</t>
<t tx="ekr.20080121105837.609">def printTrailer(self, root):
    pass

</t>
<t tx="ekr.20080121105837.610">def at_end_expression(self, tok):
    if not self.classifier.is_any_operator(tok):
        return False
    return tok.text in (';', ',', '}')

    
</t>
<t tx="ekr.20080121105837.611">def collect_multiple_args(self, origLineNo, context, var_scope):
    nameList = []
    while True:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_variable(tok):
            nameList.append((tok.text, tok.start_line))
        else:
            break
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_any_operator(tok):
            tval = tok.text
            if tval == ")": break
            elif tval != ",": break
    if not self.classifier.is_operator(tok, ")"):
        return
    tok = self.tokenizer.get_next_token()
    isArg = False
    if self.classifier.is_operator(tok, "="):
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_variable_array(tok, self.classifier.is_array_cb) and tok.text == "@_":
            tok = self.tokenizer.get_next_token()
            isArg = self._is_stmt_end_op(tok)
        else:
            tok = self.tokenizer.put_back(tok)
    for varInfo in nameList:
        if isArg: self.moduleInfo.doSetArg(varInfo[0])
        self.moduleInfo.doSetVar(name=varInfo[0], line=varInfo[1],
                                 scope=var_scope)
</t>
<t tx="ekr.20080121105837.612"># end collect_multiple_args

# Expect = shift ;
def collect_single_arg(self, varName, origLineNo, context, var_scope):
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, '='):
        isArg = False
    else:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_keyword(tok, 'shift') or tok.text == '@_':
            tok = self.tokenizer.get_next_token()
            isArg = self._is_stmt_end_op(tok)
            self.tokenizer.put_back(tok)
        else:
            self.tokenizer.put_back(tok)
            self.finish_var_assignment(varName, origLineNo, False,
                                       scope=var_scope, context=context)
            return
    if isArg:
        self.moduleInfo.doSetArg(varName)
    self.moduleInfo.doSetVar(name=varName, line=origLineNo,
                             scope=var_scope)
    
</t>
<t tx="ekr.20080121105837.613">def de_quote_string(self, tok):
    tval = tok.text
    patterns = self.classifier.get_quote_patterns(tok, self.classifier.quote_patterns_cb)
    for p in patterns:
        m = p.match(tval)
        if m:
            return m.group(1)
    return tval

</t>
<t tx="ekr.20080121105837.614"># Called from both assignments and
# my &lt;var&gt; = ... statements, where the RHS isn't 'shift' or '@_';
def finish_var_assignment(self, identifier, origLineNo, forceGlobal, **inherited_args):
    tok = self.tokenizer.get_next_token()

    # Narrow down to these possibilities:

    # 1. We're assigning a method call to a scalar

    # $lhs = $rhs-&gt;method()-&gt;{property}-&gt;...
    #
    # Reduces to
    # $lhs = $rhs
    
    # 2. We're assigning a string/int -- i.e., it's likely
    # to be a non-object value:
    
    # $lhs = "acb" eq $q
    # $lhs = $r
    # $lhs = 42
    
    # 3. We're assigning a constructor
    # Now we can take two forms:
    # &lt;constructor&gt; &lt;subpath&gt;
    # &lt;subpath&gt; -&gt; &lt;constructor&gt;
    # Note that if we don't know anything about the module, we can't say
    # anything intelligent about Package::Midd::Function -- we don't know
    # if this returns a constructor or not, although it likely doesn't.
    
    rhs_StarterVal = None
    args = { 'name':identifier, 'line':origLineNo,
            'forceGlobal':forceGlobal }
    if inherited_args:
        args.update(inherited_args)
    ttype = tok.style
    if self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
        rhs_StarterVal = tok.text
        tok = self.tokenizer.get_next_token()
        # Check and skip indexers
        if self.classifier.is_index_op(tok, self.find_open_indexer_re):
            self.skip_to_close_match()
            tok = self.tokenizer.get_next_token()
            
        # Now get the list of accessors that take us to the
        # semi-colon or close-brace.  Hop over arg lists.
        # Left looking at -&gt;, ;, }, or leave
        
        accessors = []
        while self.classifier.is_operator(tok, "-&gt;") or self.classifier.is_index_op(tok, self.find_open_indexer_re):
            if tok.text == "-&gt;":
                tok = self.tokenizer.get_next_token()
            if self.classifier.is_index_op(tok, self.find_open_indexer_re):
                propertyName = self._get_property_token()
                if not propertyName:
                    break
                accessors.append(propertyName)
                tok = self.tokenizer.get_next_token()
            elif not self.classifier.is_identifier_or_keyword(tok):
                break
            else:
                fqName = self.get_rest_of_subpath(tok.text, 1)
                accessors.append(fqName)
                tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "("):
                self.skip_to_close_paren()
                tok = self.tokenizer.get_next_token()
        # end while
        
        if accessors or self.at_end_expression(tok):
            if self.at_end_expression(tok):
                self.tokenizer.put_back(tok)
            fqname = (accessors and rhs_StarterVal.join(accessors)) or rhs_StarterVal
        self.moduleInfo.doSetVar(**args)
        
    elif self.classifier.is_number(tok):
        #XXX: Any expressions starting with an integer that
        # don't yield an int value?
        tok = self.tokenizer.get_next_token()
        if self.at_end_expression(tok):
            self.tokenizer.put_back(tok)
        self.moduleInfo.doSetVar(**args)
    elif self._is_string(tok):
        tok = self.tokenizer.get_next_token()
        if self.at_end_expression(tok):
            self.tokenizer.put_back(tok)
        self.moduleInfo.doSetVar(**args)
    elif self.classifier.is_identifier(tok):
        rhs_StarterVal = tok.text
        tok = self.tokenizer.get_next_token()
        updateVarInfo = None
        if self.classifier.is_operator(tok, "::"):
            # Package-&gt;method  or Package::method notation
            rhs_StarterVal = self.get_rest_of_subpath(rhs_StarterVal + '::', 0)
            tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "-&gt;"):
            # a-&gt;b is always good
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_identifier_or_keyword(tok) and tok.text == "new":
                # 80/20 rule: assume a new on a class gives an instance
                args['aType'] = {'assign' : rhs_StarterVal }
        elif self.classifier.is_identifier_or_keyword(tok):
            if rhs_StarterVal.find("::") &gt; -1:
                # obj A::B is always good
                pass
            elif rhs_StarterVal == 'new':
                # 80/20 rule
                package_name = tok.text
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, "::"):
                    # new Package notation
                    package_name = self.get_rest_of_subpath(package_name + '::', 0)
                    tok = self.tokenizer.get_next_token()
                args['aType'] = {'assign' : package_name }
        self.moduleInfo.doSetVar(**args)
    elif self.classifier.is_keyword(tok, 'bless') and self.moduleInfo.currentFunction:
        self.moduleInfo.currentFunction.isConstructor = True
        self.moduleInfo.doSetVar(**args)
    else:
        self.moduleInfo.doSetVar(**args)
        if self.classifier.is_index_op(tok, self.find_open_indexer_re):
            self.tokenizer.put_back(tok)
</t>
<t tx="ekr.20080121105837.615"># end finish_var_assignment

def get_exported_names(self, export_keyword):
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, '='):
        self.tokenizer.put_back(tok)
        return
    names = self.get_list_of_strings()
    for obj in names:
        name = obj[0]
        if name[0] == '&amp;': name = name[1:]
        self.moduleInfo.currentNS.export_info[export_keyword][name] = None
</t>
<t tx="ekr.20080121105837.616"># end export_keyword

def get_for_vars(self):
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_keyword(tok, 'my'):
        tlineNo = tok.start_line
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_variable(tok):
            # Don't do any more processing, as we're probably looking
            # at an open-paren.
            self.moduleInfo.doSetVar(name=tok.text, line=tlineNo, scope='my')

</t>
<t tx="ekr.20080121105837.617">def get_list_of_var_names(self):
    resArray = []
    while 1:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_variable(tok):
            resArray.append([tok.text, tok.start_line])
        else:
            break
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, ","):
            break
    return resArray

</t>
<t tx="ekr.20080121105837.618">def get_list_of_strings(self, tok=None):
    if tok is None:
        tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, "("):
        resArray = []
        while 1:
            # Simple -- either a string or a qw here as well
            tok = self.tokenizer.get_next_token()
            if self._is_string(tok):
                resArray += self.get_string_array(tok)
            else:
                break
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_any_operator(tok):
                if tok.text == ")":
                    break
                elif tok.text == ",":
                    continue
                break
    elif self._is_string(tok):
        resArray = self.get_string_array(tok)
    else:
        return []
    return resArray
</t>
<t tx="ekr.20080121105837.619"># end get_list_of_strings

def get_our_vars(self, context, var_scope):
    tok = self.tokenizer.get_next_token()
    varNames = []
    if self.classifier.is_operator(tok, "("):
        varNames = self.get_list_of_var_names()
    elif self.classifier.is_variable(tok):
        tval = tok.text.strip()
        if tval == '@ISA':
            self.get_parent_namespaces(True)
        else:
            lineNo = tok.start_line
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "="):
                self.finish_var_assignment(tval, lineNo, 0, scope=var_scope, context=context)
                return
            varNames = [(tval, lineNo)]
    for varInfo in varNames:
        self.moduleInfo.doSetVar(name=varInfo[0], line=varInfo[1], scope=var_scope)

</t>
<t tx="ekr.20080121105837.620"># Look for = stringList...
def get_parent_namespaces(self, doingIsa):
    tok = self.tokenizer.get_next_token()
    if doingIsa:
        if not self.classifier.is_operator(tok, '='):
            self.tokenizer.put_back(tok)
            return
    parentNamespaces = self.get_list_of_strings()
    for parentInfo in parentNamespaces:
        self.moduleInfo.currentNS.aParent.append(parentInfo)
        
    # Undocumented attribute, but it means one of the methods
    # should either invoke bless, SUPER:: ..., or a parent
    # constructor.
    self.moduleInfo.currentNS.isProbablyClass(True)
</t>
<t tx="ekr.20080121105837.621"># end get_parent_namespaces

# Precondition: saw ident, "-&gt;", '{'
# Still looking at the "{"
def _get_property_token(self):
    tok = self.tokenizer.get_next_token()
    if self._is_string(tok):
        finalVal = self.de_quote_string(tok)
    elif not (self.classifier.is_identifier_or_keyword(tok) or
              self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb)):
        return ""
    else:
        finalVal = tok.text
    tok = self.tokenizer.get_next_token()
    
    if not self.classifier.is_index_op(tok, re_compile(r'\}')):
        # Swallow the close-brace for the property.
        finalVal = "???";
        # Consume everything until we find the close-brace
        while True:
            tok = self.tokenizer.get_next_token()
            if tok.style == SCE_PL_UNUSED:
                break
            elif self.classifier.is_index_op(tok, re_compile(r'[\}\]]')):
                break
    return finalVal

</t>
<t tx="ekr.20080121105837.622">def get_rest_of_subpath(self, retval, expectingDblColon):
    if expectingDblColon:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        tval = tok.text
        if not self.classifier.is_operator(tok, "::"):
            self.tokenizer.put_back(tok)
            return retval
        else:
            retval += "::"
        
    while 1:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if not self.classifier.is_identifier(tok):
            if ttype != self.classifier.style_word or len(retval) == 0:
                break
        retval += tok.text
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_operator(tok, "::"):
            break
        retval += "::"
        
    self.tokenizer.put_back(tok)
    return retval
</t>
<t tx="ekr.20080121105837.623"># end get_rest_of_subpath

def get_string_array(self, tok):
    if self.classifier.is_string_qw(tok, self.classifier.is_string_qw_cb):
        res = []
        qw_re = re_compile(r'\Aqw\s*.(.*)\s*\S\s*\Z', re.DOTALL)
        match_res = qw_re.match(tok.text)
        if match_res:
            wordsPart = match_res.group(1)
            # Find first line of token
            finalLineNo = tok.start_line
            for line in wordsPart.split('\n'):
                for var in re.split(r'\s', line):
                    if re_compile(r'\s*$').match(var):
                        continue
                    res.append((var, finalLineNo))
                finalLineNo += 1
        return res
    else:
        tval = self.de_quote_string(tok)
        return [(tval, tok.start_line)]
    
</t>
<t tx="ekr.20080121105837.624">def get_used_vars(self, scope):
    tok = self.tokenizer.get_next_token()
    if self._is_string(tok):
        varNames = self.get_list_of_strings(tok)
    elif self.classifier.is_operator(tok, "("):
        varNames = self.get_list_of_strings()
    else:
        varNames = self.get_list_of_var_names()
    for varInfo in varNames:
        self.moduleInfo.doSetVar(name=varInfo[0],
                                 line=varInfo[1],
                                 scope=scope)

</t>
<t tx="ekr.20080121105837.625">def look_for_object_var_assignment(self, tok, isInnerSub):
    identifier = tok.text
    if re_compile(r'^\$[^_\w]').match(identifier) or identifier == '$_':
        # Ignore special variables, and $#$... array ref final-item index
        return
    origLineNo = tok.start_line
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_index_op(tok):
        self.tokenizer.put_back(tok)
        return
    elif tok.text != '=':
        self.tokenizer.put_back(tok)
        return
    # Is it an implicit global?
    checkGlobalScope = True
    forceGlobal = False
    #XXX Update, check this
    if self.moduleInfo.currentFunction:
        # Is it defined in the current function?
        if (self.moduleInfo.currentFunction.aVar.has_key(identifier) or
            self.moduleInfo.currentFunction.aArg.has_key(identifier)):
            checkGlobalScope = False
            # Defined in current function.
        elif isInnerSub:
            checkGlobalScope = False
            # Assume that it's defined in the containing sub
    if checkGlobalScope:
        if not self.moduleInfo.currentNS.aVar.has_key(identifier):
            self.moduleInfo.currentNS.aVar[identifier] = [{'name':identifier,
                                                           'line':origLineNo}]
        forceGlobal = True
    self.finish_var_assignment(identifier, origLineNo, forceGlobal)
</t>
<t tx="ekr.20080121105837.626"># end look_for_object_var_assignment

# Handle arrays, hashes, typeglobs, but don't bother figuring out a type.
# No 'my', 'our', or 'use vars' given
def look_for_var_assignment(self, tok1):
    # First make sure this var hasn't already been defined
    # Is it an implicit global?
    var_name = tok1.text
    if len(var_name) &lt; 2 or var_name[1] == '$':
        return
    if self.moduleInfo.currentFunction:
        # Is it defined in the current function?
        if (self.moduleInfo.currentFunction.aVar.has_key(var_name) or
            self.moduleInfo.currentFunction.aArg.has_key(var_name)):
            return
        scope = 'my'
    else:
        scope = 'our'
    if self.moduleInfo.currentNS.aVar.has_key(var_name):
        return
    tok2 = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok2, "="):
        varInfo = (tok1.text, tok1.start_line)
        self.moduleInfo.doSetVar(name=var_name, line=tok1.start_line,
                                 scope=scope)
    else:
        self.tokenizer.put_back(tok2)

</t>
<t tx="ekr.20080121105837.627">def process_import(self, fqModule, origLineNo, import_vars=None):
    tok = self.tokenizer.get_next_token()
    if self._is_string(tok) or self.classifier.is_operator(tok, "("):
        varNames = self.get_list_of_strings(tok)
        imports_nothing = not varNames
    else:
        self.tokenizer.put_back(tok)
        varNames = []
        imports_nothing = None
    args = {'module':fqModule, 'line':origLineNo}
    if not varNames:
        if import_vars and not imports_nothing:
            args['symbol'] = '*'
        self.moduleInfo.add_imported_module(args)
    elif [x[0] for x in varNames if x[0][0] == ":"]:
        # If there's a tag, assume we're just bringing in all exported names.
        if import_vars:
            args['symbol'] = '**'
        self.moduleInfo.add_imported_module(args)
    else:
        for varName in varNames:
            self.moduleInfo.add_imported_module(args, line=varName[1], symbol=varName[0])
</t>
<t tx="ekr.20080121105837.628"># end process_import

def process_module(self, moduleName, mtime, _showWarnings=False):
    showWarnings=_showWarnings
    self.moduleName = moduleName
    self.parse()
    xmlTree = self.get_CIX(mtime)
    return xmlTree

</t>
<t tx="ekr.20080121105837.629">def get_CIX(self, mtime=None):
    (root, currNode) = self.printHeader(mtime)
    self.printContents(self.moduleName, currNode)
    self.printTrailer(root)
    return root

</t>
<t tx="ekr.20080121105837.630">def produce_CIX(self, actual_mtime=None):
    return self.get_CIX(actual_mtime)

</t>
<t tx="ekr.20080121105837.631">def produce_CIX_NoHeader(self, cix_node):
    """Get the CIX for the current contents, and attach it to the cix_node.
    """
    self.printContents(self.moduleName, cix_node)

</t>
<t tx="ekr.20080121105837.632"># Codeintel interface to the parser
def parse(self):
    origLineNo = self.tokenizer.curr_line_no()
    self.moduleInfo = ModuleInfo(self.provide_full_docs)
    self.moduleInfo.doStartNS(NamespaceInfo(name='main', lineNo=origLineNo))
    self.process_package_inner_contents(True)
    if self.provide_full_docs:
        # Check for a trailing pod doc
        podName = re_sub(r'.p[ml]$', '.pod', self.moduleName)
        if not os.path.isfile(podName) and os.path.isfile(os.path.join('..', 'test', podName)):
            podName = os.path.join('..', 'test', podName)
        if os.path.isfile(podName):
            try:
                f = open(podName)
                pod_str = f.read()
                f.close()
                self.moduleInfo.currentNS.hDocs['modules'].append(pod_str)
            except:
                pass
    self.moduleInfo.doEndNS(lineNo = self.tokenizer.curr_line_no())
    
    

</t>
<t tx="ekr.20080121105837.633">def process_package_inner_contents(self, doingTopLevel):
    currPackage = self.moduleInfo.currentNS
    popNS = 0
    curr_pkg_line_no = self.tokenizer.curr_line_no()
    while 1:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if ttype == shared_lexer.EOF_STYLE:
            return
        tval = tok.text
        if ttype == self.classifier.style_word:
            if tval == 'package':
                packageName = self.get_rest_of_subpath("", 0)
                if packageName:
                    self.moduleInfo.doEndNS(lineNo=curr_pkg_line_no)
                    ns = self.moduleInfo.getNS(packageName,
                                               lineNo=self.tokenizer.curr_line_no())
                    self.moduleInfo.doStartNS(ns)
                    popNS = 1
            elif tval == 'sub':
                self.start_process_sub_definition(False); # Is outer sub
            elif tval in ['BEGIN', 'END', 'AUTOLOAD']:
                self.skip_anon_sub_contents()
            elif tval in ['our', 'my']:
                self.get_our_vars('global', tval)
                # Small warning: vars defined at this lexical level belong to
                # the containing package, but are visible without
                # qualification in other packages in the same file.
            elif tval in ['for', 'foreach']:
                self.get_for_vars()
            elif tval == 'use':
                self.process_use(0)
            elif tval == 'require':
                origLineNo = tok.start_line
                tok = self.tokenizer.get_next_token()
                ttype = tok.style
                tval = tok.text
                if (self.classifier.is_identifier(tok) or
                    self.classifier.is_variable_scalar(tok,
                                                       self.classifier.is_scalar_cb)):
                    # codeintel allows variables
                    fqModule = self.get_rest_of_subpath(tval, 1)
                    self.process_import(fqModule, origLineNo)
                    
                elif self.classifier.is_string(tok) and not self.classifier.is_string_qw(tok, self.classifier.is_string_qw_cb):
                    # Rewritten to work with UDL languages as well as native perl
                    self.process_import(tval, origLineNo)
            else:
                self.skip_to_end_of_stmt()
        elif self.classifier.is_variable_array(tok, self.classifier.is_array_cb):
            if tval == '@ISA':
                self.get_parent_namespaces(True)
            elif tval in ('@EXPORT', '@EXPORT_OK'):
                self.get_exported_names(tval)
            else:
                self.look_for_var_assignment(tok)
        elif self.classifier.is_any_operator(tok):
            if tval == '{':
                self.process_package_inner_contents(False)
            elif tval == '}':
                if not doingTopLevel:
                    if popNS:
                        self.moduleInfo.doEndNS(lineNo=curr_pkg_line_no)
                        self.moduleInfo.doStartNS(currPackage)
                    break
        elif self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
            self.look_for_object_var_assignment(tok, False)
        elif self.classifier.is_variable(tok):
            if tval == '%EXPORT_TAGS':
                pass
            else:
                self.look_for_var_assignment(tok)
        elif self.classifier.is_comment_structured(tok, self.classifier.is_pod_cb):
            self.moduleInfo.currentNS.hDocs['modules'].append(tval)
        
        curr_pkg_line_no = self.tokenizer.curr_line_no()
</t>
<t tx="ekr.20080121105837.634"># end process_package_inner_contents

def process_sub_contents(self, isInnerSub):
    # Get to the open brace or semicolon (outside the parens)
    braceCount = 0
    parenCount = 0
    while True:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if ttype == SCE_PL_UNUSED:
            return
        # Expect a paren for args, the open-brace, or a semi-colon
        tval = tok.text
        if parenCount &gt; 0:
            if self.classifier.is_operator(tok, ")"):
                parenCount -= 1
        elif self.classifier.is_any_operator(tok):
            if tval  == "(":
                parenCount += 1
            elif tval == "{":
                braceCount = 1
                break
            elif tval == ';':
                return

    # So now look for these different things:
    # '}' taking us to brace count of 0
    # my, name, =, shift;
    # my (..., ..., ...) = @_;
    # bless =&gt; mark this as a constructor
    # return =&gt; try to figure out what we're looking at

    while True:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if ttype == SCE_PL_UNUSED:
            break
        tval = tok.text
        if self.classifier.is_index_op(tok):
            if tval == "{":
                braceCount += 1
            elif tval == "}":
                braceCount -= 1
                if braceCount &lt;= 0:
                    break
            elif tval == ':':
                # Stay here -- it indicates a label
                pass
            else:
                self.tokenizer.put_back(tok)
                self.skip_to_end_of_stmt()
        elif ttype == self.classifier.style_word:
            tlineNo = tok.start_line
            if tval == 'my':
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, '('):
                    self.collect_multiple_args(tlineNo, 'local', 'my')
                elif self.classifier.is_variable(tok):
                    self.collect_single_arg(tok.text, tlineNo, 'local', 'my')
                    if self.classifier.is_operator(tok, '{'):
                        braceCount += 1
                else:
                    self.get_our_vars('local', 'my')
            elif tval in ('for', 'foreach'):
                self.get_for_vars()
                if self.classifier.is_operator(tok, '{'):
                    braceCount += 1
            elif tval == 'bless':
                self.moduleInfo.currentFunction.isConstructor = True
            elif tval == 'return':
                # If we return something of type (&lt;(module)name ('::' name)*&gt; "-&gt;" new)
                # Return an instance of type (module)
                # Either it returned an identifier, or it put the token back
                tok = self.tokenizer.get_next_token()
                ttype = tok.style
                if self.classifier.is_identifier(tok):
                    subclass = self.get_rest_of_subpath(tok.text, 1)
                    tok = self.tokenizer.get_next_token()
                    if tok.text != '-&gt;':
                        self.tokenizer.put_back(tok)
                    else:
                        tok = self.tokenizer.get_next_token()
                        if tok.text == 'new':
                            if self.moduleInfo.currentFunction:
                                self.moduleInfo.currentFunction.resultType.append(subclass)
                        else:
                            self.tokenizer.put_back(tok)
                else:
                    self.tokenizer.put_back(tok)
            elif tval == 'require':
                tok = self.tokenizer.get_next_token()
                ttype = tok.style
                if self.classifier.is_identifier(tok):
                    origLineNo = tok.start_line
                    fqModule = self.get_rest_of_subpath(tok.text, 1)
                    self.process_import(fqModule, origLineNo)
            elif tval == 'use':
                self.process_use(1)
            elif tval == 'sub':
                # Nested subs in Perl aren't really nested --
                # They're kind of like named closures -- accessible
                # by name from an outer context, but they can bind
                # the local state of the sub when defined.
                # But we can call them anyway, so let's process them

                self.start_process_sub_definition(True) # Is inner
            else:
                self.skip_to_end_of_stmt()
        elif self.classifier.is_variable_scalar(tok, self.classifier.is_scalar_cb):
            self.look_for_object_var_assignment(tok, isInnerSub)
        elif self.classifier.is_variable(tok):
            if tval == '%EXPORT_TAGS':
                pass
            else:
                self.look_for_var_assignment(tok)
        elif self.classifier.is_comment_structured(tok, self.classifier.is_pod_cb):
            if self.moduleInfo.currentFunction:
                name = getattr(self.moduleInfo.currentFunction, 'name', None)
                if name:
                    # hdoc_subs = self.moduleInfo.currentNS.hDocs['subs']
                    self.moduleInfo.set_or_append(self.moduleInfo.currentNS.hDocs['subs'], name, tval)
    # end while
</t>
<t tx="ekr.20080121105837.635"># end process_sub_contents

def process_use(self, local):
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_identifier_or_keyword(tok):
        origLineNo = tok.start_line
        #@@@ RE
        if re_compile('^[a-z]+$').match(tok.text):
            if tok.text == 'vars':
                self.get_used_vars(local and 'local' or 'global')
                return
            elif tok.text == 'base':
                if not local:
                    self.get_parent_namespaces(False)
                return
            elif self.pragmaNames.has_key(tok.text):
                firstMod = tok.text
                tok = self.tokenizer.get_next_token()
                if not self.classifier.is_operator(tok, "::"):
                    self.tokenizer.put_back(tok)
                    return
                self.tokenizer.put_back(tok)
                tval = firstMod
            else:
                tval = tok.text
        else:
            tval = tok.text
        fqModule = self.get_rest_of_subpath(tval, 1)
        self.process_import(fqModule, origLineNo, import_vars=1)
</t>
<t tx="ekr.20080121105837.636"># end process_use

def skip_anon_sub_contents(self):
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, "{"):
        self.process_package_inner_contents(False)
</t>
<t tx="ekr.20080121105837.637"># end skip_anon_sub_contents

def skip_to_close_match(self):
    nestedCount = 1
    while 1:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if ttype == SCE_PL_UNUSED:
            return
        elif self.classifier.is_index_op(tok):
            tval = tok.text
            if self.opHash.has_key(tval):
                if self.opHash[tval][1] == 1:
                    nestedCount += 1
                else:
                    nestedCount -= 1
                    if nestedCount &lt;= 0:
                        break
</t>
<t tx="ekr.20080121105837.638"># end get_rest_of_subpath

def skip_to_close_paren(self):
    tok = self.tokenizer.get_next_token()
    nestedCount = 1
    while 1:
        ttype = tok.style
        if ttype == SCE_PL_UNUSED:
            return
        elif self.classifier.is_any_operator(tok):
            tval = tok.text
            if tval == "(":
                nestedCount += 1
                tok = self.tokenizer.get_next_token()
            elif tval == ")":
                nestedCount -= 1
                if nestedCount &lt;= 0:
                    break
            else:
                tok = self.tokenizer.get_next_token()
        else:
            tok = self.tokenizer.get_next_token()
</t>
<t tx="ekr.20080121105837.639">#end skip_to_close_paren

def skip_to_end_of_stmt(self):
    nestedCount = 0
    while 1:
        tok = self.tokenizer.get_next_token()
        ttype = tok.style
        if ttype == SCE_PL_UNUSED:
            break
        if self.classifier.is_index_op(tok):
            tval = tok.text
            if self.opHash.has_key(tval):
                if tval == "{":
                    if nestedCount == 0:
                        self.tokenizer.put_back(tok)
                        # At an open-brace, keep going.
                        break
                vals = self.opHash[tval]
                if vals[1] == 1:
                    nestedCount += 1
                else:
                    nestedCount -= 1
                    if nestedCount &lt;= 0:
                        nestedCount = 0
                        if tval == "}":
                            self.tokenizer.put_back(tok)
                            break
            elif tval == ";":
                 # Don't worry about commas, since they don't separate
                 # declaration-type things.
                if nestedCount == 0:
                    break
</t>
<t tx="ekr.20080121105837.640"># end skip_to_end_of_stmt

def start_process_sub_definition(self, isInnerSub):
    tok = self.tokenizer.get_next_token()
    # Watch out for lexer buffoonery
    if self.classifier.is_identifier(tok) and len(tok.text.strip()) == 0:
        tok = self.tokenizer.get_next_token()
    if (self.classifier.is_operator(tok, "{") or
        not self.classifier.is_identifier_or_keyword(tok)):
        self.tokenizer.put_back(tok)
        self.skip_to_end_of_stmt()
    else:
        startLineNo = tok.start_line
        fnName = self.get_rest_of_subpath(tok.text, 0)
        if fnName:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "("):
                self.skip_to_close_paren()
                tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, ";"):
                # Don't process
                pass
            else:
                self.tokenizer.put_back(tok)
                # Python doesn't have Perl's localizer, so we do this manually.
                currFunction = self.moduleInfo.currentFunction
                self.moduleInfo.doStartFn(FunctionInfo(name=fnName.strip(), lineNo=startLineNo))
                self.process_sub_contents(isInnerSub)
                self.moduleInfo.doEndFn(lineNo=self.tokenizer.curr_line_no())
                self.moduleInfo.currentFunction = currFunction
        else:
            self.skipAnonSubContents()
</t>
<t tx="ekr.20080121105837.641"># end class Parser

def pp(etree, fd):
    s = tostring(etree)
    ind = 0
    iw = 4
    need_nl = False
    #actual_empty_tag_ptn = re_compile(r'&lt;(\w[-\w\d_.]*)([^&gt;]+?)&gt;\s*&lt;/\1&gt;', re.S)
    tags = [(re_compile(r'&lt;\?.*?\?&gt;', re.S), False, 0, False),
            (re_compile(r'&lt;!--.*?--&gt;', re.S), False, 0, False),
            (re_compile(r'&lt;/[^&gt;]+?&gt;', re.S), True, 0, True), # update before emitting newline
            (re_compile(r'&lt;[^&gt;]+?/&gt;', re.S), True, 0, False),
            (re_compile(r'&lt;[^&gt;]+?&gt;', re.S), True, 1, True),# update after emitting newline
            ]
    fd.write("""&lt;?xml version="1.0" encoding="UTF-8"?&gt;\n""")
    while len(s) &gt; 0:
        if need_nl:
            if s[0:1] == "\r\n":
                s = s[2:]
            elif s[0] == "\n":
                s = s[1:]
            fd.write("\n" + ' ' * (ind * iw))
            need_nl = False
        ltpt = s.find("&lt;")
        if ltpt &lt; 0:
            fd.write(s)
            break
        fd.write(s[0:ltpt])
        s = s[ltpt:]
        #m = actual_empty_tag_ptn.match(s)
        #if m:
        #    print "&lt;%s%s /&gt;" % (m.group(1), m.group(2)),
        #    need_nl = True
        #    s = s[len(m.group(1)):]
        #    continue
        for tt in tags:
            m = tt[0].match(s)
            if m:
                tag_end_idx = len(m.group(0))
                need_nl = tt[1]
                if tt[3] and len(s) &gt; tag_end_idx and s[tag_end_idx] != "&lt;":
                    gtpt = s.find("&gt;", tag_end_idx)
                    fd.write(s[0:gtpt+1])
                    s = s[gtpt+1:]
                else:
                    ind += tt[2]
                    fd.write(s[:tag_end_idx])
                    s = s[tag_end_idx:]
                # Preview end-tag breaking
                if s.startswith("&lt;/"):
                    need_nl = True
                    if ind &gt; 0:
                        ind -= 1
                break
        else:
            fd.write(s[0:ltpt+1])
            s = s[ltpt+1:]

</t>
<t tx="ekr.20080121105837.642">def main(sample_code, modulePath, mtime, showWarnings, provide_full_docs=True):
    sys.stderr.write("Skipping POD: %r\n" % provide_full_docs)
    sys.exit(1)
    tokenizer = perl_lexer.PerlLexer(sample_code, provide_full_docs)
    parser = Parser(tokenizer, provide_full_docs)
    showWarnings = False
    elementTreeRepn = parser.process_module(modulePath, mtime, showWarnings)
    return elementTreeRepn
        
</t>
<t tx="ekr.20080121105837.643">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, RubyLexer)
@ignore ### &lt;&lt; == =&gt; =~ &gt;&gt; causes problems.</t>
<t tx="ekr.20080121105837.644"># ***** BEGIN LICENSE BLOCK *****

"""
Ruby lexing support for codeintel/rubycile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Ruby pseudo-parser).

Usage:
import ruby_lexer
lexer = ruby_lexer.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import re
import sys
import string

# import SilverCity
from SilverCity import Ruby, ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE

</t>
<t tx="ekr.20080121105837.645">class RubyLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""
    @others
</t>
<t tx="ekr.20080121105837.646">
def is_comment(self, ttype):
    return ttype in (ScintillaConstants.SCE_RB_COMMENTLINE,
                     ScintillaConstants.SCE_RB_POD)

</t>
<t tx="ekr.20080121105837.647">@property
def style_comment(self):
    return ScintillaConstants.SCE_RB_COMMENTLINE
    
</t>
<t tx="ekr.20080121105837.648">@property
def style_default(self):
    return ScintillaConstants.SCE_RB_DEFAULT

</t>
<t tx="ekr.20080121105837.649">@property
def style_operator(self):
    return ScintillaConstants.SCE_RB_OPERATOR

</t>
<t tx="ekr.20080121105837.650">class _CommonLexer(shared_lexer.Lexer):
    @others
</t>
<t tx="ekr.20080121105837.651">def __init__(self):
    shared_lexer.Lexer.__init__(self)
    self.q = []
    self.multi_char_ops = self.build_dict('!= !~ &amp;&amp; ** :: &lt;= &lt;&lt; == =&gt; =~ &gt;&gt; ||')    

</t>
<t tx="ekr.20080121105837.652">class RubyLexer(_CommonLexer):
    @others
</t>
<t tx="ekr.20080121105837.653">def __init__(self, code):
    _CommonLexer.__init__(self)
    self.classifier = RubyLexerClassifier()
    Ruby.RubyLexer().tokenize_by_style(code, self._fix_token_list)
    self.string_types = [ScintillaConstants.SCE_RB_STRING,
            ScintillaConstants.SCE_RB_CHARACTER,
            ScintillaConstants.SCE_RB_STRING_Q,
            ScintillaConstants.SCE_RB_STRING_QQ,
            ScintillaConstants.SCE_RB_STRING_QX,
            ScintillaConstants.SCE_RB_STRING_QR,
            ScintillaConstants.SCE_RB_STRING_QW
            ]
    
</t>
<t tx="ekr.20080121105837.654">def _fix_token_list(self, **tok):
    """See perl_lexer.py for details on what this routine does."""
    if tok['style'] == ScintillaConstants.SCE_RB_OPERATOR and len(tok['text']) &gt; 1:
        self.append_split_tokens(tok, self.multi_char_ops, self.q)
    else:
        self.q.append(tok)

</t>
<t tx="ekr.20080121105837.655">class RubyMultiLangLexer(_CommonLexer):
    @others
</t>
<t tx="ekr.20080121105837.656">def __init__(self, token_source):
    _CommonLexer.__init__(self)
    self.csl_tokens = []
    # http://www.mozilla.org/js/language/grammar14.html
    self.js_multi_char_ops = self.build_dict('++ -- &lt;&lt; &gt;&gt; &gt;&gt;&gt; &lt;= &gt;= == != === !== &amp;&amp; || *= /= %= += -= &lt;&lt;= &gt;&gt;= &gt;&gt;&gt;= &amp;= ^= |=')
    self.string_types = [ScintillaConstants.SCE_UDL_SSL_STRING
            ]
    self.classifier = shared_lexer.UDLLexerClassifier()
    self._contains_ssl = False
    self._build_tokens(token_source)

</t>
<t tx="ekr.20080121105837.657">def _build_tokens(self, token_source):
    while True:
        try:
            tok = token_source.next()
            self._fix_token_list(tok)
        except StopIteration:
            break

</t>
<t tx="ekr.20080121105837.658">def _fix_token_list(self, tok):
    """See ruby_lexer.py for details on what this routine does."""
    ttype = tok['style']
    tval = tok['text']
    if self.is_udl_csl_family(ttype):
        if ttype == ScintillaConstants.SCE_UDL_CSL_OPERATOR and len(tval) &gt; 1:
            # Point the token splitter to the correct token queue
            self.append_split_tokens(tok, self.js_multi_char_ops,
                                     self.csl_tokens)
        else:
            self.csl_tokens.append(tok)
    elif self.is_udl_ssl_family(ttype):
        if tok['style'] == ScintillaConstants.SCE_UDL_SSL_OPERATOR and len(tok['text']) &gt; 1:
            self.append_split_tokens(tok, self.multi_char_ops, self.q)
        else:
            self.q.append(tok)
        self._contains_ssl = True
    # The only reason to count TPL tokens is to provide RHTML/Ruby
    # triggers when "&lt;%" or "&lt;%=" falls at the end of the buffer,
    # as in
    # &lt;%=lin&lt;!&gt;.  There will be a delay anyway between when the
    # first TPL or SSL characters are typed, and when the buffer
    # is re-ciled, so there's no need to check TPL tokens.
    #elif self.is_udl_tpl_family(ttype):
    #    self._contains_ssl = True

</t>
<t tx="ekr.20080121105837.659">def get_csl_tokens(self):
    return self.csl_tokens

</t>
<t tx="ekr.20080121105837.660">def has_ruby_code(self):
    return self._contains_ssl

</t>
<t tx="ekr.20080121105837.661">def provide_sample_code():
    return r"""require 'rdoc/parsers/parse_rb.rb'

# full-line comment
# comment at start of line
 # comment at col 1
  # comment at col 2

module Generators
  class XMLGenerator &lt; HTMLGenerator # a comment here
    def our_generate(file_info)
      @info       = info
      @files      = []
      @classes    = []
      @hyperlinks = {}
    end
    # comment on what test_fn does
    # more...

    def test_fn(a, b='val1', c=f(3), *d, &amp;e)
       print "nothing\n"   # end-of-line comment
       print %Q(percent string\n)
    end

    def no_paren a, b, \
           c
       print "blah"
    end
  end
end
"""


</t>
<t tx="ekr.20080121105837.662">@language python
@tabwidth -4
@others
# end class Parser
        
                    
if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = ruby_lexer.provide_sample_code();
        fs = None
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
    else:
        fs = open(sys.argv[1], "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    tokenizer = ruby_lexer.RubyLexer(sample_code)
    parser = Parser(tokenizer, "Ruby")
    tree = parser.parse()
    print "Analyze the parse tree"
    tree.dump()
@ignore</t>
<t tx="ekr.20080121105837.663"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Ruby parsing support for codeintel/rubycile.py"""

import string
import sys
import re
import textwrap

from SilverCity import ScintillaConstants
from codeintel2 import ruby_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser
from codeintel2 import util
from codeintel2.parser_data import Name_LineNum, VarInfo, Node, ClassNode, \
     FileNode, ArgNode, MethodNode, ModuleNode, VariableNode, BlockNode, \
     update_collection
from codeintel2.parser_data import VAR_KIND_UNKNOWN, VAR_KIND_GLOBAL, \
     VAR_KIND_CLASS, VAR_KIND_CLASSVAR, VAR_KIND_INSTANCE, VAR_KIND_LOCAL, \
     VAR_KIND_ALIAS

import logging
log = logging.getLogger("ruby_parser")
log.setLevel(logging.DEBUG)

# Parse Ruby code

_leading_hash_re = re.compile(r'^\s*\#+\s*')

</t>
<t tx="ekr.20080121105837.664">class RubyCommonClassifier:
    """Mixin class containing classifier callbacks"""
    @others
</t>
<t tx="ekr.20080121105837.665">
def is_array_cb(self, tok):
    tval = tok.text
    return len(tval) &gt;= 2 and tval[0] == '@' and tval[1] != '$'
    # @$name is more like an expression -- don't return it

</t>
<t tx="ekr.20080121105837.666">def is_scalar_cb(self, tok):
    tval = tok.text
    return len(tval) &gt; 1 and tval[0] == '$' and (tval[1].isalnum or tval[1] == "_")

</t>
<t tx="ekr.20080121105837.667">def is_pod_cb(self, tok):
    return tok.text[0] == '=' and tok.text[1].isalnum and tok.text.find("\n=cut", 5) &gt; 0

</t>
<t tx="ekr.20080121105837.668">def is_string_qw_cb(self, tok):
    return re_compile(r'^qw\s*[^\w\d_]').match(tok.text)
                                               
</t>
<t tx="ekr.20080121105837.669">def is_symbol_cb(self, tok):
    return tok.text[0] == ":"

</t>
<t tx="ekr.20080121105837.670"># Used for stripping the quotes off a string
_quote_patterns = {ScintillaConstants.SCE_RB_STRING : re.compile('^\"(.*)\"$'),
                   ScintillaConstants.SCE_RB_CHARACTER : re.compile('^\'(.*)\'$'),
                   ScintillaConstants.SCE_RB_STRING_QQ : re.compile('^%Q.(.*).$'),
                   ScintillaConstants.SCE_RB_STRING_Q : re.compile('^%q.(.*).$'),
                   ScintillaConstants.SCE_RB_DEFAULT : re.compile('^.(.*).$'),
                   }

def quote_patterns_cb(self, tok):
    # Caller wants an array.
    return [self.quote_patterns_cb_aux(tok)]

</t>
<t tx="ekr.20080121105837.671">def quote_patterns_cb_aux(self, tok):
    tval = tok.text
    if tval[0] == '"':
        return self._quote_patterns[ScintillaConstants.SCE_RB_STRING]
    elif tval[0] == '\'':
        return self._quote_patterns[ScintillaConstants.SCE_RB_CHARACTER]
    elif tval.startswith("%Q"):
        return self._quote_patterns[ScintillaConstants.SCE_RB_STRING_QQ]
    elif tval.startswith("%q"):
        return self._quote_patterns[ScintillaConstants.SCE_RB_STRING_Q]
    else:
        return self._quote_patterns[ScintillaConstants.SCE_RB_DEFAULT] # Fallback


</t>
<t tx="ekr.20080121105837.672">class UDLClassifier(RubyCommonClassifier, shared_parser.UDLClassifier):
    pass

</t>
<t tx="ekr.20080121105837.673">class RubyClassifier(RubyCommonClassifier, shared_parser.CommonClassifier):
    """Mixin class containing classifier callbacks"""
    @others
</t>
<t tx="ekr.20080121105837.674">def __init__(self):
    self.narrowStyles = {ScintillaConstants.SCE_RB_GLOBAL : VAR_KIND_GLOBAL,
                         ScintillaConstants.SCE_RB_INSTANCE_VAR : VAR_KIND_INSTANCE,
                         ScintillaConstants.SCE_RB_CLASS_VAR : VAR_KIND_CLASSVAR}

</t>
<t tx="ekr.20080121105837.675">def get_builtin_type(self, tok, callback):
    if self.is_number(tok):
        numval = tok.text
        if numval.find(".") &gt;= 0:
            return "Float"
        else:
            return "Fixnum" 
    elif self.is_string(tok):
        return "String"
    elif tok.style == ScintillaConstants.SCE_RB_STRING_QR:
        return "Regexp"
    elif tok.style == ScintillaConstants.SCE_RB_STRING_QW:
        return "Array"
    return None
    
</t>
<t tx="ekr.20080121105837.676">def is_any_operator(self, tok):
    return tok.style == ScintillaConstants.SCE_RB_OPERATOR

</t>
<t tx="ekr.20080121105837.677">def is_comment(self, tok):
    return tok.style in (ScintillaConstants.SCE_RB_COMMENTLINE,
                         ScintillaConstants.SCE_RB_POD)

</t>
<t tx="ekr.20080121105837.678">def is_comment_structured(self, tok, callback):
    return tok.style == ScintillaConstants.SCE_RB_POD

</t>
<t tx="ekr.20080121105837.679">def is_identifier(self, tok, allow_keywords=False):
    return (tok.style == ScintillaConstants.SCE_RB_IDENTIFIER or
        (allow_keywords and
         tok.style in [ScintillaConstants.SCE_RB_WORD,
                       ScintillaConstants.SCE_RB_WORD_DEMOTED]))

</t>
<t tx="ekr.20080121105837.680">def is_interpolating_string(self, tok, callback):
    return tok.style in [ScintillaConstants.SCE_RB_STRING,
                         ScintillaConstants.SCE_RB_REGEX,
                         ScintillaConstants.SCE_RB_HERE_QQ,
                         ScintillaConstants.SCE_RB_STRING_QQ,
                         ScintillaConstants.SCE_RB_STRING_QR,
                         ScintillaConstants.SCE_RB_STRING_QX
                         ]

</t>
<t tx="ekr.20080121105837.681">def is_keyword(self, tok, target):
    return tok.style == ScintillaConstants.SCE_RB_WORD and tok.text == target

</t>
<t tx="ekr.20080121105837.682">def is_number(self, tok):
    return tok.style == ScintillaConstants.SCE_RB_NUMBER

</t>
<t tx="ekr.20080121105837.683">def is_operator(self, tok, target):
    return tok.style == ScintillaConstants.SCE_RB_OPERATOR and tok.text == target

</t>
<t tx="ekr.20080121105837.684">def is_string(self, tok):
    return tok.style in [ScintillaConstants.SCE_RB_STRING,
                         ScintillaConstants.SCE_RB_CHARACTER,
                         ScintillaConstants.SCE_RB_HERE_Q,
                         ScintillaConstants.SCE_RB_HERE_QQ,
                         ScintillaConstants.SCE_RB_STRING_Q,
                         ScintillaConstants.SCE_RB_STRING_QQ,
                         ScintillaConstants.SCE_RB_STRING_QX
                         ]

</t>
<t tx="ekr.20080121105837.685">def is_symbol(self, tok, callback=None):
    return tok.style == ScintillaConstants.SCE_RB_SYMBOL

</t>
<t tx="ekr.20080121105837.686">def tokenStyleToContainerStyle(self, tok, callback):
    return self.narrowStyles.get(tok.style, VAR_KIND_UNKNOWN)

</t>
<t tx="ekr.20080121105837.687"># Accessors for where we'd rather work with a style than call a predicate fn

@property
def style_identifier(self):
    return ScintillaConstants.SCE_RB_IDENTIFIER

</t>
<t tx="ekr.20080121105837.688">@property
def style_operator(self):
    return ScintillaConstants.SCE_RB_OPERATOR

</t>
<t tx="ekr.20080121105837.689">@property
def style_word(self):
    return ScintillaConstants.SCE_RB_WORD

</t>
<t tx="ekr.20080121105837.690">lang_specific_classes = {"Ruby": RubyClassifier,
                         "RHTML" : UDLClassifier}

def remove_hashes(lines):
    return map(lambda s: _leading_hash_re.sub("", s), lines)

</t>
<t tx="ekr.20080121105837.691">class RailsMigrationData:    
    @others
</t>
<t tx="ekr.20080121105837.692">def __init__(self):
    self.tableHookName = None
    self.columns = []   # Array of {name, type} pairs

</t>
<t tx="ekr.20080121105837.693">class RailsMigrationBlock:
    @others
</t>
<t tx="ekr.20080121105837.694">def __init__(self):
    self.table_name = None
    # non-neg means we're in the pertinent scope
    self.class_indentLevel = -1
    self.upFunc_indentLevel = -1
    self.data = [] # Array of RailsMigrationData

</t>
<t tx="ekr.20080121105837.695">_inflector = None
def get_inflector():
    global _inflector
    if _inflector is None:
        import inflector.Inflector
        _inflector = inflector.Inflector.Inflector()
    return _inflector

</t>
<t tx="ekr.20080121105837.696">class Parser:
    @others
</t>
<t tx="ekr.20080121105837.697">def __init__(self, tokenizer, lang):
    self.tokenizer = tokenizer
    self.block_stack = []
    self.tree = FileNode()
    self.curr_node = self.tree
    self.bracket_matchers = {"[":"]", "{":"}", "(":")"}
    self.classifier = lang_specific_classes[lang]()
    self.containers = {VAR_KIND_GLOBAL : [self.tree.global_vars],
                       VAR_KIND_CLASS : [], #classes
                       VAR_KIND_CLASSVAR : [],
                       VAR_KIND_INSTANCE : [],
                       VAR_KIND_LOCAL : [self.tree.local_vars], #locals
                       VAR_KIND_ALIAS : [self.tree.aliases],
                       }
    self.rails_migration_block = RailsMigrationBlock()

</t>
<t tx="ekr.20080121105837.698">def class_has_method(self, curr_node, the_text):
    try:
        class_node = self.containers[VAR_KIND_CLASS][-1]
        for c in class_node.children:
            if isinstance(c, MethodNode) and c.name == the_text:
                return True
    except:
        pass
    return False


</t>
<t tx="ekr.20080121105837.699">def curr_block_start_indentation(self):
    try:
        ind = self.block_stack[-1].indentation
    except:
        ind = 0
    return ind

</t>
<t tx="ekr.20080121105837.700"># This routine compares the current line indentation
# with the one at the start of the block
#
# Neg value: we've moved to far back
# 0: same ind
# Pos value: curr indent'n is greater than where we started

def compare_curr_ind(self):
    start_ind = self.curr_block_start_indentation()
    curr_indent = self.tokenizer.get_curr_indentation() # 
    return curr_indent - start_ind

</t>
<t tx="ekr.20080121105837.701">def dump(self):
    self.tree.dump()
    
</t>
<t tx="ekr.20080121105837.702">def rails_migration_class_tree(self):
    rails_migration_block = self.rails_migration_block
    inflector = get_inflector()
    nodes = []
    for info in self.rails_migration_block.data:
        if info.tableHookName is None or not info.columns:
            return None                
        className = inflector.camelize(inflector.singularize(info.tableHookName))
        classNode = ClassNode(className, info.startLine, False)
        classNode.set_line_end_num(info.endLine)
        for attrib_info in info.columns:
            methodNode = MethodNode(attrib_info[0], attrib_info[2])
            methodNode.set_line_end_num(attrib_info[2])                
            classNode.append_node(methodNode)
        nodes.append(classNode)
    return nodes
    
</t>
<t tx="ekr.20080121105837.703">def parse(self):
    self.parse_aux(self.tree)
    return self.tree
    
</t>
<t tx="ekr.20080121105837.704">def get_parsing_objects(self, kwd):
    return {
        "module": [ModuleNode, self.parse_aux],
        "class" : [ClassNode, self.parse_aux],
        "def" : [MethodNode, self.parse_method]
    }.get(kwd, [None, None])

</t>
<t tx="ekr.20080121105837.705">def parse_open_parens(self):
    paren_count = 0
    while True:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, "("):
            paren_count += 1
        else:
            return (tok, paren_count)

</t>
<t tx="ekr.20080121105837.706">def parse_attr_stmt_capture_info(self, collection, attr_tok, tok, curr_node):
    base_name = tok.text[1:]
    update_collection(collection,
                      '@' + base_name, tok.start_line)
    if isinstance(curr_node, ClassNode):
        if attr_tok != 'attr_writer':
            new_node = MethodNode(base_name, tok.start_line)
            new_node.set_line_end_num(tok.start_line)
            curr_node.append_node(new_node)
        if attr_tok in ['attr_writer', 'attr_accessor']:
            new_node = MethodNode(base_name + '=', tok.start_line)
            new_node.set_line_end_num(tok.start_line)
            new_node.add_arg(base_name, "")
            curr_node.append_node(new_node)

</t>
<t tx="ekr.20080121105837.707">def parse_attr_stmts(self, attr_tok, curr_node):
    """
    attr_tok is one of ['attr', 'attr_reader', 'attr_writer', 'attr_accessor']
    if curr_node is a ClassNode then set up a bunch of methods as well
    """
    try:
        collection = self.containers[VAR_KIND_INSTANCE][-1]
        if collection is None:
            return
    except:
        return
    (tok, paren_count) = self.parse_open_parens()
    if self.classifier.is_symbol(tok, self.classifier.is_symbol_cb):
        self.parse_attr_stmt_capture_info(collection, attr_tok, tok, curr_node)                
    # Allow for more, but special case attr's
    while True:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, ","):
            tok = self.tokenizer.get_next_token()
            # Intern unless attr
            if (self.classifier.is_symbol(tok, self.classifier.is_symbol_cb) and
                attr_tok != 'attr'):
                self.parse_attr_stmt_capture_info(collection, attr_tok, tok, curr_node)
        else:
            self.tokenizer.put_back(tok)
            break
    # Might as well consume the closing parens
    while paren_count &gt; 0:
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, ")"):
            paren_count -= 1
        else:
            self.tokenizer.put_back(tok)
            break;

</t>
<t tx="ekr.20080121105837.708">def parse_assignment(self, collectionA, tok_text, start_line):
    if len(collectionA) == 0 or collectionA[-1] is None:
        return
    
    tok = self.tokenizer.get_next_token()
    # We don't need to Watch out for calls like abc=(1)
    # because that's always an assignment to a local.
    # self.abc=(1) is different
    
    if self.classifier.is_any_operator(tok):
        if tok.text == "=":
            self._finishVarAssignment(collectionA, tok_text, start_line)
            # Look to see if we have an instance of a class
            # This is 
            update_collection(collectionA[-1], tok_text, start_line)
            return
        elif tok.text in ["::", "."]:
            # Don't store fully-qualified names, but do consume them
            # Keep name for debugging purposes.
            rest_of_name = self.get_fully_qualified_name()
            return
    self.tokenizer.put_back(tok)
    
</t>
<t tx="ekr.20080121105837.709">def _actual_string_from_string_or_symbol(self, tok):
    if self.classifier.is_symbol(tok):
        return tok.text[1:]
    else:
        assert self.classifier.is_string(tok)
        return self.de_quote_string(tok)

</t>
<t tx="ekr.20080121105837.710">def _parse_migration_create_table_block(self):
    """This code is handled only when in the following conditions:
    1. The file path matches .../db/migrate/*.rb
    2. It's in a class that inherits from ActiveRecord::Migration
    3. It's in a function called "self.up"
    
    Database fields are found through two functions:
    create_table TABLE-NAME do |handle|
      handle.column COLUMN-NAME TYPE
    end
    
    To add:
    add_column TABLE-NAME COLUMN-NAME TYPE
    """
    tok = self.tokenizer.get_next_token()
    if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
        return
    rails_migration_info = RailsMigrationData()
    rails_migration_info.tableHookName = self._actual_string_from_string_or_symbol(tok)
    rails_migration_info.startLine = tok.start_line
    # Assume we don't find the end of the block, so assume the worst
    rails_migration_info.endLine = tok.start_line + 1
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, "{") or self.classifier.is_keyword(tok, "do"):
        control_tok = (tok.style, (tok.text == "{" and "}") or "end")
    else:
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, "|"):
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_identifier(tok):
        return
    table_handle = tok.text
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, "|"):
        return
    while True:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            break
        elif tok.style == control_tok[0] and tok.text == control_tok[1]:
            rails_migration_info.endLine = tok.end_line
            break
        elif self.classifier.is_identifier(tok) and tok.text == table_handle:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_operator(tok, "."):
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_identifier(tok) and tok.text == 'column':
                    line_num = tok.start_line
                    tok = self.tokenizer.get_next_token()
                    if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                        column_name = self._actual_string_from_string_or_symbol(tok)
                        tok = self.tokenizer.get_next_token()
                        if self.classifier.is_operator(tok, ','):
                            tok = self.tokenizer.get_next_token()
                            if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
                                column_type = self._actual_string_from_string_or_symbol(tok)
                            else:
                                column_type = ""
                            # Whew, we made it
                            rails_migration_info.columns.append((column_name, column_type, line_num))
                            rails_migration_info.endLine = line_num + 1
                            continue
        # Sanity check any token we have here
        if (tok.style == ScintillaConstants.SCE_RB_WORD and
            tok.text in ('class', 'def')):
            self.tokenizer.put_back(tok)
            return
    self.rails_migration_block.data.append(rails_migration_info)
    # end _parse_migration_create_table_block
    
</t>
<t tx="ekr.20080121105837.711">def _parse_migration_add_column_stmt(self):
    """This code is handled only when in the following conditions:
    1. The file path matches .../db/migrate/*.rb
    2. It's in a class that inherits from ActiveRecord::Migration
    3. It's in a function called "self.up"
    4. We saw an add_column action.
    
    Syntax:
    add_column TABLE-NAME COLUMN-NAME TYPE
    """
    tok = self.tokenizer.get_next_token()
    if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
        return
    table_name = self._actual_string_from_string_or_symbol(tok)
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, ","):
        return
    tok = self.tokenizer.get_next_token()
    if not (self.classifier.is_symbol(tok) or self.classifier.is_string(tok)):
        return
    rails_migration_info = RailsMigrationData()
    rails_migration_info.tableHookName = table_name
    rails_migration_info.endLine = rails_migration_info.startLine = tok.start_line
    column_name = self._actual_string_from_string_or_symbol(tok)
    column_type = ""
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, ','):
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_symbol(tok) or self.classifier.is_string(tok):
            column_type = self._actual_string_from_string_or_symbol(tok)
        else:
            self.tokenizer.put_back(tok)
    else:
        self.tokenizer.put_back(tok)            
    rails_migration_info.columns.append((column_name, column_type, rails_migration_info.startLine))
    self.rails_migration_block.data.append(rails_migration_info)

</t>
<t tx="ekr.20080121105837.712">def _finish_interpolating_string(self, prev_tok):
    """ Matches sequences of "#{", ... "}"
    (which could nest).  Returns a list of all the tokens.
    """

    tok1 = self.tokenizer.get_next_token()
    if not self.classifier.is_any_operator(tok1) or \
       tok1.text != "#":
        self.tokenizer.put_back(tok1)
        return [prev_tok]
    tok2 = self.tokenizer.get_next_token()
    if not self.classifier.is_any_operator(tok2) or \
       tok2.text != "{":
        self.tokenizer.put_back(tok1)
        self.tokenizer.put_back(tok2)
        return [prev_tok]
    
    nested_count = 1
    tok_list = [prev_tok, tok1, tok2]
    # At this point process a contiguous stream of tokens
    while True:
        bail_out = False
        new_tok = self.tokenizer.get_next_token()
        if new_tok.style == shared_lexer.EOF_STYLE:
            bail_out = True
        elif self.classifier.is_any_operator(new_tok):
            if new_tok.text == "#":
                tok_list.append(new_tok)
                new_tok = self.tokenizer.get_next_token()
                if self.classifier.is_any_operator(new_tok) and \
                   new_tok.text == "{":
                    nested_count += 1
                elif nested_count == 0:
                    bail_out = True
            elif new_tok.text == "}" and nested_count &gt; 0:
                nested_count -= 1
            elif nested_count == 0:
                bail_out = True
        elif self.classifier.is_interpolating_string(new_tok, self._test_interpolate_string):
            pass
        elif nested_count == 0:
            bail_out = True
        if bail_out:
            self.tokenizer.put_back(new_tok)
            return tok_list
        else:
            tok_list.append(new_tok)

</t>
<t tx="ekr.20080121105837.713">def _at_end_expression(self, tok):
    if not self.classifier.is_any_operator(tok):
        return True
    return tok.text in [",", "}", ";"]

</t>
<t tx="ekr.20080121105837.714">def skip_to_op(self, opText, nestedLevel=1):
    skipped_toks = []
    while 1:
        tok = self.tokenizer.get_next_token()
        skipped_toks.append(tok)
        if tok.style == shared_lexer.EOF_STYLE:
            return skipped_toks
        elif self.classifier.is_any_operator(tok):
            if tok.text in ["(", "{", "["]:
                nestedLevel += 1
            elif tok.text in ["]", "}", ")"]:
                nestedLevel -= 1
                if nestedLevel &lt;= 0:
                    return skipped_toks
            # don't care about other ops
        # don't care about other token types

</t>
<t tx="ekr.20080121105837.715">def de_quote_string(self, tok):
    tval = tok.text
    patterns = self.classifier.get_quote_patterns(tok, self.classifier.quote_patterns_cb)
    for p in patterns:
        m = p.match(tval)
        if m:
            return m.group(1)
    return tval

</t>
<t tx="ekr.20080121105837.716">def _finishVarAssignment(self, collectionA, var_name, start_line):
    # See doc for finishVarAssignment in src/perlcile/ParseModule.pm
    # for comments.
    # 1: a = b.c.d.e -- don't bother
    # 2.1: a = &lt;number&gt; &lt;no op&gt;
    # 2.2: a = &lt;string&gt; &lt;no op&gt;
    # 3. a = &lt;classname&gt;.New [( ... )]&lt;no op&gt;

    tok_list = self.get_fully_qualified_name_as_list()
    if not tok_list:
        return
    tok = tok_list[0]
    if self.classifier.is_identifier(tok):
        var_citdl = None
        toks_to_return = tok_list
        if len(toks_to_return) &lt; 3:
            tok2 = self.tokenizer.get_next_token()
            #toks_to_return.append(tok2)
            if self.classifier.is_operator(tok2, ','):
                #XXX : skip to end -- we must be in a parallel assignment
                pass
            else:
                if self._at_end_expression(tok2):
                    var_citdl = tok.text
                self.tokenizer.put_back(tok2)
        elif self.classifier.is_operator(toks_to_return[-2], '.') and \
            self.classifier.is_identifier(toks_to_return[-1]) and \
            toks_to_return[-1].text == 'new':
                tok3 = self.tokenizer.get_next_token()
                if self._at_end_expression(tok3):
                    var_citdl = ''.join([tok.text for tok in tok_list[:-2]])
                    self.tokenizer.put_back(tok3)
                    # toks_to_return.append(tok3)
                else:
                    if self.classifier.is_operator(tok3, "("):
                        skipped_toks = self.skip_to_op(")")
                        # toks_to_return += skipped_toks
                        tok4 = self.tokenizer.get_next_token()
                    else:
                        tok4 = tok3
                    if self._at_end_expression(tok4):
                        var_citdl = ''.join([tok.text for tok in tok_list[:-2]])
                    self.tokenizer.put_back(tok4)
        update_collection(collectionA[-1], var_name, start_line, var_citdl)
        # Idea: don't bother putting back these tokens
        #for t in tok_list:
        #    self.tokenizer.put_back(t)
        return
        
    builtin_type = self.classifier.get_builtin_type(tok, self._test_for_builtin_type)
    if builtin_type:
        type1, locn = tok.style, tok.start_line
        if self.classifier.is_interpolating_string(tok, self._test_interpolate_string):
            self._finish_interpolating_string(tok)
        tok2 = self.tokenizer.get_next_token()
        if self._at_end_expression(tok2):
            if self.classifier.is_number(tok):
                type1 = "Number"
            else:
                type1 = "String"
            update_collection(collectionA[-1], var_name, start_line, builtin_type)
            toks = [tok2]
        else:
            update_collection(collectionA[-1], var_name, start_line)
            toks = [tok2, tok]
    elif tok.style == self.classifier.style_identifier:
        raise("get_fully_qualified_name_as_list failed to process an identifer")
    elif self.classifier.is_operator(tok, "["):
        toks = self._finish_list(collectionA, var_name, start_line, tok, "]", "Array")
    elif self.classifier.is_operator(tok, "{"):
        toks = self._finish_list(collectionA, var_name, start_line, tok, "}", "Hash")
    else:
        update_collection(collectionA[-1], var_name, start_line)
        toks = [tok]
    for t in toks:
        self.tokenizer.put_back(t)
        
</t>
<t tx="ekr.20080121105837.717">def _finish_list(self, collectionA, var_name, start_line, orig_tok, end_op, class_name):
    skipped_toks = [orig_tok] + self.skip_to_op(end_op)
    final_tok = self.tokenizer.get_next_token()
    skipped_toks.append(final_tok)
    class_name_final = self._at_end_expression(final_tok) and class_name or None
    update_collection(collectionA[-1], var_name, start_line, class_name_final)
    return skipped_toks

</t>
<t tx="ekr.20080121105837.718">def _set_basename_method(self, node_class, curr_node, nm_token):
    if node_class != MethodNode: return (nm_token, False)
    method_name = nm_token[0]
    idx1 = method_name.rfind('::')
    if idx1 &gt;= 0: idx1_len = 2
    idx2 = method_name.rfind('.')
    if idx2 &gt;= 0: idx2_len = 1
    if idx1 &lt; 0:
        if idx2 &lt; 0:
            return (nm_token, False)
        idx = idx2
        idx_len = 1
    elif idx2 &lt; idx1:
        # Includes no idx2
        idx = idx1
        idx_len = 2
    else:
        idx = idx2
        idx_len = 1
    first_part = method_name[0:idx]
    if first_part != getattr(curr_node, 'name', '') and first_part != 'self':
        # We're doing something like defining inside a mix-in
        return (nm_token, False)            
        
    basename = method_name[idx + idx_len :]
    if len(nm_token) != 2:
        raise("Expectations dashed!")
    
    return ((basename, nm_token[1]), True)

</t>
<t tx="ekr.20080121105837.719">def _test_interpolate_string(self, tok, generic_tok_type):
    if generic_tok_type == shared_parser.GENERIC_TYPE_REGEX:
        return True
    elif generic_tok_type != shared_parser.GENERIC_TYPE_STRING:
        return False
    tval = tok.text
    c1 = tval[0]
    if c1 == "'":
        return False
    elif c1 == '"':
        return True
    elif c1 == '%':
        if len(c1) == 1:
            return False  #???
        c2 = tval[1]
        if c2 in "WwQrx":
            return True
    return False

</t>
<t tx="ekr.20080121105837.720"># Callback used by get_builtin_type
def _test_for_builtin_type(self, tok, generic_tok_type):
    if generic_tok_type == shared_parser.GENERIC_TYPE_NUMBER:
        numval = tok.text
        if numval.find(".") &gt;= 0:
            return "Float"
        else:
            return "Fixnum"
    elif generic_tok_type == shared_parser.GENERIC_TYPE_STRING:
        tval = tok.text
        if len(tval) &gt; 1 and tval[0] == "%":
            if tval[1] in 'wW':
                return "Array"
            elif tval[1] == 'r':
                return "Regexp"
        return "String"
    elif generic_tok_type == shared_parser.GENERIC_TYPE_REGEX:
        return "Regexp"
    else:
        return None

</t>
<t tx="ekr.20080121105837.721"># Callback used by tokenStyleToContainerStyle
def _test_token_style(self, tok, is_variable_token):
    if not is_variable_token:
        return VAR_KIND_UNKNOWN
    tval = tok.text
    if tval[0] == '$':
        return VAR_KIND_GLOBAL
    elif tval[0] == '@':
        if len(tval) &gt; 1 and tval[1] == '@':
            return VAR_KIND_CLASSVAR
        else:
            return VAR_KIND_INSTANCE
    return VAR_KIND_UNKNOWN

</t>
<t tx="ekr.20080121105837.722">def _try_loading_relative_library(self, tok, curr_node):
    """Look for instances of
    require File.dirname(__FILE__) + &lt;string&gt; and map to
    @&lt;string&gt;"""
    seq_start_line = tok.start_line
    if not self.classifier.is_identifier(tok) or tok.text != 'File':
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, '.'):
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_identifier(tok) or tok.text != 'dirname':
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, '('):
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_identifier(tok, True) or tok.text != '__FILE__':
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, ')'):
        return
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, '+'):
        return
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_string(tok):
        curr_node.imports.append(Name_LineNum
                                 (self._create_relative_libname(tok),
                                  seq_start_line))
        
</t>
<t tx="ekr.20080121105837.723">def _create_relative_libname(self, tok):
    # For now just return the path.  If we need to decorate it
    # to indicate it's a relative path, we'll do that later.
    return self.de_quote_string(tok)[1:]
        

</t>
<t tx="ekr.20080121105837.724">def _extract_alias_name(self, tok):
    if self.classifier.is_identifier(tok):
        return tok.text
    elif self.classifier.is_symbol(tok, self.classifier.is_symbol_cb):
        return tok.text[1:]
    else:
        return None

</t>
<t tx="ekr.20080121105837.725">def parse_aux(self, curr_node):
    at_start = True
    while 1:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            break
        # style, text, start_column, start_line, end_column, end_line = tok
        style, text = tok.style, tok.text
        if style == self.classifier.style_word:
            if text in ["module", "class", "def"]:
                # Check to see if we missed some nodes,
                # using heuristic that the end statements line up
                # with the start of each block, for definitions

                if len(self.block_stack) &gt; 0 and self.compare_curr_ind() &lt;= 0:
                    # We missed one or more end's, so put the token
                    # back and try in an outer instance
                    self.tokenizer.put_back(tok)
                    return

                curr_indent = self.tokenizer.get_curr_indentation() # 
                node_class, node_parser = self.get_parsing_objects(text)
                if node_class is None:
                    sys.stderr.write("Couldn't get parsing objects for type %s\n" % text)
                    break
                elif node_class is MethodNode:
                    self.tokenizer.start_sig()

                # Get the comments before further parsing.
                comment_lines = remove_hashes(self.tokenizer.curr_comment())
                nm_token = self.get_fully_qualified_name()
                if not nm_token[0]:
                    return
                elif nm_token[0] == "&lt;&lt;" and node_class == ClassNode:
                    # Singleton classes
                    nm_token = self.get_fully_qualified_name()
                    if not nm_token[0]:
                        return
                    
                if self.rails_migration_block.class_indentLevel &gt;= 0 and nm_token[0] == "self.up":
                    self.rails_migration_block.upFunc_indentLevel = curr_indent
                    rails_migration_clear_upfunc = True
                else:
                    rails_migration_clear_upfunc = False

                (nm_token, is_class_method) = self._set_basename_method(node_class, curr_node, nm_token)
                new_node = node_class(nm_token[0], tok.start_line, nm_token[0] == "initialize")
                if is_class_method:
                    new_node.is_classmethod = True
                elif node_class == MethodNode and (isinstance(curr_node, ClassNode) or isinstance(curr_node, ModuleNode)):
                    # Add info on the 'self' variable
                    update_collection(new_node.local_vars, 'self', tok.start_line, curr_node.name)
                new_node.doc_lines = comment_lines
                new_node.indentation = curr_indent
                self.block_stack.append(new_node)
                curr_node.append_node(new_node)

                # Push new containers on the symbol table
                self.containers[VAR_KIND_LOCAL].append(new_node.local_vars)
                if node_class in [ClassNode, ModuleNode]:
                    self.containers[VAR_KIND_CLASS].append(new_node)
                    self.containers[VAR_KIND_CLASSVAR].append(new_node.class_vars)
                    self.containers[VAR_KIND_INSTANCE].append(new_node.instance_vars)
                    self.containers[VAR_KIND_ALIAS].append(new_node.aliases)

                # Watch out for class inheritence
                
                rails_migration_clear_classref = False
                if node_class == ClassNode:
                    self.parse_classref(new_node)
                    if new_node.has_classref('ActiveRecord::Migration'):
                        self.rails_migration_block.class_indentLevel = curr_indent;
                        rails_migration_clear_classref = True
                node_parser(new_node)  # Has self bound to it
                if rails_migration_clear_upfunc:
                    self.rails_migration_block.upFunc_indentLevel = -1
                elif rails_migration_clear_classref:
                    self.rails_migration_block.class_indentLevel = -1
                self.block_stack.pop()
                self.containers[VAR_KIND_LOCAL].pop()
                if node_class in [ClassNode, ModuleNode]:
                    self.containers[VAR_KIND_CLASSVAR].pop()
                    self.containers[VAR_KIND_INSTANCE].pop()
                    self.containers[VAR_KIND_CLASS].pop()
                    self.containers[VAR_KIND_ALIAS].pop()

                # Clear any comment that's hanging around
                self.tokenizer.clear_comments()

            elif text == "alias":
                new_tok = self.tokenizer.get_next_token()
                new_name = self._extract_alias_name(new_tok)
                existing_tok = self.tokenizer.get_next_token()
                existing_name = self._extract_alias_name(existing_tok)
                if new_name and existing_name:
                    update_collection(self.containers[VAR_KIND_ALIAS][-1], new_name, new_tok.start_line, existing_name)
            
                    # set a variable in curr_node
            elif text == "end":
                if len(self.block_stack) &gt; 0:
                    end_position = self.compare_curr_ind()
                    if end_position &lt; 0:
                        # We've gone too far, so put it back and try later
                        curr_node.set_line_end_num(tok.start_line)
                        self.tokenizer.put_back(tok)
                        return
                    elif end_position == 0:
                        curr_node.set_line_end_num(tok.start_line)
                        # the caller will pop the stack
                        return
                    
        elif style == self.classifier.style_identifier:
            if text == "require" or text == "load":
                tok = self.tokenizer.get_next_token()
                if (self.tokenizer.is_string_token(tok)):
                    tval = self.de_quote_string(tok)
                    if tval.endswith(".rb"):
                        tval = tval[:-3]
                    curr_node.imports.append(Name_LineNum(tval, tok.start_line))
                else:
                    self._try_loading_relative_library(tok, curr_node)
            elif text == "include":
                nm_token = self.get_fully_qualified_name()
                if nm_token[0]:
                    curr_node.includes.append(Name_LineNum(nm_token[0], nm_token[1]))
            #@@@@ elif text == "base":
                # semi-hardwired rails thing
                #@@@@ self.parse_class_extension()
                # if next() == (OP, ".") \
                  # and next() == (ID, "extend") \
                   # and next() == (OP, "(") \
                   
            elif at_start or tok.start_column == self.tokenizer.get_curr_indentation():
                # Look at these things only at start of line
                if text in ['attr', 'attr_reader', 'attr_writer', 'attr_accessor']:
                    self.parse_attr_stmts(text, curr_node)
                elif text == 'create_table' and self.rails_migration_block.upFunc_indentLevel &gt;= 0:
                    self._parse_migration_create_table_block()
                elif text == 'add_column' and self.rails_migration_block.upFunc_indentLevel &gt;= 0:
                    self._parse_migration_add_column_stmt()
                elif not self.class_has_method(curr_node, tok.text + "="):
                    # Make sure it isn't an assignment function
                    self.parse_assignment(self.containers[VAR_KIND_LOCAL], text, tok.start_line)

        elif self.classifier.is_any_operator(tok):
            if text == "{":
                new_node = BlockNode("{", tok.start_line);
                new_node.indentation = self.tokenizer.get_curr_indentation()
                #XXX Transfer any children a block defines to the
                # parent of the block.  Uncommon formulation
                self.block_stack.append(new_node)
                self.parse_aux(new_node)
                self.block_stack.pop()
            elif text == "}":
                if len(self.block_stack) &gt; 0:
                    end_position = self.compare_curr_ind()
                    if end_position &lt; 0:
                        # We've gone too far, so put it back and try later
                        self.tokenizer.put_back(tok)
                        return
                    elif end_position == 0:
                        # the caller will pop the stack
                        return
        # Check for assignment to some kind of variable
        else:
            narrow_style = self.classifier.tokenStyleToContainerStyle(tok, self._test_token_style)
            if narrow_style != VAR_KIND_UNKNOWN:
                self.parse_assignment(self.containers[narrow_style], tok.text, tok.start_line)
        # end if WORD block
        #XXX: process variables as well
        at_start = False
    # end while
    return
</t>
<t tx="ekr.20080121105837.726"># end parse_aux()

"""
Simplified Ruby function-defn grammar

method_def ::= kDEF fname f_arglist bodystmt kEND
fname ::= ID
f_arglist ::= "(" f_args opt_nl ")" | f_args term
term ::= "\n" | ";"
f_args ::= f_arg(s /,/)
 | &lt;nothing&gt;
f_arg ::= f_norm_arg | f_opt | f_rest_arg | f_block_arg
f_norm_arg ::= id
f_opt ::= id '=' arg_value
f_rest_arg ::= "*" id? 
f_block_arg ::= "&amp;" id 

arg_value ::= simple_expn
simple_expn ::= (simple_term | nested_expn)+
simple_term ::= &lt;anything but a ";", "\n", ")", "," or a block-starter or closer
- the exceptions depend on whether we're in a parenthesized construct or not
simple_inner_expn ::= (simple_term | nested_expn)+
nested_expn ::= "(" simple_expn ")" | "{" simple_expn "}" | "[" simple_expn "]"
"""
    
def parse_nested_expn(self, block_end_char):
    while 1:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            return
        elif self.classifier.is_any_operator(tok):
            # Don't look at commas or semi-colons here, as we might be
            # processing nested comma-sep things or even blocks
            if len(tok.text) == 1:
                if tok.text == block_end_char:
                    return -1
                elif "[{(".find(tok.text) &gt;= 0:
                    self.parse_nested_expn(self.bracket_matchers[tok.text])
        elif self.classifier.is_keyword(tok, "end"):
            if len(self.block_stack) == 0:
                return
            elif self.compare_curr_ind() &lt;= 0:
                # Did we go too far?
                self.tokenizer.put_back(tok)
                return
</t>
<t tx="ekr.20080121105837.727"># end parse_nested_expn

# This might not always work
def parse_simple_expn(self, has_paren):
    while 1:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            return
        elif self.classifier.is_any_operator(tok):
            if tok.text == ",":
                self.tokenizer.put_back(tok)
                return
            elif has_paren and tok.text == ')':
                self.tokenizer.put_back(tok)
                return
            elif not has_paren and tok.text == ';':
                self.tokenizer.put_back(tok)
                return
            elif len(tok.text) == 1 and "[{(".find(tok.text) &gt;= 0:
                self.parse_nested_expn(self.bracket_matchers[tok.text])
        elif self.classifier.is_keyword(tok, "end"):
            if len(self.block_stack) == 0:
                return
            elif self.compare_curr_ind() &lt;= 0:
                # Did we go too far?
                self.tokenizer.put_back(tok)
                return
</t>
<t tx="ekr.20080121105837.728"># end parse_simple_expn

def parse_method_args(self, curr_node):
    tok = self.tokenizer.get_next_token()
    if tok.style == shared_lexer.EOF_STYLE:
        return
    elif self.classifier.is_operator(tok, ";"):
        self.tokenizer.put_back(tok)
        return  # No args
    elif self.classifier.is_operator(tok, "("):
        has_paren = True
    elif tok.start_line &gt; curr_node.line_num:
        # Assume a zero-paren function
        self.tokenizer.put_back(tok)
        return  # No args
    
    else:
        self.tokenizer.put_back(tok)  # simplifies the while loop
        has_paren = False
    # Further simplification: look for the "," at the start of the loop
    comma_token = shared_lexer.Token(style=self.classifier.style_operator, text=",")
    comma_token.generated = 1
    self.tokenizer.put_back(comma_token)
    while 1:
        tok = self.tokenizer.get_next_token()
        # First check for white-space, set indent,
        if tok.style == shared_lexer.EOF_STYLE:
            return
        elif has_paren and self.classifier.is_operator(tok, ")"):
            return
        elif self.classifier.is_keyword(tok, 'end') and self.compare_curr_ind() &lt;= 0:
            # Did we go too far?
            self.tokenizer.put_back(tok)
            return

        # Note -- silvercity swallows \-line-continuations,
        # so we don't need to handle them

        if self.classifier.is_operator(tok, ","):
            tok = self.tokenizer.get_next_token()
        else:
            self.tokenizer.put_back(tok)
            return
        
        # then check for arg-list termination,
        # and then process the arg...
        extra_info = ""
        if (self.classifier.is_any_operator(tok) and
            len(tok.text) == 1 and "*&amp;".find(tok.text) &gt;= 0):
            extra_info = tok.text
            tok = self.tokenizer.get_next_token()
        if self.classifier.is_identifier(tok, True):
            curr_node.add_arg(tok.text, extra_info)
        else:
            # give up -- expected to see an arg, didn't
            return
        # check for an '=' sign
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_operator(tok, '='):
            self.parse_simple_expn(has_paren)
        else:
            self.tokenizer.put_back(tok)
    # end while
</t>
<t tx="ekr.20080121105837.729"># end parse_method_args

def parse_method(self, curr_node):
    # Get the args before dispatching back to the main routine

    self.parse_method_args(curr_node)
    self.tokenizer.stop_sig()

    #XXX Remove newlines and \-prefixed newlines, with white-space
    curr_node.signature = self.tokenizer.get_sig() # @@@@ self.trimmer.trim_ws(self.tokenizer.get_sig())
    
    # Now look for the 'end' on the same line as a special case
    # The start line is contained in curr_node.line_num        
    while 1:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            return;
        # style, text, start_column, start_line, end_column, end_line = tok
        if tok.end_line &gt; self.block_stack[-1].line_num:
            self.tokenizer.put_back(tok)
            break
        #*** Heuristic: if we find an 'end' followed by a newline, end the sub here
        elif self.classifier.is_keyword(tok, "end"):
            # Assume that's the end
            # Let the caller pop the block_stack
            return
    # end while
    self.parse_aux(curr_node)
</t>
<t tx="ekr.20080121105837.730"># end parse_method

def parse_classref(self, node):
    toks = []
    tok = self.tokenizer.get_next_token(1)
    fqname = classref_type = None
    if self.classifier.is_operator(tok, "&lt;"):
        fqname, line_start = self.get_fully_qualified_name()
        if fqname == "DelegateClass":
            tok = self.tokenizer.get_next_token(1)
            if self.classifier.is_operator(tok, "("):
                # No putback once we enter this point
                inner_name, junk = self.get_fully_qualified_name()
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_operator(tok, ")"):
                    fqname = "%s(%s)" % (fqname, inner_name)
                    classref_type = inner_name
            else:
                toks.append(tok)
    else:
        fqname = "Object"
        line_start = tok.start_line
        toks.append(tok)
    if fqname is not None:
        node.add_classrefs(fqname, line_start, classref_type)
    
    for t in toks:
        self.tokenizer.put_back(t)

</t>
<t tx="ekr.20080121105837.731">def get_fully_qualified_name(self):
    tok = self.tokenizer.get_next_token()
    if tok.style == shared_lexer.EOF_STYLE:
        return (None, None)
    name_start = tok.text
    line_start = tok.start_line
    # Watch out if it starts with a "::"
    if name_start == "::":
        tok = self.tokenizer.get_next_token()
        if tok.style != self.classifier.style_identifier:
            self.tokenizer.put_back(tok)
            return (name_start, line_start)
        name_start += tok.text
            
    while 1:
        # Collect operator-type methods
        if self.classifier.is_any_operator(tok):
            while 1:
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_any_operator(tok) and tok.text not in "()@${};:?,":
                    name_start += tok.text
                else:
                    self.tokenizer.put_back(tok)
                    break
            # And it will be the end of the line
            return (name_start, line_start)
        tok = self.tokenizer.get_next_token()
        if not self.classifier.is_any_operator(tok):
            self.tokenizer.put_back(tok)
            break
        if not tok.text in ["::", "."]:
            self.tokenizer.put_back(tok)
            break
        tok2 = self.tokenizer.get_next_token()
        if tok2.style != self.classifier.style_identifier:
            self.tokenizer.put_back(tok)
            self.tokenizer.put_back(tok2)
            break
        name_start += tok.text + tok2.text
    return (name_start, line_start)

</t>
<t tx="ekr.20080121105837.732"># Consume { (CapName, ['.' | '::']) | (lcName, '::') }
# Return a list of the tokens
def get_fully_qualified_name_as_list(self):
    # Check for a leading '::' and throw it away
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, '::'):
        # Throw it away
        tok = self.tokenizer.get_next_token()
    
    if self.classifier.is_identifier(tok, False):
        tok_list = [tok]
    else:
        return [tok]

    # Now look for scope-resolution operators:
    # '::' always
    # '.' followed by an upper-case name (not fully Rubyish, but...)
    
    while True:            
        # Check for a continuation
        tok = self.tokenizer.get_next_token()
        if self.classifier.is_any_operator(tok):
            if tok.text in ("::", '.'):
                # Always keep going with a scope-resolution operator
                tok2 = self.tokenizer.get_next_token()
                if not self.classifier.is_identifier(tok2, True):
                    self.tokenizer.put_back(tok)
                    self.tokenizer.put_back(tok2)
                    break
                tok_list.append(tok)
                tok_list.append(tok2)
                # Check if we're done
                if tok.text == '.' and not tok2.text[0].isupper():
                    break
            else:
                self.tokenizer.put_back(tok)
                break
        else:
            self.tokenizer.put_back(tok)
            break

    return tok_list
        
</t>
<t tx="ekr.20080121105837.733">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.734"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
# Common wrapper around SilverCity used by Ruby, Perl

import copy
import re
import sys
import string

from SilverCity import ScintillaConstants

#---- global data

MAX_REASONABLE_LIMIT = 10000

ws_re = re.compile("^[" + string.whitespace + "\\\\" + "]*$")
trailing_spaces_re = re.compile("\n([ \t]*)$")
trim_ws_re2 = re.compile(r'[\r\n\t]')
trim_ws_re3 = re.compile(r' {2,}')

</t>
<t tx="ekr.20080121105837.735">class Token:
    @others
</t>
<t tx="ekr.20080121105837.736">def __init__(self, style, text="", start_column=None, start_line=None, end_column=None, end_line=None):
    self.style = style
    self.text = text
    self.start_column = start_column
    self.start_line = start_line
    self.end_column = end_column
    self.end_line = end_line
    
</t>
<t tx="ekr.20080121105837.737"># Hardwired cloner for convenience
def clone(tok, text):
    return Token(tok.style, text, tok.start_column, tok.start_line, tok.end_column, tok.end_line)

</t>
<t tx="ekr.20080121105837.738">def dump(self):
    s = "[" + str(self.style) + ", " + repr(self.text)
    for attr in ['start_column', 'start_line', 'end_column', 'end_line']:
        if hasattr(self, attr):
            val = getattr(self, attr)
            s += ", " + attr + "=" + str(val)
    s += "]"
    print s

</t>
<t tx="ekr.20080121105837.739">EOF_STYLE = -1
EOF_TOKEN = Token(EOF_STYLE)

class Signature:
    @others
</t>
<t tx="ekr.20080121105837.740">def __init__(self):
    self._gathering = False
    self._text = ""

</t>
<t tx="ekr.20080121105837.741">def open(self):
    self._gathering = True
    self._text = ""
    
</t>
<t tx="ekr.20080121105837.742">def close(self):
    self._gathering = False

</t>
<t tx="ekr.20080121105837.743">def text(self):
    return self._text

</t>
<t tx="ekr.20080121105837.744">def append(self, text):
    self._text += text
    
</t>
<t tx="ekr.20080121105837.745">def replace(self, text):
    self._text = text

</t>
<t tx="ekr.20080121105837.746">def is_gathering(self):
    return self._gathering

</t>
<t tx="ekr.20080121105837.747">class Lexer:
    @others
</t>
<t tx="ekr.20080121105837.748">def __init__(self):
    self.gen = self._get_next_token
    self.pending_tokens = []
    self.curr_indentation = 0
    self.curr_comments = []
    self.finished_comment = True
    self.use_leading_spaces = True
    self.signature = Signature()
    self.q = []
    self.curr_line = 1

</t>
<t tx="ekr.20080121105837.749">def build_dict(self, ws_sep_str):
    the_dict = {}
    for the_key in ws_sep_str.strip().split():
        the_dict[the_key] = 1
    return the_dict


</t>
<t tx="ekr.20080121105837.750">def is_string_token(self, tok):
    return tok.style in self.string_types


</t>
<t tx="ekr.20080121105837.751">def contains_nl(self, str2):
    return str2.find("\n") &gt;= 0

</t>
<t tx="ekr.20080121105837.752">def _adapt_line(self, line_num):
    if line_num is None:
        return None
    return line_num + 1

</t>
<t tx="ekr.20080121105837.753">def _get_next_token(self):
    if len(self.pending_tokens) &gt; 0:
        tok = self.pending_tokens[0]
        del self.pending_tokens[0]
    elif len(self.q) &gt; 0:
        raw_tok = self.q[0]
        del self.q[0]
        tok = Token(raw_tok['style'],
                    raw_tok['text'],
                    raw_tok['start_column'],
                    self._adapt_line(raw_tok.get('start_line', None)),
                    raw_tok.get('end_column',None),
                    self._adapt_line(raw_tok.get('end_line',None)))
    else:
        tok = EOF_TOKEN
    return tok

</t>
<t tx="ekr.20080121105837.754">def _get_eof_token(self):
    return EOF_TOKEN
        
</t>
<t tx="ekr.20080121105837.755">def matches_whitespace(self, text):
    return ws_re.match(text)

</t>
<t tx="ekr.20080121105837.756">def get_curr_indentation(self):
    return self.curr_indentation

</t>
<t tx="ekr.20080121105837.757">def curr_comment(self, destroy=1):
    hold = self.curr_comments
    self.curr_comments = []
    return hold

</t>
<t tx="ekr.20080121105837.758">def clear_comments(self):
    self.curr_comments = []

</t>
<t tx="ekr.20080121105837.759">def has_comment(self):
    return len(self.curr_comments) &gt; 0

</t>
<t tx="ekr.20080121105837.760">def is_udl_markup_family(self, ttype):
    return ScintillaConstants.SCE_UDL_M_DEFAULT &lt;= ttype &lt;= ScintillaConstants.SCE_UDL_M_COMMENT

</t>
<t tx="ekr.20080121105837.761">def is_udl_css_family(self, ttype):
    return ScintillaConstants.SCE_UDL_CSS_DEFAULT &lt;= ttype &lt;= ScintillaConstants.SCE_UDL_CSS_OPERATOR

</t>
<t tx="ekr.20080121105837.762">def is_udl_csl_family(self, ttype):
    return ScintillaConstants.SCE_UDL_CSL_DEFAULT &lt;= ttype &lt;= ScintillaConstants.SCE_UDL_CSL_REGEX

</t>
<t tx="ekr.20080121105837.763">def is_udl_ssl_family(self, ttype):
    return ScintillaConstants.SCE_UDL_SSL_DEFAULT &lt;= ttype &lt;= ScintillaConstants.SCE_UDL_SSL_VARIABLE

</t>
<t tx="ekr.20080121105837.764">def is_udl_tpl_family(self, ttype):
    return ScintillaConstants.SCE_UDL_TPL_DEFAULT &lt;= ttype &lt;= ScintillaConstants.SCE_UDL_TPL_VARIABLE

</t>
<t tx="ekr.20080121105837.765"># Methods for manipulating signatures

def start_sig(self):
    self.signature.open()

</t>
<t tx="ekr.20080121105837.766">def stop_sig(self):
    self.signature.close()

</t>
<t tx="ekr.20080121105837.767">def trim_ws(self, s1):
    s2 = trim_ws_re2.sub(' ', s1)
    s3 = trim_ws_re3.sub(' ', s2)
    s4 = s3.strip()
    if len(s4) == 0:
        if len(s1) &gt; 0:
            return " "
    return s4

</t>
<t tx="ekr.20080121105837.768">def get_sig(self):
    return self.signature.text().strip()

</t>
<t tx="ekr.20080121105837.769"># Main external routines
        
def put_back(self, tok):
    if self.signature.is_gathering():
        sig = self.signature.text()
        last_text = tok.text
        if sig[-len(last_text):] == last_text:
            sig = sig[0:-len(last_text)]
            self.signature.replace(sig)
    self.pending_tokens.append(tok)
    if not (tok.start_line is None):
        # Move back for the current line #
        self.curr_line = tok.start_line

</t>
<t tx="ekr.20080121105837.770">def curr_line_no(self):
    return self.curr_line

</t>
<t tx="ekr.20080121105837.771">def append_split_tokens(self, tok, multi_char_ops_dict, dest_q):
    tval = tok['text']
    split_tokens = []
    while len(tval) &gt; 0:
        if multi_char_ops_dict.has_key(tval):
            split_tokens.append(tval)
            break
        else:
            #XXX Handle allowed prefixes, as in "&lt;&lt;" and "&lt;&lt;="
            found_something = False
            for possible_op in multi_char_ops_dict.keys():
                if tval.startswith(possible_op):
                    split_tokens.append(possible_op)
                    tval = tval[len(possible_op):]
                    found_something = True
                    break
            if not found_something:
                split_tokens.append(tval[0])
                tval = tval[1:]
    if len(split_tokens) &gt; 1:
        col = tok['start_column']
        for stxt in split_tokens:
            new_tok = copy.copy(tok)
            new_tok['text'] = stxt
            new_tok['start_column'] = col
            new_tok['end_column'] = col + len(stxt) - 1
            col = new_tok['end_column']
            dest_q.append(new_tok)
    else:
        dest_q.append(tok)


</t>
<t tx="ekr.20080121105837.772">def get_next_token(self, skip_ws=1):
    while True:
        is_pending = len(self.pending_tokens) &gt; 0
        tok = self.gen()
        gather = self.signature.is_gathering() and not getattr(tok, "generated", False)
        if not (tok.start_line is None):
            self.curr_line = tok.start_line
        ttype = tok.style
        if ttype == EOF_STYLE:
            # Stop leaning on the queue, just return an eof_token
            self.gen = self._get_eof_token
            self.curr_indentation = 0
        elif ttype == self.classifier.style_comment:
            if self.finished_comment:
                self.curr_comments = []
                self.finished_comment = False
            self.curr_comments.append(tok.text)
            self.use_leading_spaces = False
            if skip_ws:
                continue
        elif ttype == self.classifier.style_default and self.matches_whitespace(tok.text):
            if gather:
                self.signature.append(self.trim_ws(tok.text))
            has_nl = self.contains_nl(tok.text)
            if has_nl or self.use_leading_spaces:
                # Update this line's indentation only if we're at the start
                if has_nl:
                    try:
                        self.curr_indentation = len(trailing_spaces_re.findall(tok.text)[-1])
                    except:
                        self.curr_indentation = 0
                else:
                    self.curr_indentation = len(tok.text)
                # Do we still need to count white-space in subsequent tokens?
                self.use_leading_spaces = (self.curr_indentation == 0)
            if skip_ws:
                continue
        else:
            # At this point we're done with comments and leading white-space
            if gather:
                self.signature.append(tok.text)
            self.finished_comment = True
            self.use_leading_spaces = False
        # If the loop doesn't continue, break here
        break
    return tok


</t>
<t tx="ekr.20080121105837.773">class UDLLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""
    @others
</t>
<t tx="ekr.20080121105837.774">
def is_comment(self, ttype):
    return ttype in (ScintillaConstants.SCE_UDL_SSL_COMMENT,
                     ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK)

</t>
<t tx="ekr.20080121105837.775">@property
def style_comment(self):
    return ScintillaConstants.SCE_UDL_SSL_COMMENT

</t>
<t tx="ekr.20080121105837.776">@property
def style_default(self):
    return ScintillaConstants.SCE_UDL_SSL_DEFAULT
    
</t>
<t tx="ekr.20080121105837.777">@property
def style_operator(self):
    return ScintillaConstants.SCE_UDL_SSL_OPERATOR


</t>
<t tx="ekr.20080121105837.778">def read_and_detab(fs, closefd=False, tabwidth=8):
    sample_code = ""
    try:
        # Decompress tabs so our indentation calculations work
        lines = []
        for line in fs:
            lines.append(line.expandtabs(tabwidth))
        sample_code = "".join(lines)
    finally:
        if closefd:
            fs.close()
    return sample_code

</t>
<t tx="ekr.20080121105837.779">def main(argv, provide_sample_code, specificLexer):
    if len(argv) == 1:
        sample_code = provide_sample_code();
        fs = None
    elif argv[1] == "-":
        fs = sys.stdin
    else:
        fs = open(argv[1], "r")
    if fs is not None:
        sample_code = read_and_detab(fs)
        # fs comes back closed

    lexer_wrapper = specificLexer(sample_code)
    last_line = -1
    while 1:
        tok = lexer_wrapper.get_next_token(1)
        if tok.style == EOF_STYLE:
            break
        if last_line != tok.start_line:
            print "[%d:%d] " % (tok.start_line, lexer_wrapper.curr_indentation),
            last_line = tok.start_line
        if lexer_wrapper.has_comment():
            comments = lexer_wrapper.curr_comment(1)
            print comments
        tok.dump()
</t>
<t tx="ekr.20080121105837.780">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.781"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#

""" Many CILE parsers have to allow for tokens to arrive with
either native Scintilla types, or UDL types (and there might be
more in the future.

This module defines the abstraction layer over the UDL types.

Some routines can't fulfill a request just by looking at the type,
and need to examine the actual text of the token.  But a common
UDL layer can't do that, as each SSL language has different properties.
So callbacks that return to the SSL CILE are used for that purpose.

See ruby_parser.py for examples on writing callbacks for
get_builtin_type, is_interpolating_string, and
tokenStyleToContainerStyle (if any of these are called, that is).

"""
import re

from SilverCity import Ruby, ScintillaConstants

GENERIC_TYPE_UNKNOWN = 0
GENERIC_TYPE_NUMBER = 1
GENERIC_TYPE_STRING = 2
GENERIC_TYPE_REGEX = 3

</t>
<t tx="ekr.20080121105837.782">class CommonClassifier:
    _quote_patterns = {}    

    @others
</t>
<t tx="ekr.20080121105837.783">def get_quote_patterns(self, tok, callback=None):
    ttype = tok.style
    if self._quote_patterns.has_key(ttype):
        return [self._quote_patterns[ttype]]
    elif callback:
        return callback(tok)
    else:
        return self._quote_patterns.values()

</t>
<t tx="ekr.20080121105837.784">def is_identifier_or_keyword(self, tok):
    return self.is_identifier(tok, True)


</t>
<t tx="ekr.20080121105837.785">class UDLClassifier(CommonClassifier):
    @others
</t>
<t tx="ekr.20080121105837.786">def get_builtin_type(self, tok, callback):
    if self.is_number(tok):
        return callback(tok, GENERIC_TYPE_NUMBER)
    elif self.is_string(tok):
        return callback(tok, GENERIC_TYPE_STRING)
    elif tok.style == ScintillaConstants.SCE_UDL_SSL_REGEX:
        return callback(tok, GENERIC_TYPE_REGEX)
    else:
        return callback(tok, GENERIC_TYPE_UNKNOWN)

</t>
<t tx="ekr.20080121105837.787">def is_any_operator(self, tok):
    return tok.style == ScintillaConstants.SCE_UDL_SSL_OPERATOR

</t>
<t tx="ekr.20080121105837.788">def is_comment(self, tok):
    return tok.style in (ScintillaConstants.SCE_UDL_SSL_COMMENT,
                         ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK)

</t>
<t tx="ekr.20080121105837.789">def is_comment_structured(self, tok, callback):
    return self.is_comment(tok) and callback and callback(tok)

</t>
<t tx="ekr.20080121105837.790">def is_identifier(self, tok, allow_keywords=False):
    return (tok.style == ScintillaConstants.SCE_UDL_SSL_IDENTIFIER or
        (allow_keywords and
         tok.style == ScintillaConstants.SCE_UDL_SSL_WORD))

</t>
<t tx="ekr.20080121105837.791">def is_index_op(self, tok, pattern=None):
    if tok.style != ScintillaConstants.SCE_UDL_SSL_OPERATOR:
        return False
    elif not pattern:
        return True
    return len(tok.text) &gt; 0 and pattern.search(tok.text)

</t>
<t tx="ekr.20080121105837.792"># Everything gets lexed as a string, so we need to look at its structure.
# We call back to the main CILE parser, which knows more about which kinds
# of strings can interpolate other values.  This routine assumes all regexes
# can interpolate.

def is_interpolating_string(self, tok, callback):
    if tok.style == ScintillaConstants.SCE_UDL_SSL_REGEX:
        return callback(tok, GENERIC_TYPE_REGEX)
    elif not self.is_string(tok):
        return False
    else:
        return callback(tok, GENERIC_TYPE_STRING)

</t>
<t tx="ekr.20080121105837.793">def is_keyword(self, tok, target):
    return tok.style == ScintillaConstants.SCE_UDL_SSL_WORD and tok.text == target

</t>
<t tx="ekr.20080121105837.794">def is_number(self, tok):
    return tok.style == ScintillaConstants.SCE_UDL_SSL_NUMBER

</t>
<t tx="ekr.20080121105837.795">def is_operator(self, tok, target):
    return tok.style == ScintillaConstants.SCE_UDL_SSL_OPERATOR and tok.text == target

</t>
<t tx="ekr.20080121105837.796">def is_string(self, tok):
    return tok.style == ScintillaConstants.SCE_UDL_SSL_STRING

</t>
<t tx="ekr.20080121105837.797">def is_string_qw(self, tok, callback=None):
    return (tok.style == ScintillaConstants.SCE_UDL_SSL_STRING and
            callback and callback(tok))

</t>
<t tx="ekr.20080121105837.798">def is_symbol(self, tok, callback=None):
    return (tok.style == ScintillaConstants.SCE_UDL_SSL_STRING and
            callback and callback(tok))

</t>
<t tx="ekr.20080121105837.799">def is_variable(self, tok):
    return tok.style in (ScintillaConstants.SCE_UDL_SSL_VARIABLE,
                         ScintillaConstants.SCE_UDL_SSL_IDENTIFIER)

</t>
<t tx="ekr.20080121105837.800"># Types of variables
def is_variable_array(self, tok, callback=None):
    if not self.is_variable(tok):
        return False
    else:
        return callback and callback(tok)

</t>
<t tx="ekr.20080121105837.801">def is_variable_scalar(self, tok, callback=None):
    if not self.is_variable(tok):
        return False
    else:
        return callback and callback(tok)

</t>
<t tx="ekr.20080121105837.802">def tokenStyleToContainerStyle(self, tok, callback):
    return callback(tok, tok.style == ScintillaConstants.SCE_UDL_SSL_VARIABLE)

</t>
<t tx="ekr.20080121105837.803"># Accessors for where we'd rather work with a style than call a predicate fn

@property
def style_identifier(self):
    return ScintillaConstants.SCE_UDL_SSL_IDENTIFIER

</t>
<t tx="ekr.20080121105837.804">@property
def style_operator(self):
    return ScintillaConstants.SCE_UDL_SSL_OPERATOR

</t>
<t tx="ekr.20080121105837.805">@property
def style_word(self):
    return ScintillaConstants.SCE_UDL_SSL_WORD
</t>
<t tx="ekr.20080121105837.806">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    shared_lexer.main(sys.argv, provide_sample_code, TclLexer)
@ignore</t>
<t tx="ekr.20080121105837.807"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""
Tcl lexing support for codeintel/tclcile.py

Get all the lexed tokens from SilverCity, and then return them
on demand to the caller (usually a Tcl pseudo-parser).

Usage:
import tcl_lexer
lexer = lex_wrapper.Lexer(code)
while 1:
    tok = lexer.get_next_token()
    if tok[0] == EOF_STYLE:
        break;
    # tok is an array of (style, text, start-col, start-line, end-col, end-line)
    # column and line numbers are all zero-based.
"""

import copy
import re
import sys
import string

import SilverCity
from SilverCity import ScintillaConstants
import shared_lexer
from shared_lexer import EOF_STYLE

from codeintel2 import lang_tcl

</t>
<t tx="ekr.20080121105837.808">class TclLexerClassifier:
    """ This classifier is similar to the parser-level classifier, but
    it works on the SilverCity "raw" tokens as opposed to the
    tokens that get created by the lexer layer.  There should be some
    folding though."""    
    @others
</t>
<t tx="ekr.20080121105837.809">
def is_comment(self, ttype):
    return ttype == ScintillaConstants.SCE_TCL_COMMENT
    
</t>
<t tx="ekr.20080121105837.810">@property
def style_comment(self):
    return ScintillaConstants.SCE_TCL_COMMENT
    
</t>
<t tx="ekr.20080121105837.811">@property
def style_default(self):
    return ScintillaConstants.SCE_TCL_DEFAULT

</t>
<t tx="ekr.20080121105837.812">@property
def style_operator(self):
    return ScintillaConstants.SCE_TCL_OPERATOR

</t>
<t tx="ekr.20080121105837.813">#---- global data

op_re = re.compile(r'(.*?)([\\\{\}\[\]])(.*)')

class TclLexer(shared_lexer.Lexer):
    @others
</t>
<t tx="ekr.20080121105837.814">def __init__(self, code):
    shared_lexer.Lexer.__init__(self)
    self.q = []
    self.classifier = TclLexerClassifier()
    lang_tcl.TclLexer().tokenize_by_style(code, self._fix_token_list)
    # Tcl.TclLexer().tokenize_by_style(code, self._fix_token_list)
    # self._fix_token_list(q_tmp) # Updates self.q in place
    self.string_types = [ScintillaConstants.SCE_TCL_STRING,
                     ScintillaConstants.SCE_TCL_CHARACTER,
                     ScintillaConstants.SCE_TCL_LITERAL
                     ]
    
</t>
<t tx="ekr.20080121105837.815">def _fix_token_list(self, **tok):
    """ Same as perl_lexer: split op tokens into separate
        recognizable operators.
    """
    if tok['start_column'] &gt; shared_lexer.MAX_REASONABLE_LIMIT:
        return
    tval = tok['text']
    if tok['style'] == ScintillaConstants.SCE_TCL_OPERATOR and len(tval) &gt; 1:
        # In Tcl rely on white-space to separate arg things except for braces and brackets
        col = tok['start_column']
        tval_accum = ""
        new_tokens = []
        while True:
            m = op_re.match(tval)
            if m:
                before, op, after = m.groups()
                if op == '\\':
                    if len(after) &gt; 0:
                        tval_accum += before + op + after[0]
                        tval = after[1:]
                    else:
                        new_tokens.append(tval_accum + before + op)
                        break
                else:
                    tval_accum += before
                    if len(tval_accum) &gt; 0:
                        new_tokens.append(tval_accum)
                    new_tokens.append(op)
                    tval = after
            else:           
                tval_accum += tval
                if len(tval_accum) &gt; 0:
                    new_tokens.append(tval_accum)
                break
        if len(new_tokens) == 1:           
            self.q.append(tok)
        else:
            col = tok['start_column']
            for stxt in new_tokens:
                new_tok = copy.copy(tok)
                new_tok['text'] = stxt
                new_tok['start_column'] = col
                new_tok['end_column'] = col + len(stxt) - 1
                col = new_tok['end_column']
                self.q.append(new_tok)
    else:
        self.q.append(tok)

</t>
<t tx="ekr.20080121105837.816">def provide_sample_code():
    return r"""# ----------------------------------------------------------------------------
#  Command Dialog::create
# ----------------------------------------------------------------------------
proc Dialog::create { path args } {
    global   tcl_platform
    variable _widget

    array set maps [list Dialog {} .bbox {}]
    array set maps [Widget::parseArgs Dialog $args]

    # Check to see if the -class flag was specified
    set dialogClass "Dialog"
    array set dialogArgs $maps(Dialog)
    if { [info exists dialogArgs(-class)] } {
    set dialogClass $dialogArgs(-class)
    }

    puts "Test a long string" ; # proper comment
    puts "bogus comment follows -- no ;" # proper comment
}

"""


</t>
<t tx="ekr.20080121105837.817">@language python
@tabwidth -4
@others
# end class Parser

if __name__ == "__main__":
    if len(sys.argv) == 1:
        sample_code = tcl_lexer.provide_sample_code();
        fs = None
    elif sys.argv[1] == "-":
        fs = sys.stdin
        closefs = False
    else:
        fs = open(sys.argv[1], "r")
        closefs = True
    if fs is not None:
        sample_code = shared_lexer.read_and_detab(fs, closefs)
        # fs comes back closed
    tokenizer = tcl_lexer.TclLexer(sample_code)
    parser = Parser(tokenizer, "Tcl")
    tree = parser.parse()
    print "Analyze the parse tree"
    tree.dump()
</t>
<t tx="ekr.20080121105837.818"># ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)

"""Tcl parsing support for codeintel/tclcile.py"""

import string
import sys
import re
import textwrap

from SilverCity import ScintillaConstants
from codeintel2 import tcl_lexer
from codeintel2 import shared_lexer
from codeintel2 import shared_parser
from codeintel2.parser_data import Name_LineNum, VarInfo, Node, ClassNode, \
     FileNode, ArgNode, MethodNode, ModuleNode, VariableNode, BlockNode, \
     update_collection
from codeintel2.parser_data import VAR_KIND_GLOBAL, VAR_KIND_LOCAL

</t>
<t tx="ekr.20080121105837.819">class TclClassifier(shared_parser.CommonClassifier):
    _quote_patterns = {ScintillaConstants.SCE_TCL_STRING : re.compile('^\"(.*)\"$'),
                       ScintillaConstants.SCE_TCL_DEFAULT : re.compile('^.(.*).$'),
                       }

    @others
</t>
<t tx="ekr.20080121105837.820">def get_builtin_type(self, tok, callback):
    if self.is_number(tok):
        numval = tok.text
        if numval.find(".") &gt;= 0:
            return "Float"
        else:
            return "Fixnum" 
    elif self.is_string(tok):
        return "String"
    return None
    
</t>
<t tx="ekr.20080121105837.821">def is_any_operator(self, tok):
    return tok.style == ScintillaConstants.SCE_TCL_OPERATOR

</t>
<t tx="ekr.20080121105837.822">def is_comment(self, tok):
    return tok.style == ScintillaConstants.SCE_TCL_COMMENT

</t>
<t tx="ekr.20080121105837.823">def is_comment_structured(self, tok, callback):
    return False

</t>
<t tx="ekr.20080121105837.824">def is_identifier(self, tok, allow_keywords=False):
    return (tok.style == ScintillaConstants.SCE_TCL_IDENTIFIER or
        (allow_keywords and
         tok.style == ScintillaConstants.SCE_TCL_WORD))

</t>
<t tx="ekr.20080121105837.825">def is_interpolating_string(self, tok, callback):
    return tok.style == ScintillaConstants.SCE_TCL_STRING

</t>
<t tx="ekr.20080121105837.826">def is_keyword(self, tok, target):
    return tok.style == ScintillaConstants.SCE_TCL_WORD and tok.text == target

</t>
<t tx="ekr.20080121105837.827">def is_number(self, tok):
    return tok.style == ScintillaConstants.SCE_TCL_NUMBER

</t>
<t tx="ekr.20080121105837.828">def is_operator(self, tok, target):
    return tok.style == ScintillaConstants.SCE_TCL_OPERATOR and tok.text == target

</t>
<t tx="ekr.20080121105837.829">def is_string(self, tok):
    return tok.style in [ScintillaConstants.SCE_TCL_STRING,
                         ScintillaConstants.SCE_TCL_CHARACTER,
                         ScintillaConstants.SCE_TCL_LITERAL
                         ]

</t>
<t tx="ekr.20080121105837.830">def is_symbol(self, tok):
    return False

</t>
<t tx="ekr.20080121105837.831">def quote_patterns_cb(tok):
    tval = tok.text
    if tval[0] == '"':
        return _quote_patterns[SCE_TCL_STRING]
    elif tval[0] == '\'':
        return _quote_patterns[SCE_TCL_CHARACTER]
    else:
        return _quote_patterns[SCE_TCL_DEFAULT] # Fallback

</t>
<t tx="ekr.20080121105837.832"># Accessors for where we'd rather work with a style than call a predicate fn

@property
def style_identifier(self):
    return ScintillaConstants.SCE_TCL_IDENTIFIER

</t>
<t tx="ekr.20080121105837.833">@property
def style_operator(self):
    return ScintillaConstants.SCE_TCL_OPERATOR

</t>
<t tx="ekr.20080121105837.834">@property
def style_word(self):
    return ScintillaConstants.SCE_TCL_WORD

</t>
<t tx="ekr.20080121105837.835">lang_specific_classes = {"Tcl": TclClassifier,
                         "AOL" : shared_parser.UDLClassifier}

leading_hash_re = re.compile(r'^\s*\#+\s*')
mostly_dashes = re.compile(r'\s*-{10}')
spaces_and_braces_re = re.compile(r'\s*\}\s*$')

def remove_hashes(lines):
    len1 = len(lines)
    if len1 == 0:
        return []
    set1 = [leading_hash_re.sub("", s) for s in lines]
    if len1 &gt; 0 and mostly_dashes.match(set1[0]):
        del set1[0]
    if len1 &gt; 1 and mostly_dashes.match(set1[-1]):
        del set1[-1]
    return set1

</t>
<t tx="ekr.20080121105837.836"># Parse Tcl code
class Parser:
    @others
    # end parse_aux()
        

</t>
<t tx="ekr.20080121105837.837">def __init__(self, tokenizer, lang):
    self.tokenizer = tokenizer
    self.block_stack = []
    self.tree = FileNode()
    self.curr_node = self.tree
    self.classifier = lang_specific_classes[lang]()
    self.containers = {VAR_KIND_GLOBAL : [self.tree.global_vars],
                       VAR_KIND_LOCAL : [self.tree.local_vars]} #locals
    
</t>
<t tx="ekr.20080121105837.838">def get_fully_qualified_name(self):
    tok = self.tokenizer.get_next_token()
    if tok.style == shared_lexer.EOF_STYLE:
        return (None, None)
    name_start = tok.text
    line_start = tok.start_line
    # Watch out if it starts with a "::"
    if name_start == "::":
        col = tok.end_column + 1
        tok = self.tokenizer.get_next_token()
        if tok.start_column != col or not self.classifier.is_identifier(tok):
            self.tokenizer.put_back(tok)
            return (name_start, line_start)
        name_start += tok.text
        
    col = tok.end_column + 1
    while 1:
        # Collect operator-type methods
        tok = self.tokenizer.get_next_token()
        if tok.start_column == col and self.classifier.is_operator(tok, "::"):
            name_start += tok.text
            col += 2
        else:
            self.tokenizer.put_back(tok)
            break
        
        tok = self.tokenizer.get_next_token()
        if tok.start_column == col and self.classifier.is_identifier(tok, True):
            name_start += tok.text                
            col = tok.end_column + 1
        else:
            self.tokenizer.put_back(tok)
            break
    return (name_start, line_start)  
       
</t>
<t tx="ekr.20080121105837.839">def parse(self):
    while self.parse_aux(self.tree):
        pass
    return self.tree
    
</t>
<t tx="ekr.20080121105837.840">def get_parsing_objects(self, kwd):
    return {
        "namespace": [ModuleNode, self.parse_aux],
        "proc" : [MethodNode, self.parse_method]
    }.get(kwd, [None, None])

</t>
<t tx="ekr.20080121105837.841">def parse_method(self, curr_node):
    # Syntax: proc name { args } { body }
    tok = self.tokenizer.get_next_token()
    if self.classifier.is_operator(tok, "{"):
        # Standard, keep going
        do_regular_args = True
    elif self.classifier.is_identifier(tok):
        # Assume it's the one arg
        if tok.text == "args":
            curr_node.add_arg(tok.text, None, "varargs")
        else:
            curr_node.add_arg(tok.text)
        curr_node.signature = "%s {%s}" % (curr_node.name, tok.text)
        do_regular_args = False
    else:
        self.tokenizer.put_back(tok)
        return
    
    if do_regular_args:
        braceCount = 1
        init_indentation = curr_node.indentation
        tok_count = 0
        tok_lim = 1000
        self.tokenizer.start_sig()
        argStart = True
        while 1:
            tok = self.tokenizer.get_next_token()
            if self.classifier.is_any_operator(tok):
                argStart = False
                tval = tok.text
                if tval == "{":
                    braceCount += 1
                    if braceCount == 2:
                        argStart = True
                elif tval == "}":
                    braceCount -= 1
                    if braceCount &lt;= 0:
                        break
                    elif braceCount == 1:
                        argStart = True
            elif argStart:
                if braceCount == 2: # Wait for a } to get next arg.
                    argStart = False
                if self.classifier.is_identifier(tok, True):
                    if tok.text == "args" and braceCount == 1:
                        # We need to peek at the next token
                        tok2 = self.tokenizer.get_next_token()
                        if self.classifier.is_operator(tok2, "}"):
                            curr_node.add_arg(tok.text, None, "varargs")
                            break
                        else:
                            self.tokenizer.put_back(tok2)
                    curr_node.add_arg(tok.text)
            tok_count += 1
            if tok_count &gt; tok_lim and tok.start_column &lt; init_indentation:
                break
        
        self.tokenizer.stop_sig()
        #XXX Check white-space in the sig
        # We don't know we've hit the end of the sig until we hit
        # that final "}", so we need to pull it out.
        curr_node.signature = "%s {%s}" % (curr_node.name,
                                           spaces_and_braces_re.sub('', self.tokenizer.get_sig()))
    
    # Now get the body
    tok = self.tokenizer.get_next_token()
    if not self.classifier.is_operator(tok, "{"):
        # Give up
        self.tokenizer.put_back(tok)
        return
    braceCount = 1
    self.parse_aux(curr_node, 1) # Count the brace we just saw.
</t>
<t tx="ekr.20080121105837.842"># end parse_method

def parse_assignment(self, tok_text, start_line, isLocal=True):
    # Don't bother trying to type it yet.
    # Figure out whether we're in a proc or not

    if isLocal:
        collectionA = self.containers[VAR_KIND_LOCAL]
    else:
        collectionA = self.containers[VAR_KIND_GLOBAL]

    if len(collectionA) == 0 or collectionA[-1] is None:
        return
    possibleType = self._finishVarAssignment(collectionA, tok_text, start_line)
    update_collection(collectionA[-1], tok_text, start_line, possibleType)
    
</t>
<t tx="ekr.20080121105837.843">def _finishVarAssignment(self, collectionA, var_name, start_line):
    #XXX Add type info
    return None
    
</t>
<t tx="ekr.20080121105837.844">def parse_aux(self, curr_node, braceCount=0):
    init_indentation = curr_node.indentation
    tok_count = 0
    tok_lim = 1000
    cmdStart = True
    curr_globals = {}
    while 1:
        tok = self.tokenizer.get_next_token()
        if tok.style == shared_lexer.EOF_STYLE:
            break
        # style, text, start_column, start_line, end_column, end_line = tok
        style, text = tok.style, tok.text
        if style == self.classifier.style_word and \
           (cmdStart or tok.start_column == self.tokenizer.get_curr_indentation()):
            cmdStart = False
            if text in ["namespace", "proc"]:
                curr_indent = self.tokenizer.get_curr_indentation()
                if text == "namespace":
                    tok1 = self.tokenizer.get_next_token()
                    if not (self.classifier.is_identifier(tok1, True) and tok1.text == "eval"):
                        continue
                node_class, node_parser = self.get_parsing_objects(text)
                if node_class is None:
                    sys.stderr.write("Couldn't get parsing objects for type %s\n" % text)
                    break
                
                # Get the comments before further parsing.
                comment_lines = remove_hashes(self.tokenizer.curr_comment())
                nm_token = self.get_fully_qualified_name()
                fqname = nm_token[0]
                if not fqname:
                    break                    
                # Handle only local names for now
                if fqname.startswith("::") and  text == "namespace":
                        fqname = fqname[2:]

                new_node = node_class(fqname, tok.start_line)
                new_node.doc_lines = comment_lines
                new_node.indentation = curr_indent
                self.block_stack.append(new_node)
                curr_node.append_node(new_node)

                # Push new containers on the symbol table
                self.containers[VAR_KIND_LOCAL].append(new_node.local_vars)

                node_parser(new_node)  # Has self bound to it
                self.block_stack.pop()
                self.containers[VAR_KIND_LOCAL].pop()

                # Clear any comment that's hanging around
                self.tokenizer.clear_comments()

            elif text == "package":
                tok1 = self.tokenizer.get_next_token()
                if self.classifier.is_identifier(tok1, True):
                    if tok1.text == "require":
                        tok2 = self.tokenizer.get_next_token()
                        if self.classifier.is_identifier(tok2, True) and tok2.text != "Tcl":
                            curr_node.imports.append(Name_LineNum(tok2.text, tok.start_line))
            elif text == "global":
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_identifier(tok, True):
                    curr_globals[tok.text] = None
            elif text == "set":
                tok = self.tokenizer.get_next_token()
                if self.classifier.is_identifier(tok, True):
                    if curr_globals.has_key(tok.text):
                        pass
                    else:
                        self.parse_assignment(tok.text, tok.start_line, isinstance(curr_node, MethodNode))
                            
        elif self.classifier.is_any_operator(tok):
            cmdStart = False
            if text == "{":
                braceCount += 1
            elif text == "}":
                braceCount -= 1
                if braceCount &lt;= 0:
                    break
            elif text in (";", "["):
                cmdStart = True
        else:
            cmdStart = False
        # Sanity check to make sure we haven't gone too far.
        tok_count += 1
        if tok_count &gt; tok_lim and tok.start_column &lt; init_indentation:
            break
    # end while
    curr_node.set_line_end_num(self.tokenizer.curr_line_no())
    return tok.style != shared_lexer.EOF_STYLE
</t>
<t tx="ekr.20080121105837.845"></t>
<t tx="ekr.20080121105837.846">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.847">#!/usr/bin/env python

"""Completion evaluation code for JavaScript"""

import types
import re
from pprint import pformat

from codeintel2.common import *
from codeintel2.util import indent
from codeintel2.tree import TreeEvaluator


</t>
<t tx="ekr.20080121105837.848">class CandidatesForTreeEvaluator(TreeEvaluator):
    # Note: the "alt" changes added in change 281350 make some of the
    # functionality on this class *not* appropriate for the shared
    # TreeEvaluator. I.e. _elem_from_scoperef et al should be moved
    # *out* of CandidatesForTreeEvaluator.
    
    # This is a dict when set, multiple elements that have the same lpath will
    # be set in here, ensuring we get the correct one from an lpath lookup.
    # Fixes the following bug:
    #   http://bugs.activestate.com/show_bug.cgi?id=71666
    # Ideally, this would not be needed once elem.names[] can return a tuple,
    # see the following bug for reference:
    #   http://bugs.activestate.com/show_bug.cgi?id=71941
    _alt_elem_from_scoperef = None

    @others
</t>
<t tx="ekr.20080121105837.849">def _elem_from_scoperef(self, scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    i = 0
    for lname in scoperef[1]:
        i += 1
        if self._alt_elem_from_scoperef is not None:
            scoperef_names = ".".join(scoperef[1][:i])
            alt_elem = self._alt_elem_from_scoperef.get(scoperef_names)
            if alt_elem is not None:
                elem = alt_elem
                continue
        elem = elem.names[lname]
    return elem

</t>
<t tx="ekr.20080121105837.850">def _tokenize_citdl_expr(self, expr):
    for tok in expr.split('.'):
        if tok.endswith('()'):
            yield tok[:-2]
            yield '()'
        else:
            yield tok
</t>
<t tx="ekr.20080121105837.851">def _join_citdl_expr(self, tokens):
    return '.'.join(tokens).replace('.()', '()')

</t>
<t tx="ekr.20080121105837.852">class JavaScriptTreeEvaluator(CandidatesForTreeEvaluator):
    @others
</t>
<t tx="ekr.20080121105837.853">def eval_cplns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    _add_xpcom_blob(self.built_in_blob)
    hits = self._hits_from_citdl(self.expr, start_scoperef)
    if not hits:
        raise CodeIntelError("No completions found")
    # For logging messages every call
    #print indent('\n'.join("%s: %s" % (lvl, m)
    #                for lvl,m in self.ctlr.log))
    #print indent('\n'.join(["Hit: %r" % (hit, ) for hit in hits]))
    return list(self._members_from_hits(hits))

</t>
<t tx="ekr.20080121105837.854">def eval_calltips(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    _add_xpcom_blob(self.built_in_blob)
    hits = self._hits_from_citdl(self.expr, start_scoperef)
    if not hits:
        raise CodeIntelError("No calltips found")
    return self._calltips_from_hits(hits)

</t>
<t tx="ekr.20080121105837.855">def eval_defns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    _add_xpcom_blob(self.built_in_blob)
    hits = self._hits_from_citdl(self.expr, start_scoperef, defn_only=True)
    if not hits:
        raise CodeIntelError("No definitions found")
    return [ self._defn_from_hit(x) for x in hits ]

</t>
<t tx="ekr.20080121105837.856">def parent_scoperef_from_scoperef(self, scoperef,
                                  started_in_builtin_window_scope=False):
    """
    For JavaScript-in-the-browser the top-level scope is the
    Window object instance. For now we are always presuming we
    are running in the browser.

    Problem: if we *started* on the Window class then the parent
    scope should be -&gt; built-in-blob. This is what
    'started_in_builtin_window_scope' is used for.
    """
    blob, lpath = scoperef
    if not started_in_builtin_window_scope \
       and lpath == ["Window"] and blob is self.built_in_blob:
        return None
    elif lpath:
        return (blob, lpath[:-1])
    elif blob is self.built_in_blob:
        if started_in_builtin_window_scope:
            return None
        else:
            return (self.built_in_blob, ["Window"])
    else:
        return (self.built_in_blob, [])

</t>
<t tx="ekr.20080121105837.857">_langintel = None
@property
def langintel(self):
    if self._langintel is None:
        self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
    return self._langintel

</t>
<t tx="ekr.20080121105837.858">_libs = None
@property
def libs(self):
    if self._libs is None:
        self._libs = self.langintel.libs_from_buf(self.buf)
    return self._libs

</t>
<t tx="ekr.20080121105837.859">_built_in_blob = None
@property
def built_in_blob(self):
    if self._built_in_blob is None:
        # JS stdlib is always the last one.
        self._built_in_blob = self.libs[-1].get_blob("*")
    return self._built_in_blob

</t>
<t tx="ekr.20080121105837.860">def _hit_from_first_token(self, token, scoperef):
    """Find the token at the given or a parent scope.

    Returns the found elem and the scope at which it was found. If
    not found, this returns (None, None).
    """
    self.log("find '%s' starting at %s", token, scoperef)

    # Because we fake JavaScript classes and put the ctor
    # function inside the class, we need to push start scopes at
    # the class to the ctor. See test
    # javascript/cpln/ctor_scope_cheat for an example of why.
    try:
        elem = self._elem_from_scoperef(scoperef)
    except KeyError, ex:
        self.warn("_hit_from_first_token:: no elem for scoperef: %r",
                  scoperef)
        return (None, None)
    if elem.get("ilk") == "class":
        class_name = elem.get("name")
        try:
            ctor = elem.names[class_name]
        except KeyError:
            pass
        else:
            if "__ctor__" in ctor.get("attributes", ""):
                scoperef = (scoperef[0], scoperef[1]+[class_name])
                self.log("push scope to class ctor %s", scoperef)

    started_in_builtin_window_scope = (scoperef[0] is self.built_in_blob
        and scoperef[1] and scoperef[1][0] == "Window")
    while 1:
        try:
            elem = self._elem_from_scoperef(scoperef)
        except KeyError, ex:
            raise EvalError("could not resolve scoperef %r: %s"
                            % (scoperef, ex))
        try:
            candidate = elem.names[token]
            if "__ctor__" in candidate.get("attributes", ""):
                # In JavaScript we include the constructor
                # function for a (faked) class as a method.
                # We must skip it here or resolution of 'this'
                # in a JS class methods will always hit the ctor
                # instead of the class (which is by far the
                # common case).
                raise KeyError("skipping JavaScript ctor")
            self.log("is '%s' accessible on %s? yes", token, scoperef)
            return candidate, scoperef
        except KeyError:
            self.log("is '%s' accessible on %s? no", token, scoperef)
            scoperef = self.parent_scoperef_from_scoperef(scoperef,
                                started_in_builtin_window_scope)
            if not scoperef:
                return None, None

</t>
<t tx="ekr.20080121105837.861">def _members_from_hits(self, hits):
    members = set()
    for elem, scope in hits:
        # In JavaScript we include the constructor function for a
        # (faked) class as a method. Completion on an instance of
        # this class shouldn't see the ctor.
        skip_js_ctor = (elem.tag == "scope" and elem.get("ilk") == "class")

        for child in elem:
            # Only add locals when the current scope is the same
            # as the variable scope.
            attributes = child.get("attributes", "").split()
            if "__local__" in attributes:
                # XXX: Move start_scoperef to be a part of the class
                #start_scoperef = self.get_start_scoperef()
                #scope_elem = start_scoperef[0]
                #for lname in start_scoperef[1]:
                #    if elem == scope_elem:
                #        members.add( ("variable", child.get("name")) )
                #        break
                #    scope_elem = scope_elem.names[lname]
                #else: # Don't show this variable
                continue

            if child.tag == "scope":
                if skip_js_ctor and child.get("ilk") == "function" \
                   and "__ctor__" in attributes:
                    continue
                members.add( (child.get("ilk"), child.get("name")) )
            elif child.tag == "variable":
                if len(child):
                    members.add( ("namespace", child.get("name")) )
                else:
                    members.add( ("variable", child.get("name")) )
            else:
                raise NotImplementedError("unknown hit child tag '%s': %r"
                                          % (child.tag, child))
        for classref in elem.get("classrefs", "").split():
            try:
                subhits = self._hits_from_type_inference(classref, scope)
                members.update(self._members_from_hits(subhits))
            except CodeIntelError:
                pass  # Ignore when parent class not found, bug 65447
    return members

</t>
<t tx="ekr.20080121105837.862">def _calltip_from_func(self, elem):
    # See "Determining a Function CallTip" in the spec for a
    # discussion of this algorithm.
    from codeintel2.util import LINE_LIMIT
    signature = elem.get("signature")
    doc = elem.get("doc")
    ctlines = []
    if not signature:
        name = elem.get("name")
        #XXX Note difference for Tcl in _getSymbolCallTips.
        ctlines = [name + "(...)"]
    else:
        ctlines = signature.splitlines(0)
    if doc:
        ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
    return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.863">def _calltip_from_class(self, elem):
    # If the class has a defined signature then use that.
    name = elem.get("name")
    signature = elem.get("signature")
    doc = elem.get("doc")
    if signature:
        ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
        return '\n'.join(ctlines)
    elif name in elem.names:
        # Typically the class element has a contructor function of
        # the same name as the class.
        ctor = elem.names[name]
        self.log("ctor is %r", ctor)
        return self._calltip_from_func(ctor)
    else:
        ctlines = [name + "(...)"]
        if doc:
            ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
        return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.864">def _calltips_from_hits(self, hits):
    """
    c.f. CitadelEvaluator._getSymbolCallTips()
    """
    calltips = []

    for elem, scoperef in hits:
        #self.log("calltip for hit: %r", hit)
        if elem.tag == "variable":
            XXX
        elif elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk == "function":
                calltips.append(self._calltip_from_func(elem))
            elif ilk == "class":
                calltips.append(self._calltip_from_class(elem))
            else:
                raise NotImplementedError("unexpected scope ilk for "
                                          "calltip hit: %r" % elem)
        else:
            raise NotImplementedError("unexpected elem for calltip "
                                      "hit: %r" % elem)

        ## Bug 59438: adding "(from $lpath in $file)" when helpful
        ## in calltips.
        ## TODO: Don't include all (or part) when not useful:
        ##       document.getElementsByClassName -&gt; "(from document in
        ##       prototype)". The "document in" in not necessary.
        ## TODO: Bad with empty lpath: "(from  in prototype)"
        ## TODO: Problematic for test suite with "rand??" module names.
        ## TODO: Don't add for a local hit.
        #blobname = scoperef[0].get("name")
        #if blobname == "*":
        #    blobname = "stdlib"
        #scopename = '.'.join(scoperef[1])
        #calltips[-1] += "\n(from %s in %s)" % (scopename, blobname)
    return calltips

</t>
<t tx="ekr.20080121105837.865">def _hits_from_citdl(self, expr, scoperef, defn_only=False):
    self._check_infinite_recursion(expr)

    tokens = list(self._tokenize_citdl_expr(expr))

    #self.log("expr tokens: %r", tokens)

    # First part... we try to match as much as possible straight up
    hits, nconsumed = self._hits_from_first_part(tokens, scoperef)
    if not hits:
        raise CodeIntelError("could not resolve first part of '%s'" % expr)
    self.debug("_hits_from_citdl: first part: %r -&gt; %r",
               tokens[:nconsumed], hits)

    # ...the remainder.
    remaining_tokens = tokens[nconsumed:]
    for token in tokens[nconsumed:]:
        new_hits = []
        for elem, scoperef in hits:
            self.debug("_hits_from_citdl: resolve %r on %r in %r",
                       token, elem, scoperef)
            if token == "()":
                try:
                    new_hits += self._hits_from_call(elem, scoperef)
                except CodeIntelError, ex:
                    self.warn("could resolve call on %r: %s", elem, ex)
            else:
                try:
                    new_hit = self._hit_from_getattr(
                                elem, scoperef, token)
                except CodeIntelError, ex:
                    self.warn(str(ex))
                else:
                    new_hits.append(new_hit)
        hits = new_hits 

    # Resolve any variable type inferences.
    #XXX Don't we have to *recursively* resolve hits?
    #    If that is done, then need to watch out for infinite loop
    #    because _hits_from_variable_type_inference() for a variable
    #    with children just returns itself. I.e. you *can't* resolve
    #    the &lt;variable&gt; away.
    resolved_hits = []
    for elem, scoperef in hits:
        if elem.tag == "variable" and not defn_only:
            try:
                subhits = self._hits_from_variable_type_inference(
                            elem, scoperef)
            except CodeIntelError, ex:
                self.warn("could not resolve %r: %s", elem, ex)
            else:
                resolved_hits += subhits
        else:
            resolved_hits.append( (elem, scoperef) )

    return resolved_hits

</t>
<t tx="ekr.20080121105837.866">def _hits_from_call(self, elem, scoperef):
    """Resolve the function call inference for 'elem' at 'scoperef'."""
    if elem.tag == "variable":
        hits = []
        var_hits = self._hits_from_variable_type_inference(elem, scoperef)
        for var_elem, var_scoperef in var_hits:
            if var_elem != elem:
                try:
                    hits += self._hits_from_call(var_elem, var_scoperef)
                except CodeIntelError:
                    pass  # Keep trying other alternatives
        if not hits:
            raise CodeIntelError("could not resolve call on %r." % elem)
        return hits
    if elem.get("ilk") == "class":
        return [(elem, scoperef)]
    if elem.get("ilk") != "function":
        raise CodeIntelError("_hits_from_call:: unexpected element type %r"
                             % elem)
    citdl = elem.get("returns")
    if not citdl:
        raise CodeIntelError("no return type info for %r" % elem)
    self.log("_hits_from_call: resolve '%s' for %r, scoperef: %r",
             citdl, elem, scoperef)
    # scoperef has to be set to the function called
    scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
    return self._hits_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.867">def _hit_from_getattr(self, elem, scoperef, token):
    """Resolve the getattr of 'token' on the given 'elem'.

    Raises CodeIntelError if could not resolve it.

    Algorithm:
    - Try to resolve it.
    - Call a hook to make an educated guess. Some attribute names
      are strong signals as to the object type -- typically those
      for common built-in classes.
    """
    self.log("resolve getattr '%s' on %r in %r:", token, elem, scoperef)
    if elem.tag == "variable":
        hits = self._hits_from_variable_type_inference(elem, scoperef)
    else:
        assert elem.tag == "scope", "elem tag is not 'scope': %r" % elem.tag
        hits = [(elem, scoperef)]

    for hit_elem, hit_scoperef in hits:
        ilk = hit_elem.get("ilk")
        if hit_elem.tag == "variable":
            attr = hit_elem.names.get(token)
            if attr is not None:
                self.log("attr is %r on %r", attr, hit_elem)
                var_scoperef = (hit_scoperef[0],
                                hit_scoperef[1]+[hit_elem.get("name")])
                return (attr, var_scoperef)
        elif ilk == "function":
            # Internal function arguments and variables should
            # *not* resolve. And we don't support function
            # attributes.
            continue
        elif ilk == "class":
            attr = hit_elem.names.get(token)
            if attr is not None:
                self.log("attr is %r on %r", attr, hit_elem)
                if hit_scoperef:
                    class_scoperef = (hit_scoperef[0],
                                  hit_scoperef[1]+[hit_elem.get("name")])
                    # If this is a variable defined in a class, move the
                    # scope to become the position in the class where the
                    # variable was defined (usually the ctor class function)
                    # this ensures we get the right citdl lookup. See bug:
                    # http://bugs.activestate.com/show_bug.cgi?id=71343
                    lineno = int(attr.get("line", "-1"))
                    if attr.tag == "variable" and \
                       lineno &gt; int(hit_elem.get("line", "-1")) and \
                       lineno &lt;= int(hit_elem.get("lineend", "-1")):
                        # get the scope of the variable
                        blob, lpath = self.buf.scoperef_from_blob_and_line(hit_elem,
                                                                  lineno)
                        if lpath:
                            class_scoperef = (class_scoperef[0],
                                              class_scoperef[1]+lpath)
                            self.log("Updating scoperef to: %r", class_scoperef)
                else:
                    class_scoperef = (None, [hit_elem.get("name")])
                return (attr, class_scoperef)
            for classref in hit_elem.get("classrefs", "").split():
                try:
                    base_hits = self._hits_from_type_inference(classref,
                                                               hit_scoperef)
                except CodeIntelError:
                    pass  # Ignore when parent class not found, bug 65447
                else:
                    for base_elem, base_scoperef in base_hits:
                        if token in base_elem.names:
                            self.log("is '%s' from %s base class? yes",
                                     token, base_elem)
                            new_scoperef = (base_scoperef[0],
                                            base_scoperef[1]+
                                            [base_elem.get("name")])
                            return (base_elem.names[token], new_scoperef)
                        self.log("is '%s' from %s base class? no", token,
                                 base_elem)
        else:
            raise NotImplementedError("unexpected scope ilk: %r" % ilk)
    raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                         % (token, elem, scoperef))

</t>
<t tx="ekr.20080121105837.868">def _hits_from_variable_type_inference(self, elem, scoperef):
    """Resolve the type inference for 'elem' at 'scoperef'."""
    assert elem.tag == "variable"
    if len(elem) != 0:
        # This is CIX for a JavaScript custom Object instance: a
        # common pattern in JS. See test javascript/cpln/local2.
        return [(elem, scoperef)]
    citdl = elem.get("citdl")
    if not citdl:
        raise CodeIntelError("no type-inference info for %r" % elem)
    self.log("resolve '%s' type inference for %r:", citdl, elem)
    if citdl == elem.get("name") and citdl not in elem.names:
        # The citdl expression is the same as the variable name, this will
        # create a recursive citdl lookup loop. What we likely want is a
        # different match that has the same name, so we go looking for it.
        # Fix for bug: http://bugs.activestate.com/show_bug.cgi?id=71666
        self.log("_hits_from_variable_type_inference:: recursive citdl "
                  " expression found, trying alternatives.")
        try:
            parent_elem = self._elem_from_scoperef(scoperef)
        except KeyError, ex:
            raise CodeIntelError("could not resolve recursive citdl expression %r" % citdl)
        else:
            alt_hits = []
            # Look for alternative non-variable matches.
            for child in parent_elem:
                if child.tag != "variable" and child.get("name") == citdl:
                    alt_hits.append((child, scoperef))
                    # Remember the alternative hit, in case we need to
                    # look up this lpath again.
                    if self._alt_elem_from_scoperef is None:
                        self._alt_elem_from_scoperef = {}
                    alt_sref_name = ".".join(scoperef[1] + [citdl])
                    self._alt_elem_from_scoperef[alt_sref_name] = child
                    self.log("Alternative hit found: %r, scoperef: %r", child, scoperef, )
            if alt_hits:
                return alt_hits
            # Try from the parent scoperef then.
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            if scoperef is None:
                # When we run out of scope, raise an error
                raise CodeIntelError("could not resolve recursive citdl expression %r" % citdl)
            # Continue looking using _hits_from_citdl with the parent.
            self.log("Continue search for %r from the parent scope.", citdl)
    return self._hits_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.869">def _hits_from_type_inference(self, citdl, scoperef):
    """Resolve the 'citdl' type inference at 'scoperef'."""
    self.log("resolve '%s' type inference:", citdl)
    return self._hits_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.870">def _hits_from_first_part(self, tokens, scoperef):
    """Resolve the first part of the expression.
    
    If the first token is found at the global or built-in level (or
    not found at all locally) then it may be a shared namespace with
    other files in the execution set. Get that down to a list of
    hits and a remaining list of expression tokens.
    """
    elem, scoperef = self._hit_from_first_token(tokens[0], scoperef)
    if elem is not None:
        self.log("_hit_from_first_part: found elem: %s %r at %r" % (
                 elem.get("ilk") or elem.tag, elem.get("name"),
                 scoperef[1]))
        # Special handling for xpcom components
        if elem == _g_xpcom_components_elem and len(tokens) &gt; 2 and \
           tokens[1] == "interfaces":
            self.log("Ensuring xpcom interface is loaded: %r",
                     tokens[2])
            _xpcom_iid_to_cix(tokens[2])
            # Let it continue below, to find the proper cix element

    if (elem is None            # first token wasn't found
        or not scoperef[1]      # first token was found at global level
        # first token was found on built-in Window class (the top scope)
        or (scoperef[1] == ['Window'] and scoperef[0].get("name") == "*")
       ):
        # Search symbol table in execution set.
        #
        # Example: 'myPet.name.toLowerCase()' and 'myPet' is found
        # at top-level. First lookup 'myPet.name.toLowerCase'
        # (everything up to first '()'), in execution set, then
        # 'myPet.name', then 'myPet'. The last one should always hit
        # in current file, at least.
        for first_call_idx, token in enumerate(tokens):
            if token == "()":
                break
        else:
            first_call_idx = len(tokens)

        hits = []
        for nconsumed in range(first_call_idx, 0, -1):
            lpath = tuple(tokens[:nconsumed]) # for hits_from_lpath()
            if elem is not None and len(lpath) &gt; 1:
                # Try at the current elem we found in the file
                try:
                    self.log("Checking for deeper local match %r from scoperef %r" % (lpath[1:], scoperef))
                    check_elem = elem
                    for p in lpath[1:]:   # we matched first token already
                        check_elem = check_elem.names[p]
                    check_scoperef = (scoperef[0], scoperef[1] + list(lpath[:-1]))
                    hits.insert(0, (check_elem,
                                    check_scoperef))
                    self.log("_hit_from_first_part: found deeper local elem: "\
                             "%s %r at %r" % (
                            check_elem.get("ilk") or check_elem.tag,
                            check_elem.get("name"),
                            check_scoperef[1]))
                except KeyError:
                    pass

            for lib in self.libs:
                self.log("lookup '%s' in %s", '.'.join(lpath), lib)
                hits_here = lib.hits_from_lpath(lpath, self.ctlr,
                                                curr_buf=self.buf)
                if hits_here:
                    self.log("found %d hits in lib", len(hits_here))
                    hits += hits_here
            if hits:
                break
        if elem is not None:
            if not hits or nconsumed == 1:
                hits.insert(0, (elem, scoperef))
                nconsumed = 1
            else:
                # Hits were found in the libs that are deeper than
                # the hit in the local buf: we need to adjust the
                # local hit.
                new_elem = elem
                for token in tokens[1:nconsumed]:
                    try:
                        new_elem = new_elem.names[token]
                    except KeyError:
                        break
                else:
                    if new_elem not in (e for e,sr in hits):
                        new_scoperef = (scoperef[0], tokens[:nconsumed-1])
                        hits.insert(0, (new_elem, new_scoperef))
    else:
        hits = [(elem, scoperef)]
        nconsumed = 1

    return hits, nconsumed


</t>
<t tx="ekr.20080121105837.871">#####################################
# Devel work
#####################################

# Dictionary of already created xpcom wrappers, used so we do not keep
# creating xpcom instances / services
from ciElementTree import Element, SubElement, dump
try:
    from xpcom import xpt
    _xpcom_ = True
    import xpcom.xpt
    from gencix_utils import *
    
    # Dictionary of known xpcom types and what they map to in JavaScript
    javascript_type_from_xpt_tag = {
        xpt.T_I8                : "Number",
        xpt.T_I16               : "Number",
        xpt.T_I32               : "Number",
        xpt.T_I64               : "Number",
        xpt.T_U8                : "Number",
        xpt.T_U16               : "Number",
        xpt.T_U32               : "Number",
        xpt.T_U64               : "Number",
        xpt.T_FLOAT             : "Number",
        xpt.T_DOUBLE            : "Number",
        xpt.T_BOOL              : "Boolean",
        xpt.T_CHAR              : "String",
        xpt.T_WCHAR             : "String",
        xpt.T_VOID              : "void",
        xpt.T_IID               : None,
        xpt.T_DOMSTRING         : "DOMString",
        xpt.T_CHAR_STR          : "String",
        xpt.T_WCHAR_STR         : "String",
        xpt.T_INTERFACE         : None,
        xpt.T_INTERFACE_IS      : None,
        xpt.T_ARRAY             : "Array",
        xpt.T_PSTRING_SIZE_IS   : None,
        xpt.T_PWSTRING_SIZE_IS  : None,
        # These are missing from xpt, when these cross the xpconnect boundary
        # they are converted into unicode strings automatically. See:
        # http://developer.mozilla.org/en/docs/XPCOM_string_guide#IDL_String_types
        23: "String", # T_UTF8STRING
        24: "String", # T_CSTRING
        25: "String", # T_ASTRING
    }

    def process_xpcom_arguments(m):
        args = []
        returntype = None
        param_count = 1
        for param in m.params:
            t = xpt.TypeDescriber(param.type_desc[0], param)
            if t.tag in (xpt.T_INTERFACE, ):
                arg_type = t.Describe()
            elif t.tag in (xpt.T_ARRAY, ):
                arg_type = "Array"
            else:
                arg_type = javascript_type_from_xpt_tag.get(t.tag, "unknown")
    
            if param.IsIn():
                args.append("in %s" % (arg_type))
                param_count += 1
            elif param.IsRetval():
                if t.tag in (xpt.T_INTERFACE, ):
                    returntype = "Components.interfaces.%s" % (arg_type)
                else:
                    returntype = arg_type
            elif param.IsOut():
                args.append("out %s" % (arg_type))
                param_count += 1
        return args, returntype

    def iid_to_cix(iid):
        elem = Element("scope", name=iid, ilk="class")
        try:
            interface = xpt.Interface(iid)
        except:
            print "No interface with iid: %r" % (iid, )
        else:
            # Filter out non-xpcom methods
            methods = [ m for m in interface.methods if not m.IsNotXPCOM() ]
            getters = [ m for m in methods if m.IsGetter() ]
            getters += [ m for m in methods if m.IsSetter() ]
            methods = [ m for m in methods if not m.IsGetter() and
                                              not m.IsSetter() ]
        
            for m in getters:
                args, returntype = process_xpcom_arguments(m)
                variable_elem = elem.names.get(m.name)
                # Don't override an existing element.
                if variable_elem is None:
                    variable_elem = SubElement(elem, "variable", name=m.name,
                                               citdl=returntype)
                # Else, this must be a setter, which does not have a type.
            for m in methods:
                #print m.name
                func_elem = SubElement(elem, "scope", name=m.name,
                                       ilk="function")
                args, returntype = process_xpcom_arguments(m)
                signature = "%s(%s)" % (m.name, ", ".join(args))
                if returntype is not None:
                    func_elem.attrib["returns"] = returntype
                    signature += " =&gt; %s" % (returntype, )
                func_elem.attrib["signature"] = signature
            for c in interface.constants:
                # XXX: assuming all constants are integers, I am yet to see a
                #      case where this is not true...
                variable_elem = SubElement(elem, "variable", name=c.name,
                                           citdl="Number",
                                           attributes="constant")
        return elem
    
except ImportError:
    _xpcom_ = False

# Globals used for holding the xpcom cix information, the base xpcom structure
# is generated once per run, then interface details are added on demand.
_g_xpcom_interfaces_elem = None
_g_xpcom_components_elem = None
# The map of iid to xpcom cix element.
_g_xpcom_cix_for_iid = {}

def _add_xpcom_blob(built_in_blob):
    global _g_xpcom_components_elem
    global _g_xpcom_interfaces_elem
    if _xpcom_:
        if _g_xpcom_components_elem is None:
            # create the blob to hold xpcom data
            #print "Building xpcom cix wrapper for the first time"
            _g_xpcom_components_elem = SubElement(built_in_blob, "variable",
                                         citdl="Object", name="Components")
            xpcComponents = iid_to_cix("nsIXPCComponents")

            elem_classes = None
            for elem in xpcComponents:
                if elem.get("name") == "classes":
                    #print "Found the classes elem: %r" % (elem, )
                    elem.attrib["citdl"] = "Object"
                    elem_classes = elem
                elif elem.get("name") == "interfaces":
                    #print "Found the interfaces elem: %r" % (elem, )
                    elem.attrib["citdl"] = "Object"
                    _g_xpcom_interfaces_elem = elem
                _g_xpcom_components_elem.append(elem)
    
            # Add Components.interfaces data
            for interface in components.interfaces.keys():
                elem = SubElement(_g_xpcom_interfaces_elem, "scope",
                                  ilk="class", name=interface)
    
            # Add Components.classes data
            for klass in components.classes.keys():
                elem = SubElement(elem_classes, "variable", name=klass)
    
            # Add some common aliases
            for alias_name in ("CI", "Ci", ):
                SubElement(built_in_blob, "variable",
                           citdl="Components.interfaces", name=alias_name)
            for alias_name in ("CC", "Cc", ):
                SubElement(built_in_blob, "variable",
                           citdl="Components.classes", name=alias_name)
            for alias_name in ("CU", "Cu", ):
                SubElement(built_in_blob, "variable",
                           citdl="Components.utils", name=alias_name)
        # This check is necessary as sometimes a blob will be cached and
        # will already contain the Components elem.
        elif built_in_blob.names.get("Components") is None:
            built_in_blob.append(_g_xpcom_components_elem)

</t>
<t tx="ekr.20080121105837.872">def _xpcom_iid_to_cix(iid):
    """Return a cix element containg the xpcom interface for the given iid."""
    if not _xpcom_:
        return None
    if not iid:
        # Default to nsISupports, all xpcom components support this.
        iid = "nsISupports"
    # Try and get it from the cached interfaces.
    elem = _g_xpcom_cix_for_iid.get(iid)
    if elem is None:
        # Else, we load it up.
        elem = iid_to_cix(iid)
        # Remove the dummy place holder element if there is one, this is here
        # only to provide support for "Components.interfaces.&lt;|&gt;" completions.
        if iid in _g_xpcom_interfaces_elem.names:
            _g_xpcom_interfaces_elem.remove(_g_xpcom_interfaces_elem.names[iid])
        _g_xpcom_interfaces_elem.append(elem)
        _g_xpcom_cix_for_iid[iid] = elem
    return elem
</t>
<t tx="ekr.20080121105837.873">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.874">#!/usr/bin/env python

"""Completion evaluation code for Perl.

Dev Note: A Perl "package" vs. a Perl "module"
----------------------------------------------

A Perl *module* is the content of a .pm file (or .so file for binary
modules) that one imports via a "use" or "require" statement. This
corresponds to a codeintel "blob".

A Perl *package* is a language construct that is created in Perl modules
(or Perl scripts) via the "package" statement. Typically (*are* there
exceptions?) a Perl module file "Foo/Bar.pm" will define a "Foo::Bar"
package. These are represented in codeintel/CIX with a *class*.

Hence:

    -------- Salad.pm --------
    use strict;
    package Salad;
    # ...
    1;
    --------------------------

    &lt;codeintel version="2.0"&gt;
      &lt;file path="Salad.pm" lang="Perl"&gt;
        &lt;scope ilk="blob" name="Salad"&gt;     &lt;!-- this is the Salad *module* --&gt;
          &lt;scope ilk="class" name="Salad"&gt;  &lt;!-- this is the Salad *package* --&gt;
              ...
          &lt;/scope&gt;
        &lt;/scope&gt;
      &lt;/file&gt;
    &lt;codeintel&gt;

"""

from pprint import pprint

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.database.stdlib import StdLib
from codeintel2.util import banner, isident


</t>
<t tx="ekr.20080121105837.875">#---- internal support class for Perl package import semantics

class _PerlPkgTable(object):
    """An object for handling Perl module/package import semantics. Each
    cpln evaluation creates one of these to determine (and cache) the
    working set of loaded Perl packages.

    Usage:
        pkg_tbl = _PerlPkgTable(blob,       # top-level (i.e. current) blob
                                buf.libs)   # DB libs for the current buffer

        # Generate (&lt;blob&gt;, &lt;package-names&gt;) tuples for loaded packages.
        for blob, pkg_names in pkg_tbl.gen_loaded_pkgs():
            ...

        # Get the pkg (CIX 'class' element) defining the named package.
        pkg = pkg_tbl.pkg_from_pkg_name(pkg_name)
        mod, pkg = pkg_tbl.mod_and_pkg_from_pkg_name(pkg_name)
    """
    @others
</t>
<t tx="ekr.20080121105837.876">#TODO: Consider an index (a la toplevelname_index) for imported
#      Perl packages. Post-4.0. Only iff Perl cpln needs the
#      speed.

def __init__(self, blob, libs):
    self.blob = blob
    self.libs = libs

    self._generator_cache = None
    self._mod_from_pkg_name = {}
    # Used to support multiple calls to .gen_loaded_pkgs()
    self._item_cache = []

</t>
<t tx="ekr.20080121105837.877">@property
def _generator(self):
    if self._generator_cache is None:
        self._generator_cache = self._gen_loaded_pkgs(self.blob, set())
    return self._generator_cache

</t>
<t tx="ekr.20080121105837.878">def pkg_from_pkg_name(self, pkg_name):
    """Return the package (a CIX &lt;scope ilk="class"&gt; element) for
    the given package name. If the package definition cannot be
    found, this returns None.
    """
    if pkg_name in self._mod_from_pkg_name:
        mod = self._mod_from_pkg_name[pkg_name]
        return mod.names.get(pkg_name)
    for mod, pkg_names in self._generator:
        if pkg_name in pkg_names:
            return mod.names.get(pkg_name)
    return None

</t>
<t tx="ekr.20080121105837.879">def mod_and_pkg_from_pkg_name(self, pkg_name):
    """Return the module (a CIX &lt;scope ilk="blob"&gt;) and package (a
    CIX &lt;scope ilk="class"&gt; element) for the given package name. If
    the package definition cannot be found, this returns
    (None, None).
    """
    if pkg_name in self._mod_from_pkg_name:
        mod = self._mod_from_pkg_name[pkg_name]
        return mod, mod.names.get(pkg_name)
    for mod, pkg_names in self._generator:
        if pkg_name in pkg_names:
            return mod, mod.names.get(pkg_name)
    return None, None

</t>
<t tx="ekr.20080121105837.880">def gen_loaded_pkgs(self):
    """Generate loaded (*) Perl packages recursively, starting from
    the given blob.

    This yields the following 2-tuples:
        (&lt;blob&gt;, &lt;set of packages defined in this blob&gt;)

    A "loaded" Perl package is one that is imported (via "use" or
    "require") or locally defined via a "package" statement.
    
    If a particular Perl module cannot be imported it is presumed to
    define one package of the same name (which is typical). In this
    case, &lt;blob&gt; will be None.
    """ 
    for item in self._item_cache:
        yield item
    for item in self._generator:
        yield item

</t>
<t tx="ekr.20080121105837.881">def _gen_loaded_pkgs(self, mod, handled_mod_names):
    mod_names, pkg_names = self._pkg_info_from_mod(mod)
    item = (mod, pkg_names)
    self._item_cache.append(item)
    for pkg_name in pkg_names:
        self._mod_from_pkg_name[pkg_name] = mod
    yield item

    for mod_name in (m for m in mod_names if m not in handled_mod_names):
        handled_mod_names.add(mod_name)
        for lib in self.libs:
            mod = lib.get_blob(mod_name)
            if mod is not None:
                break
        else:
            #self.debug("could not import module %r, assuming it "
            #           "defines package of same name", mod_name)
            item = (None, set([mod_name]))
            self._item_cache.append(item)
            self._mod_from_pkg_name[mod_name] = None
            yield item
            continue

        for item in self._gen_loaded_pkgs(mod, handled_mod_names):
            yield item

</t>
<t tx="ekr.20080121105837.882">def _imported_mod_names_from_mod(self, mod):
    """Yield "reasonable" module names imported in the given module.
    
    "Reasonable" here means those that can be handled by the Perl
    cpln evalrs. The issue is Perl 'require' statements that can
    quote a string, use string interpolation, etc.
    """
    from os.path import splitext

    for imp_elem in mod.getiterator("import"):
        mod_name = imp_elem.get("module")
        
        if '$' in mod_name:
            # Abort on these guys:
            #   require $blah;        &lt;import module="$blah"/&gt;
            #   require '$foo.pm';    &lt;import module="'$foo.pm'"/&gt;
            continue
        elif mod_name[0] in ('"', "'"):
            # Try to gracefully handle these guys:
            #   require 'MyFoo.pm';   &lt;import module="'MyFoo.pm'"/&gt;
            #   require "MyBar.pm";   &lt;import module="&amp;quot;MyBar.pm&amp;quot;"/&gt;
            sans_quotes = mod_name[1:-1]
            sans_ext, ext = splitext(sans_quotes)
            if ext != ".pm":
                # Note that we don't allow '.pl' b/c the import
                # mechanics won't pick those up. I suspect that the
                # frequency of "require 'foo.pl'" is low enough that
                # we don't need to worry about this.
                continue
            mod_name = sans_ext.replace('/', '::')
        yield mod_name

</t>
<t tx="ekr.20080121105837.883">def _pkg_info_from_mod(self, mod):
    """Return Perl package info for this module blob.
    
    Returns a 2-tuple:
        (&lt;set of imported module names&gt;, &lt;set of defined package names&gt;)
    """
    key = "perl-pkg-info"
    if key not in mod.cache:
        mod_names = set(self._imported_mod_names_from_mod(mod))
        #print "%r imports: %s" % (mod, ', '.join(mod_names))

        # Perl packages can only be defined at the top-level.
        pkg_names = set(elem.get("name") for elem in mod
                        if elem.get("ilk") == "class")
        #print "%r defines: %s" % (mod, ', '.join(pkg_names))

        mod.cache[key] = (mod_names, pkg_names)
    return mod.cache[key]




</t>
<t tx="ekr.20080121105837.884">#---- the tree evaluators

class CandidatesForTreeEvaluator(TreeEvaluator):
    """Candidate functionality for the base TreeEvaluator class to be
    shared by the other lang-specific TreeEvaluators.

    TODO: evaluate and move these to base class sometime after K4
    """

    _built_in_blob = None
    @others
</t>
<t tx="ekr.20080121105837.885">@property
def built_in_blob(self):
    if self._built_in_blob is None:
        stdlib = self.buf.stdlib
        assert isinstance(stdlib, StdLib), \
            "buf.stdlib did not return a StdLib instance: %r" % stdlib
        self._built_in_blob = stdlib.get_blob("*")
    return self._built_in_blob

</t>
<t tx="ekr.20080121105837.886">def parent_scoperef_from_scoperef(self, scoperef):
    blob, lpath = scoperef
    if lpath:
        return (blob, lpath[:-1])
    elif blob is self.built_in_blob:
        return None
    else:
        return (self.built_in_blob, [])

</t>
<t tx="ekr.20080121105837.887">def _elem_from_scoperef(self, scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        elem = elem.names[lname]
    return elem

</t>
<t tx="ekr.20080121105837.888">def _tokenize_citdl_expr(self, expr):
    for tok in expr.split('.'):
        if tok.endswith('()'):
            yield tok[:-2]
            yield '()'
        else:
            yield tok
</t>
<t tx="ekr.20080121105837.889">def _join_citdl_expr(self, tokens):
    return '.'.join(tokens).replace('.()', '()')

</t>
<t tx="ekr.20080121105837.890"># The SENTINEL_MAX_EXPR_COUNT could probably be *reduced*.
# Note: This is an approximation that we are infinitely looping
# on the same evaluation. The *actual* appropriate key would be:
#
#   (expr, scoperef)
#
# but that is overkill for now, I think.
_SENTINEL_MAX_EXPR_COUNT = 10
_eval_count_from_expr = None
def _check_infinite_recursion(self, expr):
    if self._eval_count_from_expr is None:
        # Move this init into eval() when on TreeEvalutor.
        self._eval_count_from_expr = {}
    eval_count = self._eval_count_from_expr.get(expr, 0)
    eval_count += 1
    if eval_count &gt;= self._SENTINEL_MAX_EXPR_COUNT:
        raise EvalError("hit eval sentinel: expr '%s' eval count "
                        "is %d (abort)" % (expr, eval_count))
    self._eval_count_from_expr[expr] = eval_count


</t>
<t tx="ekr.20080121105837.891">class PerlTreeEvaluatorBase(CandidatesForTreeEvaluator):
    @others
</t>
<t tx="ekr.20080121105837.892">def __init__(self, ctlr, buf, trg, expr, line, prefix_filter=None):
    CandidatesForTreeEvaluator.__init__(self, ctlr, buf, trg, expr, line)
    self.prefix_filter = prefix_filter

</t>
<t tx="ekr.20080121105837.893">def pre_eval(self):
    curr_blob = self.buf.blob_from_lang[self.trg.lang]
    self.pkg_tbl = _PerlPkgTable(curr_blob, self.buf.libs)

</t>
<t tx="ekr.20080121105837.894">def _func_members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
    """Return the function completions for the given Perl package
    (traversing package inheritance, if any).
    """
    # Guard against infinite recursion.
    if _handled_pkg_names is None:
        _handled_pkg_names = set()
    if pkg_name in _handled_pkg_names:
        return []
    _handled_pkg_names.add(pkg_name)

    # Get the locally defined subs.
    members = [("function", n) for n,el in pkg.names.items()
               if el.get("ilk") == "function"]

    # Get inherited subs.
    for classref in pkg.get("classrefs", "").split():
        if classref == "Exporter":
            # Special case: skip "Exporter" base class members in
            # Perl. These are not desired 99% of the time.
            continue
        self.info("add inherited functions from %r", classref)
        classref_pkg = self.pkg_tbl.pkg_from_pkg_name(classref)
        members += self._func_members_from_pkg(classref, classref_pkg,
                                               _handled_pkg_names)

    return members


</t>
<t tx="ekr.20080121105837.895"># Special Perl variables/subs to typically _exclude_ from completions.
_special_names_to_skip = set([
    "$AUTOLOAD", "AUTOLOAD", "DESTROY",
    "@EXPORT", "@EXPORT_FAIL", "@EXPORT_OK", "%EXPORT_TAGS",
    "@ISA", "import", "unimport",
])
_perl_var_tokenizer = re.compile(r"([$\\%&amp;@]+)?(\w+)")

def post_process_cplns(self, cplns):
    DEBUG = False
    if DEBUG:
        print banner("Perl post_process_cplns (before)")
        pprint(cplns)
    
    trg_type = self.trg.type
    if trg_type in ("package-subs", "object-subs"):
        #TODO: This may not be necessary if current evalr only
        #      generates the function.
        cplns = [c for c in cplns
                 if c[0] == "function"
                 if c[1] not in self._special_names_to_skip]
    elif trg_type == "package-members":
        if self.prefix_filter in ('', '&amp;'): # filter out variables
            cplns = [c for c in cplns
                     if c[0] != "variable"
                     if c[1] not in self._special_names_to_skip]
        elif self.prefix_filter in ('$', '@', '%'): # filter out funcs
            cplns = [c for c in cplns
                     if c[0] != "function"
                     if c[1] not in self._special_names_to_skip]
        else:
            cplns = [c for c in cplns 
                     if c[1] not in self._special_names_to_skip]
            
        # Morph type and value of variable based on the prefix.
        # For example the completions for: `$HTTP::Message::` include
        # ("variable", "$VERSION"). The actual correct completion is
        # "VERSION" (no '$'-prefix). We morph this to ("$variable",
        # "VERSION") so that:
        # 1. the proper completion will be used, and
        # 2. the different type string can be used for a custom
        #    autocomplete image.
        # Ditto for '@' and '%'.
        morphed_cplns = []
        for type, value in cplns:
            if type == "variable":
                match = self._perl_var_tokenizer.match(value)
                if not match:
                    self.warn("could not parse Perl var '%s': "
                              "pattern='%s'", value,
                              self._perl_var_tokenizer.pattern)
                    continue
                prefix, name = match.groups()
                if DEBUG:
                    print "tokenize perl var: %r -&gt; %r %r"\
                          % (value, prefix, name)
                if prefix:
                    prefix = prefix[-1] # only last char is relevant
                
                if self.prefix_filter in (None, '*', '$'):
                    # '*': pass all
                    # '$': pass all because arrays and hashes can have
                    #      a '$' prefix for subsequent indexing
                    pass
                elif self.prefix_filter and self.prefix_filter != prefix:
                    # If the filter is '%' or '@', then filter out vars
                    # not of that persuasion.
                    continue
                
                #TODO: Test cases for these and review by Perl guy.
                if prefix in ('$', '%', '@'):
                    # Don't yet support '*' special a/c image.
                    type = prefix+type
                value = name
            morphed_cplns.append((type, value))
        cplns = morphed_cplns

    cplns.sort(key=lambda c: c[1].upper())
    if DEBUG:
        print banner("(after)", '-')
        pprint(cplns)
        print banner(None, '-')
    return cplns


</t>
<t tx="ekr.20080121105837.896">class PerlPackageMembersTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle 'perl-complete-package-members'.
    
        [prefix]SomePackage::&lt;|&gt;
    """
    @others
</t>
<t tx="ekr.20080121105837.897"># TODO: Consider implementing this subtlety (if current behaviour is
#       not pleasing):
#   - if trigger is explicit, then don't bother ensuring package
#     is imported: *presume* it is
#   - if trigger is implicit, then ensure package is imported

def eval_cplns(self):
    self.log_start()

    prefix = self.expr + "::"
    prefix_len = len(prefix)
    prefix_matches = set()
    matching_blob = None
    for blob, pkg_names in self.pkg_tbl.gen_loaded_pkgs():
        for pkg_name in pkg_names:
            if pkg_name == self.expr:
                matching_blob = blob
            elif pkg_name.startswith(prefix):
                prefix_match = pkg_name[prefix_len:]
                if "::" in prefix_match:
                    prefix_match = prefix_match[:prefix_match.index("::")]
                #self.debug("prefix match: %r -&gt; %r", pkg_name, prefix_match)
                prefix_matches.add(prefix_match)

    if prefix_matches:
        self.info("loaded pkg prefix matches: %r", prefix_matches)
    cplns = [("class", pm) for pm in prefix_matches]
    if matching_blob is not None:
        try:
            pkg = matching_blob.names[self.expr]
        except KeyError:
            self.warn("%s unexpectedly doesn't define package %r",
                      matching_blob, self.expr)
        else:
            self.info("pkg match for %r: %r", self.expr, pkg)
            cplns += self._members_from_pkg(self.expr, pkg)
            
    return cplns

</t>
<t tx="ekr.20080121105837.898">def _members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
    """Return the completions for the given Perl package (traversing
    package inheritance, if any).
    """
    # Guard against infinite recursion.
    if _handled_pkg_names is None:
        _handled_pkg_names = set()
    if pkg_name in _handled_pkg_names:
        return []
    _handled_pkg_names.add(pkg_name)

    # Get the locally defined members.
    members = []
    for name, elem in pkg.names.items():
        #self.debug("%r: %r", name, elem)
        if elem.tag == "variable":
            if "__local__" not in elem.get("attributes", ""):
                members.append(("variable", name))
        else:
            members.append((elem.get("ilk"), name))

    # Note: For perl-complete-package-members, inherited package
    # members should NOT be included. See
    # test_perl.py::test_myvars_2(). (Noting this because it might
    # be surprising.)

    return members


</t>
<t tx="ekr.20080121105837.899">class PerlPackageSubsTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle 'perl-complete-package-subs'

        SomePackage-&gt;&lt;|&gt;
    """
    @others
</t>
<t tx="ekr.20080121105837.900">def eval_cplns(self):
    self.log_start()

    # First ensure that this Perl package has been loaded.
    pkg = self.pkg_tbl.pkg_from_pkg_name(self.expr)
    if pkg is None:
        self.error("Perl package %r is not loaded", self.expr)
        return None

    self.info("pkg match for %r: %r", self.expr, pkg)
    return self._func_members_from_pkg(self.expr, pkg)

</t>
<t tx="ekr.20080121105837.901">def _func_members_from_pkg(self, pkg_name, pkg, _handled_pkg_names=None):
    """Return the function completions for the given Perl package
    (traversing package inheritance, if any).
    """
    # Guard against infinite recursion.
    if _handled_pkg_names is None:
        _handled_pkg_names = set()
    if pkg_name in _handled_pkg_names:
        return []
    _handled_pkg_names.add(pkg_name)

    # Get the locally defined subs.
    members = [("function", n) for n,el in pkg.names.items()
               if el.get("ilk") == "function"]

    # Get inherited subs.
    for classref in pkg.get("classrefs", "").split():
        if classref == "Exporter":
            # Special case: skip "Exporter" base class members in
            # Perl. These are not desired 99% of the time.
            continue
        self.info("add inherited functions from %r", classref)
        classref_pkg = self.pkg_tbl.pkg_from_pkg_name(classref)
        members += self._func_members_from_pkg(classref, classref_pkg,
                                               _handled_pkg_names)

    return members



</t>
<t tx="ekr.20080121105837.902">class PerlTreeEvaluator(PerlTreeEvaluatorBase):
    """TreeEvaluator to handle the following triggers:

        perl-calltip-space-call-signature   "open &lt;|&gt;"
        perl-calltip-call-signature         "some_func(&lt;|&gt;"
        perl-complete-object-subs           "$foo-&gt;&lt;|&gt;"

    TODO: perl-defn-defn
    """
    @others
</t>
<t tx="ekr.20080121105837.903">def __init__(self, ctlr, buf, trg, expr, line, prefix_filter=None):
    PerlTreeEvaluatorBase.__init__(self, ctlr, buf, trg, expr, line)
    self.prefix_filter = prefix_filter

</t>
<t tx="ekr.20080121105837.904">def eval_cplns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    hit = self._hit_from_citdl(self.expr, start_scoperef)

    elem, scoperef = hit
    if not (elem.tag == "scope" and elem.get("ilk") == "class"):
        perl_type = self._perl_type_from_elem(elem)
        self.error("cannot get completions from a Perl %s: '%s' is "
                   "&lt;%s %s&gt; (expected a Perl package element)",
                   perl_type, self.expr, perl_type, name)
        return None
    return self._func_members_from_pkg(elem.get("name"), elem)

</t>
<t tx="ekr.20080121105837.905">def eval_calltips(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    elem, scoperef = self._hit_from_citdl(self.expr, start_scoperef)
    if not (elem.tag == "scope" and elem.get("ilk") == "function"):
        perl_type = self._perl_type_from_elem(elem)
        self.error("cannot call a Perl %s: '%s' is &lt;%s %s&gt;",
                   perl_type, self.expr, perl_type, name)
        return None
    return [ self._calltip_from_func(elem) ]

</t>
<t tx="ekr.20080121105837.906">def eval_defns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
    return [ self._defn_from_hit(hit) ]

</t>
<t tx="ekr.20080121105837.907">def _perl_type_from_elem(self, elem):
    if elem.tag == "scope":
        ilk = elem.get("ilk")
        return {"function": "sub",
                "class": "package",
                "blob": "module"}.get(ilk, ilk)
    else:
        return "variable"

</t>
<t tx="ekr.20080121105837.908">def _calltip_from_func(self, elem):
    # See "Determining a Function CallTip" in the spec for a
    # discussion of this algorithm.
    from codeintel2.util import LINE_LIMIT #TODO: -&gt; CALLTIP_LINE_LIMIT
    signature = elem.get("signature")
    if not signature:
        ctlines = [elem.get("name") + "(...)"]
    else:
        ctlines = signature.splitlines(0)
    doc = elem.get("doc")
    if doc:
        ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
    return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.909">def _hit_from_citdl(self, expr, scoperef, defn_only=False):
    """Resolve the given CITDL expression (starting at the given
    scope) down to a non-import/non-variable hit: i.e. down to a
    function or class (a.k.a., Perl package).
    """
    self._check_infinite_recursion(expr)

    tokens = list(self._tokenize_citdl_expr(expr))
    #self.debug("expr tokens: %r", tokens)

    # First part...
    first_token = tokens.pop(0)
    hit = self._hit_from_first_part(first_token, scoperef)
    if not hit:
        raise CodeIntelError("could not resolve '%s'" % first_token)
    #self.debug("_hit_from_citdl: first part: %r -&gt; %r", first_token, hit)

    # ...remaining parts.
    while tokens:
        token = tokens.pop(0)
        if token == "()":
            raise CodeIntelError("eval of Perl function calls not yet "
                                 "implemented: %r" % expr)
        self.info("lookup '%s' on %r in %r", token, *hit)
        #TODO: Should we catch CodeIntelError, self.error() and
        #      return None?
        hit = self._hit_from_getattr(token, *hit)
    if tokens:
        raise CodeIntelError("multi-part Perl CITDL expr '%s' cannot "
                             "yet be handled" % expr)

    # Resolve any variable type inferences.
    elem, scoperef = hit
    if elem.tag == "variable" and not defn_only:
        hit = self._hit_from_variable_type_inference(elem, scoperef)

    self.info("'%s' is %s on %s", expr, *hit)
    return hit

</t>
<t tx="ekr.20080121105837.910">def _hit_from_first_part(self, first_token, scoperef):
    """Find a hit for the first part of the tokens.

    Returns a &lt;hit&gt; or None if could not resolve.

    Examples:
        '$ua'    -&gt; &lt;variable '$ua'&gt;,
                    (&lt;blob 'myscript'&gt;, [])
        'Dumper' -&gt; &lt;function 'Dumper'&gt;,
                    (&lt;blob 'Data::Dumper'&gt;, ['Data::Dumper'])
        'Data::Dumper' -&gt;
                    &lt;class 'Data::Dumper'&gt;,
                    (&lt;blob 'Data::Dumper'&gt;, [])
    """
    #self.log("find '%s' starting at %s:", first_token, scoperef)
    while 1:
        elem = self._elem_from_scoperef(scoperef)
        if first_token in elem.names:
            #TODO: skip __hidden__ names
            self.log("is '%s' accessible on %s? yes: %s",
                     first_token, scoperef, elem.names[first_token])
            return elem.names[first_token], scoperef

        if "::" not in first_token:
            hit = self._hit_from_elem_imports(first_token, elem)
            if hit is not None:
                self.log("is '%s' accessible on %s? yes: %s",
                         first_token, scoperef, hit[0])
                return hit

        mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(first_token)
        if mod is not None:
            self.log("is '%s' accessible on %s? yes: %s",
                     first_token, scoperef, pkg)
            return (pkg, (mod, [first_token]))


        self.log("is '%s' accessible on %s? no", first_token, scoperef)
        scoperef = self.parent_scoperef_from_scoperef(scoperef)
        if not scoperef:
            return None

</t>
<t tx="ekr.20080121105837.911">def _hit_from_getattr(self, token, elem, scoperef):
    """Return a hit for a getattr on the given element.

    Returns &lt;hit&gt; or raises CodeIntelError if cannot resolve.
    """
    if elem.tag == "variable":
        elem_is_var_on_entry = True
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)
    else:
        elem_is_var_on_entry = False

    assert elem.tag == "scope"
    ilk = elem.get("ilk")
    if ilk == "class": # i.e. a Perl package
        attr = elem.names.get(token)
        if attr is not None:
            return attr, (scoperef[0], scoperef[1] + [elem.get("name")])

        # To inherit or not to inherit
        # ============================
        #
        # Both of the following get here:
        #   $ua-&gt;foo();              lookup "foo" on LWP::UserAgent
        #   Data::Dumper::Dumper();  lookup "Dumper" on Data::Dumper
        # However, only the former should include inherited methods.
        #
        # I *believe* we can tell the difference based on whether
        # 'elem' (on entry to this function) is a variable. If it is
        # a variable then this is the former case.
        #
        # Note that we cannot use the trigger type to determine this
        # because this could be part of eval of
        # "perl-calltip-call-signature" for both:
        #   $ua-&gt;foo(&lt;|&gt;);
        #   Data::Dumper::Dumper(&lt;|&gt;);
        if elem_is_var_on_entry:
            # Look on inherited packages (test 'perl/cpln/lwp'
            # tests for multi-level inheritance).
            for base_mod, base_pkg \
                    in self._inherited_mods_and_pkgs_from_pkg(elem):
                attr = base_pkg.names.get(token)
                if attr is not None:
                    return attr, (base_mod, [base_pkg.get("name")])

    elif ilk == "blob":  # i.e. a Perl module
        raise CodeIntelError("didn't expect a getattr on a Perl "
                             "module: %r on %r" % (token, elem))
        #attr = elem.names.get(first_token)
        #if attr is not None:
        #    self.log("attr is %r in %r", attr, elem)
        #    return attr, scoperef

    elif ilk == "function":
        raise CodeIntelError("cannot get attributes of a "
                             "function: %r on %r" % (token, elem))

    else:
        raise NotImplementedError("unexpected scope ilk: %r" % ilk)

    raise CodeIntelError("could not resolve '%s' attr on %s"
                         % (token, elem))

</t>
<t tx="ekr.20080121105837.912">def _inherited_mods_and_pkgs_from_pkg(self, pkg, _handled_pkg_names=None):
    """Generate the inherited packages of the given package.

    Yields (mod, pkg) 2-tuples. The "Exporter" package is skipped.
    """
    pkg_name = pkg.get("name")

    # Guard against infinite recursion.
    if _handled_pkg_names is None:
        _handled_pkg_names = set()
    if pkg_name not in _handled_pkg_names:
        _handled_pkg_names.add(pkg_name)

        for classref in pkg.get("classrefs", "").split():
            if classref == "Exporter":
                # Special case: skip "Exporter" base class members in
                # Perl. These are not desired 99% of the time.
                continue
            classref_mod, classref_pkg \
                = self.pkg_tbl.mod_and_pkg_from_pkg_name(classref)
            if classref_pkg is None:
                continue
            yield (classref_mod, classref_pkg)
            for item in self._inherited_mods_and_pkgs_from_pkg(
                            classref_pkg, _handled_pkg_names):
                yield item

</t>
<t tx="ekr.20080121105837.913">def _hit_from_elem_imports(self, token, elem):
    """See if token is from one of the imports on this &lt;scope&gt; elem.

    Returns &lt;hit&gt; or None if not found.
    """
    for imp_elem in (i for i in elem if i.tag == "import"):
        # Note: Perl &lt;import&gt; elements never use 'alias'.
        symbol_name = imp_elem.get("symbol")
        module_name = imp_elem.get("module")
        assert module_name, \
            "bogus Perl &lt;import&gt; without module name: %r" % imp_elem

        if not symbol_name:
            # use Foo ();           &lt;import module="Foo"/&gt;
            # require $blah;        &lt;import module="$blah"/&gt;
            # require '$foo.pm';    &lt;import module="'$foo.pm'"/&gt;
            # require 'MyFoo.pm';   &lt;import module="'MyFoo.pm'"/&gt;
            # require "MyBar.pm";   &lt;import module="&amp;quot;MyBar.pm&amp;quot;"/&gt;
            pass

        elif symbol_name == token:
            # use Foo qw(a);        &lt;import module="Foo" symbol="a"/&gt;
            mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
            if mod is not None:
                elem = pkg.names.get(token)
                if elem is not None:
                    #TODO: Should we exclude this if not in
                    #      @EXPORT_OK?
                    self.debug("is '%s' from %r? yes: %s",
                               token, imp_elem, elem)
                    return (elem, (mod, [module_name]))

        elif symbol_name == "*":
            # use Foo;              &lt;import module="Foo" symbol="*"/&gt;
            mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
            if mod is not None:
                elem = pkg.names.get(token)
                if elem is not None \
                   and "__exported__" in elem.get("attributes", ""):
                    self.debug("is '%s' from %r? yes: %s",
                               token, imp_elem, elem)
                    return (elem, (mod, [module_name]))

        elif symbol_name == "**":
            # use Foo qw(:key);     &lt;import module="Foo" symbol="**"/&gt;
            mod, pkg = self.pkg_tbl.mod_and_pkg_from_pkg_name(module_name)
            if mod is not None:
                elem = pkg.names.get(token)
                # "__exported__" attribute means in @EXPORT
                # "__exportable__" attribute means in @EXPORT_OK
                if elem is not None \
                   and "__export" in elem.get("attributes", ""):
                    self.debug("is '%s' from %r? yes: %s",
                               token, imp_elem, elem)
                    return (elem, (mod, [module_name]))

        self.debug("is '%s' from %r? no", token, imp_elem)
    return None

</t>
<t tx="ekr.20080121105837.914">def _hit_from_variable_type_inference(self, elem, scoperef):
    """Resolve the type inference for the given element."""
    #TODO:PERF: Consider cheating here with the knowledge that the
    #           current perlcile (the one as of Komodo 4.0.0) never
    #           emits anything except a package name for a type
    #           inference.
    citdl = elem.get("citdl")
    if not citdl:
        raise CodeIntelError("no type-inference info for %r" % elem)
    self.info("resolve '%s' type inference for %r:", citdl, elem)
    return self._hit_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.915">def _hit_from_type_inference(self, citdl, scoperef):
    """Resolve the 'citdl' type inference at 'scoperef'."""
    #TODO:PERF: Consider cheating here with the knowledge that the
    #           current perlcile (the one as of Komodo 4.0.0) never
    #           emits anything except a package name for a type
    #           inference.
    self.info("resolve '%s' type inference:", citdl)
    return self._hit_from_citdl(citdl, scoperef)


</t>
<t tx="ekr.20080121105837.916">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.917">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Completion evaluation code for PHP"""

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.util import make_short_name_dict, banner


php_magic_global_method_data = {
    "__autoload"  : "__autoload(string $className)\n"
                    "This function is automatically called when a class\n"
                    "is being called, but which hasn't been defined yet.",
}
php_magic_class_method_data = {
    "__construct" : "__construct([mixed $args [, $...]])\n"
                    "Initializes a newly created class instance.\n"
                    "Note: parent constructors will need to be implictly\n"
                    "called.",
    "__destruct"  : "__destruct()\n"
                    "This function is called when all references to this\n"
                    "particular class instance are removed or when the\n"
                    "object is explicitly destroyed.\n"
                    "Note: parent destructors will need to be implictly\n"
                    "called.",
    "__call"      : "__call(string $name, array $arguments) -&gt; mixed\n"
                    "Is triggered when your class instance (and inherited\n"
                    "classes) does not contain the method name.",
    "__get"       : "__get(string $name) -&gt; mixed\n"
                    "Is triggered when your class instance (and inherited\n"
                    "classes) does not contain the member or method name.",
    "__set"       : "__set(string $name, mixed $value)\n"
                    "Is triggered when your class instance (and inherited\n"
                    "classes) does not contain the member or method name.",
    "__isset"     : "__isset(string $name) -&gt; bool\n"
                    "Overload the isset function for the class instance.",
    "__unset"     : "__unset(string $name)\n"
                    "Overload the unset function for the class instance.",
    "__sleep"     : "__sleep() -&gt; array\n"
                    "Called through serialize in order to generate a\n"
                    "storable representation of a class instance. Returns\n"
                    "an array of the variable names that need to\n"
                    "be stored.",
    "__wakeup"    : "__wakeup()\n"
                    "Called through unserialize after restoring a\n"
                    "a class instance with it's serialized values.",
    "__toString"  : "__toString() -&gt; string\n"
                    "Returns a string representation of the class instance.",
    "__set_state" : "__set_state(array $properties)\n"
                    "Static method that is called to restore a class\n"
                    "instance's state that was previously exported\n"
                    "using the var_export() function. Properties are\n"
                    "in the form array('property' =&gt; value, ...).",
    "__clone"     : "__clone()\n"
                    "When the class instance is cloned using the\n"
                    "clone($object) function call, a new class instance\n"
                    "is created with shallow copies of all $object's\n"
                    "values. This function is then called after to allow\n"
                    "the new instance to update any of these values.",
}


</t>
<t tx="ekr.20080121105837.918">class PHPTreeEvaluator(TreeEvaluator):
    """
    scoperef: (&lt;blob&gt;, &lt;lpath&gt;) where &lt;lpath&gt; is list of names
        self._elem_from_scoperef()
    hit: (&lt;elem&gt;, &lt;scoperef&gt;)
    """

    # Calltips with this expression value are ignored. See bug:
    # http://bugs.activestate.com/show_bug.cgi?id=61497
    php_ignored_calltip_expressions = ("if", "elseif",
                                       "for", "foreach",
                                       "while",
                                       "switch",
                                      )

    php_magic_global_method_cplns = [ ("function", name) for name in
                sorted(php_magic_global_method_data.keys()) ]
    # Classes can use both global and class specific functions.
    php_magic_class_method_cplns = [ ("function", name) for name in
                sorted(php_magic_class_method_data.keys()) ]

    #TODO: candidate for base TreeEvaluator class
    _langintel = None
    @others
</t>
<t tx="ekr.20080121105837.919">@property
def langintel(self):
    if self._langintel is None:
        self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
    return self._langintel

</t>
<t tx="ekr.20080121105837.920">#TODO: candidate for base TreeEvaluator class
_libs = None
@property
def libs(self):
    if self._libs is None:
        self._libs = self.langintel.libs_from_buf(self.buf)
    return self._libs

</t>
<t tx="ekr.20080121105837.921">def eval_cplns(self):
    self.log_start()
    self._imported_blobs = {}
    start_scope = self.get_start_scoperef()
    trg = self.trg
    if trg.type == "variables":
        return self._variables_from_scope(self.expr, start_scope)
    elif trg.type == "functions":
        retval = self._functions_from_scope(self.expr, start_scope) + \
                 self._constants_from_scope(self.expr, start_scope)
        #if self.ctlr.is_aborted():
        #    return None
        return retval
    elif trg.type == "classes":
        return self._classes_from_scope(self.expr, start_scope)
    elif trg.type == "interfaces":
        return self._interfaces_from_scope(self.expr, start_scope)
    elif trg.type == "magic-methods":
        elem = self._elem_from_scoperef(start_scope)
        if elem.get("ilk") == "function":
            # Use the parent for our check.
            blob, lpath = start_scope
            if len(lpath) &gt; 1:
                elem = self._elem_from_scoperef((blob, lpath[:-1]))
        if elem.get("ilk") == "class":
            # All looks good, return the magic class methods.
            return self.php_magic_class_method_cplns
        else:
            # Return global magic methods.
            return self.php_magic_global_method_cplns
    else:
        hit = self._hit_from_citdl(self.expr, start_scope)
        if hit[0] is not None:
            self.log("self.expr: %r", self.expr)
            # special handling for parent, explicitly set the
            # protected and private member access for this case
            if self.expr == "parent" or \
               self.expr.startswith("parent."):
                self.log("Allowing protected parent members")
                return list(self._members_from_hit(hit, allowProtected=True,
                                                   allowPrivate=False))
            else:
                return list(self._members_from_hit(hit))

</t>
<t tx="ekr.20080121105837.922">def eval_calltips(self):
    self.log_start()
    self._imported_blobs = {}
    start_scope = self.get_start_scoperef()
    # Ignore doing a lookup on certain expressions
    # XXX - TODO: Might be better to do this in trg_from_pos.
    expr = self.expr
    if expr in self.php_ignored_calltip_expressions:
        return None
    # XXX - Check the php version, magic methods only appeared in php 5.
    elif expr in php_magic_class_method_data:
        elem = self._elem_from_scoperef(start_scope)
        if elem.get("ilk") == "function":
            # Use the parent for our check.
            blob, lpath = start_scope
            if len(lpath) &gt; 1:
                elem = self._elem_from_scoperef((blob, lpath[:-1]))
        if elem.get("ilk") == "class":
            # Use the class magic methods.
            return [ php_magic_class_method_data[expr] ]
        # Else, let the tree work it out.
    elif expr in php_magic_global_method_data:
        elem = self._elem_from_scoperef(start_scope)
        if elem.get("ilk") == "function":
            # Check the parent is not a class. See:
            # http://bugs.activestate.com/show_bug.cgi?id=69758
            blob, lpath = start_scope
            if len(lpath) &gt; 1:
                elem = self._elem_from_scoperef((blob, lpath[:-1]))
        if elem.get("ilk") == "class":
            # Not available inside a class.
            return []
        return [ php_magic_global_method_data[expr] ]
    hit = self._hit_from_citdl(expr, start_scope)
    return self._calltips_from_hit(hit)

</t>
<t tx="ekr.20080121105837.923">def eval_defns(self):
    self.log_start()
    self._imported_blobs = {}
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)

    hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
    return [self._defn_from_hit(hit)]

</t>
<t tx="ekr.20080121105837.924"># Determine if the hit is valid
def _return_with_hit(self, hit, nconsumed):
    # Added special attribute __not_yet_defined__ to the PHP ciler,
    # this is used to indicate the variable was made but is not yet
    # assigned a type, i.e. it's not yet defined.
    elem, scoperef = hit
    attributes = elem.get("attributes")
    if attributes:
        attr_split = attributes.split(" ")
        if "__not_yet_defined__" in attr_split:
            self.log("_return_with_hit:: hit was a not_yet_defined, ignoring it: %r", hit)
            return False
    self.log("_return_with_hit:: hit is okay: %r", hit)
    return True

</t>
<t tx="ekr.20080121105837.925">def _element_names_from_scope_starting_with_expr(self, expr, scoperef,
                                                 elem_type, scope_names,
                                                 elem_retriever):
    """Return all available elem_type names beginning with expr"""
    self.log("%s_names_from_scope_starting_with_expr:: expr: %r, scoperef: %r for %r",
             elem_type, expr, scoperef, scope_names)
    global_blob = self._elem_from_scoperef(self._get_global_scoperef(scoperef))
    # Get all of the imports

    # Start making the list of names
    all_names = set()
    for scope_type in scope_names:
        elemlist = []
        if scope_type == "locals":
            elemlist = [self._elem_from_scoperef(scoperef)]
        elif scope_type == "globals":
            elemlist = [global_blob]
        elif scope_type == "builtins":
            lib = self.buf.stdlib
            # Find the matching names (or all names if no expr)
            #log.debug("Include builtins: elem_type: %s", elem_type)
            names = lib.toplevel_cplns(prefix=expr, ilk=elem_type)
            all_names.update([n for ilk,n in names])
        # "Include everything" includes the builtins already
        elif scope_type == "imports":
            # Iterate over all known libs
            for lib in self.libs:
                # Find the matching names (or all names if no expr)
                #log.debug("Include everything: elem_type: %s", elem_type)
                names = lib.toplevel_cplns(prefix=expr, ilk=elem_type)
                all_names.update([n for ilk,n in names])
            # Standard imports, specified through normal import semantics
            elemlist = self._get_all_import_blobs_for_elem(global_blob)
        for elem in elemlist:
            names = elem_retriever(elem)
            if expr and isinstance(names, dict):
                try:
                    names = names[expr]
                except KeyError:
                    # Nothing in the dict matches, thats okay
                    names = []
            self.log("%s_names_from_scope_starting_with_expr:: adding %s: %r",
                     elem_type, scope_type, names)
            all_names.update(names)
    return self._convertListToCitdl(elem_type, all_names)

</t>
<t tx="ekr.20080121105837.926">def _variables_from_scope(self, expr, scoperef):
    """Return all available variable names beginning with expr"""
    # The current scope determines what is visible, see bug:
    #   http://bugs.activestate.com/show_bug.cgi?id=65159
    blob, lpath = scoperef
    if len(lpath) &gt; 0:
        # Inside a function or class, don't get to see globals
        scope_chain = ("locals", "builtins", )
    else:
        # Already global scope, so get to see them all
        scope_chain = ("locals", "globals", "imports", )
    # XXX - TODO: Move to 3 char trigger (if we want/need to)
    vars = self._element_names_from_scope_starting_with_expr(None,
                        scoperef,
                        "variable",
                        scope_chain,
                        self.variable_names_from_elem)
    # XXX - TODO: Use VARIABLE_TRIGGER_LEN instead of hard coding 1
    expr = expr[:1]
    return [ (ilk, name) for ilk, name in vars if name.startswith(expr) ]

</t>
<t tx="ekr.20080121105837.927">def _constants_from_scope(self, expr, scoperef):
    """Return all available constant names beginning with expr"""
    # XXX - TODO: Use FUNCTION_TRIGGER_LEN instead of hard coding 3
    return self._element_names_from_scope_starting_with_expr(expr[:3],
                        scoperef,
                        "constant",
                        ("globals", "imports", "builtins"),
                        self.constant_shortnames_from_elem)

</t>
<t tx="ekr.20080121105837.928">def _functions_from_scope(self, expr, scoperef):
    """Return all available function names beginning with expr"""
    # XXX - TODO: Use FUNCTION_TRIGGER_LEN instead of hard coding 3
    return self._element_names_from_scope_starting_with_expr(expr[:3],
                        scoperef,
                        "function",
                        ("locals", "globals", "imports",),
                        self.function_shortnames_from_elem)

</t>
<t tx="ekr.20080121105837.929">def _classes_from_scope(self, expr, scoperef):
    """Return all available class names beginning with expr"""
    return self._element_names_from_scope_starting_with_expr(None,
                        scoperef,
                        "class",
                        ("locals", "globals", "imports",),
                        self.class_names_from_elem)

</t>
<t tx="ekr.20080121105837.930">def _interfaces_from_scope(self, expr, scoperef):
    """Return all available interface names beginning with expr"""
    # Need to work from the global scope for this one
    return self._element_names_from_scope_starting_with_expr(expr,
                        scoperef,
                        "interface",
                        ("globals", "imports",),
                        self.interface_names_from_elem)

</t>
<t tx="ekr.20080121105837.931"># c.f. tree_python.py::PythonTreeEvaluator

def _calltips_from_hit(self, hit):
    # TODO: compare with CitadelEvaluator._getSymbolCallTips()
    elem, scoperef = hit
    calltips = []
    if elem.tag == "variable":
        XXX
    elif elem.tag == "scope":
        ilk = elem.get("ilk")
        if ilk == "function":
            calltips.append(self._calltip_from_func(elem))
        elif ilk == "class":
            calltips.append(self._calltip_from_class(elem))
        else:
            raise NotImplementedError("unexpected scope ilk for "
                                      "calltip hit: %r" % elem)
    else:
        raise NotImplementedError("unexpected elem for calltip "
                                  "hit: %r" % elem)
    return calltips

</t>
<t tx="ekr.20080121105837.932">def _calltip_from_class(self, node):
    # If the class has a defined signature then use that.
    signature = node.get("signature")
    doc = node.get("doc")
    if signature:
        ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
        return '\n'.join(ctlines)

    # Alternatively we use calltip information on the class'
    # constructor. PHP does not automatically inherit class contructors,
    # so we just return the one on the current class.
    else:
        # In PHP our CIX classes may have a special constructor function
        # with the name "__construct".
        ctor = node.names.get("__construct")
        if ctor is not None:
            self.log("_calltip_from_class:: ctor is %r", ctor)
            return self._calltip_from_func(ctor)
        else:
            name = node.get("name")
            self.log("_calltip_from_class:: no ctor in class %r", name)
            return "%s()" % (name)

</t>
<t tx="ekr.20080121105837.933">def _members_from_elem(self, elem, name_prefix=''):
    """Return the appropriate set of autocomplete completions for
    the given element. Typically this is just one, but can be more for
    '*'-imports
    """
    members = set()
    if elem.tag == "import":
        alias = elem.get("alias")
        symbol_name = elem.get("symbol")
        module_name = elem.get("module")
        if symbol_name:
            #XXX Ignore failure to import.
            blob = import_handler.import_blob_name(
                        module_name, self.buf.libs, self.ctlr)
            if symbol_name == "*":
                XXX
            else:
                symbol = blob.names[symbol_name]
                member_type = (symbol.get("ilk") or symbol.tag)
                members.add( (member_type, alias or symbol_name) )
        else:
            cpln_name = alias or module_name.split('.', 1)[0]
            members.add( ("module", cpln_name) )
    else:
        members.add( (elem.get("ilk") or elem.tag,
                      name_prefix + elem.get("name")) )
    return members

</t>
<t tx="ekr.20080121105837.934">def _isElemInsideScoperef(self, elem, scoperef):
    blob, lpath = scoperef
    i = 0
    for i in range(len(lpath)):
        name = lpath[i]
        if name == elem.get("name"):
            check_elem = self._elem_from_scoperef((blob, lpath[:i+1]))
            if check_elem == elem:
                # It's in the scope
                return True
    return False

</t>
<t tx="ekr.20080121105837.935">def _members_from_hit(self, hit, allowProtected=None, allowPrivate=None):
    """Retrieve members from the given hit.

    @param hit {tuple} (elem, scoperef)
    """
    elem, scoperef = hit
    members = set()
    elem_name = elem.get("name")
    static_cplns = (self.trg.type == "static-members")
    for child in elem:
        name_prefix = ''   # Used to add "$" for static variable names.
        attributes = None
        if not allowProtected:
            attributes = child.get("attributes", "").split()
            # Protected and private vars can only be shown from inside
            # the class scope
            if "protected" in attributes:
                if allowProtected is None:
                    # Need to check if it's allowed
                    allowProtected = self._isElemInsideScoperef(elem, self.get_start_scoperef())
                if not allowProtected:
                    # Checked scope already and it does not allow protected
                    # Thats means it also does not allow private
                    allowPrivate = False
                    self.log("hit '%s.%s' is protected, not including",
                             elem_name, child.get("name"))
                    continue
        if not allowPrivate:
            if attributes is None:
                attributes = child.get("attributes", "").split()
            # we now know protected is allowed, now check private
            if "private" in attributes:
                if allowPrivate is None:
                    # Need to check if it's allowed
                    allowPrivate = self._isElemInsideScoperef(elem, self.get_start_scoperef())
                if not allowPrivate:
                    # Checked scope already and it does not allow private
                    self.log("hit '%s.%s' is private, not including",
                             elem_name, child.get("name"))
                    continue
        if child.tag == "variable":
            if attributes is None:
                attributes = child.get("attributes", "").split()
            if static_cplns:
                # Static variables use the '$' prefix, constants do not.
                if "static" in attributes:
                    name_prefix = '$'
                elif child.get("ilk") != "constant":
                    continue
            elif "static" in attributes or child.get("ilk") == "constant":
                continue
        # add the element, we've already checked private|protected scopes
        members.update(self._members_from_elem(child, name_prefix))
    if elem.get("ilk") == "class":
        for classref in elem.get("classrefs", "").split():
            self.debug("_members_from_hit: Getting members for inherited class: %r", classref)
            try:
                subhit = self._hit_from_citdl(classref, scoperef)
            except CodeIntelError, ex:
                # Continue with what we *can* resolve.
                self.warn(str(ex))
            else:
                if allowProtected is None:
                    # Need to check if it's allowed
                    allowProtected = self._isElemInsideScoperef(elem, self.get_start_scoperef())
                # Checking the parent class, private is not allowed for sure
                members.update(self._members_from_hit(subhit, allowProtected, allowPrivate=False))
    return members

</t>
<t tx="ekr.20080121105837.936">def _hit_from_citdl(self, expr, scoperef, defn_only=False):
    """Resolve the given CITDL expression (starting at the given
    scope) down to a non-import/non-variable hit.
    """
    self.log("_hit_from_citdl:: expr: %r, scoperef: %r", expr, scoperef)
    try:
        self._check_infinite_recursion(expr)
    except EvalError:
        # In the case of a recursion error, it is likely due to a class
        # variable having the same name as the class itself, so to try
        # to get better completions for this case we do not abort here,
        # but rather try from the parent scope instead. See bug:
        # http://bugs.activestate.com/show_bug.cgi?id=67774
        scoperef = self.parent_scoperef_from_scoperef(scoperef)
        if scoperef is None:
            # When we run out of scope, raise an error
            raise
        self.debug("_hit_from_citdl: recursion found for '%s', "
                   "moving to parent scope %r",
                   expr, scoperef)

    tokens = list(self._tokenize_citdl_expr(expr))
    self.log("_hit_from_citdl:: expr tokens: %r", tokens)

    # First part...
    hit, nconsumed = self._hit_from_first_part(tokens, scoperef)
    if not hit:
        #TODO: Add the fallback Buffer-specific near-by hunt
        #      for a symbol for the first token. See my spiral-bound
        #      book for some notes.
        raise CodeIntelError("could not resolve first part of '%s'" % expr)

    self.debug("_hit_from_citdl:: first part: %r -&gt; %r",
               tokens[:nconsumed], hit)

    # ...the remainder.
    remaining_tokens = tokens[nconsumed:]
    while remaining_tokens:
        self.debug("_hit_from_citdl:: resolve %r on %r in %r",
                   remaining_tokens, *hit)
        if remaining_tokens[0] == "()":
            #TODO: impl this function
            # _hit_from_call(elem, scoperef) -&gt; hit or raise
            #   CodeIntelError("could resolve call on %r: %s", hit[0], ex)
            new_hit = self._hit_from_call(*hit)
            nconsumed = 1
        else:
            new_hit, nconsumed \
                = self._hit_from_getattr(remaining_tokens, *hit)
        remaining_tokens = remaining_tokens[nconsumed:]
        hit = new_hit

    # Resolve any variable type inferences.
    #TODO: Need to *recursively* resolve hits.
    elem, scoperef = hit
    if elem.tag == "variable" and not defn_only:
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)

    self.info("_hit_from_citdl:: found '%s' =&gt; %s on %s", expr, elem, scoperef)
    return (elem, scoperef)

</t>
<t tx="ekr.20080121105837.937">def _elem_from_scoperef(self, scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        elem = elem.names[lname]
    return elem

</t>
<t tx="ekr.20080121105837.938">def _hit_from_first_part(self, tokens, scoperef):
    """Find a hit for the first part of the tokens.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or (None, None) if could
    not resolve.

    Example for 'os.sep':
        tokens: ('os', 'sep')
        retval: ((&lt;variable 'sep'&gt;,  (&lt;blob 'os', [])),   1)
    Example for 'os.path':
        tokens: ('os', 'path')
        retval: ((&lt;import os.path&gt;,  (&lt;blob 'os', [])),   2)
    """
    first_token = tokens[0]
    self.log("_hit_from_first_part:: find '%s ...' starting at %s:",
             first_token, scoperef)

    if first_token in ("this", "self", "parent"):
        # Special handling for class accessors
        self.log("_hit_from_first_part:: Special handling for %r",
                 first_token)
        elem = self._elem_from_scoperef(scoperef)
        while elem is not None and elem.get("ilk") != "class":
            # Return the class element
            blob, lpath = scoperef
            if not lpath:
                return (None, None)
            scoperef = blob, lpath[:-1]
            elem = self._elem_from_scoperef(scoperef)
        if not elem:
            return (None, None)
        self.log("_hit_from_first_part:: need %s for %r", first_token, elem)
        if first_token == "parent":
            first_token = elem.get("classrefs")
            self.log("_hit_from_first_part:: Special handling for parent, "
                     "classref %r", first_token)
            if not first_token:
                return (None, None)
            # Change scope to global scope
            tokens = [first_token] + tokens[1:]
            scoperef = self._get_global_scoperef(scoperef)
            # Now go below and find the parent class members
        elif self._return_with_hit((elem, scoperef), 1):
            self.log("_hit_from_first_part:: %s returning scoperef: %r",
                     first_token, scoperef)
            return (elem, scoperef), 1

    while 1:
        self.log("_hit_from_first_part:: scoperef now %s:", scoperef)
        elem = self._elem_from_scoperef(scoperef)
        if first_token in elem.names:
            first_token_elem = elem.names[first_token]
            if self._return_with_hit((first_token_elem, scoperef), 1):
                #TODO: skip __hidden__ names
                self.log("_hit_from_first_part:: is '%s' accessible on %s? "
                         "yes: %s", first_token, scoperef, first_token_elem)
                return (first_token_elem, scoperef), 1

        self.log("_hit_from_first_part:: is '%s' accessible on %s? no", first_token, scoperef)
        # Do not go past the global scope reference
        if len(scoperef[1]) &gt;= 1:
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            assert scoperef and scoperef[0] is not None, "Something is " \
                    "seriously wrong with our php logic."
        else:
            # We shall fallback to imports then
            break

    # elem and scoperef *are* for the global level
    hit, nconsumed = self._hit_from_elem_imports(tokens, elem)
    if hit is not None and self._return_with_hit(hit, nconsumed):
        self.log("_hit_from_first_part:: is '%s' accessible on %s? yes, "
                 "imported: %s",
                 '.'.join(tokens[:nconsumed]), scoperef, hit[0])
        return hit, nconsumed
    return None, None


</t>
<t tx="ekr.20080121105837.939">def _hit_from_elem_imports(self, tokens, elem):
    """See if token is from one of the imports on this &lt;scope&gt; elem.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or (None, None) if not found.
    """
    #PERF: just have a .import_handler property on the evalr?
    self.debug("_hit_from_elem_imports:: Checking imports, tokens[0]: %r "
               "... imp_elem: %r", tokens[0], elem)
    import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
    libs = self.buf.libs

    #PERF: Add .imports method to ciElementTree for quick iteration
    #      over them. Or perhaps some cache to speed this method.
    #TODO: The right answer here is to not resolve the &lt;import&gt;,
    #      just return it. It is complicated enough that the
    #      construction of members has to know the original context.
    #      See the "Foo.mypackage.&lt;|&gt;mymodule.yo" part of test
    #      python/cpln/wacky_imports.
    #      XXX Not totally confident that this is the right answer.
    first_token = tokens[0]
    for imp_elem in (i for i in elem if i.tag == "import"):
        self.debug("_hit_from_elem_imports:: import '%s ...' from %r?",
                   tokens[0], imp_elem)
        module_name = imp_elem.get("module")
        try_module_names = [module_name]
        # If a module import is absolute and it fails, try a relative one
        # as well. Example:
        #   include (MYDIR + "/file.php");
        if module_name[0] == "/":
            try_module_names.append(module_name[1:])
        for module_name in try_module_names:
            if module_name not in self._imported_blobs:
                try:
                    blob = import_handler.import_blob_name(
                                module_name, libs, self.ctlr)
                except CodeIntelError:
                    self.debug("_hit_from_elem_imports:: Failed import: %s",
                               module_name)
                    pass # don't freak out: might not be our import anyway
                else:
                    self._imported_blobs[module_name] = 1
                    try:
                        hit, nconsumed = self._hit_from_getattr(
                                            tokens, blob, (blob, []))
                        if hit:
                            return hit, nconsumed
                    except CodeIntelError, e:
                        self.debug("_hit_from_elem_imports:: "
                                   "_hit_from_getattr could not resolve: "
                                   "%r on %r", tokens, blob)
                        pass # don't freak out: we'll try the next import
            else:
                self.debug("_hit_from_elem_imports:: Recursive import: "
                           "Already imported module: %r", module_name)

    # include-everything stuff
    self.log("_hit_from_elem_imports:: trying import everything: tokens: "
             "%r", tokens)
    #self.log(banner("include-everything stuff", length=50))

    # First check the full lpath, then try for smaller and smaller lengths
    for nconsumed in range(len(tokens), 0, -1):
        lpath = tuple(tokens[:nconsumed])
        self.log("_hit_from_elem_imports:: trying with lpath: %r", lpath)
        # for each directory in all known php file directories
        for lib in self.libs:
            # see if there is a match (or partial match) in this directory
            hits = lib.hits_from_lpath(lpath, self.ctlr,
                                          curr_buf=self.buf)
            self.log("_hit_from_elem_imports:: ie: lookup %r in %s =&gt; %r",
                     lpath, lib, hits)
            for hit in hits:
                (hit_elem, import_scoperef) = hit
                (hit_blob, hit_lpath) = import_scoperef
                self.log("_hit_from_elem_imports:: ie: matched %r to %r "
                         "in blob %r", lpath, hit_elem, hit_blob, )
                unique_import_name = hit_blob.get("name") + "#" + str(lpath)
                #print unique_import_name
                if unique_import_name not in self._imported_blobs:
                    self._imported_blobs[unique_import_name] = 1
                    try:
                        if hit and self._return_with_hit(hit, 1):
                            return hit, nconsumed
                    except CodeIntelError, e:
                        self.debug("_hit_from_elem_imports:: ie: "
                                   "_hit_from_getattr could not resolve: "
                                   "%r on %r", tokens, blob)
                        pass # don't freak out: we'll try the next import
                else:
                    self.debug("_hit_from_elem_imports:: ie: Recursive "
                               "import: Already imported module: %r",
                               unique_import_name)
        self.log("_hit_from_elem_imports:: ie: no matches found")
        #self.log(banner(None, length=50))

    return None, None

</t>
<t tx="ekr.20080121105837.940">def _hit_from_getattr(self, tokens, elem, scoperef):
    """Return a hit for a getattr on the given element.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or raises an EvalError.

    Typically this just does a getattr of tokens[0], but handling
    some multi-level imports can result in multiple tokens being
    consumed.
    """
    #TODO: On failure, call a hook to make an educated guess. Some
    #      attribute names are strong signals as to the object type
    #      -- typically those for common built-in classes.
    first_token = tokens[0]
    self.log("_hit_from_getattr:: resolve '%s' on %r in %r:", first_token,
             elem, scoperef)
    if elem.tag == "variable":
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)

    assert elem.tag == "scope"
    ilk = elem.get("ilk")
    if ilk == "function":
        # Internal function arguments and variable should
        # *not* resolve. And we don't support function
        # attributes.
        pass
    elif ilk == "class":
        attr = elem.names.get(first_token)
        if attr is not None:
            self.log("_hit_from_getattr:: attr is %r in %r", attr, elem)
            classname = elem.get("name")
            # XXX - This works, but does not feel right.
            # Add the class name if it's not already there
            if len(scoperef[1]) == 0 or scoperef[1][-1] != classname:
                class_scoperef = (scoperef[0], scoperef[1]+[classname])
            else:
                class_scoperef = scoperef
            return (attr, class_scoperef), 1
        for classref in elem.get("classrefs", "").split():
            #TODO: update _hit_from_citdl to accept optional node type,
            #      i.e. to only return classes in this case.
            self.log("_hit_from_getattr:: is '%s' available on parent "
                     "class: %r?", first_token, classref)
            base_elem, base_scoperef \
                = self._hit_from_citdl(classref, scoperef)
            if base_elem is not None and base_elem.get("ilk") == "class":
                self.log("_hit_from_getattr:: is '%s' from %s base class?",
                         first_token, base_elem)
                try:
                    hit, nconsumed = self._hit_from_getattr(tokens,
                                                            base_elem,
                                                            base_scoperef)
                    if hit is not None and self._return_with_hit(hit,
                                                                 nconsumed):
                        self.log("_hit_from_getattr:: is '%s' accessible "
                                 "on %s? yes: %s",
                                 '.'.join(tokens[:nconsumed]), scoperef,
                                 hit[0])
                        return hit, nconsumed
                except CodeIntelError, e:
                    pass # don't freak out: we'll try the next classref
    elif ilk == "blob":
        attr = elem.names.get(first_token)
        if attr is not None:
            self.log("_hit_from_getattr:: attr is %r in %r", attr, elem)
            return (attr, scoperef), 1

        hit, nconsumed = self._hit_from_elem_imports(tokens, elem)
        if hit is not None:
            return hit, nconsumed
    else:
        raise NotImplementedError("unexpected scope ilk: %r" % ilk)
    raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                         % (first_token, elem, scoperef))

</t>
<t tx="ekr.20080121105837.941">def _hit_from_call(self, elem, scoperef):
    """Resolve the function call inference for 'elem' at 'scoperef'."""
    citdl = elem.get("returns")
    if not citdl:
        raise CodeIntelError("no _hit_from_call info for %r" % elem)
    self.log("_hit_from_call: resolve '%s' for %r, lpath: %r", citdl, elem, scoperef[1])
    # scoperef has to be on the function called
    func_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
    return self._hit_from_citdl(citdl, func_scoperef)

</t>
<t tx="ekr.20080121105837.942">def _hit_from_variable_type_inference(self, elem, scoperef):
    """Resolve the type inference for 'elem' at 'scoperef'."""
    citdl = elem.get("citdl")
    if not citdl:
        raise CodeIntelError("no type-inference info for %r" % elem)
    self.log("_hit_from_variable_type_inference:: resolve '%s' type inference for %r:", citdl, elem)
    return self._hit_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.943">def parent_scoperef_from_scoperef(self, scoperef):
    # For PHP, either it's in the current scope or it's in the global scope
    # or last of all, it's in the builtins
    blob, lpath = scoperef
    if blob is self._built_in_blob:
        # Nothin past the builtins
        return None
    elif len(lpath) &gt;= 1:
        # Return the global scope
        return self._get_global_scoperef(scoperef)
    else:
        return (self.built_in_blob, [])


</t>
<t tx="ekr.20080121105837.944">#--- These method were inherited from JavaScriptTreeEvaluator.
# If they are generic enough they should be moved to base
# TreeEvaluator.

_built_in_blob = None
@property
def built_in_blob(self):
    if self._built_in_blob is None:
        self._built_in_blob = self.buf.stdlib.get_blob("*")
    return self._built_in_blob

</t>
<t tx="ekr.20080121105837.945">_built_in_cache = None
@property
def built_in_cache(self):
    if self._built_in_cache is None:
        phpcache = self.built_in_blob.cache.get('php')
        if phpcache is None:
            phpcache = {}
            self.built_in_blob.cache['php'] = phpcache
        self._built_in_cache = phpcache
    return self._built_in_cache

</t>
<t tx="ekr.20080121105837.946">def _tokenize_citdl_expr(self, expr):
    for tok in expr.split('.'):
        if tok.endswith('()'):
            yield tok[:-2]
            yield '()'
        else:
            yield tok
</t>
<t tx="ekr.20080121105837.947">def _join_citdl_expr(self, tokens):
    return '.'.join(tokens).replace('.()', '()')

</t>
<t tx="ekr.20080121105837.948">def _calltip_from_func(self, node):
    # See "Determining a Function CallTip" in the spec for a
    # discussion of this algorithm.
    from codeintel2.util import LINE_LIMIT
    signature = node.get("signature")
    doc = node.get("doc")
    ctlines = []
    if not signature:
        name = node.get("name")
        #XXX Note difference for Tcl in _getSymbolCallTips.
        ctlines = [name + "(...)"]
    else:
        ctlines = signature.splitlines(0)
    if doc:
        ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
    return '\n'.join(ctlines)


</t>
<t tx="ekr.20080121105837.949">#---- Internal Utility functions for PHP

def _get_global_scoperef(self, scoperef):
    return (scoperef[0], [])

</t>
<t tx="ekr.20080121105837.950">def _convertListToCitdl(self, citdl_type, lst):
    return sorted([ (citdl_type, v) for v in lst ])

</t>
<t tx="ekr.20080121105837.951">def _make_shortname_lookup_citdl_dict(self, citdl_type, namelist, length=1):
    d = make_short_name_dict(namelist, length=length)
    for key, values in d.items():
        d[key] = self._convertListToCitdl(citdl_type, values)
    return d

</t>
<t tx="ekr.20080121105837.952"># XXX PERF : Anything below here is in need of performance tweaking

def _get_all_children_with_details(self, node, tagname, attributes=None, startswith=None):
    """Returns a list of child nodes that have the tag name and attributes.
    
    @param node {Element} the base node to search from
    @param tagname {str} the child tag name to find
    @param attributes {dict} the child node must have these attributes
    @param startswith {str} the child node name must start with this string
    @returns list of matched Element nodes
    """
    result = []
    for childnode in node.getchildren():
        if childnode.tag == tagname:
            doesMatch = True
            if attributes:
                for attrname, attrvalue in attributes.items():
                    if childnode.get(attrname) != attrvalue:
                        doesMatch = False
                        break
            if doesMatch and startswith:
                name = childnode.get("name")
                if not name or not name.startswith(startswith):
                    doesMatch = False
            if doesMatch:
                result.append(childnode)
    return result

</t>
<t tx="ekr.20080121105837.953">def _get_import_blob_with_module_name(self, module_name):
    import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
    libs = self.buf.libs
    try:
        return import_handler.import_blob_name(module_name, libs,
                                               self.ctlr)
    except CodeIntelError:
        pass # don't freak out: might not be our import anyway

</t>
<t tx="ekr.20080121105837.954"># Only used by _get_all_import_blobs_for_elem
def _get_all_import_blobs_dict_for_elem(self, elem, imported_blobs):
    """Return all imported php blobs for the given element
    @param elem {Element} The element to find imports from.
    @param imported_blobs {dict} key: import name, value: imported blob
    """
    for imp_elem in (i for i in elem if i.tag == "import"):
        module_name = imp_elem.get("module")
        self.debug("_get_all_import_blobs_dict_for_elem:: Getting imports from %r", module_name)
        if module_name and module_name not in imported_blobs:
            import_blob = self._get_import_blob_with_module_name(module_name)
            if import_blob is not None:
                imported_blobs[module_name] = import_blob
                # Get imports from imports
                # Example, foo imports bar, bar imports baz
                self._get_all_import_blobs_dict_for_elem(import_blob, imported_blobs)
        else:
            self.debug("_get_all_import_blobs_dict_for_elem:: Recursive import: Already imported module: %r",
                       module_name)

</t>
<t tx="ekr.20080121105837.955">def _get_all_import_blobs_for_elem(self, elem):
    """Return all imported php blobs for the given element
    @param elem {Element} The element to find imports from.
    """
    # imported_blobs is used to keep track of what we import and to ensure
    # we don't get a recursive import situation
    imported_blobs = {}
    self._get_all_import_blobs_dict_for_elem(elem, imported_blobs)
    blobs = imported_blobs.values()
    self.debug("_get_all_import_blobs_for_elem:: Imported blobs: %r", blobs)
    return blobs

</t>
<t tx="ekr.20080121105837.956">#_built_in_keyword_names = None
#@property
#def built_in_keyword_names(self):
#    if self._built_in_keyword_names is None:
#        # Get all class names from the nodes
#        # XXX - Fix keywords
#        self._built_in_keyword_names = ["print", "echo", "class", "function"]
#    return self._built_in_keyword_names

def _php_cache_from_elem(self, elem):
    cache = elem.cache.get('php')
    if cache is None:
        # Add one in then
        cache = {}
        elem.cache['php'] = cache
    return cache

</t>
<t tx="ekr.20080121105837.957">def variable_names_from_elem(self, elem, cache_item_name='variable_names'):
    cache = self._php_cache_from_elem(elem)
    variable_names = cache.get(cache_item_name)
    if variable_names is None:
        variables = self._get_all_children_with_details(elem, "variable")
        variable_names = [ x.get("name") for x in variables if x.get("ilk") != "constant" ]
        cache[cache_item_name] = variable_names
    return variable_names

</t>
<t tx="ekr.20080121105837.958">def constant_names_from_elem(self, elem, cache_item_name='constant_names'):
    cache = self._php_cache_from_elem(elem)
    constant_names = cache.get(cache_item_name)
    if constant_names is None:
        constants = self._get_all_children_with_details(elem, "variable",
                                                        {"ilk": "constant"})
        constant_names = [ x.get("name") for x in constants ]
        cache[cache_item_name] = constant_names
    return constant_names

</t>
<t tx="ekr.20080121105837.959">def constant_shortnames_from_elem(self, elem, cache_item_name='constant_shortnames'):
    cache = self._php_cache_from_elem(elem)
    constant_short_names = cache.get(cache_item_name)
    if constant_short_names is None:
        constant_short_names = make_short_name_dict(
                                self.constant_names_from_elem(elem),
                                # XXX - TODO: Use constant_TRIGGER_LEN instead of hard coding 3
                                length=3)
        cache[cache_item_name] = constant_short_names
    return constant_short_names

</t>
<t tx="ekr.20080121105837.960">def function_names_from_elem(self, elem, cache_item_name='function_names'):
    cache = self._php_cache_from_elem(elem)
    function_names = cache.get(cache_item_name)
    if function_names is None:
        functions = self._get_all_children_with_details(elem, "scope",
                                                        {"ilk": "function"})
        function_names = [ x.get("name") for x in functions ]
        cache[cache_item_name] = function_names
    return function_names

</t>
<t tx="ekr.20080121105837.961">def function_shortnames_from_elem(self, elem, cache_item_name='function_shortnames'):
    cache = self._php_cache_from_elem(elem)
    function_short_names = cache.get(cache_item_name)
    if function_short_names is None:
        function_short_names = make_short_name_dict(
                                self.function_names_from_elem(elem),
                                # XXX - TODO: Use FUNCTION_TRIGGER_LEN instead of hard coding 3
                                length=3)
        cache[cache_item_name] = function_short_names
    return function_short_names

</t>
<t tx="ekr.20080121105837.962">def class_names_from_elem(self, elem, cache_item_name='class_names'):
    cache = self._php_cache_from_elem(elem)
    class_names = cache.get(cache_item_name)
    if class_names is None:
        classes = self._get_all_children_with_details(elem, "scope",
                                                        {"ilk": "class"})
        class_names = [ x.get("name") for x in classes ]
        cache[cache_item_name] = class_names
    return class_names

</t>
<t tx="ekr.20080121105837.963">def interface_names_from_elem(self, elem, cache_item_name='interface_names'):
    cache = self._php_cache_from_elem(elem)
    interface_names = cache.get(cache_item_name)
    if interface_names is None:
        interfaces = self._get_all_children_with_details(elem, "scope",
                                                        {"ilk": "interface"})
        interface_names = [ x.get("name") for x in interfaces ]
        cache[cache_item_name] = interface_names
    return interface_names
</t>
<t tx="ekr.20080121105837.964">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Completion evaluation code for Python"""

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator

@language python
@tabwidth -4

class PythonTreeEvaluator(TreeEvaluator):
    @others

</t>
<t tx="ekr.20080121105837.967">def eval_cplns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    #if self.trg.type == 'available-classes':
    #    return self._available_classes(start_scoperef, self.trg.extra["consumed"])
    hit = self._hit_from_citdl(self.expr, start_scoperef)
    return list(self._members_from_hit(hit))

</t>
<t tx="ekr.20080121105837.968">def eval_calltips(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    hit = self._hit_from_citdl(self.expr, start_scoperef)
    return [ self._calltip_from_hit(hit) ]

</t>
<t tx="ekr.20080121105837.969">def eval_defns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.info("start scope is %r", start_scoperef)
    hit = self._hit_from_citdl(self.expr, start_scoperef, defn_only=True)
    return [ self._defn_from_hit(hit) ]

</t>
<t tx="ekr.20080121105837.970">#def _available_classes(self, scoperef, consumed):
#    matches = set()
#    blob = scoperef[0] # XXX??
#    for elem in blob:
#        if elem.tag == 'scope' and elem.get('ilk') == 'class':
#            matches.add(elem.get('name'))
#    matches.difference_update(set(consumed))
#    matches_list = sorted(list(matches))
#    return [('class', m) for m in matches_list]

def _tokenize_citdl_expr(self, citdl):
    for token in citdl.split('.'):
        if token.endswith('()'):
            yield token[:-2]
            yield '()'
        else:
            yield token
</t>
<t tx="ekr.20080121105837.971">def _join_citdl_expr(self, tokens):
    return '.'.join(tokens)

</t>
<t tx="ekr.20080121105837.972">def _calltip_from_func(self, elem, scoperef, class_name=None):
    # See "Determining a Function CallTip" in the spec for a
    # discussion of this algorithm.
    from codeintel2.util import LINE_LIMIT #TODO: -&gt; CALLTIP_LINE_LIMIT
    signature = elem.get("signature")
    ctlines = []
    if not signature:
        name = class_name or elem.get("name")
        ctlines = [name + "(...)"]
    else:
        ctlines = signature.splitlines(0)
    doc = elem.get("doc")
    if doc:
        ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
    return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.973">def _calltip_from_class(self, elem, scoperef):
    # If the class has a defined signature then use that.
    from codeintel2.util import LINE_LIMIT #TODO: -&gt; CALLTIP_LINE_LIMIT
    signature = elem.get("signature")
    if signature:
        doc = elem.get("doc")
        ctlines = signature.splitlines(0)
        if doc:
            ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
        return '\n'.join(ctlines)
    else:
        ctor_hit = self._ctor_hit_from_class(elem, scoperef)
        if ctor_hit and (ctor_hit[0].get("doc")
                         or ctor_hit[0].get("signature")):
            self.log("ctor is %r on %r", *ctor_hit)
            return self._calltip_from_func(ctor_hit[0], ctor_hit[1],
                                           class_name=elem.get("name"))
            
        else:
            doc = elem.get("doc")
            if doc:
                ctlines = [ln for ln in doc.splitlines(0)[:LINE_LIMIT] if ln]
            else:
                ctlines = [elem.get("name") + "()"]
            return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.974">def _ctor_hit_from_class(self, elem, scoperef):
    """Return the Python ctor for the given class element, or None."""
    if "__init__" in elem.names:
        class_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
        return elem.names["__init__"], class_scoperef
    else:
        for classref in elem.get("classrefs", "").split():
            try:
                basehit = self._hit_from_type_inference(classref, scoperef)
            except CodeIntelError, ex:
                self.warn(str(ex))
            else:
                ctor_hit = self._ctor_hit_from_class(*basehit)
                if ctor_hit:
                    return ctor_hit
    return None

</t>
<t tx="ekr.20080121105837.975">def _calltip_from_hit(self, hit):
    # TODO: compare with CitadelEvaluator._getSymbolCallTips()
    elem, scoperef = hit
    if elem.tag == "variable":
        XXX
    elif elem.tag == "scope":
        ilk = elem.get("ilk")
        if ilk == "function":
            calltip = self._calltip_from_func(elem, scoperef)
        elif ilk == "class":
            calltip = self._calltip_from_class(elem, scoperef)
        else:
            raise NotImplementedError("unexpected scope ilk for "
                                      "calltip hit: %r" % elem)
    else:
        raise NotImplementedError("unexpected elem for calltip "
                                  "hit: %r" % elem)
    return calltip

</t>
<t tx="ekr.20080121105837.976">def _members_from_elem(self, elem):
    """Return the appropriate set of autocomplete completions for
    the given element. Typically this is just one, but can be more for
    '*'-imports
    """
    members = set()
    if elem.tag == "import":
        alias = elem.get("alias")
        symbol_name = elem.get("symbol")
        module_name = elem.get("module")
        if symbol_name:
            # This can fail as follows:
            #   foo.py:          import bar; bar.&lt;|&gt;
            #   bar/__init__.py: import blam
            #   bar/blam.py
            # 'blam.py' should be imported to report it as a
            # completion for 'bar.&lt;|&gt;' in foo.py. However the
            # &lt;currdirlib&gt; won't find it because we are using
            # foo.py's cwd, not the bar directory.
            #
            # The right answer is to have a buf for bar/__init__.py
            # and ask it to do the import (it has its own .libs).
            #
            # TODO: What about having
            #   buf.members_from_elem(elem, trg.lang, ctlr)?
            #   Pass around scoperef. Scoperef becomes (buf, lang,
            #   lpath). 
            import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
            try:
                blob = import_handler.import_blob_name(
                            module_name, self.buf.libs, self.ctlr)
            except:
                self.warn("limitation in handling imports in imported modules")
                raise

            if symbol_name == "*":
                for m_name, m_elem in blob.names.items():
                    m_type = m_elem.get("ilk") or m_elem.tag
                    members.add( (m_type, m_name) )
            elif symbol_name in blob.names:
                symbol = blob.names[symbol_name]
                member_type = (symbol.get("ilk") or symbol.tag)
                members.add( (member_type, alias or symbol_name) )
            else:
                hit, nconsumed \
                    = self._hit_from_elem_imports([symbol_name], blob)
                if hit:
                    symbol = hit[0]
                    member_type = (symbol.get("ilk") or symbol.tag)
                    members.add( (member_type, alias or symbol_name) )
                else:
                    self.warn("could not resolve %r", elem)
        else:
            cpln_name = alias or module_name.split('.', 1)[0]
            members.add( ("module", cpln_name) )
    else:
        members.add( (elem.get("ilk") or elem.tag, elem.get("name")) )
    return members

</t>
<t tx="ekr.20080121105837.977">def _members_from_hit(self, hit):
    elem, scoperef = hit
    members = set()
    for child in elem:
        if "__hidden__" not in child.get("attributes", "").split():
            try:
                members.update(self._members_from_elem(child))
            except CodeIntelError, ex:
                self.warn("%s (skipping members for %s)", ex, child)
    if elem.get("ilk") == "class":
        for classref in elem.get("classrefs", "").split():
            try:
                subhit = self._hit_from_type_inference(classref, scoperef)
            except CodeIntelError, ex:
                # Continue with what we *can* resolve.
                self.warn(str(ex))
            else:
                members.update(self._members_from_hit(subhit))
    return members

</t>
<t tx="ekr.20080121105837.978">def _hit_from_citdl(self, expr, scoperef, defn_only=False):
    """Resolve the given CITDL expression (starting at the given
    scope) down to a non-import/non-variable hit.
    """
    self._check_infinite_recursion(expr)
    tokens = list(self._tokenize_citdl_expr(expr))
    #self.log("expr tokens: %r", tokens)

    # First part...
    hit, nconsumed = self._hit_from_first_part(tokens, scoperef)
    if not hit:
        #TODO: Add the fallback Buffer-specific near-by hunt
        #      for a symbol for the first token. See my spiral-bound
        #      book for some notes.
        raise CodeIntelError("could not resolve first part of '%s'" % expr)
    self.debug("_hit_from_citdl: first part: %r -&gt; %r",
               tokens[:nconsumed], hit)

    # ...the remainder.
    remaining_tokens = tokens[nconsumed:]
    while remaining_tokens:
        self.debug("_hit_from_citdl: resolve %r on %r in %r",
                   remaining_tokens, *hit)
        if remaining_tokens[0] == "()":
            new_hit = self._hit_from_call(*hit)
            nconsumed = 1
        else:
            new_hit, nconsumed \
                = self._hit_from_getattr(remaining_tokens, *hit)
        remaining_tokens = remaining_tokens[nconsumed:]
        hit = new_hit

    # Resolve any variable type inferences.
    #TODO: Need to *recursively* resolve hits.
    elem, scoperef = hit
    if elem.tag == "variable" and not defn_only:
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)

    self.info("'%s' is %s on %s", expr, elem, scoperef)
    return (elem, scoperef)

</t>
<t tx="ekr.20080121105837.979">def _hit_from_first_part(self, tokens, scoperef):
    """Find a hit for the first part of the tokens.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or (None, None) if could
    not resolve.

    Example for 'os.sep':
        tokens: ('os', 'sep')
        retval: ((&lt;variable 'sep'&gt;,  (&lt;blob 'os', [])),   1)
    Example for 'os.path':
        tokens: ('os', 'path')
        retval: ((&lt;import os.path&gt;,  (&lt;blob 'os', [])),   2)
    """
    first_token = tokens[0]
    self.log("find '%s ...' starting at %s:", first_token, scoperef)

    # pythoncile will sometimes give a citdl expression of "__builtins__",
    # check for this now, bug:
    #   http://bugs.activestate.com/show_bug.cgi?id=71972
    if first_token == "__builtins__":
        # __builtins__ is the same as the built_in_blob, return it.
        scoperef = (self.built_in_blob, [])
        return (self.built_in_blob, scoperef), 1

    while 1:
        elem = self._elem_from_scoperef(scoperef)
        if first_token in elem.names:
            #TODO: skip __hidden__ names
            self.log("is '%s' accessible on %s? yes: %s",
                     first_token, scoperef, elem.names[first_token])
            return (elem.names[first_token], scoperef), 1

        hit, nconsumed \
            = self._hit_from_elem_imports(tokens, elem)
        if hit is not None:
            self.log("is '%s' accessible on %s? yes: %s",
                     '.'.join(tokens[:nconsumed]), scoperef, hit[0])
            return hit, nconsumed

        self.log("is '%s' accessible on %s? no", first_token, scoperef)
        scoperef = self.parent_scoperef_from_scoperef(scoperef)
        if not scoperef:
            return None, None

</t>
<t tx="ekr.20080121105837.980">def _hit_from_elem_imports(self, tokens, elem):
    """See if token is from one of the imports on this &lt;scope&gt; elem.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or (None, None) if not found.
    XXX import_handler.import_blob_name() calls all have potential
        to raise CodeIntelError.
    """
    #PERF: just have a .import_handler property on the evalr?
    import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
    libs = self.buf.libs

    #PERF: Add .imports method to ciElementTree for quick iteration
    #      over them. Or perhaps some cache to speed this method.
    #TODO: The right answer here is to not resolve the &lt;import&gt;,
    #      just return it. It is complicated enough that the
    #      construction of members has to know the original context.
    #      See the "Foo.mypackage.&lt;|&gt;mymodule.yo" part of test
    #      python/cpln/wacky_imports.
    #      XXX Not totally confident that this is the right answer.
    first_token = tokens[0]
    self._check_infinite_recursion(first_token)
    for imp_elem in (i for i in elem if i.tag == "import"):
        self.debug("'%s ...' from %r?", tokens[0], imp_elem)
        alias = imp_elem.get("alias")
        symbol_name = imp_elem.get("symbol")
        module_name = imp_elem.get("module")

        if symbol_name:
            # from module import symbol, from module import symbol as alias
            # from module import submod, from module import submod as alias
            if (alias and alias == first_token) \
               or (not alias and symbol_name == first_token):
                # Try 'from module import symbol/from module import
                # symbol as alias' first.
                try:
                    blob = import_handler.import_blob_name(
                                module_name, libs, self.ctlr)
                    if symbol_name in blob.names:
                        return (blob.names[symbol_name], (blob, [])),  1
                    else:
                        hit, nconsumed = self._hit_from_elem_imports(
                            [first_token] + tokens[1:], blob)
                        if hit: 
                            return hit, nconsumed
                except CodeIntelError:
                    pass

                # That didn't work, try 'from module import
                # submod/from module import submod as alias'.
                submodule_name = import_handler.sep.join(
                                    [module_name, symbol_name])
                try:
                    subblob = import_handler.import_blob_name(
                                submodule_name, libs, self.ctlr)
                    return (subblob, (subblob, [])), 1
                except CodeIntelError:
                    # That didn't work either. Give up.
                    self.warn("could not import '%s' from %s",
                              first_token, imp_elem)

            # from module import *
            elif symbol_name == "*":
                try:
                    blob = import_handler.import_blob_name(
                                module_name, libs, self.ctlr)
                except CodeIntelError:
                    pass # don't freak out: might not be our import anyway
                else:
                    try:
                        hit, nconsumed = self._hit_from_getattr(
                                            tokens, blob, (blob, []))
                    except CodeIntelError:
                        pass
                    else:
                        if hit:
                            return hit, nconsumed

        elif (alias and alias == first_token) \
             or (not alias and module_name == first_token):
            blob = import_handler.import_blob_name(
                        module_name, libs, self.ctlr)
            return (blob, (blob, [])),  1

        elif '.' in module_name:
            # E.g., might be looking up ('os', 'path', ...) and
            # have &lt;import os.path&gt;.
            module_tokens = module_name.split('.')
            if module_tokens == tokens[:len(module_tokens)]:
                # E.g. tokens:   ('os', 'path', ...)
                #      imp_elem: &lt;import os.path&gt;
                #      return:   &lt;blob 'os.path'&gt; for first two tokens
                blob = import_handler.import_blob_name(
                            module_name, libs, self.ctlr)
                #XXX Is this correct scoperef for module object?
                return (blob, (blob, [])),  len(module_tokens)
            else:
                # E.g. tokens:   ('os', 'sep', ...)
                #      imp_elem: &lt;import os.path&gt;
                #      return:   &lt;blob 'os'&gt; for first token
                for i in range(len(module_tokens)-1, 0, -1):
                    if module_tokens[:i] == tokens[:i]:
                        blob = import_handler.import_blob_name(
                                    '.'.join(module_tokens[:i]),
                                    libs, self.ctlr)
                        #XXX Is this correct scoperef for module object?
                        return (blob, (blob, [])),  i

    return None, None

</t>
<t tx="ekr.20080121105837.981">def _hit_from_call(self, elem, scoperef):
    """Resolve the function call inference for 'elem' at 'scoperef'."""
    # This might be a variable, in that case we keep resolving the variable
    # until we get to the final function/class element that is to be called.
    while elem.tag == "variable":
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)
    ilk = elem.get("ilk")
    if ilk == "class":
        # Return the class element.
        self.log("_hit_from_call: resolved to class '%s'", elem.get("name"))
        return (elem, scoperef)
    if ilk == "function":
        citdl = elem.get("returns")
        if citdl:
            self.log("_hit_from_call: function with citdl %r",
                     citdl)
            # scoperef has to be set to the function called
            func_scoperef = (scoperef[0], scoperef[1]+[elem.get("name")])
            return self._hit_from_citdl(citdl, func_scoperef)
    raise CodeIntelError("no return type info for %r" % elem)

</t>
<t tx="ekr.20080121105837.982">def _hit_from_getattr(self, tokens, elem, scoperef):
    """Return a hit for a getattr on the given element.

    Returns (&lt;hit&gt;, &lt;num-tokens-consumed&gt;) or raises an CodeIntelError.

    Typically this just does a getattr of tokens[0], but handling
    some multi-level imports can result in multiple tokens being
    consumed.
    """
    #TODO: On failure, call a hook to make an educated guess. Some
    #      attribute names are strong signals as to the object type
    #      -- typically those for common built-in classes.
    first_token = tokens[0]
    self.log("resolve getattr '%s' on %r in %r:", first_token,
             elem, scoperef)
    if elem.tag == "variable":
        elem, scoperef = self._hit_from_variable_type_inference(elem, scoperef)

    assert elem.tag == "scope"
    ilk = elem.get("ilk")
    if ilk == "function":
        # Internal function arguments and variable should
        # *not* resolve. And we don't support function
        # attributes.
        pass
    elif ilk == "class":
        attr = elem.names.get(first_token)
        if attr is not None:
            self.log("attr is %r in %r", attr, elem)
            # update the scoperef, we are now inside the class.
            scoperef = (scoperef[0], scoperef[1] + [elem.get("name")])
            return (attr, scoperef), 1

        self.debug("look for %r from imports in %r", tokens, elem)
        hit, nconsumed \
            = self._hit_from_elem_imports(tokens, elem)
        if hit is not None:
            return hit, nconsumed

        for classref in elem.get("classrefs", "").split():
            try:
                self.log("is '%s' from base class: %r?", first_token,
                         classref)
                base_elem, base_scoperef \
                    = self._hit_from_type_inference(classref, scoperef)
                return self._hit_from_getattr(tokens, base_elem,
                                              base_scoperef)
            except CodeIntelError, ex:
                self.log("could not resolve '%s' getattr on base class %r",
                         first_token, base_elem)
                # Was not available, try the next class then.
    elif ilk == "blob":
        attr = elem.names.get(first_token)
        if attr is not None:
            self.log("attr is %r in %r", attr, elem)
            return (attr, scoperef), 1

        hit, nconsumed \
            = self._hit_from_elem_imports(tokens, elem)
        if hit is not None:
            return hit, nconsumed
    else:
        raise NotImplementedError("unexpected scope ilk: %r" % ilk)

    raise CodeIntelError("could not resolve '%s' getattr on %r in %r"
                         % (first_token, elem, scoperef))

</t>
<t tx="ekr.20080121105837.983">def _hit_from_variable_type_inference(self, elem, scoperef):
    """Resolve the type inference for 'elem' at 'scoperef'."""
    citdl = elem.get("citdl")
    if not citdl:
        raise CodeIntelError("no type-inference info for %r" % elem)
    self.log("resolve '%s' type inference for %r:", citdl, elem)
    return self._hit_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.984">def _hit_from_type_inference(self, citdl, scoperef):
    """Resolve the 'citdl' type inference at 'scoperef'."""
    self.log("resolve '%s' type inference:", citdl)
    return self._hit_from_citdl(citdl, scoperef)

</t>
<t tx="ekr.20080121105837.985">_built_in_blob = None
@property
def built_in_blob(self):
    if self._built_in_blob is None:
        #XXX Presume last lib is stdlib.
        self._built_in_blob = self.buf.libs[-1].get_blob("*")
    return self._built_in_blob

</t>
<t tx="ekr.20080121105837.986">def parent_scoperef_from_scoperef(self, scoperef):
    blob, lpath = scoperef
    if lpath:
        parent_lpath = lpath[:-1]
        if parent_lpath:
            elem = self._elem_from_scoperef((blob, parent_lpath))
            if elem.get("ilk") == "class":
                # Python eval shouldn't consider the class-level
                # scope as a parent scope when resolving from the
                # top-level. (test python/cpln/skip_class_scope)
                parent_lpath = parent_lpath[:-1]
        return (blob, parent_lpath)
    elif blob is self._built_in_blob:
        return None
    else:
        return (self.built_in_blob, [])

</t>
<t tx="ekr.20080121105837.987">def _elem_from_scoperef(self, scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        elem = elem.names[lname]
    return elem

</t>
<t tx="ekr.20080121105837.988">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.989">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Completion evaluation code for Ruby"""

import re

from codeintel2.common import *
from codeintel2.tree import TreeEvaluator
from codeintel2.tree_javascript import JavaScriptTreeEvaluator
from codeintel2.database.stdlib import StdLib

# Evaluator
#   CitadelEvaluator
#       PythonCitadelEvaluator
#       ...
#   TreeEvaluator
#       PythonTreeEvaluator

# Global constants

NO_HITS = [] # Any value, as long as it's boolean(False)

_ANY_RESOLUTION = 1
_NAMESPACE_RESOLUTION = 2
_CLASS_RESOLUTION     = 3

_OP_TO_RESOLUTION = {"::" : _NAMESPACE_RESOLUTION,
                     "." : _CLASS_RESOLUTION}

# Bitmask for completion types
        
_CPLN_MODULES        = 0x0001
_CPLN_METHODS_CLASS  = 0x0002
_CPLN_METHODS_INST   = 0x0004
_CPLN_METHODS_ALL    = _CPLN_METHODS_CLASS|_CPLN_METHODS_INST
_CPLN_METHODS_ALL_FOR_MODULE = 0x0008
    # Look at the left hand side:
    # Module type: accept all methods
    # Class type: accept class methods only
_CPLN_CLASSES        = 0x0010
_CPLN_VARIABLES      = 0x0020

_CPLN_ALL_BUT_METHODS = _CPLN_MODULES|_CPLN_CLASSES|_CPLN_VARIABLES
_CPLN_ALL            = _CPLN_ALL_BUT_METHODS|_CPLN_METHODS_ALL

# Global data

letter_start_re = re.compile('^[a-zA-Z]')
token_splitter_re = re.compile(r'(\.|::)')

_looks_like_constant_re = re.compile(r'[A-Z]\w*(?:::[A-Z]\w*)*$')

</t>
<t tx="ekr.20080121105837.990">class HitHelper:
    """Encapsulate the ElementTree-based represetation
    of Ruby code"""
    @others
</t>
<t tx="ekr.20080121105837.991">
def get_name(self, hit):
    return hit[0].get("name")

</t>
<t tx="ekr.20080121105837.992">def get_type(self, hit):
    elem = hit[0]
    return elem.get("ilk") or elem.tag

</t>
<t tx="ekr.20080121105837.993">def is_class(self, hit):
    return self.get_type(hit) == "class"

</t>
<t tx="ekr.20080121105837.994">def is_compound(self, hit):
    return self.get_type(hit) in ("class", "namespace")

</t>
<t tx="ekr.20080121105837.995">def is_function(self, hit):
    return self.get_type(hit) == "function"

</t>
<t tx="ekr.20080121105837.996">def is_namespace(self, hit):
    return self.get_type(hit) == "namespace"

</t>
<t tx="ekr.20080121105837.997">def is_variable(self, hit):
    return self.get_type(hit) == "variable"

</t>
<t tx="ekr.20080121105837.998">class TreeEvaluatorHelper(TreeEvaluator):
    @others
</t>
<t tx="ekr.20080121105837.999">
def _elem_from_scoperef(self, scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        elem = elem.names[lname]
    return elem

</t>
<t tx="ekr.20080121105837.1000"># Why is this not done specifically for Ruby?
def _calltip_from_func(self, node):
    # See "Determining a Function CallTip" in the spec for a
    # discussion of this algorithm.
    from codeintel2.util import LINE_LIMIT
    signature = node.get("signature")
    doc = node.get("doc")
    ctlines = []
    if not signature:
        name = node.get("name")
        #XXX Note difference for Tcl in _getSymbolCallTips.
        ctlines = [name + "(...)"]
    else:
        ctlines = signature.splitlines(0)
    if doc:
        ctlines += doc.splitlines(0)[:LINE_LIMIT-len(ctlines)]
    return '\n'.join(ctlines)

</t>
<t tx="ekr.20080121105837.1001"># This code taken from JavaScriptTreeEvaluator

_langintel = None
@property
def langintel(self):
    if self._langintel is None:
        self._langintel = self.mgr.langintel_from_lang(self.trg.lang)
    return self._langintel

</t>
<t tx="ekr.20080121105837.1002">_libs = None
@property
def libs(self):
    if self._libs is None:
        self._libs = self.langintel.libs_from_buf(self.buf)
    return self._libs


</t>
<t tx="ekr.20080121105837.1003">class RubyTreeEvaluator(TreeEvaluatorHelper):
    """
    scoperef: (&lt;blob&gt;, &lt;lpath&gt;) where &lt;lpath&gt; is list of names
        self._elem_from_scoperef()
    hit: (&lt;elem&gt;, &lt;scoperef&gt;)

    tokens = list(self._tokenize_citdl_expr(expr))   'foo.bar'
    """
    @others
    # c.f. tree_python.py::PythonTreeEvaluator
    # c.f. citadel.py::CitadelEvaluator
</t>
<t tx="ekr.20080121105837.1004">def __init__(self, ctlr, buf, trg, citdl_expr, line,
             converted_dot_new=False):
    TreeEvaluatorHelper.__init__(self, ctlr, buf, trg, citdl_expr, line)
    #self._did_object = False
    self.converted_dot_new = converted_dot_new
    self.recursion_check_getattr = 0;
    self.visited = {}
    self._hit_helper = HitHelper()
    self._get_current_names = trg.type == "names"
    self._framework_role = buf.framework_role or ""

</t>
<t tx="ekr.20080121105837.1005">recursion_check_limit = 10
def _rec_check_inc_getattr(self):
    self.recursion_check_getattr += 1
    if self.recursion_check_getattr &gt; self.recursion_check_limit:
        raise CodeIntelError("Expression too complex")

</t>
<t tx="ekr.20080121105837.1006">def _rec_check_dec_getattr(self):
    self.recursion_check_getattr -= 1

</t>
<t tx="ekr.20080121105837.1007">_common_classes = {"Kernel":None, "Class":None, "Object":None}
def _skip_common_ref(self, cls_name):
   return self.trg.implicit and self._common_classes.has_key(cls_name)

</t>
<t tx="ekr.20080121105837.1008">def _tokenize_citdl_expr(self, expr):
    toks = [x for x in token_splitter_re.split(expr) if x]
    if not toks:
        if self._get_current_names:
            return [""]
        else:
            return []
    elif toks[0] == "::":
        #XXX How does a leading :: affect symbol resolution here?
        # And a leading '.' should be a mistake
        del toks[0]
    return toks

</t>
<t tx="ekr.20080121105837.1009">def eval_cplns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self.debug("eval_cplns **************** -- eval(%r), scoperef(%r)", self.expr, start_scoperef)
    self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
    # This maps blob names to None, but it should map
    # (blob_name, scoperef[0], str(scoperef[1])) to None
    self._visited_blobs = {}
    # And this should be (variable_name, scoperef) =&gt; None,
    # Not just variable_name
    self._visited_variables = {}
    hits = self._hits_from_citdl(self.expr)
    hits = self._uniqify(hits)
    # eval_cplns doesn't call itself recursively.
    self._visited_blobs = {}
    self._visited_variables = {}
    
    trg_type = self.trg.type
    if trg_type == "literal-methods":
        allowed_cplns = _CPLN_METHODS_INST
    elif trg_type == "module-names":
        allowed_cplns = _CPLN_ALL_BUT_METHODS|_CPLN_METHODS_ALL_FOR_MODULE
    elif trg_type == "object-methods":
        if _looks_like_constant_re.match(self.expr):
            allowed_cplns = _CPLN_ALL_BUT_METHODS|_CPLN_METHODS_ALL_FOR_MODULE
        else:
            allowed_cplns = _CPLN_METHODS_INST
    elif self._get_current_names:
        allowed_cplns = _CPLN_ALL
        elem = self._elem_from_scoperef(start_scoperef)
        if elem:
            ilk = elem.get("ilk")
            if ilk == "class":
                allowed_cplns = _CPLN_ALL_BUT_METHODS|_CPLN_METHODS_CLASS
            elif ilk == "function" and not self._framework_role.startswith("rails.models"):
                # Rails does too much with instance models dynamically
                # at runtime:
                # 1.) adds methods based on column names in the model's
                #     underlying database table
                # 2.) copies class methods into instance methods
                
                parent_scope = self.parent_scoperef_from_scoperef(start_scoperef)
                parent_elem = self._elem_from_scoperef(parent_scope)
                if parent_elem.get("ilk") == "class":
                    allowed_cplns = _CPLN_ALL_BUT_METHODS|_CPLN_METHODS_INST
                # Otherwise allow them all
        
    else:
        raise CodeIntelError("Failed to handle trigger type '%s'" % trg_type)
    
    held_get_current_names = self._get_current_names
    self._get_current_names = False
    cplns = self._cplns_from_hits(hits, allowed_cplns)
    if held_get_current_names:
        for kwd in self.langintel.RUBY_KEYWORDS.keys():
            cplns.add(("function", kwd)) # "keyword" would be nice
        cplns = self._filter_by_prefix(cplns, self.expr)
    self.debug("eval_cplns: raw list: %r", cplns)
    cpln_list = list(cplns)
    # Don't bother if they have one more char to type.
    if (held_get_current_names and
        self.trg.implicit and
        len(cpln_list) == 1 and
        (cpln_list[0][1] == self.expr or
         (cpln_list[0][1][0 : -1] == self.expr))):
        return []
    return cpln_list

</t>
<t tx="ekr.20080121105837.1010">def _filter_by_prefix(self, cplns, prefix):
    if prefix and len(prefix):
        cplns = [x for x in cplns if x[1].startswith(prefix)]
    return cplns

</t>
<t tx="ekr.20080121105837.1011">def eval_calltips(self):
    self.log_start()
    self.debug("eval_calltip **************** -- eval(%r)" % self.expr)
    start_scoperef = self.get_start_scoperef()
    self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
    self._visited_blobs = {}
    self._visited_variables = {}
    hits = self._hits_from_citdl(self.expr)
    hits = self._uniqify(hits)
    self._visited_blobs = {}
    self._visited_variables = {}
    return self._calltips_from_hits(hits)

</t>
<t tx="ekr.20080121105837.1012">def eval_defns(self):
    self.log_start()
    start_scoperef = self.get_start_scoperef()
    self._base_scoperefs = self._calc_base_scoperefs(start_scoperef)
    self._visited_blobs = {}
    self._visited_variables = {}
    hits = self._hits_from_citdl(self.expr)
    hits = self._uniqify(hits)
    defns = [self._defn_from_hit(hit) for hit in hits]
    return defns

</t>
<t tx="ekr.20080121105837.1013">def _flatten(self, a):
    return reduce(lambda x,y: x + y, a, [])

</t>
<t tx="ekr.20080121105837.1014">def _calc_base_scoperefs(self, curr_scoperef):
    scoperefs = [curr_scoperef, (self.built_in_blob, [])]
    # Next find the other scoperefs in the current scoperef
    imports = []
    while curr_scoperef:
        elem = self._elem_from_scoperef(curr_scoperef)
        # Are there any import tags here?
        imports.append([x for x in elem if x.tag == "import"])
        curr_scoperef = self.parent_scoperef_from_scoperef(curr_scoperef)
    imports.reverse()
    imports = self._flatten(imports)
    for imp_elem in imports:
        if imp_elem.get("module") is None:
            # include Namespace
            # Look at current scoperefs to resolve it
            namespace_name = imp_elem.get("symbol")
            if namespace_name[0].isupper():
                # Use new_scoperefs to avoid modifying a list
                # while we're looping over it
                new_scoperefs = []
                for sc in scoperefs:
                    self._visited_blobs = {}
                    sc_hits = self._hits_from_citdl(namespace_name,
                                                    resolve_var=False,
                                                    only_scoperef=sc)
                    for sc_hit in sc_hits:
                        sc_hit_name = sc_hit[0].get("name")
                        if sc_hit_name:
                            new_scoperefs.append((sc_hit[1][0],
                                    sc_hit[1][1] + sc_hit_name.split("::")))
                scoperefs += new_scoperefs
        elif imp_elem.get("symbol") == "*":
            # Here we need to import a blob...
            blob = self._get_imported_blob(imp_elem)
            if blob is not None:
                scoperefs.append((blob, []))

    # Check for blobs in the catalog
    # Note that we're getting closer to implementing 
    # a transitive closure for include statements.  With the
    # way Rails is implemented we're safe doing this to
    # one level of inclusion.

    if self._framework_role:
        framework_parts = self._framework_role.split(".")
        try:
            framework_name = framework_parts[0]
            catalog_selections = [framework_name]
            new_lib = self.mgr.db.get_catalog_lib("Ruby",
                                                  catalog_selections, True)
            if new_lib:
                node = new_lib.get_blob(framework_name)
                framework_sc = (node, [])
                scoperefs.append(framework_sc)

                for imp_elem in imports:
                    if imp_elem.get("module") is None:
                        # include Namespace
                        # Look at current scoperefs to resolve it
                        namespace_name = imp_elem.get("symbol")
                        if namespace_name[0].isupper():
                            # Use new_scoperefs to avoid modifying a list
                            # while we're looping over it
                            new_scoperefs = []
                            self._visited_blobs = {}
                            sc_hits = self._hits_from_citdl(namespace_name,
                                                            resolve_var=False,
                                                            only_scoperef=framework_sc)
                            for sc_hit in sc_hits:
                                inner_elem = sc_hit[0]
                                sc_hit_name = inner_elem.get("name")
                                if sc_hit_name:
                                    new_scoperefs.append((sc_hit[0], []))
                                    inner_imports = inner_elem.findall('import')
                                    for import2 in inner_imports:
                                        if import2.get('module') is None:
                                            inner_namespace_name = import2.get('symbol')
                                            if inner_namespace_name[0].isupper():
                                                sc2_hits = self._hits_from_citdl(inner_namespace_name,
                                                            resolve_var=False,
                                                            only_scoperef=framework_sc)
                                                for sc2_hit in sc2_hits:
                                                    new_scoperefs.append((sc2_hit[0], []))
                            scoperefs += new_scoperefs
                            
        except AttributeError, ex:
            self.debug("_calc_base_scoperefs: %s", ex)
            pass
        
    kh = self._get_kernel_hit()
    if kh is not None:
        scoperefs.append((kh[0], kh[1][1]))
    
    return scoperefs

</t>
<t tx="ekr.20080121105837.1015">def _is_rails_application_controller(self, blob):
    for kid in blob.findall("scope"):
        if kid.tag == "scope" and kid.get("ilk") == "class" and kid.get("classrefs") == "ActiveController::Base":
            return True
    return False

</t>
<t tx="ekr.20080121105837.1016"># All following methods initially stolen from tree_python.py,
# then rewritten

def _is_alias(self, elem):
    return elem.tag == "variable" and elem.get("attributes", "").find("__alias__") &gt;= 0

</t>
<t tx="ekr.20080121105837.1017">def _calltips_from_hits(self, hits):
    calltips = []
    for hit in hits:
        self.debug("looking for a calltip on hit %r", hit)
        elem, scoperef = hit
        if elem.tag == "scope":
            ilk = elem.get("ilk")
            if ilk == "function":
                calltips.append(self._calltip_from_func(elem))
            elif ilk != "class":
                # no calltips on classes
                # only method and class names are expected here.
                raise NotImplementedError("unexpected scope ilk for "
                                          "calltip hit: %r" % elem)
        elif self._is_alias(elem):
            # Is it an alias for a function?
            scoperef = self._find_first_scoperef(elem)
            if scoperef:
                alias_hits = self._hits_from_variable_type_inference((elem, scoperef),
                                                                     resolve_var=False)
                for alias_hit in alias_hits:
                    alias_elem = alias_hit[0]
                    if self._hit_helper.is_function(alias_hit):
                        calltip = self._calltip_from_func(alias_elem)\
                        # Hack: Perform surgery on the calltip if needed
                        if calltip.startswith(alias_elem.get("name")):
                            calltip = elem.get("name") + calltip[len(alias_elem.get("name")):]
                        calltips.append(calltip)
        else:
            raise NotImplementedError("unexpected elem for calltip "
                                      "hit: %r" % elem)
    return calltips

</t>
<t tx="ekr.20080121105837.1018">def _uniqify(self, lst):
    if not lst:
        return lst
    new_list = []
    for i in range(len(lst) - 1):
        if lst[i] not in lst[i + 1:]:
            new_list.append(lst[i])
    new_list.append(lst[-1])
    return new_list

</t>
<t tx="ekr.20080121105837.1019">def _find_first_scoperef(self, elem):
    blob = self._base_scoperefs[0][0]
    nodes = [node for node in blob.findall(".//variable")
             if node.get("name") == elem.get("name")]
    for node in nodes:
        line_num = node.get("line")
        if line_num:
            return self.buf.scoperef_from_blob_and_line(blob, int(line_num) + 1)
        
</t>
<t tx="ekr.20080121105837.1020">def _elem_classification(self, elem):
    if elem.tag == "variable":
        return _CPLN_VARIABLES
    elif elem.tag == "scope":
        ilk = elem.get("ilk")
        if ilk is None:
            return 0
        elif ilk == "namespace":
            return _CPLN_MODULES
        elif ilk == "class":
            return _CPLN_CLASSES
        elif ilk == "function":
            if (elem.get("attributes", "").find("__classmethod__") &gt; -1
                or elem.get("name").find(".") &gt; -1):
                return _CPLN_METHODS_CLASS
            else:
                return _CPLN_METHODS_INST
    
    self.debug("Can't classify elem '%r'", elem)
    return 0
  
</t>
<t tx="ekr.20080121105837.1021">def _cplns_from_hits(self, hits, allowed_cplns):
    members = set()
    self.debug("_cplns_from_hits: allowed_cplns %x", allowed_cplns)
      
    for hit in hits:
        elem, scoperef = hit
        self.debug("elem %r", elem)
        for child in elem:
            #self.debug("child %r", child)
            # child_type = self._hit_helper.get_type([child])
            if child.tag == "variable":
                if self._is_alias(child):
                    # If the variable resolves to another object:
                    #    If it resolves to a function, use the target only
                    #    Otherwise use both the variable and its hits
                    scoperef = self._find_first_scoperef(child)
                    if scoperef:
                        alias_hits = self._hits_from_variable_type_inference((child, scoperef),
                                                                             resolve_var=False)
                        include_self = False
                        for alias_hit in alias_hits:
                            alias_elem = alias_hit[0]
                            if self._hit_helper.is_variable(alias_hit):
                                # Don't point var_lhs to var_rhs
                                pass
                            elif (self._hit_helper.is_function(alias_hit)
                                  and not include_self
                                  and (allowed_cplns &amp; _CPLN_METHODS_ALL)):
                                include_self = True
                                members.add( ("function", child.get("name")) )
                                members.add( (alias_elem.get("ilk") or alias_elem.tag, alias_elem.get("name")) )
                            else:
                                members.update(self._members_from_elem(child, allowed_cplns))
                elif allowed_cplns &amp; _CPLN_VARIABLES:
                    members.update(self._members_from_elem(child, allowed_cplns))
            else:
                members.update(self._members_from_elem(child, allowed_cplns))
                # Special case the child w.r.t the parent
                if allowed_cplns &amp; _CPLN_METHODS_ALL_FOR_MODULE:
                    elem_type = self._elem_classification(elem)
                    if elem_type &amp; (_CPLN_MODULES|_CPLN_CLASSES):
                        child_type = self._elem_classification(child)
                        if ((child_type &amp; _CPLN_METHODS_CLASS) or
                            ((child_type &amp; _CPLN_METHODS_INST) and
                             (elem_type == _CPLN_MODULES))):
                            members.add(("function", child.get("name")))
                
        if elem.get("ilk") == "class":
            classref = elem.get("classrefs")
            if classref is not None:
                if not self._visited_blobs.has_key(classref):
                    self._visited_blobs[classref] = None
                    insert_scoperef = True
                    self._base_scoperefs.insert(0, scoperef)
                    try:
                        ref_hits = self._hits_from_classref(classref)
                        del self._base_scoperefs[0]
                        insert_scoperef = False
                        if ref_hits:
                            members.update(self._cplns_from_hits(ref_hits, allowed_cplns))
                    finally:
                        if insert_scoperef:
                            del self._base_scoperefs[0]
     
            if ((allowed_cplns &amp; _CPLN_METHODS_CLASS) or
                ((allowed_cplns &amp; _CPLN_METHODS_ALL_FOR_MODULE) and
                 (self._elem_classification(elem) &amp; _CPLN_CLASSES))):
                init_method = elem.names.get("initialize")
                if not init_method or \
                   not init_method.get("attributes") == "private":
                    members.add(("function", "new"))
                
    return members

</t>
<t tx="ekr.20080121105837.1022">def _members_from_elem(self, elem, allowed_cplns):
    """Return the appropriate set of autocomplete completions for
    the given element. Typically this is just one, but can be more for
    '*'-imports
    """
    members = set()
    if elem.tag == "import":
        symbol_name = elem.get("symbol")
        module_name = elem.get("module")
        if module_name is None:
            if self._visited_blobs.has_key(symbol_name):
                return members
            self._visited_blobs[symbol_name] = None
            hits = self._hits_from_citdl(symbol_name)
            for hit in hits:
                for child in hit[0]:
                    members.update(self._members_from_elem(child, allowed_cplns))
        elif symbol_name is not None and self.citadel:
            if self._visited_blobs.has_key(module_name):
                return members
            self._visited_blobs[module_name] = None
            import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
            try:
                self.debug("_members_from_elem: about to call import_handler.import_blob_name(module_name=%r), symbol_name=%r", module_name, symbol_name)
                blob = import_handler.import_blob_name(
                            module_name, self.libs, self.ctlr)
            except CodeIntelError:
                self.warn("_members_from_elem: limitation in handling imports in imported modules")
                # It could be an incomplete module name in a require statement in the current buffer,
                # so don't throw an exception.
                return members
            
            # Check all children
            for blob_child in blob.getchildren():
                imported_name = blob_child.get('name')
                if imported_name is None:
                    continue
                if symbol_name == "*" or symbol_name == imported_name:
                    try:
                        member_type = (blob_child.get("ilk") or blob_child.tag)
                        if symbol_name == "*":
                            if self._elem_classification(blob_child) &amp; allowed_cplns:
                                members.add((member_type, imported_name))
                        elif (member_type == "class"
                              and (allowed_cplns &amp; _CPLN_METHODS_INST)):
                            # Burrow if it doesn't match
                            for child_elem in blob_child:
                                if self._elem_classification(child_elem) &amp; allowed_cplns:
                                    members.add((child_elem.get("ilk"), child_elem.get("name")))
                                else:
                                    self.debug("Not adding from %s: %s isn't allowed", imported_name, child_elem.get("name"))
                                    pass
                        else:
                            self.debug("Not adding from %s: member_type=%s or not fabricated", imported_name, member_type)
                            pass
                    except CodeIntelError, ex:
                        self.warn("_members_from_elem: %s (can't look up member %r in blob %r)", ex, imported_name, blob)
            
        elif allowed_cplns &amp; _CPLN_MODULES:
            cpln_name = module_name.split('/', 1)[0]
            members.add( ("module", cpln_name) )
    elif self._elem_classification(elem) &amp; allowed_cplns:
        members.add( (elem.get("ilk") or elem.tag, elem.get("name")) )
    return members

</t>
<t tx="ekr.20080121105837.1023">def _hits_from_classref(self, expr):
    hits = self._hits_from_citdl(expr)
    if hits:
        return hits
    hits = [] # In case they're none
    # Look at the includes in this scoperef
    curr_scoperef = self._base_scoperefs[0]
    imports = []
    blobs = []
    #XXX Look only at includes in the current scope
    while curr_scoperef:
        elem = self._elem_from_scoperef(curr_scoperef)
        imports += self._get_included_modules(elem)
        blobs += [self._get_imported_blob(x) for x in self._get_required_modules(elem)]
        curr_scoperef = self.parent_scoperef_from_scoperef(curr_scoperef)
    
    for blob in blobs:
        # First look for top-level names in each blob
        hit_list = [x for x in blob if x.get("name") == expr]
        if expr in blob.names:
            hits += [(hit, (blob, [])) for hit in hit_list]
        # Now look to see if we've included any modules in blob
        for imp in imports:
            ns_name = imp.get('symbol')
            for ns_blob in blob:
                if ns_blob.get("ilk") == "namespace" and ns_blob.get("name") == ns_name:
                    for candidate in ns_blob:
                        if candidate.get("ilk") == "class" and candidate.get("name") == expr:
                            hits += [(candidate, (blob, [ns_name]))]
    return hits
                
        

</t>
<t tx="ekr.20080121105837.1024">def _hits_from_citdl(self, expr, resolve_var=True, only_scoperef=None):
    """Resolve the given CITDL expression (starting at the given
    scope) down to a non-import/non-variable hit.
    
    The tokens contain ::'s and .'s so we know when we should have
    a namespace on the left, and when we should have a class or object.
    """
    tokens = self._tokenize_citdl_expr(expr)
    self.debug("_hit_from_citdl: expr tokens: %r, look in %d scopes",
               tokens, only_scoperef and 1 or len(self._base_scoperefs))
    # Another note: if we only have one token, we assume we're
    # resolving a variable expression, and do the usual name lookups
    # Prefix handling has to be done by a different function that
    # looks only at self._base_scoperefs

    # First part...
    hits = self._hits_from_first_part(tokens[0], only_scoperef)
    if not hits:
        return NO_HITS
    #sys.stderr.write("%r\n" % hits)

    first_hit = hits[0]
    # If we're doing definition-lookup, we don't want to resolve
    # a standalone variable expression to its underlying type.
    # Just use the point its defined at, which is in the
    # hits variable.
    if (self._hit_helper.is_variable(first_hit) 
        and resolve_var
        and (len(tokens) &gt; 1 or self.trg.form != TRG_FORM_DEFN)):
        hits = self._hits_from_variable_type_inference(first_hit)
        if not hits:
            return NO_HITS
        first_hit = hits[0]
        if self._hit_helper.is_variable(first_hit):
            var_name = self._hit_helper.get_name(first_hit)
            self.debug("_hit_from_citdl: failed to resolve variable '%r'",
                       var_name)
            return NO_HITS
            #raise CodeIntelError("Failed to resolve variable '%r'" % var_name)
        #sys.stderr.write("%r\n" % hits)
        prev_tok = first_hit[0].get("name", None) or tokens[0]
    else:
        prev_tok = tokens[0]
    
    # Now walk our list, first culling complete names separated
    # by [::, name] or [., name]
    idx = 1
    lim_sub1 = len(tokens) - 1

    if idx &lt;= lim_sub1:
        if tokens[1] == "::" and not self._hit_helper.is_compound(first_hit):
            self.debug("_hit_from_citdl: trying to do namespace resolution on %s '%r'",
                       self._hit_helper.get_type(first_hit),
                       self._hit_helper.get_name(first_hit))
            return NO_HITS

    while idx &lt;= lim_sub1 and hits:
        tok = tokens[idx]
        if tok == '::':
            filter_type = _NAMESPACE_RESOLUTION
        elif tok == '.':
            filter_type = _CLASS_RESOLUTION
        else:
            self.debug("_hit_from_citdl: got an unexpected resolution op of '%r'", tok)
            return NO_HITS
        idx += 1
        if idx &gt; lim_sub1:
            break
        tok = tokens[idx]
        #XXX Pull out each name that isn't a prefix
        new_hits = []
        for hit in hits:
            new_hits += self._hits_from_getattr(hit, tok, filter_type) or []
        if not new_hits:
            return []
        hits = [(x[0], (x[1][0], x[1][1] + [prev_tok])) for x in new_hits]
        prev_tok = tok
        #XXX Replace with:
        #hits = [x for x in [self._continue_hit(hit, tok, filter_type) for hit in hits] if x]
        idx += 1
    return hits

</t>
<t tx="ekr.20080121105837.1025">def _hits_from_getattr(self, hit, token, filter_type):
    self._rec_check_inc_getattr()
    try:
        new_hits = self._hits_from_getattr_aux(hit, token, filter_type)
        if not new_hits:
            self.debug("_hits_from_getattr: couldn't resolve %r.%r", hit[0], token)
        return new_hits
    finally:
        self._rec_check_dec_getattr()

</t>
<t tx="ekr.20080121105837.1026">def _hits_from_getattr_aux(self, hit, first_token, filter_type):
    elem = hit[0]
    self.log("_hits_from_getattr: resolve getattr '%s' on %r, filter_type %d", first_token, elem, filter_type)
    
    if elem.tag == "variable":
        self.log("... failed on %s", elem.tag)
        return None
    
    assert elem.tag == "scope"
    ilk = elem.get("ilk")
    if ilk == "function":
        self.log("... failed on %s", ilk)
        return None
    elif ilk == "class":
        if first_token == 'new':
            return [hit]
        #XXX - stop allowing variables here.
        if first_token in elem.names:
            self.log("_hits_from_getattr: name %s is in %r", first_token, elem)                
            hits = []
            self._append_hits_from_name(hits, first_token, hit[1], elem)
            return hits
        self.debug("_hits_from_getattr: look for %r from imports in %r", first_token, elem)
        new_hit = self._hit_from_elem_imports(elem, first_token, filter_type)
        if new_hit:
            return [new_hit]

        classref = elem.get("classrefs")
        if classref:
            #if self._skip_common_ref(classref):
            #    continue
            if not self._visited_blobs.has_key(classref):
                self._visited_blobs[classref] = True
                new_hit = self._hit_from_type_inference(classref, first_token, filter_type)
                if new_hit:
                    return [new_hit]
    elif ilk == "namespace":
        if first_token in elem.names:
            self.log("_hits_from_getattr: name %s is in %r", first_token, elem)              
            hits = []
            self._append_hits_from_name(hits, first_token, hit[1], elem)
            return hits
    
</t>
<t tx="ekr.20080121105837.1027">def _hit_from_elem_imports(self, elem, first_token, filter_type):
    """See if token is from one of the imports on this &lt;scope&gt; elem.

    Returns a hit
    """
    #XXX Allow multiple hits
    
    self.debug("_hit_from_elem_imports :")
    # See some comments in the method with the same name in
    # tree_python.
    #
    # This routine recursively follows Ruby include statements,
    # guarding duplicates.

    imports = self._get_included_modules(elem)
    for imp in imports:
        hits = self._hits_from_citdl(imp.get("symbol"))
        for hit in hits:
            new_hits = self._hits_from_getattr(hit, first_token, filter_type)
            if new_hits:
                return new_hits[0]
            
</t>
<t tx="ekr.20080121105837.1028">def _hit_from_type_inference(self, classname, first_token, filter_type):
    hits = self._hits_from_citdl(classname)
    for hit in hits:
        new_hits = self._hits_from_getattr(hit, first_token, filter_type)
        if new_hits:
            return new_hits[0]
        
</t>
<t tx="ekr.20080121105837.1029">def _get_kernel_hit(self):
    try:
        return self.built_in_blob.names["Kernel"], (self.built_in_blob, [])
    except KeyError:
        return None
    

</t>
<t tx="ekr.20080121105837.1030">def _hits_from_first_part(self, first_token, only_scoperef):
    """Find all possible hits for the first token in the submitted
    scoperefs (normally the current blob and the builtin blob).
    
    We need to check all required modules as well --
    these look like &lt;import module=lib symbol="*"&gt;
    
    Also check imported names: &lt;import symbol=Namespace /&gt;

    Returns a list of &lt;hit&gt; or [] if we could
    not resolve.

    Example for 'String' normally:
        retval: [(&lt;class 'String'&gt;, (&lt;blob '*'&gt;, [])),]
    
    Let's say they opened it in the source to add a new method:
        retval: [(&lt;class 'String'&gt;, (&lt;blob '*'&gt;, [])),]
                 (&lt;class 'String'&gt;, (&lt;blob 'this'&gt;, ['file', 'class']))]
    """
    
    if self._get_current_names:
        # Look up the completions later.
        # Like in triggered lookup, move up the first blob only scoperef = self._base_scoperefs[0]
        hits = []
        scoperef = only_scoperef or self._base_scoperefs[0]
        while True:
            elem = self._elem_from_scoperef(scoperef)
            if elem is not None:
                if only_scoperef is None:
                    hits.append((elem, scoperef))
                elif first_token in elem.names:
                    self._append_hits_from_name(hits, first_token, scoperef, elem)
            scoperef = self.parent_scoperef_from_scoperef(scoperef)
            if not scoperef:
                break
        
        # And put the rest of the blobs on the hit list
        if only_scoperef is None:
            hits += [(sc[0], sc) for sc in self._base_scoperefs[1:]]
        return hits
            
    # With the first one, we move up.  With others we don't.
    scoperef = only_scoperef or self._base_scoperefs[0]
    hits = []
    self.log("_hit_from_first_part: try to resolve '%s' ...", first_token)
    while scoperef:
        elem = self._elem_from_scoperef(scoperef)
        if elem is not None and first_token in elem.names:
            #TODO: skip __hidden__ names
            self.log("_hit_from_first_part: is '%s' accessible on %s? yes: %s",
                     first_token, scoperef, elem.names[first_token])
            self._append_hits_from_name(hits, first_token, scoperef, elem)
            break
        self.log("_hit_from_first_part: is '%s' accessible on %s? no", first_token, scoperef)
        scoperef = self.parent_scoperef_from_scoperef(scoperef)
    if only_scoperef or (hits and self._hit_helper.is_variable(hits[0])):
        return hits
    
    for scoperef in self._base_scoperefs[1:]:
        elem = self._elem_from_scoperef(scoperef)
        if first_token in elem.names:
            #TODO: skip __hidden__ names
            self.log("_hit_from_first_part: is '%s' accessible on %s? yes: %s",
                     first_token, scoperef, elem.names[first_token])
            self._append_hits_from_name(hits, first_token, scoperef, elem)
            
    if not hits:
        # Try importing all importable blobs then
        for scoperef in self._base_scoperefs[2:]:
            imports = self._get_required_modules(scoperef[0])
            for imp in imports:
                blob = self._get_imported_blob(imp)
                if blob and first_token in blob.names:
                    # Stop with one
                    return [(blob.names[first_token], [])]
            
    return hits

</t>
<t tx="ekr.20080121105837.1031">def _append_hits_from_name(self, hits, first_token, scoperef, elem):
    blob, list = scoperef
    new_scoperef = blob, list # + [first_token]
    # Allow for multiple hits of compound things -- names() returns the last
    hit_list = [x for x in elem.findall("scope") if x.get("name") == first_token]
    if hit_list:
        if len(hit_list) &gt; 1 and not hit_list[-1].get("name")[0].isupper():
            # Keep the last variable or function def
            hits.append((hit_list[-1], new_scoperef))
        else:
            hits += [(x, new_scoperef) for x in hit_list]
    else:
        hits.append((elem.names[first_token], new_scoperef))
                    
</t>
<t tx="ekr.20080121105837.1032">def _get_imported_blob(self, imp_elem):
    return self._get_imported_blob_from_name(imp_elem.get("module"))

</t>
<t tx="ekr.20080121105837.1033">def _get_imported_blob_from_name(self, module_name):
    import_handler = self.citadel.import_handler_from_lang(self.trg.lang)
    self.debug("_get_imported_blob(1): (module %r)?", module_name)
    try:
        blob = import_handler.import_blob_name(module_name, self.libs, self.ctlr)
        return blob
    except CodeIntelError, ex:
        # Continue looking
        self.warn("_get_imported_blob(2): %s", str(ex))

</t>
<t tx="ekr.20080121105837.1034">def _get_included_modules(self, elem):
    return [x for x in elem.findall("import") if x.get("module") is None]

</t>
<t tx="ekr.20080121105837.1035">def _get_required_modules(self, elem):
    return [x for x in elem.findall("import") if x.get("symbol") == "*"]

</t>
<t tx="ekr.20080121105837.1036">def _hits_from_variable_type_inference(self, hit, resolve_var=True):
    """Resolve the type inference for 'elem' at 'scoperef'."""
    assert self._hit_helper.is_variable(hit)
    elem, scoperef = hit
    citdl = elem.get("citdl")
    if not citdl:
        raise CodeIntelError("_hit_from_variable_type_inference: no type-inference info for %r" % elem)
    if self._visited_variables.has_key(citdl):
        self.log("_hit_from_variable_type_inference: already looked at var '%s'", citdl)
        return NO_HITS
    self._visited_variables[citdl] = None
        
    self.log("_hit_from_variable_type_inference: resolve '%s' type inference for %r:", citdl, elem)
    # Always insert a scoperef while we're looking for a hit.
    self._base_scoperefs.insert(0, scoperef)
    try:
        hits = self._hits_from_citdl(citdl, resolve_var)
    finally:
        del self._base_scoperefs[0]
    self.debug("_hits_from_variable_type_inference(%s) (citdl '%r') ==&gt; '%r'", elem.get("name"), citdl, hits)
    return hits

</t>
<t tx="ekr.20080121105837.1037">_built_in_blob = None
@property
def built_in_blob(self):
    if self._built_in_blob is None:
        #HACK: Presume second-last or last lib is stdlib.
        #TODO: replace this with buf.stdlib.
        if isinstance(self.libs[-1], StdLib):
            stdlib = self.libs[-1]
        elif isinstance(self.libs[-2], StdLib):
            stdlib = self.libs[-2]
        assert isinstance(stdlib, StdLib), \
               "not stdlib, but '%r'" % stdlib
        self._built_in_blob = stdlib.get_blob("*")
    return self._built_in_blob

</t>
<t tx="ekr.20080121105837.1038">def parent_scoperef_from_scoperef(self, scoperef):
    #TODO: compare with CitadelEvaluator.getParentScope()
    blob, lpath = scoperef
    if lpath:
        return (blob, lpath[:-1])
    else:
        return None

</t>
<t tx="ekr.20080121105837.1039">def post_process_cplns(self, cplns):
    self.debug("In RubyTreeEvaluator.post_process_cplns: %r", cplns)
    """Remove completions that don't start with a letter"""
    fixed_cplns = [x for x in cplns if letter_start_re.match(x[1])]
    fixed_cplns.sort(key=lambda c: c[1].upper())
    return fixed_cplns

</t>
<t tx="ekr.20080121105837.1040">_s_initialize_new = re.compile(r'^initialize\(')
def post_process_calltips(self, calltips):
    #XXX Trent is this test right, or should I always convert?
    # Inside a class 'initialize' is a private class, and while
    # it shouldn't be called, it can be.
    
    if self.converted_dot_new:
        fixed_calltips = [self._s_initialize_new.sub('new(', x) for x in calltips]
        return fixed_calltips
    return calltips

</t>
<t tx="ekr.20080121105837.1041"></t>
<t tx="ekr.20080121105837.1042">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1043">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""CSS support for CodeIntel"""

import os
from os.path import isfile, isdir, exists, dirname, abspath, splitext, join
import sys
import stat
import string
from cStringIO import StringIO
import logging
import traceback
from pprint import pprint

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity.ScintillaConstants import (
    SCE_CSS_DIRECTIVE, SCE_CSS_DOUBLESTRING, SCE_CSS_IDENTIFIER,
    SCE_CSS_IDENTIFIER2, SCE_CSS_OPERATOR, SCE_CSS_SINGLESTRING,
    SCE_CSS_TAG, SCE_CSS_UNKNOWN_IDENTIFIER, SCE_CSS_VALUE,
    SCE_UDL_CSS_COMMENT, SCE_UDL_CSS_DEFAULT, SCE_UDL_CSS_IDENTIFIER,
    SCE_UDL_CSS_NUMBER, SCE_UDL_CSS_OPERATOR, SCE_UDL_CSS_STRING,
    SCE_UDL_CSS_WORD, SCE_UDL_M_STRING, SCE_UDL_M_ATTRNAME, SCE_UDL_M_OPERATOR,
)
from SilverCity import Keywords

from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import CompareNPunctLast, make_short_name_dict
from codeintel2.langintel import LangIntel, ParenStyleCalltipIntelMixin
from codeintel2.udl import UDLBuffer, is_udl_css_style
from codeintel2.accessor import AccessorCache
from codeintel2 import constants_css

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

lang = "CSS"
log = logging.getLogger("codeintel.css")
WHITESPACE = tuple(" \t\r\n")  # care about '\v', '\f'?



</t>
<t tx="ekr.20080121105837.1044">#---- language support

class CSSLexer(Lexer):
    lang = "CSS"
    @others
</t>
<t tx="ekr.20080121105837.1045">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_CSS)
    self._keyword_lists = [
        # See 'scite/src/css.properties'.
        # CSS1 keywords
        SilverCity.WordList("""
            color background-color background-image background-repeat
            background-attachment background-position background
            font-family font-style font-variant font-weight font-size
            font word-spacing letter-spacing text-decoration
            vertical-align text-transform text-align text-indent
            line-height margin-top margin-right margin-bottom margin-left
            margin padding-top padding-right padding-bottom padding-left
            padding border-top-width border-right-width
            border-bottom-width border-left-width border-width border-top
            border-right border-bottom border-left border border-color
            border-style width height float clear display white-space
            list-style-type list-style-image list-style-position
            list-style
        """),
        # CSS pseudo-classes
        SilverCity.WordList("""
            first-letter first-line link active visited first-child focus
            hover lang before after left right first
        """),
        # CSS2 keywords
        SilverCity.WordList("""
            border-top-color border-right-color border-bottom-color
            border-left-color border-color border-top-style
            border-right-style border-bottom-style border-left-style
            border-style top right bottom left position z-index direction
            unicode-bidi min-width max-width min-height max-height
            overflow clip visibility content quotes counter-reset
            counter-increment marker-offset size marks page-break-before
            page-break-after page-break-inside page orphans widows
            font-stretch font-size-adjust unicode-range units-per-em src
            panose-1 stemv stemh slope cap-height x-height ascent descent
            widths bbox definition-src baseline centerline mathline
            topline text-shadow caption-side table-layout border-collapse
            border-spacing empty-cells speak-header cursor outline
            outline-width outline-style outline-color volume speak
            pause-before pause-after pause cue-before cue-after cue
            play-during azimuth elevation speech-rate voice-family pitch
            pitch-range stress richness speak-punctuation speak-numeral
        """),
    ]

</t>
<t tx="ekr.20080121105837.1046">class _StraightCSSStyleClassifier:
    @others
</t>
<t tx="ekr.20080121105837.1047">def is_css_style(self, style, accessorCacheBack=None):
    return True

</t>
<t tx="ekr.20080121105837.1048">def is_default(self, style, accessorCacheBack=None):
    return style in self.default_styles

</t>
<t tx="ekr.20080121105837.1049">def is_comment(self, style, accessorCacheBack=None):
    return style in self.comment_styles

</t>
<t tx="ekr.20080121105837.1050">def is_string(self, style, accessorCacheBack=None):
    return style in self.string_styles

</t>
<t tx="ekr.20080121105837.1051">def is_operator(self, style, accessorCacheBack=None):
    return style in self.operator_styles or \
           style == ScintillaConstants.SCE_CSS_IMPORTANT

</t>
<t tx="ekr.20080121105837.1052">def is_identifier(self, style, accessorCacheBack=None):
    return style in self.identifier_styles

</t>
<t tx="ekr.20080121105837.1053">def is_value(self, style, accessorCacheBack=None):
    return style in self.value_styles

</t>
<t tx="ekr.20080121105837.1054">def is_tag(self, style, accessorCacheBack=None):
    return style in self.tag_styles

</t>
<t tx="ekr.20080121105837.1055">def is_class(self, style, accessorCacheBack=None):
    return style in self.class_styles

</t>
<t tx="ekr.20080121105837.1056">def is_number(self, style, accessorCacheBack=None):
    return style in self.number_styles

</t>
<t tx="ekr.20080121105837.1057">@property
def default_styles(self):
    return (ScintillaConstants.SCE_CSS_DEFAULT, )

</t>
<t tx="ekr.20080121105837.1058">@property
def comment_styles(self):
    return (ScintillaConstants.SCE_CSS_COMMENT,)

</t>
<t tx="ekr.20080121105837.1059">@property
def string_styles(self):
    return (ScintillaConstants.SCE_CSS_SINGLESTRING,
            ScintillaConstants.SCE_CSS_DOUBLESTRING)

</t>
<t tx="ekr.20080121105837.1060">@property
def operator_styles(self):
    return (ScintillaConstants.SCE_CSS_OPERATOR, )

</t>
<t tx="ekr.20080121105837.1061">@property
def identifier_styles(self):
    return (ScintillaConstants.SCE_CSS_IDENTIFIER,
            ScintillaConstants.SCE_CSS_IDENTIFIER2,
            ScintillaConstants.SCE_CSS_UNKNOWN_IDENTIFIER)

</t>
<t tx="ekr.20080121105837.1062">@property
def value_styles(self):
    return (ScintillaConstants.SCE_CSS_VALUE, )

</t>
<t tx="ekr.20080121105837.1063">@property
def tag_styles(self):
    return (ScintillaConstants.SCE_CSS_TAG, )

</t>
<t tx="ekr.20080121105837.1064">@property
def class_styles(self):
    return (ScintillaConstants.SCE_CSS_CLASS, )

</t>
<t tx="ekr.20080121105837.1065">@property
def number_styles(self):
    return ()

</t>
<t tx="ekr.20080121105837.1066">@property
def ignore_styles(self):
    return (ScintillaConstants.SCE_CSS_DEFAULT,
            ScintillaConstants.SCE_CSS_COMMENT)

</t>
<t tx="ekr.20080121105837.1067">class _UDLCSSStyleClassifier(_StraightCSSStyleClassifier):
    @others
</t>
<t tx="ekr.20080121105837.1068">def is_css_style(self, style, accessorCacheBack=None):
    return is_udl_css_style(style)

</t>
<t tx="ekr.20080121105837.1069">def _is_html_style_attribute(self, ac, style):
    # Check to see if it's a html style attribute
    # Note: We are starting from the html string delimiter, i.e.:
    #   &lt;body style=&lt;|&gt;"abc...
    DEBUG = False
    # We may have already found out this is a style attribute, check it
    if getattr(ac, "is_html_style_attribute", False):
        return True
    p, ch, style = ac.getPrecedingPosCharStyle(style,
                    ignore_styles=self.ignore_styles)
    if DEBUG:
        print "  _is_html_style_attribute:: Prev style: %d, ch: %r" % (
              style, ch, )
    if style == SCE_UDL_M_OPERATOR:
        p, ch, style = ac.getPrecedingPosCharStyle(style,
                        ignore_styles=self.ignore_styles)
        if style == SCE_UDL_M_ATTRNAME:
            p, name = ac.getTextBackWithStyle(style)
            if DEBUG:
                print "  _is_html_style_attribute:: HTML Attribute: %r" % (
                      name, )
            if name == "style":
                # Remember this is a html style attribute
                ac.is_html_style_attribute = True
                return True
    return False

</t>
<t tx="ekr.20080121105837.1070">def is_identifier(self, style, accessorCacheBack=None):
    if style not in self.identifier_styles:
        return False

    # Previous style must be operator and one of "{;"
    ac = accessorCacheBack
    if ac is not None:
        DEBUG = False
        #DEBUG = True
        pcs = ac.getCurrentPosCharStyle()
        if DEBUG:
            print "  is_identifier:: pcs: %r" % (pcs, )
        try:
            # Check that the preceding character before the identifier
            ppcs = ac.getPrecedingPosCharStyle(pcs[2],
                                               ignore_styles=self.ignore_styles)
            if DEBUG:
                print "  is_identifier:: ppcs: %r" % (ppcs, )
            if self.is_operator(ppcs[2]) and ppcs[1] in "{;":
                return True
            elif ppcs[2] == SCE_UDL_M_STRING and \
                 self._is_html_style_attribute(ac, ppcs[2]):
                return True
            if DEBUG:
                print "  is_identifier:: Not an identifier style"
        finally:
            # Reset the accessor back to the current position
            ac.resetToPosition(pcs[0])
    return False

</t>
<t tx="ekr.20080121105837.1071">def is_class(self, style, accessorCacheBack=None):
    ac = accessorCacheBack
    if ac is not None:
        pcs = ac.getCurrentPosCharStyle()
        print "  is_class:: pcs: %r" % (pcs, )
        if self.is_operator(pcs[2]) and pcs[1] in "&gt;.;}{":
            return True
        try:
            DEBUG = False
            # Check that the preceding character before the identifier is a "."
            ppcs = ac.getPrecedingPosCharStyle(pcs[2],
                                               ignore_styles=self.ignore_styles)
            if DEBUG:
                print "  is_class:: ppcs: %r" % (ppcs, )
            if ppcs[2] in self.identifier_styles:
                ppcs = ac.getPrecedingPosCharStyle(ppcs[2],
                                                   ignore_styles=self.ignore_styles)
                if self.is_operator(ppcs[2]) and ppcs[1] == ".":
                    return True
                elif not is_udl_css_style(ppcs[2]):
                    return True
            # If there is no identifer, may be operator, which is okay
            elif not is_udl_css_style(ppcs[2]) or \
                 (self.is_operator(ppcs[2]) and ppcs[1] in "};"):
                return True
            if DEBUG:
                print "  is_class:: Not a class style"
        finally:
            # Reset the accessor back to the current position
            ac.resetToPosition(pcs[0])
    return False

</t>
<t tx="ekr.20080121105837.1072">def is_tag(self, style, accessorCacheBack=None):
    ac = accessorCacheBack
    if ac is not None:
        # Tags follow operators or other tags
        # For use, we'll go back until we find an operator in "}&gt;"
        if style in self.identifier_styles:
            DEBUG = False
            p, ch, style = ac.getCurrentPosCharStyle()
            start_p = p
            min_p = max(0, p - 50)
            try:
                while p &gt; min_p:
                    # Check that the preceding character before the identifier is a "."
                    p, ch, style = ac.getPrecedingPosCharStyle(style,
                                        ignore_styles=self.ignore_styles)
                    if style in self.operator_styles:
                        # Thats good, we get our decision now
                        if ch in "}&gt;":
                            return True
                        elif ch == ",":
                            # Might be following another tag, "div, div",
                            # http://bugs.activestate.com/show_bug.cgi?id=58637
                            continue
                        if DEBUG:
                            print "  is_tag:: Not a tag operator ch: %s" % (ch)
                        return False
                    elif not self.is_css_style(style):
                        if DEBUG:
                            print "  is_tag:: Not a css style: %d, ch: %r" % (style, ch, )
                        if style == SCE_UDL_M_STRING and \
                           self._is_html_style_attribute(ac, style):
                            return False
                        return True
                    elif style not in self.identifier_styles:
                        if DEBUG:
                            print "  is_tag:: Not a tag style, style: %d" % (style)
                        return False
                    # else: # Thats okay, we'll keep going
            finally:
                # Reset the accessor back to the current position
                ac.resetToPosition(start_p)
    return False

</t>
<t tx="ekr.20080121105837.1073">@property
def default_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_DEFAULT, )

</t>
<t tx="ekr.20080121105837.1074">@property
def comment_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_COMMENT,)

</t>
<t tx="ekr.20080121105837.1075">@property
def string_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_STRING, )

</t>
<t tx="ekr.20080121105837.1076">@property
def operator_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_OPERATOR, )

</t>
<t tx="ekr.20080121105837.1077">@property
def identifier_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_IDENTIFIER,
            ScintillaConstants.SCE_UDL_CSS_WORD)

</t>
<t tx="ekr.20080121105837.1078">@property
def value_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_WORD,
            ScintillaConstants.SCE_UDL_CSS_IDENTIFIER,
            ScintillaConstants.SCE_UDL_CSS_NUMBER)

</t>
<t tx="ekr.20080121105837.1079">@property
def tag_styles(self):
    return (ScintillaConstants.SCE_CSS_TAG, )

</t>
<t tx="ekr.20080121105837.1080">@property
def number_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_NUMBER, )

</t>
<t tx="ekr.20080121105837.1081">@property
def ignore_styles(self):
    return (ScintillaConstants.SCE_UDL_CSS_DEFAULT,
            ScintillaConstants.SCE_UDL_CSS_COMMENT)


</t>
<t tx="ekr.20080121105837.1082">StraightCSSStyleClassifier = _StraightCSSStyleClassifier()
UDLCSSStyleClassifier      = _UDLCSSStyleClassifier()

class CSSLangIntel(LangIntel, ParenStyleCalltipIntelMixin):
    # CSS attributes:
    #     key (string) is the css property (attribute) name
    #     value (list) is the possible css property (attribute) values
    CSS_ATTRIBUTES = constants_css.CSS_ATTR_DICT
    # Length required to trigger the property-names completion
    CSS_PROPERTY_NAME_TRIGGER_LENGTH = 1
    # Setup the names triggered for "property-names"
    CSS_PROPERTY_NAMES = CSS_ATTRIBUTES.keys()
    CSS_PROPERTY_NAMES.sort(CompareNPunctLast)
    CSS_PROPERTY_NAMES_LOOKUP \
        = make_short_name_dict(CSS_PROPERTY_NAMES,
                               length=CSS_PROPERTY_NAME_TRIGGER_LENGTH)

    # Calltips for css property attributes
    CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT = constants_css.CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT

    # Tag names
    CSS_HTML_TAG_NAMES = Keywords.hypertext_elements.split()
    # Length required to trigger the property-names completion
    CSS_HTML_TAG_NAME_TRIGGER_LENGTH = 1
    # Setup the names triggered for "tag-names"
    CSS_HTML_TAG_NAMES_LOOKUP = make_short_name_dict(CSS_HTML_TAG_NAMES,
                                        length=CSS_HTML_TAG_NAME_TRIGGER_LENGTH)

    # pseudo-class-names
    CSS_PSEUDO_CLASS_NAMES = """first-letter first-line link active visited
        first-child focus hover lang before after left right first""".split()
    CSS_PSEUDO_CLASS_NAMES.sort(CompareNPunctLast)

    # at rules
    CSS_AT_RULE_NAMES = ["import", "media", "charset", "font-face", "page"]
    CSS_AT_RULE_NAMES.sort(CompareNPunctLast)


    @others
</t>
<t tx="ekr.20080121105837.1083">def preceding_trg_from_pos(self, buf, pos, curr_pos):
    DEBUG = False # not using 'logging' system, because want to be fast
    #DEBUG = True # not using 'logging' system, because want to be fast

    if DEBUG:
        print "\npreceding_trg_from_pos -- pos: %d, curr_pos: %d" % (
                pos, curr_pos, )
    if isinstance(buf, UDLBuffer):
        styleClassifier = UDLCSSStyleClassifier
    else:
        styleClassifier = StraightCSSStyleClassifier
    ac = AccessorCache(buf.accessor, curr_pos+1, fetchsize=50)
    currTrg = self._trg_from_pos(buf, (curr_pos == pos) and pos or pos+1,
                                 implicit=False, DEBUG=DEBUG,
                                 ac=ac, styleClassifier=styleClassifier)
    if DEBUG:
        print "  currTrg: %r" % (currTrg, )

    # If we're not looking for a previous trigger, or else the current
    # trigger position is for a calltip, then do not look any further.
    if (pos == curr_pos) or (currTrg and currTrg.form == TRG_FORM_CALLTIP):
        return currTrg
    # Else, work our way backwards from pos.

    ac.resetToPosition(pos+1)
    p, ch, style = ac.getPrevPosCharStyle()
    if DEBUG:
        print "  preceding_trg_from_pos: p: %r, ch: %r, style: %r" % (p, ch, style)
    min_p = max(0, p - 200)
    ignore_styles = styleClassifier.comment_styles + \
                    styleClassifier.string_styles + \
                    styleClassifier.number_styles
    while p &gt; min_p and styleClassifier.is_css_style(style):
        p, ch, style = ac.getPrecedingPosCharStyle(style, ignore_styles=ignore_styles, max_look_back=100)
        if DEBUG:
            print "  preceding_trg_from_pos: Trying preceding p: %r, ch: %r, style: %r" % (p, ch, style)
        if ch and (_isident(ch) or ch in ":( \t"):
            trg = self._trg_from_pos(buf, p+1, implicit=False, DEBUG=DEBUG,
                                     ac=ac, styleClassifier=styleClassifier)
            if trg is not None:
                if DEBUG:
                    print "trg: %r" % (trg, )
                if currTrg is not None:
                    if currTrg.type != trg.type:
                        if DEBUG:
                            print "  Next trigger is a different type, ending search"
                        return None
                    elif currTrg.form != trg.form:
                        return trg
                    elif DEBUG:
                        print "  Found same trigger again, continuing " \
                              "looking for a different trigger"
                else:
                    return trg
    return None

</t>
<t tx="ekr.20080121105837.1084">def _trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None, styleClassifier=None):
    #DEBUG = True # not using 'logging' system, because want to be fast
    if DEBUG:
        print "\n----- CSS _trg_from_pos(pos=%r, implicit=%r) -----"\
              % (pos, implicit)
    try:
        if pos == 0:
            return None

        if ac is None:
            ac = AccessorCache(buf.accessor, pos, fetchsize=50)
        else:
            ac.resetToPosition(pos)
        # Ensure this variable is initialized as False, it is used by UDL
        # for checking if the css style is inside of a html tag, example:
        #   &lt;p style="mycss: value;" /&gt;
        # When it's found that it is such a case, this value is set True
        ac.is_html_style_attribute = False

        last_pos, last_char, last_style = ac.getPrevPosCharStyle()
        if DEBUG:
            print "  _trg_from_pos:: last_pos: %s" % last_pos
            print "  last_char: %r" % last_char
            print "  last_style: %s" % last_style

        # The easy ones are triggering after any of '#.[: '.
        # For speed, let's get the common ' ' out of the way. The only
        # trigger on space is 'complete-property-values'.

        if styleClassifier.is_default(last_style):
            if DEBUG:
                print "  _trg_from_pos:: Default style: %d, ch: %r" % (last_style, last_char)
            # This may not even be a property-value, but at this stage we
            # don't care, as it will get worked out later in the
            # asynchronous call async_eval_at_trg().
            return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                           pos, implicit, extra={"ac": ac})

        elif styleClassifier.is_operator(last_style, ac):
            # anchors
            if DEBUG:
                print "  _trg_from_pos:: OPERATOR style"
            if last_char == '#':
                return Trigger("CSS", TRG_FORM_CPLN, "anchors",
                               pos, implicit, extra={"ac": ac})

            elif last_char == ':':
                try:
                    p, ch, style = ac.getPrevPosCharStyle(ignore_styles=styleClassifier.ignore_styles)
                    if DEBUG:
                        print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                except IndexError:
                    style = None
                if DEBUG:
                    print "  _trg_from_pos:: style: %r" % (style)
                if style is None or \
                   not styleClassifier.is_identifier(style, ac):
                #if style is None or \
                #   not styleClassifier.is_css_style(style) or \
                #   styleClassifier.is_class(style, ac):
                    # complete for pseudo-class-names
                    return Trigger("CSS", TRG_FORM_CPLN, "pseudo-class-names",
                                   pos, implicit, extra={"ac": ac})
                else:
                #if styleClassifier.is_identifier(style, ac):
                    # calltip for property-values
                    return Trigger("CSS", TRG_FORM_CALLTIP, "property-values",
                                   pos, implicit, extra={"ac": ac})

            # class-names
            elif last_char == '.':
                return Trigger("CSS", TRG_FORM_CPLN, "class-names",
                               pos, implicit, extra={"ac": ac})

            # at-rule
            elif last_char == '@':
                #p, ch, style = ac.getPrevPosCharStyle(ignore_styles=styleClassifier.comment_styles)
                # XXX - Should check not beyond first rule set
                #     - Should check not within a rule block.
                return Trigger("CSS", TRG_FORM_CPLN, "at-rule",
                               pos, implicit, extra={"ac": ac})

            elif last_char == '/':
                try:
                    p, ch, style = ac.getPrevPosCharStyle()
                except IndexError:
                    pass
                else:
                    if ch == "&lt;":
                        # Looks like start of closing '&lt;/style&gt;'
                        # tag. While typing this the styling will
                        # still be in the CSS range.
                        return Trigger(buf.m_lang, TRG_FORM_CPLN,
                                       "end-tag", pos, implicit)

        # tag-names
        elif styleClassifier.is_tag(last_style, ac):
            # We trigger on tag names of specified length &gt;= 1 char
            if DEBUG:
                print "  _trg_from_pos:: TAG style"
            p, ch, style = last_pos, last_char, last_style
            try:
                while p &gt;= 0:
                    if DEBUG:
                        print "  _trg_from_pos:: Looking at p: %d, ch: %r, style: %d" % (p, ch, style)
                    if not _isident(ch):
                        p += 1
                        break
                    elif style != last_style:
                        if DEBUG:
                            print "  _trg_from_pos:: Current style is not a tag: %d" % (style)
                        return None
                    p, ch, style = ac.getPrevPosCharStyle()
            except IndexError:
                p = 0
            return Trigger("CSS", TRG_FORM_CPLN, "tag-names",
                           p, implicit, extra={"ac": ac})

        elif styleClassifier.is_identifier(last_style, ac):
            if DEBUG:
                print "  _trg_from_pos:: IDENTIFIER style"
            # property-names
            #print "here", accessor.text_range(0, pos)
            # We trigger on identifier names with any length &gt;= 1 char
            pos = last_pos
            while pos &gt;= 0:
                pos, ch, style = ac.getPrevPosCharStyle()
                if not _isident(ch):
                    break
                elif style != last_style:
                    return None
            return Trigger("CSS", TRG_FORM_CPLN, "property-names",
                           pos+1, implicit, extra={"ac": ac})

        elif styleClassifier.is_value(last_style, ac):
            p, ch, style = ac.getPrevPosCharStyle(ignore_styles=styleClassifier.comment_styles)
            if DEBUG:
                print "  _trg_from_pos:: VALUE style"
                print "  _trg_from_pos::   p: %s" % p
                print "  _trg_from_pos::   ch: %r" % ch
                print "  _trg_from_pos::   style: %s" % style
                ac.dump()
            # Implicit triggering only happens on a whitespace character
            # after any one of these ":,%) " characters
            # Note: last_char can be a value style yet also be whitespace
            #       in straight CSS.
            if last_char in WHITESPACE:
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               last_pos+1, implicit, extra={"ac": ac})
            elif ch in WHITESPACE or ch in ":,%)":
                # Check to ensure this is not a pseudo-class! Bug:
                #   http://bugs.activestate.com/show_bug.cgi?id=71073
                if ch == ":":
                    # Last style must be an identifier then!
                    pp, pch, pstyle = ac.getPrevPosCharStyle(
                            ignore_styles=styleClassifier.ignore_styles)
                    if DEBUG:
                        print "pp: %d, pch: %r, pstyle: %d" % (pp, pch,
                                                               pstyle)
                    if not styleClassifier.is_identifier(pstyle, ac):
                        # This is likely a pseudo-class definition then,
                        # no trigger here.
                        if DEBUG:
                            print "pseudo-class style found, no trigger."
                        return None
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               p+1, implicit, extra={"ac": ac})
            # For explicit, we can also be inside a property already
            if not implicit and _isident(ch):
                # If there is already part of a value there, we need to move
                # the trigger point "p" to the start of the value.
                while _isident(ch):
                    p, ch, style = ac.getPrevPosCharStyle()
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               p+1, implicit, extra={"ac": ac})
            return None

        elif styleClassifier.is_default(last_style):
            if DEBUG:
                print "  _trg_from_pos:: Default style: %d, ch: %r" % (last_style, last_char)
            p, ch, style = ac.getPrecedingPosCharStyle(last_style)
            while style in styleClassifier.identifier_styles:
                p, ch, style = ac.getPrecedingPosCharStyle(style)
            if styleClassifier.is_operator(style) and ch in ":,)":
                return Trigger("CSS", TRG_FORM_CPLN, "property-values",
                               p+1, implicit, extra={"ac": ac})

        elif DEBUG:
            print "  _trg_from_pos:: Unknown style: %d, ch: %r" % (last_style, last_char)

        # XXX "at-property-names" - Might be used later
        #elif last_style == SCE_CSS_DIRECTIVE:
        #    # property-names
        #    # We trigger on identifier names with length == 3
        #    #print "here", accessor.text_range(0, pos)
        #    if pos &gt;= 4 and accessor.char_at_pos(pos - 4) == ' ' and \
        #       self._is_ident_of_length(accessor, pos, length=3):
        #        # We are good for completion
        #        if DEBUG:
        #            print "Got a trigger for 'at-property-names'"
        #        return Trigger("CSS", TRG_FORM_CPLN, "at-property-names",
        #                       pos-3, implicit, extra={"ac": ac})

    except IndexError:
        # Wen't out of range of buffer before we found anything useful
        pass

    if DEBUG:
        print "----- CSS trg_from_pos() -----"
    return None

</t>
<t tx="ekr.20080121105837.1085">def trg_from_pos(self, buf, pos, implicit=True, ac=None):
    DEBUG = False # not using 'logging' system, because want to be fast
    if isinstance(buf, UDLBuffer):
        # This is CSS content in a multi-lang buffer.
        return self._trg_from_pos(buf, pos, implicit, DEBUG, ac, UDLCSSStyleClassifier)
    else:
        return self._trg_from_pos(buf, pos, implicit, DEBUG, ac, StraightCSSStyleClassifier)

</t>
<t tx="ekr.20080121105837.1086">def _async_eval_at_trg(self, buf, trg, ctlr, styleClassifier):
    # Note: Currently this is NOT asynchronous. I believe that is fine
    # as long as evaluation is fast -- because the IDE UI thread could
    # be blocked on this. If processing might be slow (e.g. scanning
    # a number of project files for appropriate anchors, etc.), then
    # this should be made asynchronous.
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    DEBUG = False
    #DEBUG = True
    if DEBUG:
        print "\n----- async_eval_at_trg(trg=%r) -----"\
              % (trg)

    # Setup the AccessorCache
    extra = trg.extra
    ac = None
    #print "Extra: %r" % (extra)
    if isinstance(extra, dict):
        extra = extra.get("extra", None)
        if isinstance(extra, dict):
            ac = extra.get("ac", None)
            if ac and DEBUG:
                print "  _async_eval_at_trg:: Trigger had existing AC"
                ac.dump()
    if ac is None:
        if DEBUG:
            print "  _async_eval_at_trg:: Created new trigger!"
        ac = AccessorCache(buf.accessor, trg.pos, fetchsize=20)

    ctlr.start(buf, trg)
    pos = trg.pos

    try:
        if trg.id == ("CSS", TRG_FORM_CPLN, "tag-names"):
            tagname = ac.text_range(pos, pos+self.CSS_HTML_TAG_NAME_TRIGGER_LENGTH)
            if DEBUG:
                print "  _async_eval_at_trg:: 'tag-names'"
                print "  _async_eval_at_trg:: tagname:", tagname
            if trg.implicit:
                cplns = self.CSS_HTML_TAG_NAMES_LOOKUP.get(tagname)
            else:
                cplns = self.CSS_HTML_TAG_NAMES
            if DEBUG:
                print "  _async_eval_at_trg:: cplns:", cplns
            if cplns:
                ctlr.set_cplns( [ ("element", v) for v in cplns ] )
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CPLN, "anchors"):
            # Can be a colour or an id tag, depending upon what the
            # previous char/style is
            # The previous style must be an op style or alphanumeric ch
            #i = 0
            #max_total_lookback = 100 # Up to 100 chars back
            #while i &lt; max_total_lookback:
            #    p, ch, style = ac.getPrecedingPosCharStyle(last_style,
            #                    ignore_styles=styleClassifier.ignore_styles)
            #    if not is_udl_css_style(style) or \
            #       (styleClassifier.is_operator(style, ac) and \
            #        ch in "};"):
            #    i = last_pos - p
            # XXX - Needs to lookup the project HTML files for anchors...
            #anchors = self._get_all_anchors_names_in_project(accessor)
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CPLN, "class-names"):
            #raise NotImplementedError("not yet implemented: completion for "
            #                          "most css triggers")
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CPLN, "property-names"):
            if trg.implicit:
                property_name = ac.text_range(pos,
                                pos+self.CSS_PROPERTY_NAME_TRIGGER_LENGTH)
                #print "\ntagname:", property_name
                cplns = self.CSS_PROPERTY_NAMES_LOOKUP.get(property_name)
            else:
                cplns = self.CSS_PROPERTY_NAMES
            if cplns:
                ctlr.set_cplns( [ ("property", v) for v in cplns ] )
                #print "  _async_eval_at_trg:: cplns:", cplns
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CALLTIP, "property-values"):
            property, v1, v2 \
                = self._extract_css_declaration(ac, styleClassifier, trg,
                                                is_for_calltip=True)
            if DEBUG:
                print "  _async_eval_at_trg:: Property name: %r" % \
                        (property, )
            try:
                calltip = self.CSS_PROPERTY_ATTRIBUTE_CALLTIPS_DICT[property]
                if DEBUG:
                    print "  _async_eval_at_trg:: calltip:", calltip
                ctlr.set_calltips([calltip])
            except KeyError:
                #print "Unknown CSS property: '%s'" % (property)
                pass    # Ignore unknown CSS attributes
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CPLN, "property-values"):
            property, current_value, values \
                = self._extract_css_declaration(ac, styleClassifier, trg)
            if DEBUG:
                print "  _async_eval_at_trg:: XXX property: %r, " \
                      " current_value: %r, values: %r" % (property,
                                                          current_value,
                                                          values)
            try:
                #print "\ndict:", self.CSS_ATTRIBUTES[property]
                property_values = self.CSS_ATTRIBUTES[property]
                # Check if it matches anything, if not, dismiss the list
                if current_value:
                    clen = len(current_value)
                    for v in property_values:
                        if clen &lt;= len(v) and current_value == v[:clen]:
                            # Found a match
                            break
                    # Else, return the full list, even though no match made
                    # XXX - May want to cancel the CC list, any way to do this?
                cplns = [("value", v)
                         for v in property_values
                         if v not in values or v == current_value]
                ctlr.set_cplns(cplns)
            except KeyError:
                if DEBUG: 
                    print "  _async_eval_at_trg:: Unknown CSS property: "\
                          "'%s'" % (property)
                pass    # Ignore unknown CSS attributes
            ctlr.done("success")

            #XXX Handling for property not in list.
        elif trg.id == ("CSS", TRG_FORM_CPLN, "pseudo-class-names"):
            cplns = [("pseudo-class", v)
                     for v in self.CSS_PSEUDO_CLASS_NAMES]
            ctlr.set_cplns(cplns)
            ctlr.done("success")
        elif trg.id == ("CSS", TRG_FORM_CPLN, "at-rule"):
            cplns = [("rule", v)
                     for v in self.CSS_AT_RULE_NAMES]
            ctlr.set_cplns(cplns)
            ctlr.done("success")

        # Punt - Lower priority
        #elif trg.id == ("CSS", TRG_FORM_CPLN, "units"):

        # Punt - Fancy
        #elif trg.id == ("CSS", TRG_FORM_CPLN, "import-url"):

        # Punt - uncommon
        #elif trg.id == ("CSS", TRG_FORM_CPLN, "attr-names"):
        #elif trg.id == ("CSS", TRG_FORM_CPLN, "attr-values"):

        else:
            raise NotImplementedError("not yet implemented: completion for "
                                      "most css triggers")
    except IndexError:
        # Tried to go out of range of buffer, nothing appropriate found
        if DEBUG:
            print "  _async_eval_at_trg:: ** Out of range error **"
        ctlr.done("success")

</t>
<t tx="ekr.20080121105837.1087">def async_eval_at_trg(self, buf, trg, ctlr):
    if isinstance(buf, UDLBuffer):
        # This is CSS content in a multi-lang buffer.
        return self._async_eval_at_trg(buf, trg, ctlr,
                                       UDLCSSStyleClassifier)
    else:
        return self._async_eval_at_trg(buf, trg, ctlr,
                                       StraightCSSStyleClassifier)

</t>
<t tx="ekr.20080121105837.1088">def _get_all_anchors_names_in_project(self):
    #anchors = []
    #pos = 0
    #LENGTH = accessor.length
    #style = 0
    #func_style_at_pos = accessor.style_at_pos
    #func_char_at_pos = accessor.char_at_pos
    #while pos &lt; LENGTH:
    #    if func_char_at_pos(pos) == '#' and \
    #       func_style_at_pos(pos) == SCE_CSS_OPERATOR:
    #        # Likely an anchor
    #        pass
    #    pos += 1
    #return anchors
    return []

</t>
<t tx="ekr.20080121105837.1089">def _is_ident_of_length(self, accessor, pos, length=3):
    # Fourth char to left should not be an identifier
    if pos &gt; length and _isident(accessor.char_at_pos((pos - length) - 1)):
        return False
    # chars to left should all be identifiers
    for i in range(pos - 1, (pos - length) -1, -1):
        if not _isident(accessor.char_at_pos(i)):
            return False
    return True

</t>
<t tx="ekr.20080121105837.1090">def _extract_css_declaration(self, ac, styleClassifier, trg,
                             is_for_calltip=False):
    """Extract the CSS declaration around the given position.

    Returns a 3-tuple:
        (&lt;property&gt;, &lt;current_value&gt;, &lt;value_list&gt;)

    If is_for_calltip is true, we do not bother to parse out the values, so
    &lt;current_value&gt; and &lt;value_list&gt; will be empty.

    The value gets parsed into &lt;value_list&gt;, a list of individual values.
    Comments and strings are striped from the return value.

    If the &lt;current_value&gt; is '', then the trigger position is
    ready to start a new value.
    """
    DEBUG = False
    #DEBUG = True
    #PERF: Use accessor.gen_chars_and_styles() if possible.
    try:
        ac.resetToPosition(trg.pos)
        p, ch, style = ac.getPrevPosCharStyle()
        if not styleClassifier.is_operator(style, ac):
            if DEBUG:
                print "Current ch is not an operator, so getting the " \
                      "preceeding one, p: %d, ch: %r, style: %d" % \
                      (p, ch, style, )
            p, ch, style = ac.getPrevPosCharStyle(
                                ignore_styles=styleClassifier.ignore_styles)
    except IndexError:
        # This occurs when already at the end of the buffer, so we reset to
        # the last buffer position then
        ac.resetToPosition(trg.pos - 1)
        p, ch, style = ac.getCurrentPosCharStyle()
    if DEBUG:
        print """------ _extract_css_declaration -----"""
        print "  _extract_css_declaration:: Trg.pos: %d" % (trg.pos)
        #ac._debug = True
        print "  _extract_css_declaration:: pos: %r" % (p)
        print "  _extract_css_declaration:: ch: %r" % (ch)
        print "  _extract_css_declaration:: style: %r" % (style)
        ac.dump()
    # Walk back to ':' operator.
    num_close_parenthesis = 0
    min_pos = max(0, trg.pos - 200)  # Lookback up to 200 chars in total
    while p &gt;= min_pos:
        #print "ch: %r, style: %d" % (ch, style, )
        if ch == ':' and styleClassifier.is_operator(style, ac):
            break
        elif num_close_parenthesis &gt; 0:
            if ch == "(":
                num_close_parenthesis -= 1
                if DEBUG:
                    print "Found matching open paren," \
                          " num_close_parenthesis now: %d" % (
                                num_close_parenthesis)
            elif DEBUG:
                print "Ignoring everything inside the parenthesis"
        elif ch == "(" and (styleClassifier.is_operator(style) or
                            styleClassifier.is_value(style)):
            if DEBUG:
                print "Already inside a paren, no cpln's then."
            return (None, None, None)
        elif ch == ")" and (styleClassifier.is_operator(style) or
                            styleClassifier.is_value(style)):
            num_close_parenthesis += 1
            if DEBUG:
                print "Found close paren, need to skip over contents," \
                      " num_close_parenthesis: %d" % (
                            num_close_parenthesis)
        elif styleClassifier.is_operator(style):
            if ch not in ":,%":
                if DEBUG:
                    print "%s: couldn't find ':' operator, found invalid " \
                          "operator: %d %r %d" % (trg.name, p, ch, style)
                return (None, None, None)
        elif styleClassifier.is_string(style):
            # Used to skip over string items in property values
            if DEBUG:
                print "Found string style, ignoring it"
        elif not styleClassifier.is_value(style):
            # is_value is used for sraight CSS, where everything is a value
            if DEBUG:
                print "%s: couldn't find ':' operator, found invalid " \
                      "style: pcs: %d %r %d" % (trg.name, p, ch, style)
            return (None, None, None)
        p, ch, style = ac.getPrevPosCharStyle(
                                ignore_styles=styleClassifier.ignore_styles)
    else:
        if DEBUG:
            print "%s: couldn't find ':' operator within 200 chars, " \
                  "giving up" % (trg.name)
        return (None, None, None)

    if DEBUG:
        print "  _extract_css_declaration:: Found ':' at pos: %d" % (p)
    # Parse out the property name.
    colan_pos = p
    p, ch, style = ac.getPrecedingPosCharStyle(style,
                                ignore_styles=styleClassifier.ignore_styles,
                                max_look_back=150)
    if style not in styleClassifier.identifier_styles:
        if DEBUG:
            print "  _extract_css_declaration:: No identifier style found" \
                  " before ':', found style %d instead" % (style)
        return (None, None, None)
    p, property = ac.getTextBackWithStyle(style)
    property = property.strip()

    if is_for_calltip:
        # We have all the info we need
        if DEBUG:
            print "  _extract_css_declaration:: Returning property: %r" % (
                        property)
        return (property, '', [])

    # Walk forward parsing the value information, ends when we hit a ";" or
    # have gone ahead a maximum of 200 chars.
    ac.resetToPosition(colan_pos)
    prev_pos, prev_ch, prev_style = ac.getCurrentPosCharStyle()
    from_pos = prev_pos
    p = colan_pos
    # Value info, list of tuples (pos, text)
    value_info = []
    max_p = p + 200
    try:
        while p &lt; max_p:
            p, ch, style = ac.getNextPosCharStyle(max_look_ahead=100, ignore_styles=styleClassifier.comment_styles)
            if p is None or not styleClassifier.is_css_style(style):
                # Went past max_look_ahead, just use what we've got then
                if DEBUG:
                    print "%s: css value reached max length or end of " \
                          "document: trg.pos %d" % (trg.name, trg.pos)
                value_info.append((from_pos, ac.text_range(from_pos, p)))
                break

            if ch in WHITESPACE or styleClassifier.is_string(style):
                if not prev_ch in WHITESPACE and not styleClassifier.is_string(prev_style):
                    value_info.append((from_pos, ac.text_range(from_pos, p)))
                from_pos = p+1
            elif styleClassifier.is_operator(style):
                if ch in ";{}":
                    value_info.append((from_pos, ac.text_range(from_pos, p)))
                    break
                # Other chars should be okay to collect
            elif not styleClassifier.is_value(style) and \
                 style not in styleClassifier.ignore_styles:
                if DEBUG:
                    print "%s: invalid style found: pos %d, style: %d" % (
                             trg.name, trg.pos, style)
                return (None, None, None)
            prev_pos, prev_ch, prev_style = p, ch, style
        else:
            if DEBUG:
                print "%s: css value too long: trg.pos %d" % (trg.name, trg.pos)
            return (None, None, None)
    except IndexError:
        if DEBUG:
            print "ran out of buffer"

    # Work out the values and the current value
    current_value = None
    values = []
    trg_pos = trg.pos
    for p, value in value_info:
        if value and _isident_first_char(value[0]):
            if DEBUG:
                print "Is a valid value, p: %d, value: %r" % (p, value, )
            values.append(value)
            if current_value is None and trg_pos &gt;= p and \
               trg_pos &lt;= p + len(value):
                current_value = value

    if DEBUG:
        print "  _extract_css_declaration:: Returning property: %r, " \
              "current_value: %r, values: %r" % (property, current_value,
                                                 values)
    return (property, current_value, values)


</t>
<t tx="ekr.20080121105837.1091">class CSSBuffer(Buffer):
    lang = "CSS"
    sce_prefixes = ["SCE_CSS_"]
    cpln_fillup_chars = ""  # none for now, should probably add some
    cpln_stop_chars = " ('\";},.&gt;"



</t>
<t tx="ekr.20080121105837.1092">#---- internal support stuff

_ident_chars = string.lowercase + string.uppercase + string.digits + "-"
_ident_chars_dictionary = {}
ch = None
for ch in _ident_chars:
    _ident_chars_dictionary[ch] = 1
# Cleanup un-needed namespace definitions
del ch
del _ident_chars

def _isident_first_char(char):
    return _isident(char) and char != "-" and (char &lt; "0" or char &gt; "9")

</t>
<t tx="ekr.20080121105837.1093">def _isident(char):
    # In CSS2, identifiers  (including element names, classes, and IDs in
    # selectors) can contain only the characters [A-Za-z0-9] and ISO 10646
    # characters 161 and higher, plus the hyphen (-); they cannot start with a
    # hyphen or a digit
    return char in _ident_chars_dictionary or ord(char) &gt;= 161

</t>
<t tx="ekr.20080121105837.1094">def _isdigit(char):
    return "0" &lt;= char &lt;= "9"

</t>
<t tx="ekr.20080121105837.1095">def _is_udl_css_ident(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" \
            or char == "_" or char == "="



</t>
<t tx="ekr.20080121105837.1096">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=CSSLexer(),
                      buf_class=CSSBuffer,
                      langintel_class=CSSLangIntel,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1097">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1098">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Django support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "Django"
log = logging.getLogger("codeintel.django")



</t>
<t tx="ekr.20080121105837.1099">#---- language support

class DjangoLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1100">class DjangoBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Python"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    # - TODO: adjust for Python
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"


</t>
<t tx="ekr.20080121105837.1101">class DjangoCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    tpl_lang = "Django"



</t>
<t tx="ekr.20080121105837.1102">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=DjangoLexer(),
                      buf_class=DjangoBuffer,
                      import_handler_class=None,
                      cile_driver_class=DjangoCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1103">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1104">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""HTML support for CodeIntel"""

import os
import sys
import logging
import re
import traceback
from pprint import pprint

from codeintel2.common import *
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin
from codeintel2.lang_xml import XMLLangIntel


try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

lang = "HTML"
log = logging.getLogger("codeintel.html")



</t>
<t tx="ekr.20080121105837.1105">#---- language support

class HTMLLexer(UDLLexer):
    lang = lang


</t>
<t tx="ekr.20080121105837.1106">class HTMLLangIntel(XMLLangIntel):
    lang = lang

</t>
<t tx="ekr.20080121105837.1107">class HTMLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "HTML"
    csl_lang = "JavaScript"
    css_lang = "CSS"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    # - TODO: might want to drop '-' because causes problem with CSS and XML
    #   (ditto for other XML-y langs)
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"



</t>
<t tx="ekr.20080121105837.1108">class HTMLCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"




</t>
<t tx="ekr.20080121105837.1109">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=HTMLLexer(),
                      buf_class=HTMLBuffer,
                      langintel_class=HTMLLangIntel,
                      cile_driver_class=HTMLCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1110">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1111">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""JavaScript support for Code Intelligence

    This is a Language Engine for the Code Intelligence (codeintel) system.
    Code Intelligence XML format. See:
        http://specs.tl.activestate.com/kd/kd-0100.html#xml-based-import-export-syntax-cix
"""

import os
from os.path import splitext, basename
import sys
import types
import logging
from cStringIO import StringIO
import weakref
from glob import glob

from ciElementTree import Element, ElementTree, SubElement

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity.ScintillaConstants import (
    SCE_C_COMMENT, SCE_C_COMMENTDOC, SCE_C_COMMENTDOCKEYWORD,
    SCE_C_COMMENTDOCKEYWORDERROR, SCE_C_COMMENTLINE,
    SCE_C_COMMENTLINEDOC, SCE_C_DEFAULT, SCE_C_IDENTIFIER, SCE_C_NUMBER,
    SCE_C_OPERATOR, SCE_C_STRING, SCE_C_CHARACTER, SCE_C_WORD,
    SCE_UDL_CSL_COMMENT, SCE_UDL_CSL_COMMENTBLOCK, SCE_UDL_CSL_DEFAULT,
    SCE_UDL_CSL_IDENTIFIER, SCE_UDL_CSL_NUMBER, SCE_UDL_CSL_OPERATOR,
    SCE_UDL_CSL_REGEX, SCE_UDL_CSL_STRING, SCE_UDL_CSL_WORD,
)

from codeintel2.citadel import CitadelBuffer, ImportHandler
from codeintel2.buffer import Buffer
from codeintel2.tree_javascript import JavaScriptTreeEvaluator
from codeintel2 import util
from codeintel2.parseutil import getAttrStr
from codeintel2.common import *
from codeintel2.indexer import PreloadBufLibsRequest, PreloadLibRequest
from codeintel2.jsdoc import JSDoc, JSDocParameter, jsdoc_tags
from codeintel2.gencix_utils import *
from codeintel2.database.langlib import LangDirsLib
from codeintel2.udl import UDLBuffer, is_udl_csl_style
from codeintel2.accessor import AccessorCache
from codeintel2.langintel import (LangIntel, ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin,
                                  PythonCITDLExtractorMixin)

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

lang = "JavaScript"
# Setup the logger
log = logging.getLogger("codeintel.javascript")
#log.setLevel(logging.DEBUG)
#log.setLevel(logging.INFO)

keywords = ["abstract", "boolean", "break", "byte", "case", "catch",
            "char", "class", "const", "continue", "debugger", "default",
            "delete", "do", "double", "else", "enum", "export",
            "extends", "false", "final", "finally", "float", "for", "function",
            "goto", "if", "implements", "import", "in", "instanceof",
            "int", "interface", "long", "native", "new", "null", "package",
            "private", "protected", "public", "return", "short",
            "static", "super", "switch", "synchronized", "this", "throw",
            "throws", "transient", "true", "try", "typeof", "var", "void",
            "while", "with"]

# States used by JavaScriptScanner when parsing information
S_DEFAULT = 0
S_IN_ARGS = 1
S_IN_ASSIGNMENT = 2
S_IGNORE_SCOPE = 3
S_OBJECT_ARGUMENT = 4

# Types used by JavaScriptScanner when parsing information
TYPE_NONE = 0
TYPE_FUNCTION = 1
TYPE_VARIABLE = 2
TYPE_GETTER = 3
TYPE_SETTER = 4
TYPE_MEMBER = 5
TYPE_OBJECT = 6
TYPE_CLASS = 7
TYPE_PARENT = 8



</t>
<t tx="ekr.20080121105837.1112">#---- language support

class JavaScriptLexer(Lexer):
    lang = "JavaScript"
    @others
</t>
<t tx="ekr.20080121105837.1113">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_CPP)
    self._keyword_lists = [
        SilverCity.WordList(' '.join(keywords)),
        SilverCity.WordList(),
        SilverCity.WordList(),
        SilverCity.WordList(),
        SilverCity.WordList()
    ]

</t>
<t tx="ekr.20080121105837.1114">class PureJavaScriptStyleClassifier:
    @others
</t>
<t tx="ekr.20080121105837.1115">def __init__(self):
    self.is_udl = False
    self.operator_style   = SCE_C_OPERATOR
    self.identifier_style = SCE_C_IDENTIFIER
    self.keyword_style    = SCE_C_WORD
    self.comment_styles   = (SCE_C_COMMENT,
                             SCE_C_COMMENTDOC,
                             SCE_C_COMMENTLINE,
                             SCE_C_COMMENTLINEDOC,
                             SCE_C_COMMENTDOCKEYWORD,
                             SCE_C_COMMENTDOCKEYWORDERROR)
    self.string_styles    = (SCE_C_STRING, SCE_C_CHARACTER)
    self.ignore_styles    = self.comment_styles + (SCE_C_DEFAULT, )

</t>
<t tx="ekr.20080121105837.1116">class UDLJavaScriptStyleClassifier:
    @others
</t>
<t tx="ekr.20080121105837.1117">def __init__(self):
    self.is_udl = True
    self.operator_style   = SCE_UDL_CSL_OPERATOR
    self.identifier_style = SCE_UDL_CSL_IDENTIFIER
    self.keyword_style    = SCE_UDL_CSL_WORD
    self.comment_styles   = (SCE_UDL_CSL_COMMENT,
                             SCE_UDL_CSL_COMMENTBLOCK,)
    self.string_styles    = (SCE_UDL_CSL_STRING, )
    self.ignore_styles    = self.comment_styles + (SCE_UDL_CSL_DEFAULT, )

</t>
<t tx="ekr.20080121105837.1118">pureJSClassifier = PureJavaScriptStyleClassifier()
udlJSClassifier = UDLJavaScriptStyleClassifier()

class JavaScriptLangIntel(LangIntel, ParenStyleCalltipIntelMixin,
                          ProgLangTriggerIntelMixin,
                          PythonCITDLExtractorMixin):

    # The way namespacing is done with variables in JS means that grouping
    # global vars is just annoying.
    cb_group_global_vars = False
    # Define the trigger chars we use, used by ProgLangTriggerIntelMixin
    trg_chars = tuple(".(@ ")
    calltip_trg_chars = tuple('( ')
    # Define literal mapping to citdl member, used in PythonCITDLExtractorMixin
    citdl_from_literal_type = {"string": "String"}

    @others
</t>
<t tx="ekr.20080121105837.1119">def cb_variable_data_from_elem(self, elem):
    """Use the 'namespace' image in the Code Browser for a variable
    acting as one.
    """
    data = LangIntel.cb_variable_data_from_elem(self, elem)
    if len(elem) and data["img"].startswith("variable"):
        data["img"] = data["img"].replace("variable", "namespace")
    return data

</t>
<t tx="ekr.20080121105837.1120">def trg_from_pos(self, buf, pos, implicit=True,
                 lang="JavaScript"):
    DEBUG = False  # not using 'logging' system, because want to be fast
    #DEBUG = True
    #if DEBUG:
    #    print util.banner("JavaScript trg_from_pos(pos=%r, implicit=%r)"
    #                      % (pos, implicit))

    if pos == 0:
        return None

    if isinstance(buf, UDLBuffer):
        jsClassifier = udlJSClassifier
    else:
        jsClassifier = pureJSClassifier

    accessor = buf.accessor
    last_pos = pos - 1
    last_char = accessor.char_at_pos(last_pos)
    last_style = accessor.style_at_pos(last_pos)
    if DEBUG:
        print "  last_pos: %s" % last_pos
        print "  last_ch: %r" % last_char
        print "  last_style: %r" % last_style

    if (jsClassifier.is_udl and last_char == '/'
        and last_pos &gt; 0 and accessor.char_at_pos(last_pos-1) == '&lt;'
        and last_style not in (SCE_UDL_CSL_STRING,
                               SCE_UDL_CSL_COMMENTBLOCK,
                               SCE_UDL_CSL_COMMENT,
                               SCE_UDL_CSL_REGEX)):
        # Looks like start of closing '&lt;/script&gt;' tag. While typing this
        # the styling will still be in the CSL range.
        return Trigger(buf.m_lang, TRG_FORM_CPLN,
                       "end-tag", pos, implicit)

    # JSDoc completions
    elif last_char == "@" and last_style in jsClassifier.comment_styles:
        # If the preceeding non-whitespace character is a "*" or newline
        # then we complete for jsdoc tag names
        p = last_pos - 1
        min_p = max(0, p - 50)      # Don't bother looking more than 50 chars
        if DEBUG:
            print "Checking match for jsdoc completions"
        while p &gt;= min_p and \
              accessor.style_at_pos(p) in jsClassifier.comment_styles:
            ch = accessor.char_at_pos(p)
            p -= 1
            #if DEBUG:
            #    print "Looking at ch: %r" % (ch)
            if ch == "*" or ch in "\r\n":
                break
            elif ch not in " \t\v":
                # Not whitespace, not a valid tag then
                return None
        else:
            # Nothing found in the specified range
            if DEBUG:
                print "trg_from_pos: not a jsdoc"
            return None
        if DEBUG:
            print "Matched trigger for jsdoc completion"
        return Trigger("JavaScript", TRG_FORM_CPLN,
                       "jsdoc-tags", pos, implicit)

    # JSDoc calltip
    elif last_char in " \t" and last_style in jsClassifier.comment_styles:
        # whitespace in a comment, see if it matches for jsdoc calltip
        p = last_pos - 1
        min_p = max(0, p - 50)      # Don't bother looking more than 50 chars
        if DEBUG:
            print "Checking match for jsdoc calltip"
        ch = None
        ident_found_pos = None
        while p &gt;= min_p and \
              accessor.style_at_pos(p) in jsClassifier.comment_styles:
            ch = accessor.char_at_pos(p)
            p -= 1
            if ident_found_pos is None:
                #print "jsdoc: Looking for identifier, at ch: %r" % (ch)
                if ch in " \t":
                    pass
                elif _isident(ch):
                    ident_found_pos = p+1
                else:
                    if DEBUG:
                        print "No jsdoc, whitespace not preceeded by an " \
                              "identifer"
                    return None
            elif ch == "@":
                # This is what we've been looking for!
                jsdoc_field = accessor.text_range(p+2, ident_found_pos+1)
                if DEBUG:
                    print "Matched trigger for jsdoc calltip: '%s'" % (jsdoc_field, )
                return Trigger("JavaScript", TRG_FORM_CALLTIP,
                               "jsdoc-tags", ident_found_pos, implicit,
                               jsdoc_field=jsdoc_field)
            elif not _isident(ch):
                if DEBUG:
                    print "No jsdoc, identifier not preceeded by an '@'"
                # Not whitespace, not a valid tag then
                return None
        # Nothing found in the specified range
        if DEBUG:
            print "No jsdoc, ran out of characters to look at."

    elif last_char not in ".(":
        if DEBUG:
            print "trg_from_pos: no: %r is not in '.('" % last_char
        return None

    elif last_style == jsClassifier.operator_style:
        # Go back and check what we are operating on, should be
        # an identifier or a close brace type ")]}".
        p = last_pos - 1
        while p &gt;=0:
            style = accessor.style_at_pos(p)
            if style == jsClassifier.identifier_style:
                break
            elif style == jsClassifier.keyword_style and last_char == ".":
                break
            elif style == jsClassifier.operator_style and \
                 last_char == "." and accessor.char_at_pos(p) in ")]}":
                break
            elif style in jsClassifier.string_styles:
                break
            elif style not in jsClassifier.ignore_styles:
                # Else, wrong style for calltip
                if DEBUG:
                    print "not a trigger: unexpected style: %d at pos: %d" \
                          % (style, p)
                return None
            p -= 1
        else:
            # Did not find the necessary style, no completion/calltip then
            return None

        if last_char == ".":
            if style in jsClassifier.string_styles:
                return Trigger("JavaScript", TRG_FORM_CPLN,
                               "literal-members", pos, implicit,
                               citdl_expr="String")
            elif style == jsClassifier.keyword_style:
                # Check if it's a "this." expression
                isThis = False
                if last_pos &gt;= 4:
                    word = []
                    p = last_pos - 1
                    p_end = last_pos - 5
                    while p &gt; p_end:
                        word.insert(0, accessor.char_at_pos(p))
                        p -= 1
                    if "".join(word) == "this":
                        isThis = True
                if not isThis:
                    return None
            return Trigger("JavaScript", TRG_FORM_CPLN,
                           "object-members", pos, implicit)
        elif last_char == "(":
            # p is now at the end of the identifier, go back and check
            # that we are not defining a function
            ac = AccessorCache(accessor, p)
            # Get the previous style, if it's a keyword style, check that
            # the keyword is not "function"
            prev_pos, prev_char, prev_style = ac.getPrecedingPosCharStyle(jsClassifier.identifier_style, jsClassifier.ignore_styles)
            if prev_style == jsClassifier.keyword_style:
                p, prev_text = ac.getTextBackWithStyle(prev_style, jsClassifier.ignore_styles, max_text_len=len("function")+1)
                if prev_text in ("function", ):
                    # Don't trigger here
                    return None
            return Trigger("JavaScript", TRG_FORM_CALLTIP,
                           "call-signature", pos, implicit)
    return None

</t>
<t tx="ekr.20080121105837.1121">_jsdoc_cplns = [ ("variable", t) for t in sorted(jsdoc_tags) ]

def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    ctlr.start(buf, trg)

    # JSDoc completions
    if trg.id == ("JavaScript", TRG_FORM_CPLN, "jsdoc-tags"):
        #TODO: Would like a "javadoc tag" completion image name.
        ctlr.set_cplns(self._jsdoc_cplns)
        ctlr.done("success")
        return

    # JSDoc calltip
    elif trg.id == ("JavaScript", TRG_FORM_CALLTIP, "jsdoc-tags"):
        #TODO: Would like a "javadoc tag" completion image name.
        jsdoc_field = trg.extra.get("jsdoc_field")
        if jsdoc_field:
            #print "jsdoc_field: %r" % (jsdoc_field, )
            calltip = jsdoc_tags.get(jsdoc_field)
            if calltip:
                ctlr.set_calltips([calltip])
        ctlr.done("success")
        return

    if trg.type == "literal-members":
        # We could leave this to citdl_expr_from_trg, but this is a
        # little bit faster, since we already know the citdl expr.
        citdl_expr = trg.extra.get("citdl_expr")
    else:
        try:
            citdl_expr = self.citdl_expr_from_trg(buf, trg)
        except CodeIntelError, ex:
            ctlr.error(str(ex))
            ctlr.done("error")
            return
    line = buf.accessor.line_from_pos(trg.pos)
    evalr = JavaScriptTreeEvaluator(ctlr, buf, trg,
                                    citdl_expr, line)
    buf.mgr.request_eval(evalr)

</t>
<t tx="ekr.20080121105837.1122">def _extra_dirs_from_env(self, env):
    extra_dirs = set()
    proj_base_dir = env.get_proj_base_dir()
    if proj_base_dir is not None:
        extra_dirs.add(proj_base_dir)  # Bug 68850.
    for pref in env.get_all_prefs("javascriptExtraPaths"):
        if not pref: continue
        extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                          if exists(d.strip()))
    if extra_dirs:
        log.debug("JavaScript extra lib dirs: %r", extra_dirs)
        max_depth = env.get_pref("codeintel_max_recursive_dir_depth", 10)
        js_assocs = env.assoc_patterns_from_lang("JavaScript")
        extra_dirs = tuple(
            util.gen_dirs_under_dirs(extra_dirs,
                max_depth=max_depth,
                interesting_file_patterns=js_assocs)
        )
    else:
        extra_dirs = () # ensure retval is a tuple
    return extra_dirs

</t>
<t tx="ekr.20080121105837.1123">def libs_from_buf(self, buf):
    env = buf.env

    # A buffer's libs depend on its env and the buf itself so
    # we cache it on the env and key off the buffer.
    if "javascript-buf-libs" not in env.cache:
        env.cache["javascript-buf-libs"] = weakref.WeakKeyDictionary()
    cache = env.cache["javascript-buf-libs"] # &lt;buf-weak-ref&gt; -&gt; &lt;libs&gt;

    if buf not in cache:
        env.add_pref_observer("javascriptExtraPaths",
            self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("codeintel_selected_catalogs",
                              self._invalidate_cache)
        env.add_pref_observer("codeintel_max_recursive_dir_depth",
                              self._invalidate_cache)
        # (Bug 68850) Both of these 'live_*' prefs on the *project*
        # prefset can result in a change of project base dir. It is
        # possible that we can get false positives here if there is ever
        # a global pref of this name.
        env.add_pref_observer("import_live",
            self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("import_dirname",
            self._invalidate_cache_and_rescan_extra_dirs)

        db = self.mgr.db
        libs = []

        # - extradirslib
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            libs.append( db.get_lang_lib("JavaScript", "extradirslib",
                            extra_dirs) )

        # Warn the user if there is a huge number of import dirs that
        # might slow down completion.
        num_import_dirs = len(extra_dirs)
        if num_import_dirs &gt; 100:
            db.report_event("This buffer is configured with %d JavaScript "
                            "import dirs: this may result in poor "
                            "completion performance" % num_import_dirs)

        if buf.lang == "JavaScript":
            # - curdirlib (before extradirslib; only if pure JS file)
            cwd = dirname(normpath(buf.path))
            if cwd not in extra_dirs:
                libs.insert(0, db.get_lang_lib(lang, "curdirlib", [cwd]))

        # - cataloglib, stdlib
        catalog_selections = env.get_pref("codeintel_selected_catalogs")
        libs += [
            db.get_catalog_lib("JavaScript", catalog_selections),
            db.get_stdlib("JavaScript"),
        ]
        cache[buf] = libs
    return cache[buf]

</t>
<t tx="ekr.20080121105837.1124">def _invalidate_cache(self, env, pref_name):
    if "javascript-buf-libs" in env.cache:
        log.debug("invalidate 'javascript-buf-libs' cache on %r", env)
        del env.cache["javascript-buf-libs"]

</t>
<t tx="ekr.20080121105837.1125">def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
    self._invalidate_cache(env, pref_name)
    extra_dirs = self._extra_dirs_from_env(env)
    if extra_dirs:
        extradirslib = self.mgr.db.get_lang_lib(
            "JavaScript", "extradirslib", extra_dirs)
        request = PreloadLibRequest(extradirslib)
        self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1126">def lpaths_from_blob(self, blob):
    """Return &lt;lpaths&gt; for this blob
    where,
        &lt;lpaths&gt; is a set of externally referencable lookup-paths, e.g.
            [("YAHOO",), ("YAHOO", "util"), ...]

    Note: The jury is out on whether this should include imports.
    However, currently this is only being used for JS (no imports)
    so it doesn't yet matter.
    """
    return set(lpath for child in blob
               for lpath in _walk_js_symbols(child))


</t>
<t tx="ekr.20080121105837.1127">class JavaScriptBuffer(CitadelBuffer):
    lang = "JavaScript"

    # Fillup chars for JavaScript: basically, any non-identifier char.
    cpln_fillup_chars = "" #XXX todo: add apropriate set, copy from Python?
    cpln_stop_chars = "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    sce_prefixes = ["SCE_C_"]

    cb_show_if_empty = True

    @others
</t>
<t tx="ekr.20080121105837.1128">def __init__(self, *args, **kwargs):
    CitadelBuffer.__init__(self, *args, **kwargs)
    
    # Encourage the database to pre-scan dirs relevant to completion
    # for this buffer -- because of recursive-dir-include-everything
    # semantics for JavaScript this first-time scan can take a while.
    request = PreloadBufLibsRequest(self)
    self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1129">@property
def libs(self):
    return self.langintel.libs_from_buf(self)

</t>
<t tx="ekr.20080121105837.1130">@property
def stdlib(self):
    return self.libs[-1]

</t>
<t tx="ekr.20080121105837.1131">def scoperef_from_blob_and_line(self, blob, line):
    """Return the scope for the given position in this buffer.

        "line" is 1-based.

    See CitadelBuffer.scoperef_from_pos() for details.
    JavaScript has two differences here:
    - &lt;variable&gt;'s are scopes if they have child tags. This CIX
      technique is used in JavaScript to define customized object
      instances.
    - Currently a JavaScript "class" line range may not include its
      methods in some cases.
        function Foo() {
        }
        Foo.prototype.bar = function() {
        }
      Class "Foo" has a line range that does not include method "bar".
      c.f. test javascript/cpln/intermixed_class_definitions
    """
    DEBUG = False
    if DEBUG:
        print "scoperef_from_pos: look for line %d in %r" % (line, blob)

    best_fit_lpath = None
    for scope, lpath in _walk_js_scopes(blob):
        start = int(scope.get("line"))
        # JS CIX &lt;scope&gt; should alway have lineend. The default is
        # because JS &lt;variable&gt;'s with content (i.e. anonymous
        # custom Object instances) do not typically have lineend.
        # Note: not sure the fallback is correct.
        end = int(scope.get("lineend", start))
        if DEBUG:
            print "scoperef_from_pos:    scope %r (%r-%r)?"\
                  % (scope, start, end),
        if line &lt; start:
            if DEBUG: print "no, before start"
            continue
        elif line &gt; end:
            if DEBUG: print "no, after end"
            continue
        elif line &lt;= end:
            if DEBUG: print "yes, could be"
            best_fit_lpath = lpath
        else:
            if DEBUG: print "no, passed end"
            if best_fit_lpath is not None:
                break
    if best_fit_lpath is not None:
        return (blob, best_fit_lpath)
    else:
        return (blob, [])


</t>
<t tx="ekr.20080121105837.1132">class JavaScriptImportHandler(ImportHandler):
    @others
</t>
<t tx="ekr.20080121105837.1133">def setCorePath(self, compiler=None, extra=None):
    self.corePath = []

</t>
<t tx="ekr.20080121105837.1134">def _findScannableFiles(self, (files, searchedDirs), dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = os.path.join(dirname, names[i])
        if os.path.isdir(path):
            pass
        elif os.path.splitext(names[i])[1] in (".js",):
            #XXX The list of extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs.
            #XXX This check for files should probably include
            #    scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            files.append(path)

</t>
<t tx="ekr.20080121105837.1135">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        if dirname == os.curdir:
            # Do NOT traverse the common '.' element of @INC. It is
            # environment-dependent so not useful for the typical call
            # of this method.
            continue
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs))
        for file in files:
            yield file

</t>
<t tx="ekr.20080121105837.1136">def find_importables_in_dir(self, dir):
    """See citadel.py::ImportHandler.find_importables_in_dir() for
    details.

    Importables for JavaScript look like this:
        {"foo.js":  ("foo.js", None, False),
         "somedir": (None,     None, True)}

    TODO: log the fs-stat'ing a la codeintel.db logging.
    """
    from os.path import join, isdir, splitext

    if dir == "&lt;Unsaved&gt;":
        #TODO: stop these getting in here.
        return {}

    #TODO: log the fs-stat'ing a la codeintel.db logging.
    try:
        names = os.listdir(dir)
    except OSError, ex:
        return {}
    dirs, nondirs = set(), set()
    for name in names:
        if isdir(join(dir, name)):
            dirs.add(name)
        else:
            nondirs.add(name)

    importables = {}
    for name in nondirs:
        base, ext = splitext(name)
        if ext != ".js":
            continue
        if base in dirs:
            importables[base] = (name, None, True)
            dirs.remove(base)
        else:
            importables[base] = (name, None, False)
    for name in dirs:
        importables[name] = (None, None, True)

    return importables


</t>
<t tx="ekr.20080121105837.1137">class JavaScriptCILEDriver(CILEDriver):
    lang = lang

    @others
</t>
<t tx="ekr.20080121105837.1138">def scan_purelang(self, buf):
    #print &gt;&gt; sys.stderr, buf.path
    log.info("scan_purelang: path: %r", buf.path)
    norm_path = buf.path
    if sys.platform == "win32":
        # CIX requires a normalized path.
        norm_path = norm_path.replace('\\', '/')
    mtime = "XXX"
    jscile = JavaScriptCiler(norm_path, mtime)
    # Profiling code: BEGIN
    #import hotshot, hotshot.stats
    #profiler = hotshot.Profile("%s.prof" % (__file__))
    #profiler.runcall(jscile.scan_puretext, buf.accessor.text)
    # Profiling code: END
    jscile.scan_puretext(buf.accessor.text)

    tree = createCixRoot()
    jscile.convertToElementTreeFile(tree, file_lang="JavaScript")

    return tree

</t>
<t tx="ekr.20080121105837.1139">def scan_multilang(self, buf, csl_cile_driver=None):
    """Given the buffer, scan the buffer tokens for CSL UDL tokens."""

    #print &gt;&gt; sys.stderr, buf.path
    log.info("scan_multilang: path: %r", buf.path)

    norm_path = buf.path
    if sys.platform == "win32":
        # CIX requires a normalized path.
        norm_path = norm_path.replace('\\', '/')
    #XXX Remove mtime when move to CIX 2.0.
    mtime = "XXX"
    jscile = JavaScriptCiler(norm_path, mtime)

    jscile.setStyleValues(wordStyle=SCE_UDL_CSL_WORD,
                          identiferStyle=SCE_UDL_CSL_IDENTIFIER,
                          operatorStyle=SCE_UDL_CSL_OPERATOR,
                          stringStyles=(SCE_UDL_CSL_STRING, ),
                          numberStyle=SCE_UDL_CSL_NUMBER,
                          commentStyles=jscile.UDL_COMMENT_STYLES)
    for token in buf.accessor.gen_tokens():
        # The tokens can be a generator of mixed UDL tokens (CSL, SSL, CSS
        # etc.). Need to parse out the tokens that are not CSL.
        if is_udl_csl_style(token['style']):
            jscile.token_next(**token)
    # Ensure we take notice of any text left in the ciler
    jscile._endOfScanReached()
    # We've parsed up the JavaScript, fix any variables types
    jscile.cile.updateAllScopeNames()

    tree = createCixRoot()
    jscile.convertToElementTreeFile(tree, file_lang=buf.lang)
    return tree

</t>
<t tx="ekr.20080121105837.1140">def scan_csl_tokens(self, file_elem, blob_name, csl_tokens):
    """csl_tokens are pure JavaScript UDL tokens.
    
    There is no need to parse out other types of tokens.
    """

    #print &gt;&gt; sys.stderr, file_elem.get("path")
    log.info("scan_csl_tokens: %r", file_elem.get("path"))
    blob_elem = createCixModule(file_elem, blob_name, lang,
                                src=file_elem.get("path"))
    jscile = JavaScriptCiler()
    jscile.setStyleValues(wordStyle=SCE_UDL_CSL_WORD,
                          identiferStyle=SCE_UDL_CSL_IDENTIFIER,
                          operatorStyle=SCE_UDL_CSL_OPERATOR,
                          stringStyles=(SCE_UDL_CSL_STRING, ),
                          numberStyle=SCE_UDL_CSL_NUMBER,
                          commentStyles=jscile.UDL_COMMENT_STYLES)
    for csl_token in csl_tokens:
        jscile.token_next(**csl_token)
    # Ensure we take notice of any text left in the ciler
    jscile._endOfScanReached()
    # We've parsed up the JavaScript, fix any variables types
    jscile.cile.updateAllScopeNames()
    jscile.convertToElementTreeModule(blob_elem)


</t>
<t tx="ekr.20080121105837.1141">def _sortByLineCmp(val1, val2):
    try:
    #if hasattr(val1, "line") and hasattr(val2, "line"):
        return cmp(val1.line, val2.line)
    except AttributeError:
        return cmp(val1, val2)

</t>
<t tx="ekr.20080121105837.1142">def sortByLine(seq):
    seq.sort(_sortByLineCmp)
    return seq


</t>
<t tx="ekr.20080121105837.1143">class JSArgs:
    @others
</t>
<t tx="ekr.20080121105837.1144">def __init__(self, arglist):
    self.args = arglist
    self.argline = ", ".join(arglist)

</t>
<t tx="ekr.20080121105837.1145">def __repr__(self):
    args = []
    for arg in self.args:
        args.append(repr(arg))
    return string.join(args, ', ')

</t>
<t tx="ekr.20080121105837.1146">def toElementTree(self, cixelement, jsdoc=None):
    for arg in self.args:
        typename = None
        doc = None
        # Use the jsdoc for assistance, type and doc information
        if jsdoc:
            for jsdocParam in jsdoc.params:
                if jsdocParam.paramname == arg:
                    # we have a match
                    typename = jsdocParam.paramtype
                    doc = jsdocParam.doc
        if not typename and ENABLE_HEURISTICS:
            if arg == 'event': # assume that variables named event are Events
                typename = "Event"
        addCixArgument(cixelement, arg, standardizeJSType(typename), doc)

</t>
<t tx="ekr.20080121105837.1147"># Everything is JS is an object.... MUMUHAHAHAHAHAHAAAA.......

class JSObject:
    @others
</t>
<t tx="ekr.20080121105837.1148">def __init__(self, name, parent, lineno, depth, type=None, args=None,
             doc=None, isLocal=False, isHidden=False):
    self.name = name
    self.parent = parent
    self.cixname = self.__class__.__name__[2:].lower()
    self.line = lineno
    self.lineend = -1
    self.depth = depth
    self.type = type
    self._class = None  # Used when part of a class
    self.classes = {} # declared sub-classes
    self.members = {} # all private member variables used in class
    self.variables = {} # all variables used in class
    self.functions = {}
    self.attributes = []    # Special attributes for object
    self.returnTypes = []    # List of possible return values
    self.constructor = None
    self.extends = None
    self.doc = doc
    self.isHidden = isHidden  # Special case, should not be output to cix
    if isLocal:
        # XXX: TODO: It may be appropriate to just use private..., although
        #            my feeling of the difference between the two names
        #            is that private elements should still be listed in
        #            completions from the class itself, whereas local
        #            should not...
        #
        # Local has a special meaning within the javascript tree evaluator,
        # elements with a "__local__" attribute will not be included in js
        # codeintel completion results.
        self.attributes.append("__local__")
        # Private has a special meaning within the code browser,
        # an element with a "private" attribute shows a small lock icon.
        # Private also has special meaning for jsdoc purposes, where it
        # means not to show documentation for these elements.
        self.attributes.append("private")

    if args:
        self.args = JSArgs(args)
        self.argline = self.args.argline
    else:
        self.args = None
        self.argline = ""
    self.doc = doc
    self.jsdoc = None
    if self.doc:
        # Turn the doc list into a JSDoc object
        self.jsdoc = JSDoc("".join(self.doc))

</t>
<t tx="ekr.20080121105837.1149">def addVariable(self, name, lineno, depth, typeNames=None, doc=None,
                isLocal=False):
    v = self.variables.get(name, None)
    if v is None:
        v = self.members.get(name, None)
    if v is None:
        log.info("VAR:%s, line:%d, type:%r, scope:%r, isLocal: %r",
                 name, lineno, typeNames, self.name, isLocal)
        v = JSVariable(name, self, lineno, depth, typeNames, doc=doc,
                       isLocal=isLocal)
        # Check to make sure it's not a function argument already
        if not isinstance(self, JSFunction) or not self.args or \
           name not in self.args.args:
            self.variables[name] = v
        else:
            log.debug("addVariable:: Did not add variable because a "
                      "function argument exists with the same name")
    # Else if there is no citdl type yet, assign it the given type
    elif typeNames and not v.type:
        v.type = ".".join(typeNames)
    return v

</t>
<t tx="ekr.20080121105837.1150">def addMemberVariable(self, name, lineno, depth, typeNames=None, doc=None,
                      isLocal=False):
    v = self.members.get(name, None)
    if v is None:
        v = self.variables.get(name, None)
    if v is None:
        log.info("CLASSMBR: %r, isLocal:%r in %s %r", name, isLocal,
                 self.cixname, self.name)
        v = JSVariable(name, self, lineno, depth, typeNames, doc=doc,
                       isLocal=isLocal)
        self.members[name] = v
    # Else if there is no citdl type yet, assign it the given type
    elif typeNames and not v.type:
        v.type = ".".join(typeNames)
    return v

</t>
<t tx="ekr.20080121105837.1151">def getReturnType(self):
    """Get the JS return type for this function, JSDoc gets precedence."""
    bestType = None
    if self.jsdoc and self.jsdoc.returns:
        bestType = self.jsdoc.returns.paramtype
    elif len(self.returnTypes) &gt; 0:
        d = {}
        bestCount = 0
        bestType = None
        for rtype in self.returnTypes:
            if isinstance(rtype, (str, unicode)):
                count = d.get(rtype, 0) + 1
                d[rtype] = count
                if count &gt; bestCount:
                    bestType = rtype
    if bestType:
        bestType = standardizeJSType(bestType)
    return bestType

</t>
<t tx="ekr.20080121105837.1152">def __repr__(self):
    # dump our contents to human readable form
    if self.parent:
        r = ["%s: %r, line:%d (%r)" % (self.cixname, self.name, self.line, self.parent.name) ]
    else:
        r = ["%s: %r, line:%d (None)" % (self.cixname, self.name, self.line) ]
    if self.extends:
        r.append("  Extends: %s" % self.extends)
    if self.type:
        r.append("  Type: %s" % self.type)
    for attrname in ("classes", "members", "functions", "variables"):
        d = getattr(self, attrname)
        if d and len(d) &gt; 0:
            r.append("  %s:" % (attrname.capitalize()))
            for v in d.values():
                if not v.isHidden:
                    r.append("    %r" % v)
    return '\n'.join(r)

</t>
<t tx="ekr.20080121105837.1153">def outline(self, depth=0):
    result = []
    if self.cixname == "function":
        result.append("%s%s %s(%s)" % (" " * depth, self.cixname, self.name, self.argline))
    elif self.cixname == "class" and self.extends:
        result.append("%s%s %s [%s]" % (" " * depth, self.cixname, self.name, self.extends))
    else:
        result.append("%s%s %s" % (" " * depth, self.cixname, self.name))
    for attrname in ("classes", "members", "functions", "variables"):
        d = getattr(self, attrname, {})
        for v in d.values():
            result += v.outline(depth + 2)
    return result

</t>
<t tx="ekr.20080121105837.1154">def toElementTree(self, cixelement):
    if not self.name:
        log.info("%s has no name, line: %d, ignoring it.",
                 self.cixname, self.line)
        return
    if self.cixname == "function":
        cixobject = createCixFunction(cixelement, self.name)
    elif self.cixname in ("object", "variable"):
        cixobject = createCixVariable(cixelement, self.name)
    elif self.cixname in ("class"):
        cixobject = createCixClass(cixelement, self.name)
    #else:
    #    print "self.cixname: %r" %(self.cixname)

    cixobject.attrib["line"] = str(self.line)
    if self.lineend &gt;= 0:
        cixobject.attrib["lineend"] = str(self.lineend)

    jsdoc = self.jsdoc
    if jsdoc:
        #print "jsdoc: %r" % (jsdoc)
        # the docstring
        #docElem.text = self.doc
        attributeDocs = []
        if jsdoc.isDeprecated():
            attributeDocs.append("DEPRECATED")
            self.attributes.append("deprecated")
        if jsdoc.isPrivate():
            attributeDocs.append("PRIVATE")
            if "private" not in self.attributes:
                self.attributes.append("private")
        if jsdoc.isStatic():
            attributeDocs.append("STATIC")
            if "__static__" not in self.attributes:
                self.attributes.append("__static__")
        if jsdoc.isConstant():
            attributeDocs.append("CONSTANT")
            if "constant" not in self.attributes:
                self.attributes.append("constant")
        if jsdoc.isConstructor():
            attributeDocs.append("CONSTRUCTOR")
            if "__ctor__" not in self.attributes:
                self.attributes.append("__ctor__")
        if jsdoc.tags:
            cixobject.attrib["tags"] = jsdoc.tags
        if jsdoc.doc:
            if attributeDocs:
                setCixDoc(cixobject, "%s: %s" % (" ".join(attributeDocs), jsdoc.doc))
            else:
                setCixDoc(cixobject, jsdoc.doc)

    # Additional one-off attributes
    if self.attributes:
        cixobject.attrib["attributes"] = " ".join(self.attributes)

    # Add the type information, JSDoc overrides whatever the ciler found
    if jsdoc and jsdoc.type:
        # Convert the value into a standard name
        addCixType(cixobject, standardizeJSType(jsdoc.type))
    elif self.type:
        addCixType(cixobject, standardizeJSType(self.type))

    if isinstance(self, JSFunction):
        signature = "%s(" % (self.name)
        # Add function arguments
        if self.args:
            signature += ' '.join(self.args.argline.split())
            # Add function arguments to tree
            self.args.toElementTree(cixobject, jsdoc)
        # Add signature - calltip
        signature += ")"
        cixobject.attrib["signature"] = signature
        # Add return type for functions, JSDoc gets precedence
        returnType = self.getReturnType()
        if returnType:
            addCixReturns(cixobject, returnType)

        # Add a "this" member for class functions
        if self._class:
            createCixVariable(cixobject, "this", vartype=self._class.name)
        elif self.parent and self.parent.cixname in ("object", "variable"):
            createCixVariable(cixobject, "this", vartype=self.parent.name)

    if self.extends:
        addClassRef(cixobject, self.extends)

    # Sort and include contents
    allValues = self.functions.values() + self.members.values() + \
                self.classes.values() + self.variables.values()
    for v in sortByLine(allValues):
        if not v.isHidden:
            v.toElementTree(cixobject)


</t>
<t tx="ekr.20080121105837.1155">class JSVariable(JSObject):
    @others
</t>
<t tx="ekr.20080121105837.1156">def __init__(self, name, parent, line, depth, vartype='', doc=None,
             isLocal=False):
    if isinstance(vartype, list):
        vartype = ".".join(vartype)
    JSObject.__init__(self, name, parent, line, depth, type=vartype,
                      doc=doc, isLocal=isLocal)

</t>
<t tx="ekr.20080121105837.1157">class JSFunction(JSObject):
    @others
</t>
<t tx="ekr.20080121105837.1158">def __init__(self, funcname, parent, args, lineno, depth=0, doc=None,
             isLocal=False, isHidden=False):
    # funcname: string
    # args: list (or None)
    JSObject.__init__(self, funcname, parent, lineno, depth, args=args,
                      doc=doc, isLocal=isLocal, isHidden=isHidden)
    if isinstance(parent, JSClass):
        self._class = parent
    self._parent_assigned_vars = []

</t>
<t tx="ekr.20080121105837.1159">##
# @rtype {string or JSObject} add this possible return type
def addReturnType(self, rtype):
    self.returnTypes.append(rtype)

</t>
<t tx="ekr.20080121105837.1160">class JSClass(JSObject):
    @others
</t>
<t tx="ekr.20080121105837.1161">def __init__(self, name, parent, lineno, depth, doc=None):
    JSObject.__init__(self, name, parent, lineno, depth, doc=doc)
    self.constructor = name

</t>
<t tx="ekr.20080121105837.1162">class JSFile:
    """CIX specifies that a &lt;file&gt; tag have zero or more &lt;module&gt; children.
    In JavaScript this is a one-to-one relationship, so this class represents both
    (and emits the XML tags for both).
    """
    @others
</t>
<t tx="ekr.20080121105837.1163">def __init__(self, path, mtime=None):
    self.path = path
    self.name = os.path.basename(path)
    self.parent = None
    self.cixname = self.__class__.__name__[2:].lower()
    #XXX Drop mtime when move to CIX 2.0.
    if mtime is None: mtime = "XXX"
    self.mtime = mtime

    self.functions = {} # functions declared in file
    self.classes = {} # classes declared in file
    self.variables = {} # all variables used in file
    self.includes = {} # files included into this file
    self.interfaces = {} # interfaces declared in file

</t>
<t tx="ekr.20080121105837.1164">def __repr__(self):
    # dump our contents to human readable form
    r = ["File: %r" % (self.name) ]
    for attrname in ("includes", "interfaces", "classes", "functions", "variables"):
        d = getattr(self, attrname)
        if d and len(d) &gt; 0:
            r.append("  %s:" % (attrname.capitalize()))
            for v in d.values():
                if not v.isHidden:
                    r.append("    %r" % v)
    return '\n'.join(r)

</t>
<t tx="ekr.20080121105837.1165">def outline(self):
    result = ["File: %r" % (self.name) ]
    for attrname in ("includes", "interfaces", "classes", "functions", "variables"):
        d = getattr(self, attrname, {})
        for v in d.values():
            result += v.outline(2)
    return result

</t>
<t tx="ekr.20080121105837.1166">def _findScopeWithName(self, name, scopeStack, type="variables"):
    if not name:
        return None
    log.debug("_findScopeWithName: %r with name:%r in scopeStack:%r", type, name, scopeStack[-1].name)
    # Work up the scope stack looking for the name
    #for scopePos in range(len(scope) - 1, -1, -1):
    #    currentScope = scope[scopePos]
    for scopePos in range(len(scopeStack) - 1, -1, -1):
        currentScope = scopeStack[scopePos]
        #print "Looking in scope %r" % (currentScope.name)
        #print "Looking in %s: %r" % (currentScope.__class__.__name__,
        #                             currentScope.name)
        namesDict = getattr(currentScope, type, None)
        if namesDict:
            foundScope = namesDict.get(name)
            if foundScope:
                log.debug("Found %r in scope:%r(%s)", name,
                          currentScope.name, currentScope.cixname)
                return foundScope
    log.debug("NO scope found for: %r", name)
    return None

</t>
<t tx="ekr.20080121105837.1167">def _lookupVariableType(self, varType, jsobject, scopeStack, depth=0):
    #print "Looking for varType:%r in scope:%r" % (varType, scopeStack[-1].name)
    if depth &lt; 10 and varType:
        # Don't look any further if it's a known type
        if varType.lower() in known_javascript_types:
            return jsobject
        sp = varType.split(".")
        #print "sp: %r" % (sp)
        namePos = 0
        while namePos &lt; len(sp):
            name = sp[namePos]
            #print "sp[%d]: %r" % (namePos, name)
            foundScope = self._findScopeWithName(name, scopeStack, type="variables")
            if not foundScope:
                #print "Trying member variables"
                # Then look for a class members with this name
                foundScope = self._findScopeWithName(name, scopeStack, type="members")
                #if foundScope:
                #    print "Found a member variable with this name"
            if not foundScope:
                # Then look for a class with this name
                #print "Trying class"
                foundScope = self._findScopeWithName(name, scopeStack, type="classes")
                if foundScope:
                    #print "Found a class with this name"
                    # Only search this scope now
                    scopeStack.append(foundScope)
            if not foundScope:
                break
            #print "Found scope"
            if isinstance(foundScope, JSVariable):
                #print "Recursively searching scope"
                foundScope = self._lookupVariableType(foundScope.type, foundScope, scopeStack, depth+1)
            #return self._lookupVariableType(foundType, scopeStack)
            namePos += 1
        #print "Returning: %s" % foundScope
        return foundScope
    return None
    #print "jsobject:%r" % (jsobject)
    #print "jsobject.type:%r" % (jsobject.type)

</t>
<t tx="ekr.20080121105837.1168">def _lookupVariableTypes(self, jstypelist, scopeStack):
    """Work out variable types according to their namespace"""

    for jstype in jstypelist:
        if hasattr(jstype, "classes"):
            # Recursive lookup for the class variables
            self._lookupVariableTypes(jstype.classes.values(), scopeStack + [jstype])
        if hasattr(jstype, "functions"):
            # Recursive lookup for the function variables
            self._lookupVariableTypes(jstype.functions.values(), scopeStack + [jstype])
        if hasattr(jstype, "variables"):
            for jsvariable in jstype.variables.values():
                varType = jsvariable.type
                if varType:
                    actualType = self._lookupVariableType(varType, jsvariable, scopeStack + [jstype])
                    if actualType:
                        if isinstance(actualType, JSVariable):
                            #print "ActualType is: %r" % (actualType.type)
                            jsvariable.type = actualType.type
                        else:
                            #print "ActualType is: %r" % (actualType.name)
                            jsvariable.type = actualType.name
        # Lookup function return type values
        if isinstance(jstype, JSFunction):
            for i in range(len(jstype.returnTypes)):
                returnType = jstype.returnTypes[i]
                #print "Looking up function return type: %r" % (returnType, )
                if isinstance(returnType, (str, unicode)):
                    actualType = self._lookupVariableType(returnType, jstype, scopeStack + [jstype])
                    if actualType and actualType != jstype:
                        #print "actualType: %r" % (actualType, )
                        # Use the variable name if it's type is "Object"
                        if isinstance(actualType, JSVariable) and \
                           actualType.type != "Object":
                            #print "ActualType is: %r" % (actualType.type)
                            jstype.returnTypes[i] = actualType.type
                        else:
                            #print "ActualType is: %r" % (actualType.name)
                            jstype.returnTypes[i] = actualType.name

</t>
<t tx="ekr.20080121105837.1169">def _updateClassConstructors(self, jsobject):
    if isinstance(jsobject, JSClass):
        if jsobject.constructor:
            jsfunc = self._findScopeWithName(jsobject.constructor, [jsobject], type='functions')
            if jsfunc and "__ctor__" not in jsfunc.attributes:
                log.debug("Making function:%r the constructor for class:%r",
                          jsfunc.name, jsobject.name)
                jsfunc.attributes.append("__ctor__")
    allObjects = jsobject.functions.values() + jsobject.classes.values() + \
                 jsobject.variables.values()
    if not isinstance(jsobject, JSFile):
        allObjects += jsobject.members.values()
    for subobj in allObjects:
        self._updateClassConstructors(subobj)

</t>
<t tx="ekr.20080121105837.1170">def updateAllScopeNames(self):
    """We've gathered as much information as possible, update all scope
    names as best as possible."""

    log.info("****************************************")
    log.info("Finished scanning, updating all scope names")
    self._lookupVariableTypes([self], [])
    log.info("Updating all class constructor names")
    self._updateClassConstructors(self)

</t>
<t tx="ekr.20080121105837.1171">def addVariable(self, name, lineno, depth, typeNames=None, doc=None,
                isLocal=False):
    v = self.variables.get(name, None)
    if v is None:
        log.info("VAR: %s on line %d, type:%r", name, lineno, typeNames)
        v = JSVariable(name, self, lineno, depth, typeNames, doc=doc,
                       isLocal=isLocal)
        self.variables[name] = v
    # Else if there is no citdl type yet, assign it the given type
    elif typeNames and not v.type:
        v.type = ".".join(typeNames)
    return v

</t>
<t tx="ekr.20080121105837.1172">def convertToElementTreeModule(self, cixmodule):
    # Includes
    for incFile, line in self.includes.items():
        # XXX - CI2
        cixinclude = SubElement(cixmodule, "import",
                                filename=incFile,
                                line=str(line))

    # Sort and include contents
    allValues = self.functions.values() + self.variables.values() + \
                self.interfaces.values() + self.classes.values()
    for v in sortByLine(allValues):
        if not v.isHidden:
            v.toElementTree(cixmodule)

</t>
<t tx="ekr.20080121105837.1173">def convertToElementTreeFile(self, cixelement, file_lang):
    cixfile = createCixFile(cixelement, self.path, lang=file_lang,
                            mtime=str(self.mtime))
    cixmodule = createCixModule(cixfile, self.name, lang="JavaScript",
                                src=self.path)
    self.convertToElementTreeModule(cixmodule)


</t>
<t tx="ekr.20080121105837.1174">class JavaScriptCiler:
    JS_COMMENT_STYLES = (SCE_C_COMMENT,
                        SCE_C_COMMENTDOC,
                        SCE_C_COMMENTLINE,
                        SCE_C_COMMENTLINEDOC,
                        SCE_C_COMMENTDOCKEYWORD,
                        SCE_C_COMMENTDOCKEYWORDERROR)
    UDL_COMMENT_STYLES = (SCE_UDL_CSL_COMMENT,
                          SCE_UDL_CSL_COMMENTBLOCK)

    @others
</t>
<t tx="ekr.20080121105837.1175">def __init__(self, path="", mtime=None):
    # hook up the lexical matches to a function that handles the token

    # Working variables, used in conjunction with state
    self.lineno = 0
    self.last_lineno = 0
    self.depth = 0
    self.styles = []
    self.text = []
    self.in_variable_definition = False  # for multi variable assignment
    self.comment = []
    self.last_comment_and_jsdoc = [None, None]
    self.argumentPosition = 0
    self.argumentTextPosition = 0  # keep track of arg position in self.text
    self.objectArguments = []

    # state : used to store the current JS lexing state
    # state_stack : used to store JS state to return to
    self.state = S_DEFAULT
    self.state_stack = []

    # JScile will store all references for what we scan in
    self.cile = JSFile(path, mtime)
    # Cile information, used to store code structure
    self.currentScope = self.cile
    self._scopeStack = [self.currentScope]
    self.objectStack = [self.currentScope]
    self.currentClass = None
    # Used for determining Javascript closures
    self.bracket_depth = 0
    self.lastText = []
    self.lastScope = None

    # Document styles used for deciding what to do
    # Note: Can be customized by calling setStyleValues()
    self.JS_WORD        = SCE_C_WORD
    self.JS_IDENTIFIER  = SCE_C_IDENTIFIER
    self.JS_OPERATOR    = SCE_C_OPERATOR
    self.JS_STRINGS     = (SCE_C_STRING, SCE_C_CHARACTER, )
    self.JS_NUMBER      = SCE_C_NUMBER
    # js_cile styles are styles that the ciler uses
    self.JS_CILE_STYLES = self.JS_STRINGS + \
                          (self.JS_WORD, self.JS_IDENTIFIER,
                           self.JS_OPERATOR, self.JS_NUMBER)
                          

</t>
<t tx="ekr.20080121105837.1176"># Allows to change styles used by scanner
# Needed for UDL languages etc... where the style bits are different
def setStyleValues(self, wordStyle      = SCE_C_WORD,
                         identiferStyle = SCE_C_IDENTIFIER,
                         operatorStyle  = SCE_C_OPERATOR,
                         stringStyles   = (SCE_C_STRING, SCE_C_CHARACTER, ),
                         numberStyle    = SCE_C_NUMBER,
                         commentStyles  = None):
    self.JS_WORD        = wordStyle
    self.JS_IDENTIFIER  = identiferStyle
    self.JS_OPERATOR    = operatorStyle
    self.JS_STRINGS     = stringStyles
    self.JS_NUMBER      = numberStyle
    self.JS_CILE_STYLES = self.JS_STRINGS + \
                          (self.JS_WORD, self.JS_IDENTIFIER,
                           self.JS_OPERATOR, self.JS_NUMBER)
    if commentStyles:
        self.JS_COMMENT_STYLES = commentStyles

</t>
<t tx="ekr.20080121105837.1177">def _logVariables(self):
    if log.level &gt;= logging.DEBUG:
        log.debug("    lineno:%r, state:%r, depth:%r", self.lineno,
                  self.state, self.depth)
        log.debug("    d: %r", d)
        log.debug("    currentScope: %r", self.currentScope)
        log.debug("")

</t>
<t tx="ekr.20080121105837.1178">def incBlock(self):
    self.depth = self.depth+1
    log.info("incBlock: depth:%d, line:%d, currentScope:%r", self.depth, self.lineno, self.currentScope.name)
    if not self.currentScope:
        log.info("incBlock:: No currentScope available. Defaulting to global file scope.")
        # Use the global file scope then
        self.currentScope = self.cile
    if len(self.objectStack) == 0 or self.currentScope != self.objectStack[-1]:
        # Not the same scope...
        self.objectStack.append(self.currentScope)
    self._scopeStack.append(self.currentScope)

</t>
<t tx="ekr.20080121105837.1179">def decBlock(self):
    log.info("decBlock: depth:%d, line:%d, leavingScope:%r", self.depth, self.lineno, self.currentScope.name)
    if self.depth &gt; 0:
        self.depth = self.depth-1
        self.lastScope = self.currentScope
        # Update lineend for scope
        if hasattr(self.currentScope, "lineend"):
            self.currentScope.lineend = self.lineno
            if isinstance(self.currentScope, JSClass) and \
               len(self.currentScope.functions) == 1:
                jsfunc = self.currentScope.functions.values()[0]
                if jsfunc.depth == self.depth and jsfunc.lineend == -1:
                    jsfunc.lineend = self.lineno
                    log.debug("Setting lineend: %d for scope %r",
                             self.lineno, jsfunc)
            log.debug("Setting lineend: %d for scope %r",
                     self.lineno, self.currentScope.name)
        else:
            log.debug("Current scope does not have a lineend: %r",
                     self.currentScope.name)
        self._scopeStack.pop()
        #assert(len(self._scopeStack) &gt; 0)
        if self._scopeStack[-1] != self.objectStack[-1]:
            self.objectStack.pop()
            #assert(len(self.objectStack) &gt; 0)
        self.currentScope = self._scopeStack[-1]
        log.debug("decBlock: currentScope:%r", self.currentScope.name)
        if not self.currentScope:
            log.info("decBlock:: No currentScope available. Defaulting to global file scope.")
            # Use the global file scope then
            self.currentScope = self.cile
            return
        # Update currentClass variable
        oldCurrentClass = self.currentClass
        if isinstance(self.currentScope, JSClass):
            self.currentClass = self.currentScope
            log.debug("Currentclass now: %r", self.currentClass.name)
        elif isinstance(self.currentScope, JSFunction):
            self.currentClass = self.currentScope._class
            if self.currentClass:
                log.debug("Currentclass now: %r", self.currentClass.name)
            else:
                log.debug("Currentclass now: %r", self.currentClass)
        else:
            self.currentClass = None
            log.debug("Currentclass now: %r", self.currentClass)
        # Update line number for the current class if it doesn't have one already
        if oldCurrentClass and oldCurrentClass.lineend == -1 and \
           oldCurrentClass != self.currentClass:
            oldCurrentClass.lineend = self.lineno
    else: # Likely there is a syntax error in the document
        log.debug("decBlock:: Scope already at 0. Document has syntax errors.")

</t>
<t tx="ekr.20080121105837.1180">def _findInScope(self, name, attrlist=("variabes", ), scope=None):
    if scope is None:
        scope = self.objectStack
    for attr in attrlist:
        namesDict = getattr(scope, attr, None)
        if namesDict:
            subscope = namesDict.get(name)
            if subscope:
                log.debug("_findInScope: Found a scope for: %r in %s.%s:",
                          name, scope.name, attr)
                return subscope
    # Not found
    return None

</t>
<t tx="ekr.20080121105837.1181">def _locateScopeForName(self, namelist, attrlist=("variables", ), scope=None):
    if not namelist:
        return None
    if scope is None:
        scope = self.currentScope
    log.debug("Finding in scope: %s.%r with names: %r", scope.name, attrlist, namelist)
    # Work up the scope stack looking for the classname
    while scope:
        currentScope = scope
        #print "Looking in scope %r" % (currentScope.name)
        namePos = 0
        foundScope = None
        for namePos in range(len(namelist)):
            name = namelist[namePos]
            #attrToLookIn = "variables"
            #if namePos == len(namelist) - 1:
            for attrToLookIn in attrlist:
                #print "Looking for name:%r in scope with name:%r" % (name, currentScope.name)
                namesDict = getattr(currentScope, attrToLookIn, None)
                if namesDict:
                    foundScope = namesDict.get(name)
                    if foundScope:
                        log.debug("_locateScopeForName: Found a scope for: %r", name)
                        # Look in this sub-scope if we have more names to check
                        if type != "variables" or namePos &lt; len(namelist) - 1:
                            currentScope = foundScope
                        # else we've located the scope we want
                        break
            else:
                # Not found
                break
        else:
            log.debug("Found %r in scope:%s.%s", namelist, currentScope.name, attrToLookIn)
            return currentScope
        # Try parent scope
        scope = scope.parent
    log.debug("NO scope found for: %r", namelist)
    return None

</t>
<t tx="ekr.20080121105837.1182">def _lookupVariableTypeFromScope(self, typeNames):
    """See if we can determine what type this is"""
    scope = self._locateScopeForName(typeNames[:-1])
    if scope:
        scope = scope.variables[typeNames[-2]]
        while isinstance(scope, JSVariable) and scope.type not in ("int", "string", "object"):
            scopeType = scope.type
            #print "scope:%r, scope.type:%r" % (scope.name, scopeType)
            scope = self._locateScopeForName(scopeType, attrlist=("variables", "classes"))
        if hasattr(scope, "type"):
            return scope.type
    return []

</t>
<t tx="ekr.20080121105837.1183">##
# Create a JSFunction and add it to the current scope
# @param namelist {list} list of names for the function
# @param args {list} list of arguments for the function
# @param doc {list} list of comment strings for given scope
#
def addFunction(self, namelist, args=None, doc=None, isLocal=False,
                isHidden=False):
    log.debug("AddFunction: %s(%s)", namelist, args)
    funcName = namelist[-1]
    toScope = self.currentScope
    if len(namelist) &gt; 1:
        isLocal = False
        scopeNames = namelist[:-1]
        if "prototype" in namelist:
            pIndex = namelist.index("prototype")
            scopeNames = namelist[:pIndex]
            jsclass = self._addClassPart(funcName, self.ADD_CLASS_FUNCTION, scopeNames, args=args, doc=doc)
            # Ensure we onte the currentClass which we'll be working with
            self.currentClass = jsclass
            return
        else:
            toScope = self._findOrCreateScope(namelist[:-1], ('variables', 'classes', 'functions'))
    elif isinstance(toScope, JSFile):
        isLocal = False
    log.info("FUNC: %s(%s) isLocal:%r adding to %s %r", funcName, args,
             isLocal, toScope.cixname, toScope.name)
    #log.debug("jsdoc: %r", JSDoc("".join(doc)))
    fn = JSFunction(funcName, toScope, args, self.lineno, self.depth,
                    doc=doc, isLocal=isLocal, isHidden=isHidden)
    toScope.functions[fn.name] = fn
    self.currentScope = fn
    # Special jsdoc parameter telling us explicitly that it's a class
    jsdoc_says_class = False
    if fn.jsdoc and fn.jsdoc.isClass():
        jsdoc_says_class = True
    # Also check the last comment, sometimes it's meant for this scope
    if not jsdoc_says_class and self.last_comment_and_jsdoc[0]:
        last_jsdoc = self.last_comment_and_jsdoc[1]
        if last_jsdoc is None:
            last_jsdoc = JSDoc("".join(self.last_comment_and_jsdoc[0]))
            self.last_comment_and_jsdoc[1] = last_jsdoc
            if last_jsdoc.isClass() and \
               fn.name == last_jsdoc.classname:
                # Name is same, check the namespace as well if it exists
                nspc = reversed(last_jsdoc.namespace.split("."))
                scope = fn.parent
                for name in nspc:
                    if scope is None or name != scope.name:
                        break
                    scope = scope.parent
                else:
                    jsdoc_says_class = True
                    fn.jsdoc = last_jsdoc
                    log.debug("last_jsdoc classname: %r, namespace: %r",
                              last_jsdoc.classname, last_jsdoc.namespace)
    if fn.name and jsdoc_says_class:
        # Ick, this is really a class constructor
        jsclass = self._convertFunctionToClass(fn)
        jsclass.doc = None
        jsclass.jsdoc = None

</t>
<t tx="ekr.20080121105837.1184">##
# Create a JSFunction and add it to the current scope
# @param namelist {list} list of names for the function
# @param args {list} list of arguments for the function
# @param doc {list} list of comment strings for given scope
#
def addClassFunction(self, namelist, args=None, doc=None):
    log.debug("AddClassFunction: %s(%s)", namelist, args)
    toScope = self.currentClass
    if not toScope:
        # See if it's a function, we'll convert it into a class then
        if isinstance(self.currentScope, JSFunction):
            topScope = self._convertFunctionToClass(self.currentScope)
    if not toScope or len(namelist) &gt; 1:
        self.addFunction(namelist, args, doc)
    else:
        funcName = namelist[-1]
        log.info("FUNC: %s(%s) on line %d", funcName, args, self.lineno)
        fn = JSFunction(funcName, toScope, args, self.lineno, self.depth, doc=doc)
        toScope.functions[fn.name] = fn
        self.currentScope = fn

</t>
<t tx="ekr.20080121105837.1185">ADD_CLASS = 0
ADD_CLASS_MEMBER = 1
ADD_CLASS_VARIABLE = 2
ADD_CLASS_FUNCTION = 3
ADD_CLASS_PARENT = 4
ADD_CLASS_CONSTRUCTOR = 5
def _addClassPart(self, partName, addType, scopeNames=None, args=None, doc=None):
    log.debug("_addClassPart: partName:%r, addType:%r, scopeNames:%r, args:%r",
              partName, addType, scopeNames, args)
    jsclass = None
    fn = None
    # Find the class to place this part into
    #jsclass = self._findClassWithNames(scopeNames)
    if scopeNames:
        # Look for the class first, then if we don't find it look for
        # a function or variable: bug 70324
        jsclass = self._locateScopeForName(scopeNames, attrlist=("classes", ))
        if jsclass is None:
            jsclass = self._locateScopeForName(scopeNames, attrlist=("classes", "functions", "variables", ))
            if isinstance(jsclass, JSFunction):
                # Convert it to a class
                jsclass = self._convertFunctionToClass(jsclass)
    else:
        jsclass = self.currentClass
    if not jsclass and scopeNames:
        className = ".".join(scopeNames)
        jsclass = JSClass(className, self.currentScope, self.lineno, self.depth, doc=doc)
        self.currentScope.classes[jsclass.name] = jsclass
        log.info("CLASS: %r on line %d in %r at depth %d", jsclass.name,
                 jsclass.line, self.currentScope.name, self.depth)
        self.currentScope = jsclass

    if addType == self.ADD_CLASS_FUNCTION:
        log.info("CLASS_FUNC: %s(%s) on line %d", partName, args, self.lineno)
        fn = JSFunction(partName, jsclass, args, self.lineno, self.depth, doc=doc)
        fn._class = jsclass
        jsclass.functions[fn.name] = fn
        #print "num functions: %d" % (len(jsclass.functions))
        self.currentScope = fn
    elif addType == self.ADD_CLASS_MEMBER:
        if partName not in jsclass.variables:
            log.info("CLASS_MBR added: %r", partName)
            v = JSVariable(partName, jsclass, self.lineno, self.depth, doc=doc)
            jsclass.variables[partName] = v
        else:
            log.info("CLASS_MBR already exists: %r", partName)
    elif addType == self.ADD_CLASS_VARIABLE:
        if partName not in jsclass.variables:
            log.info("CLASS_VBR added: %r", partName)
            v = JSVariable(partName, jsclass, self.lineno, self.depth, doc=doc)
            jsclass.variables[partName] = v
        else:
            log.info("CLASS_MBR already exists: %r", partName)
    elif addType == self.ADD_CLASS_PARENT:
        log.info("CLASS_PARENT: %r", partName)
        jsclass.extends = partName
    elif addType == self.ADD_CLASS_CONSTRUCTOR:
        log.info("CLASS_CTOR: %r", partName)
        jsclass.constructor = partName

    if jsclass:
        self.currentClass = jsclass
        if addType == self.ADD_CLASS:
            self.currentScope = jsclass
        elif addType == self.ADD_CLASS_PARENT and partName == "Object":
            self.currentScope = jsclass
    return jsclass

</t>
<t tx="ekr.20080121105837.1186"># a class part using prototype.name = function
#def addClassPart(self):
#    self._addClassPart()

# a class using classname.prototype = { ... }
def addClass(self, namelist, doc=None):
    jsclass = self._addClassPart(namelist[-1], self.ADD_CLASS, scopeNames=namelist, doc=doc)
    return jsclass

</t>
<t tx="ekr.20080121105837.1187">def addAnonymousClass(self, namelist, doc=None):
    # Example syntax: c.prototype = { rows: { return this._rows.length; } }
    self.addClass(namelist[:-1], doc=doc)

</t>
<t tx="ekr.20080121105837.1188">def addClassOrVariableMember(self, namelist, typeNames, scope=None, doc=None,
                             assignAsCurrentScope=False,
                             isLocal=False):
    """Add the variable to the given scope or current scope

    If the scope is a
      * variable or object: add as a variable to this scope.
      * class: add as a member to this class.
      * function: then this is a little more tricky:
        * If it's class function, then add as a member for the class.
        * If it's a function inside a variable/object, then add as a
          variable to the variable/object.
        * If it's just a function on it's own, turn the function into a
          class and then add a member variable for the class.
    """
    if not scope:
        scope = self.currentScope

    log.debug("addClassOrVariableMember: namelist:%r, type:%r, isLocal:%r, scope (%s):%s", namelist, typeNames, isLocal, scope.cixname, scope.name)
    memberName = namelist[-1]

    if len(namelist) &gt; 2 and "prototype" in namelist:
        pIndex = namelist.index("prototype")
        scopeNames = namelist[:pIndex]
        log.debug("Adding class prototype. class name: %r, variable: %r",
                  scopeNames, memberName)
        scope = self._addClassPart(memberName, self.ADD_CLASS_MEMBER,
                                   scopeNames, args=None, doc=doc)

    elif scope.cixname in ("object", "variable"):
        if isLocal:
            log.warn("addClassOrVariableMember: %s:%d Trying to add %r as "
                     "a local member variable??",
                     self.cile.name, self.lineno, namelist)
            return
        v = scope.addVariable(memberName, self.lineno,
                              self.depth, typeNames,
                              doc=doc, isLocal=isLocal)
        if assignAsCurrentScope:
            self.currentScope = v

    # Special case - classes and anonymous functions
    elif isinstance(scope, JSClass) or scope.name == "":
        v = scope.addMemberVariable(memberName, self.lineno, self.depth,
                                    typeNames, doc=doc, isLocal=isLocal)
        if assignAsCurrentScope:
            self.currentScope = v

    elif isinstance(scope, JSFunction):
        # If it's a function already within a class, then thats okay
        parentScope = scope.parent
        if not parentScope:
            log.debug("addClassOrVariableMember: ignoring assignment %r "
                      "into a dummy function", namelist)
            return
        log.debug("ParentScope is: %s (%s)", parentScope.name, parentScope.cixname)
        if isinstance(parentScope, JSClass):
            self.currentClass = parentScope
            log.debug("Assigning to parent class: %r:%r",
                      parentScope.cixname, parentScope.name)
            v = parentScope.addMemberVariable(memberName, self.lineno,
                                              self.depth, typeNames,
                                              doc=doc, isLocal=isLocal)
            if assignAsCurrentScope:
                self.currentScope = v
        # If it's a function within a variable, then thats okay too
        elif parentScope and parentScope.cixname in ("object", "variable"):
            log.debug("Assigning to parent scope: %r:%r",
                      parentScope.cixname, parentScope.name)
            v = parentScope.addVariable(memberName, self.lineno,
                                        self.depth, typeNames,
                                        doc=doc, isLocal=isLocal)
            # We need to keep track of what we assign in this particular
            # case, as we may later turn this function into it's own class,
            # and then we'll need to grab these "this." variables back!
            # Example code:
            #   var ko = {}
            #   ko.f1 = function() { this.x = 1; }   // x assigned to ko
            #   ko.f1.prototype.run = function() {}  // convert f1 to class
            #   // Now we want ko.x to move into class ko.f1
            scope._parent_assigned_vars.append(v)

            if assignAsCurrentScope:
                self.currentScope = v
        # Convert the function to class then
        else:
            # If the class name exists already, assign to that class
            func = scope
            funcName = func.name
            jsclass = self._locateScopeForName([funcName], attrlist=("classes", ), scope=scope)
            if not jsclass:
                log.debug("Creating class %r, function %r now ctor", funcName, funcName)
                # Turn function into a constructor for the class
                jsclass = self._convertFunctionToClass(func)
            else:
                # Update the function class information
                self._convertFunctionToClassContructor(func, jsclass)
            v = jsclass.addMemberVariable(memberName, self.lineno,
                                          self.depth, typeNames, doc=doc,
                                          isLocal=isLocal)
            if assignAsCurrentScope:
                self.currentScope = v
    elif isinstance(scope, JSFile):
        self.addVariable(namelist, typeNames, scope, doc,
                         assignAsCurrentScope, isLocal)
    else:
        log.info("addClassOrVariableMember:: Invalid scope type. Could not add %r to scope: %r - %r",
                 namelist, scope.cixname, scope.name)

</t>
<t tx="ekr.20080121105837.1189">def addClassParent(self, namelist, typeNames):
    log.debug("addClassParent: namelist:%r, typeNames:%r", namelist, typeNames)
    self._addClassPart(".".join(typeNames), self.ADD_CLASS_PARENT, namelist[:-1])

</t>
<t tx="ekr.20080121105837.1190">def addGetter(self, namelist, typeNames, scopeNames=None, doc=None):
    log.debug("addGetter: namelist:%r, type: %r, scopeNames: %r", namelist,
              typeNames, scopeNames)
    if scopeNames:
        toScope = self._locateScopeForName(scopeNames, attrlist=("variables", "classes"))
        if not toScope:
            log.info("addGetter:: Not adding getter. Could not find scope for: %r",
                     scopeNames)
            return
        self.currentScope = toScope
    else:
        toScope = self.currentScope
    self.addClassOrVariableMember(namelist, typeNames, toScope, doc=doc)

</t>
<t tx="ekr.20080121105837.1191">def addSetter(self, namelist, scopeNames=None, doc=None):
    log.debug("addSetter: namelist:%r, scopeNames: %r", namelist, scopeNames)
    if scopeNames:
        toScope = self._locateScopeForName(scopeNames, attrlist=("variables", "classes"))
        if not toScope:
            log.info("addSetter:: Not adding setter. Could not find scope for: %r",
                     scopeNames)
            return
        self.currentScope = toScope
    else:
        toScope = self.currentScope
    self.addClassOrVariableMember(namelist, [], toScope, doc=doc)

</t>
<t tx="ekr.20080121105837.1192">def _convertFunctionToClassContructor(self, jsfunc, jsclass):
    # Mark it as a constructor if it's not already so marked
    funcName = jsfunc.name
    # Copy attributes across, except for "__ctor__"
    class_attributes = jsfunc.attributes[:]
    if "__ctor__" not in jsfunc.attributes:
        jsfunc.attributes.append("__ctor__")
    else:
        class_attributes.remove("__ctor__")
    jsclass.attributes = class_attributes
    # Might already be the contructor for the class
    if funcName not in jsclass.functions:
        parentScope = jsfunc.parent
        log.debug("Converting function: %r into a class contructor for: %r",
                  funcName, jsclass.name)
        jsclass.functions[funcName] = jsfunc
        # Update references
        parentScope.functions.pop(funcName)
        parentScope.classes[funcName] = jsclass
        # Fix starting line number
        if jsfunc.line &lt; jsclass.line:
            jsclass.line = jsfunc.line
        # Copy over non-local variables from the function to the class,
        # all the local variables stay inside the function scope.
        for varName, v in jsfunc.variables.items():
            isLocal = "__local__" in v.attributes
            if not isLocal:
                # Add to class and remove from the function
                jsclass.variables[varName] = JSVariable(varName, jsclass, v.line,
                                                        v.depth, v.type, v.doc,
                                                        isLocal=isLocal)
                del jsfunc.variables[varName]
    parent = jsfunc.parent
    for var in jsfunc._parent_assigned_vars:
        log.debug("Converting function: Moved parent assigned variable %r "
                  "into the class instance", var.name)
        jsclass.members[var.name] = var
        parent.variables.pop(var.name, None)
    jsfunc._parent_assigned_vars = []
    jsfunc._class = jsclass
    jsfunc.parent = jsclass

</t>
<t tx="ekr.20080121105837.1193">def _convertFunctionToClass(self, jsfunc):
    funcName = jsfunc.name
    log.debug("Creating class %r, from function %r", funcName, funcName)
    jsclass = JSClass(funcName, jsfunc.parent, jsfunc.line, self.depth - 1, jsfunc.doc)
    self._convertFunctionToClassContructor(jsfunc, jsclass)
    if self.currentScope == jsfunc:
        self.currentClass = jsclass
    return jsclass

</t>
<t tx="ekr.20080121105837.1194">def _convertFunctionToClosureVariable(self, jsfunc):
    funcName = jsfunc.name
    log.debug("Creating variable %r, from function closure %r", funcName, funcName)
    jsvariable = JSVariable(funcName, jsfunc.parent, jsfunc.line,
                            jsfunc.depth, jsfunc.type, jsfunc.doc)
    if jsfunc.returnTypes:
        jsro = jsfunc.returnTypes[0]
        #print jsro
        if isinstance(jsro, JSVariable):
            # Convert this object into the variable
            jsro.parent = jsfunc.parent
            jsro.line = jsfunc.line
            jsro.name = funcName
            jsvariable = jsro
    parent = jsfunc.parent
    parent.functions.pop(funcName)
    parent.variables[funcName] = jsvariable
    return jsvariable

</t>
<t tx="ekr.20080121105837.1195">def _findOrCreateScope(self, namelist, attrlist=("variables", ),
                       fromScope=None, isLocal=False):
    # Ensure the scope exists, else create it
    # Find the base scope first
    if fromScope is None:
        fromScope = self.currentScope
    log.debug("_findOrCreateScope: %r, attrlist: %r, from scope: %s",
              namelist, attrlist, fromScope.name)
    name = namelist[0]

    # Determine where variables get added when they are not found
    if isLocal:
        applyToScope = fromScope
    else:
        applyToScope = self.cile   # Global file level

    for name in namelist:
        scope = self._locateScopeForName([name], attrlist, fromScope)
        if not scope:
            scope = JSVariable(name, applyToScope, self.lineno, self.depth,
                               "Object")
            fromScope.variables[name] = scope
            applyToScope = scope
            log.info("Could not find %r in scope: %r, creating variable (type=Object) for it!!!",
                     name, fromScope.name)
        fromScope = scope
    return fromScope

</t>
<t tx="ekr.20080121105837.1196">def addVariable(self, namelist, typeNames, toScope=None, doc=None,
                assignAsCurrentScope=False, isLocal=False):
    log.debug("addVariable: %r, typeNames:%r, isLocal: %r",
              namelist, typeNames, isLocal)
    varName = namelist[-1]
    if toScope is None:
        toScope = self.currentScope

    if isinstance(self.currentScope, JSFunction) and \
       self.currentScope.args and \
       namelist[0] in self.currentScope.args.args:
        log.debug("Not adding variable, function has argument with same name: %r, line: %d", namelist, self.lineno)
        return

    if len(namelist) &gt; 1:
        if namelist[-2] == "prototype":
            # Adding to an existing class then
            toScope = self._locateScopeForName(namelist[:-2], attrlist=("classes", ))
            if not toScope:
                # Create a class for it then
                log.debug("Creating class now: %r", namelist[:-2])
                self.addClass(namelist[:-2], doc=doc)
                #raise CodeIntelError("Could not find scope for: %r" % (namelist[:-2], ))
            if varName == "constructor":
                ctorName = ".".join(typeNames)
                func = self._locateScopeForName([ctorName], attrlist=("functions", ))
                if func:
                    self._convertFunctionToClassContructor(func, self.currentClass)
                else:
                    self._addClassPart(ctorName, self.ADD_CLASS_CONSTRUCTOR,
                                       namelist[:-2], doc=doc)
            return
        else:
            # Find or create the parent scope
            # Don't create it if it's an argument in a function...??
            toScope = self._findOrCreateScope(namelist[:-1],
                                              ('variables', 'classes',
                                               'functions'),
                                              fromScope=toScope,
                                              isLocal=isLocal)
    elif not isLocal:
        # Try and find the scope we are assigning to, should be in
        # a parent scope somewhere!
        #print("addVariable: namelist:%r, typeNames:%r, isLocal: %r, line: %d" % (namelist, typeNames, isLocal, self.lineno))
        fromscope = toScope
        toScope = self._locateScopeForName(namelist,
                                           ('variables', 'classes',
                                            'functions'),
                                           toScope)
        if toScope is None:
            #if self.text[0] not in ("var", "const"):
            #    sys.stderr.write("Undeclared var in %s:%d, %r in %s %r\n" % (
            #            self.cile.name,
            #            self.lineno, varName, fromscope.cixname, fromscope.name))
            # Place it at the global level then
            toScope = self.cile
        else:
            toScope = toScope.parent

    # Add it to scope if it's not already in there
    if toScope:
        if isinstance(toScope, JSVariable):
            if toScope.type.lower() not in ("object", ):
                # Not going to add sub-variables, as it's likely a class
                # object already, which has this variable information set
                #if not toScope.type:
                #    msg = "Assignment to a unknown type, %s:%d, %r (%s)" % (self.filename, self.lineno, ".".join(namelist), toScope.type)
                #    print &gt;&gt; sys.stderr, msg
                return
        #if not isLocal and varName not in toScope.variables:
        #    print("addVariable: namelist:%r, typeNames:%r, isLocal: %r, line: %d" % (namelist, typeNames, isLocal, self.lineno))
        v = toScope.addVariable(varName, self.lineno, self.depth, typeNames,
                                doc=doc, isLocal=isLocal)
        if assignAsCurrentScope:
            self.currentScope = v

</t>
<t tx="ekr.20080121105837.1197">def addObjectVariable(self, namelist, toScope=None, doc=None,
                      isLocal=False):
    if not toScope:
        toScope = self.currentScope
    log.debug("addObjectVariable: namelist:%r, scope:%r", namelist,
              toScope.name)
    varName = namelist[-1]

    if len(namelist) &gt; 1:
        # Ensure the scope exists, else create it
        toScope = self._findOrCreateScope(namelist[:-1], ("variables", "classes", "functions"), toScope)
        # Assignment to a function, outside the function scope... create a class for it
        if isinstance(toScope, JSFunction):
            toScope = self._convertFunctionToClass(toScope)
    # Add it to scope if it's not already in there
    v =  toScope.variables.get(varName)
    if not v:
        v = toScope.addVariable(varName, self.lineno, self.depth, "Object",
                                doc=doc, isLocal=isLocal)
    self.currentScope = v

</t>
<t tx="ekr.20080121105837.1198">def addReturnObject(self, doc=None):
    log.debug("addReturnObject: scope:%r", self.currentScope.name)
    jsro = JSVariable("", self.currentScope, self.lineno, self.depth, vartype="Object", doc=doc)
    self.currentScope.addReturnType(jsro)
    self.currentScope = jsro
    return jsro

</t>
<t tx="ekr.20080121105837.1199">def addFunctionReturnType(self, typeNames, doc=None):
    if isinstance(self.currentScope, JSFunction):
        log.debug("addFunctionReturnType: type: %r, scope:%r", typeNames, self.currentScope.name)
        self.currentScope.addReturnType(".".join(typeNames))

</t>
<t tx="ekr.20080121105837.1200">##
# Read everything up to and including the matching close paren
# @param styles list
# @param text list 
# @param p int position in the styles and text list
# @param paren string type of parenthesis
def _getParenArguments(self, styles, text, p, paren=None):
    # Examples:
    #  (arg1, arg2) {
    #   =&gt; [(arg1, arg2)]
    #  [row][this.columns[column][0]];
    #   =&gt; [row]

    if paren is None:
        paren = text[p]
    parenMatches = { '{': '}', '[': ']', '(': ')' }
    args = []
    oppParen = parenMatches.get(paren)
    if oppParen is None:
        log.info("_getParenArguments:: No matching paren for: %r, " \
                 "ignoring arguments.", paren)
        return args, p
    parenCount = 0
    while p &lt; len(styles):
        args.append(text[p])
        if styles[p] == self.JS_OPERATOR:
            if text[p] == paren:
                parenCount += 1
            elif text[p] == oppParen:
                parenCount -= 1
                if parenCount &lt;= 0:
                    p += 1
                    break
        p += 1
    return args, p

</t>
<t tx="ekr.20080121105837.1201">def _skipOverParenArguments(self, styles, text, p, paren="("):
    args, p = self._getParenArguments(styles, text, p, paren)
    return p

</t>
<t tx="ekr.20080121105837.1202"># Skip over all the variable assignment details. Returns position at
# the end of the assignment, usually a "," or a ";" character.
#
# Examples:
#    var nGroupIndex = typeof &lt;|&gt;p_nGroupIndex=="number" ?p_nGroupIndex :0,
#        aGroup = this._getItemGroup(nGroupIndex);
# should skip to "aGroup = this._getItemGroup(nGroupIndex);"
def _skipToEndOfVariableAssignment(self, styles, text, p):
    old_p = p
    while p &lt; len(styles):
        style = styles[p]
        if style == self.JS_OPERATOR:
            t = text[p]
            if t in '([{':
                p = self._skipOverParenArguments(styles, text, p, t)
                continue
            elif t in ',;':
                break
        p += 1
    if old_p == p:
        # Ensure we at least move somewhere (avoid recursion)
        p += 1
    log.debug("_skipToEndOfVariableAssignment:: skipped text %r, p: %d",
              text[old_p:p], p)
    return p

</t>
<t tx="ekr.20080121105837.1203">def _getArgumentsFromPos(self, styles, text, pos):
    log.debug("_getArgumentsFromPos: text: %r", text[pos:])
    if pos &lt; len(styles) and styles[pos] == self.JS_OPERATOR and text[pos] == "(":
        ids = []
        pos += 1
        start_pos = pos
        while pos &lt; len(styles):
            if styles[pos] == self.JS_IDENTIFIER:
                ids.append(text[pos])
            elif styles[pos] != self.JS_OPERATOR or text[pos] != ",":
                break
            pos += 1
        return ids, pos
    return None, pos

</t>
<t tx="ekr.20080121105837.1204">def _getIdentifiersFromPos(self, styles, text, pos):
    log.debug("_getIdentifiersFromPos: text: %r", text[pos:])
    start_pos = pos
    ids = []
    last_style = self.JS_OPERATOR
    while pos &lt; len(styles):
        style = styles[pos]
        if style == self.JS_IDENTIFIER:
            if last_style != self.JS_OPERATOR:
                break
            ids.append(text[pos])
        elif style != self.JS_OPERATOR or text[pos] != "." or \
            last_style != self.JS_IDENTIFIER:
            break
        pos += 1
        last_style = style
    return ids, pos

</t>
<t tx="ekr.20080121105837.1205">##
# Grab all necessary citdl information from the given text
# @param styles list
# @param text list 
# @param p int position in the styles and text list
# @return the citdl list and the position after the last item swallowed
def _getCitdlTypeInfo(self, styles, text, p):
    log.debug("_getCitdlTypeInfo:: text: %r", text[p:])
    citdl = []
    last_style = self.JS_OPERATOR
    while p &lt; len(styles):
        style = styles[p]
        #print "p: %d, text[p]: %r" % (p, text[p], )
        #print "style: %d, last_style: %d" % (style, last_style)
        if style == self.JS_IDENTIFIER or text[p] == "this":
            if last_style != self.JS_OPERATOR:
                break
            citdl.append(text[p])
            style = self.JS_IDENTIFIER
        elif style == self.JS_OPERATOR and last_style == self.JS_IDENTIFIER:
            if text[p] == ".":
                pass
            elif text[p] == "(":
                paren_pos = p
                p = self._skipOverParenArguments(styles, text, p)
                if citdl:
                    if len(citdl) &gt; 1 and 'QueryInterface' == citdl[-1]:
                        # QueryInterface is specific to xpcom interfaces.
                        citdl = []
                        # Don't want the "." items in the citdl
                        for t in text[paren_pos+1:p-1]:
                            if t != ".":
                                citdl.append(t)
                    else:
                        citdl[-1] = citdl[-1] + "()"
                style = self.JS_IDENTIFIER
                p -= 1   # Are at the pos after the paren, move back to it
            elif text[p] == "[":
                # Arrays, just read in the arguments and add it to the citdl
                args, p = self._getParenArguments(styles, text, p, "[")
                if args and citdl:
                    # Check if this is an xpcom component.
                    if citdl in  (["CC"], ["Cc"],
                                  ["Components", "classes"]) and \
                       p &lt; (len(styles) + 2) and \
                       text[p] == "." and \
                       text[p+1] in ("getService", "createInstance") and \
                       text[p+2] == "(":
                        # Add the xpcom interface information.
                        # TODO: Change this once array completions are
                        #       supported
                        citdl, p = self._getArgumentsFromPos(styles, text,
                                                             p+2)
                    else:
                        citdl[-1] = citdl[-1] + "".join(args)
                style = self.JS_IDENTIFIER
                p -= 1  # We are are after the last "]", move back
            else:
                break
        else:
            break
        p += 1
        last_style = style
    return citdl, p

</t>
<t tx="ekr.20080121105837.1206">def _getVariableType(self, styles, text, p, assignmentChar="="):
    log.debug("_getVariableType: text: %r, assign char: %s", text[p:],
              assignmentChar)
    typeNames = []
    if p &gt;= len(styles):
        # Nothing left to examine
        return typeNames, p

    if assignmentChar and styles[p] == self.JS_OPERATOR and \
       text[p] == assignmentChar:
        # Assignment to the variable
        p += 1
    if p &lt; len(styles) and styles[p] == self.JS_OPERATOR and \
       text[p] in "+-":
        # Example: var x = -1;
        # Skip over + and -, commonly used with strings and integers
        p += 1

    if p &lt; len(styles):
        if styles[p] == self.JS_WORD:
            # Keyword
            keyword = text[p]
            if keyword == "new":
                typeNames, p = self._getIdentifiersFromPos(styles, text, p+1)
                #if not typeNames:
                #    typeNames = ["object"]
            elif keyword in ("true", "false"):
                typeNames = ["boolean"]
            elif keyword == "this":
                typeNames, p = self._getCitdlTypeInfo(styles, text, p)
                p -= 1   # We are already at the next position, step back
            # Don't record null, as it doesn't help us with anything
            #elif keyword == "null":
            #    typeNames = ["null"]
            p += 1
        elif styles[p] in self.JS_STRINGS:
            typeNames = ["string"]
            p += 1
        elif styles[p] == self.JS_NUMBER:
            typeNames = ["int"]
            p += 1
        elif styles[p] == self.JS_IDENTIFIER:
            typeNames, p = self._getCitdlTypeInfo(styles, text, p)
        elif styles[p] == self.JS_OPERATOR:
            if text[p] == "{":
                # This is actually a newly created object
                typeNames = ["Object"]
                p += 1
            elif text[p] == "[":
                while p+1 &lt; len(styles):
                    if text[p] == "]" and styles[p] == self.JS_OPERATOR:
                        break
                    p += 1
                typeNames = ["Array"]
                p += 1
    return typeNames, p

</t>
<t tx="ekr.20080121105837.1207">def _unquoteJsString(self, s):
    """Return the string without quotes around it"""
    if len(s) &gt;= 2 and s[0] in "\"'":
        return s[1:-1]
    return s

</t>
<t tx="ekr.20080121105837.1208">def _getVariableDetail(self, namelist, styles, text, p, assignmentChar="="):
    # this.myname = "123";
    # myclass.prototype.list = function () {
    # this.myname = new function(x, y) {
    # var num = mf.field1;
    # names = { "myname": 1, "yourname": 2 }
    
    log.debug("_getVariableDetail: namelist: %r, text:%r", namelist, text[p:])

    if len(namelist) &gt; 1 and "prototype" in namelist:
        # Check for special class prototypes
        protoName = namelist[-1]
        if protoName == "prototype":
            typeNames, p = self._getVariableType(styles, text, p, assignmentChar)
            return (TYPE_PARENT, typeNames, None, p)
        elif namelist[-2] == "prototype":
            typeNames = []
            if p+1 &lt; len(styles) and styles[p+1] in self.JS_STRINGS:
                typeNames = [self._unquoteJsString(text[p+1])]
            if protoName == "__defineGetter__":
                return (TYPE_GETTER, typeNames, None, p)
            elif protoName == "__defineSetter__":
                return (TYPE_SETTER, typeNames, None, p)
    elif len(namelist) == 1 and p+1 &lt; len(styles) and \
         styles[p] == self.JS_IDENTIFIER:
        keyword = namelist[0]
        if keyword == "get":
            # get log() {
            newnamelist, p = self._getIdentifiersFromPos(styles, text, p)
            namelist.pop()
            for name in newnamelist:
                namelist.append(name)
            log.debug("Found getter:%r", namelist)
            return (TYPE_GETTER, [], None, p)
        elif keyword == "set":
            # set application(value) {
            newnamelist, p = self._getIdentifiersFromPos(styles, text, p)
            namelist.pop()
            for name in newnamelist:
                namelist.append(name)
            log.debug("Found setter:%r", namelist)
            return (TYPE_SETTER, [], None, p)

    if p+1 &lt; len(styles) and styles[p+1] == self.JS_OPERATOR and text[p+1] == "{":
        # This is actually a newly created object
        return (TYPE_OBJECT, [], None, p+2)
    elif p+2 &lt; len(styles) and styles[p+1] == self.JS_WORD and \
         text[p+1] == "function":
        # Skip over any function name
        # Example:  var f = function my_f(a, b) { }
        p += 2
        while p &lt; len(styles):
            if text[p] == "(":
                break
            p += 1
        args, p = self._getArgumentsFromPos(styles, text, p)
        return (TYPE_FUNCTION, [], args, p)
    elif p+3 &lt; len(styles) and styles[p+1] == self.JS_WORD and \
         text[p+1] == "new" and text[p+2] == "function":
        # Skip over any function name
        # Example:  var f = new function my_f(a, b) { }
        p += 3
        while p &lt; len(styles):
            if text[p] == "(":
                break
            p += 1
        args, p = self._getArgumentsFromPos(styles, text, p)
        return (TYPE_FUNCTION, [], args, p)
    else:
        typeNames, p = self._getVariableType(styles, text, p, assignmentChar)
        return (TYPE_VARIABLE, typeNames, None, p)

</t>
<t tx="ekr.20080121105837.1209">def _variableHandler(self, lineno, styles, text, p, namelist,
                     allowedAssignmentChars="=",
                     isLocal=False):
    log.debug("_variableHandler:: namelist:%r, p:%d, isLocal: %r",
              namelist, p, isLocal)
    #print "p:", p
    #print "text:", text[p:]

    # The while loop is used to handle multiple variable assignments.
    # Example1:
    #   var x = 1, y = 2, z = 3;
    #     namelist: ['x']
    #     text:     ['=', '1', ',', 'y', '=', '2', ',', 'z', '=', '3', ';']
    #
    # Example2:
    #   var x = y = z = 1;
    #     namelist: ['x']
    #     text:     ['=', 'y', '=', 'z', '=', '1', ';']
    #
    # Example3:
    #   var x, y, z = 1;
    #     namelist: ['x']
    #     text:     [',', 'y', ',', 'z', '=', '1', ';']
    #
    already_looped = False
    while p &lt; len(styles):
        #log.debug("_variableHandler:: p: %d, text: %r", p, text[p:])
        if already_looped:
            # We've already done one loop, need to get a new namelist
            #     text:     [',', 'y', '=', '2', ',', 'z', '=', '3']
            #log.debug("_variableHandler:: already_looped:: text:%r, p:%d", text[p:], p)
            if text[p] == "=" and styles[p] == self.JS_OPERATOR and len(typeNames) &gt; 0:
                # Assignment to an assignment (aka Example 2)
                namelist = typeNames
            elif text[p] != "," or styles[p] != self.JS_OPERATOR:
                p = self._skipToEndOfVariableAssignment(styles, text, p)
                if p &lt; len(styles) and text[p] == ";":
                    p += 1
                continue
            else:
                # Multiple assignment (aka Example 1)
                namelist, p = self._getIdentifiersFromPos(styles, text, p+1)
            log.debug("_variableHandler:: already_looped:: namelist now:%r, p:%d", namelist, p)

        if len(namelist) &lt; 1:
            log.debug("_variableHandler:: Invalid namelist! Text: %r", text)
            return

        if p &gt;= len(styles) or text[p] in ",;":
            # It's a uninitialized variable?
            log.debug("Adding uninitialized variable: %r, line: %d",
                      namelist, lineno)
            self.addVariable(namelist, [],
                             doc=self.comment,
                             isLocal=isLocal)
            already_looped = True
            continue

        typeNames = []
        name_prefix = namelist[0]
        assignChar = text[p]
        try_getter_setter = False

        addToClass = False
        assignToCurrentScope = False
        if assignChar == ":" or name_prefix == "this":
            assignToCurrentScope = True
            if name_prefix == "this" or \
               isinstance(self.currentScope, JSClass):
                addToClass = True

        if p+1 &lt; len(styles) and len(namelist) == 1 and \
           name_prefix in ("get", "set") and styles[p] == self.JS_IDENTIFIER:
            log.debug("First element in namelist is a getter/setter")
            try_getter_setter = True

        if p+1 &lt; len(styles) and (try_getter_setter or
                                    (styles[p] == self.JS_OPERATOR and
                                     assignChar in allowedAssignmentChars)):
            if name_prefix == "this":
                namelist = namelist[1:]
                if len(namelist) &lt; 1:
                    log.debug("_variableHandler:: No namelist for 'this'! Text: %r", text)
                    return
                name_prefix = namelist[0]
            elif name_prefix[0] in "'\"":
                # String assignment  { "myfield" : 123, ....
                name_prefix = self._unquoteJsString(name_prefix)
                namelist = [name_prefix]
                # Treat it like a variable/object assignment
                assignToCurrentScope = True

            # Assignment to the scope
            #print "text[p:]", text[p:]
            varType, typeNames, args, p = self._getVariableDetail(namelist, styles, text, p, assignmentChar=assignChar)
            log.debug("_variableHandler:: varType:%r, typeNames:%r, args:%r, p: %d", varType, typeNames, args, p)
            if varType == TYPE_FUNCTION:
                if addToClass:
                    log.debug("_variableHandler:: Line %d, class function: %r(%r)",
                              lineno, namelist, args)
                    self.addClassFunction(namelist, args, doc=self.comment)
                else:
                    log.debug("_variableHandler:: Line %d, function: %r(%r)",
                              lineno, namelist, args)
                    self.addFunction(namelist, args, doc=self.comment,
                                     isLocal=(not assignToCurrentScope))
            elif varType == TYPE_VARIABLE:
                if assignToCurrentScope:
                    log.debug("_variableHandler:: Line %d, class member variable: %r (type=%r)",
                              lineno, namelist, typeNames)
                    self.addClassOrVariableMember(namelist, typeNames,
                                                  doc=self.comment,
                                                  isLocal=isLocal)
                else:
                    if len(namelist) &gt; 1:
                        log.debug("_variableHandler:: Line %d, scoped assignment: %r, type=%r",
                                  lineno, namelist, typeNames)
                    else:
                        log.debug("_variableHandler:: Line %d, local variable assignment: %r, type=%r",
                                  lineno, namelist, typeNames)
                    # XXX - Check this, do we need this hack?
                    if typeNames == ["Object"] and text[-1] == "{":
                        # Turn it into a class
                        log.info("_variableHandler:: Turning Object into class: %r", namelist)
                        #self.addVariable(namelist, typeNames)
                        self.addClass(namelist, doc=self.comment)
                    else:
                        self.addVariable(namelist, typeNames,
                                         doc=self.comment,
                                         isLocal=isLocal)
                # We ignore any defined functions, as we gain no value from them
            elif varType == TYPE_PARENT:
                if len(typeNames) &gt; 0:
                    self.addClassParent(namelist, typeNames)
                else:
                    self.addAnonymousClass(namelist, doc=self.comment)
            elif varType == TYPE_GETTER:
                log.debug("_variableHandler:: Found getter:%r", namelist)
                self.addGetter(namelist, [], doc=self.comment)
            elif varType == TYPE_SETTER:
                log.debug("_variableHandler:: Found setter:%r", namelist)
                self.addSetter(namelist, doc=self.comment)
            elif varType == TYPE_OBJECT:
                # var obj = { observer: function() { ... }, count: 10 }
                if not typeNames:
                    typeNames = ["Object"]
                if assignToCurrentScope:
                    log.debug("_variableHandler:: Line %d, class object variable: %r", lineno,
                              namelist)
                    self.addClassOrVariableMember(namelist, typeNames,
                                                  doc=self.comment,
                                                  assignAsCurrentScope=True)
                else:
                    log.debug("_variableHandler:: Line %d, object variable: %r", lineno,
                              namelist)
                    self.addObjectVariable(namelist, doc=self.comment,
                                           isLocal=isLocal)
            else:
                log.info("_variableHandler:: Ignoring. Unhandled assignment type: %r",
                         text)
                return
        else:
            log.debug("_variableHandler:: Line %d, calling scoped variable: %r",
                      lineno, namelist)
        already_looped = True

</t>
<t tx="ekr.20080121105837.1210">def createObjectArgument(self, styles, text):
    log.debug("createObjectArgument")
    #obj = toScope.addVariable(varName, self.lineno, self.depth, "Object", doc=doc)
    obj = JSObject(None, None, self.lineno, self.depth, "Object")
    return obj

</t>
<t tx="ekr.20080121105837.1211">def createFunctionArgument(self, styles, text):
    log.debug("createFunctionArgument")
    return JSFunction(None, None, None, self.lineno, self.depth,
                      isHidden=True)

</t>
<t tx="ekr.20080121105837.1212">def _addCodePiece(self, styles, text, pos=0):
    if pos &gt;= len(styles):
        return
    lineno = self.lineno

    log.debug("*** Line: %d ********************************", lineno)
    #log.debug("Styles: %r", self.styles)
    log.debug("Text: %r", self.text[pos:])
    log.debug("currentScope: %s %r", self.currentScope.cixname,
              self.currentScope.name)
    if self.currentClass:
        log.debug("currentClass: %r", self.currentClass.name)
    if self.in_variable_definition:
        log.debug("in_variable_definition: %r", self.in_variable_definition)
    #print "%d: %r" % (lineno, " ".join(self.text[pos:]))
    #log.debug("Comment: %r", self.comment)
    #log.debug("")

    firstStyle = styles[pos]
    if firstStyle == self.JS_WORD:
        # Keyword
        keyword = text[pos]
        if keyword == "function":
            isLocal = not isinstance(self.currentScope, JSFile)
            namelist, p = self._getIdentifiersFromPos(styles, text, pos+1)
            if namelist:
                args, p = self._getArgumentsFromPos(styles, text, p)
                log.debug("Line %d, function: %r(%r)",
                          lineno, namelist, args)
                self.addFunction(namelist, args, doc=self.comment,
                                 isLocal=isLocal)
            else:
                # We shall add the function, but without a name as it does
                # not really have one... it's anonymous.
                args, p = self._getArgumentsFromPos(styles, text, p)
                self.addFunction([""], args, doc=self.comment,
                                 isLocal=isLocal, isHidden=True)
        elif keyword == "this":
            # Member variable of current object
            p = pos+1
            if p &lt; len(styles) and styles[p] == self.JS_OPERATOR and \
               text[p] == ".":
                namelist, p = self._getIdentifiersFromPos(styles, text, p+1)
                self._variableHandler(lineno, styles, text, p, ["this"] + namelist)
        elif keyword in ("var", "const"):
            # Variable of current scope
            self.in_variable_definition = True
            namelist, p = self._getIdentifiersFromPos(styles, text, pos+1)
            # if in the global/file scope the variable is global also,
            # if the scope is something else, add as a local variable
            if namelist:
                isLocal = not isinstance(self.currentScope, JSFile)
                if p &lt; len(styles):
                    self._variableHandler(lineno, styles, text, p, namelist,
                                          isLocal=isLocal)
                else:
                    log.debug("Adding uninitialized variable: %r, line: %d",
                              namelist, lineno)
                    self.addVariable(namelist, [],
                                     doc=self.comment,
                                     isLocal=isLocal)
        elif keyword == "return":
            p = pos+1
            if p &lt; len(styles) and styles[p] == self.JS_OPERATOR and \
               text[p] == "{":
                # Returning a new object
                self.addReturnObject(doc=self.comment)
                ## XXX - Fixme to allow variables with sub-elements
                #log.debug("Ignoring scope due to return of object")
                #newstate = S_IGNORE_SCOPE
            else:
                # Return types are only valid in functions
                if isinstance(self.currentScope, JSFunction):
                    typeNames, p = self._getVariableType(styles, text, pos+1, assignmentChar=None)
                    #varType, typeNames, args, p = self._getVariableDetail([], styles, text, pos, assignmentChar="return")
                    log.debug("Return type: %r", typeNames)
                    self.addFunctionReturnType(typeNames)
        elif keyword == "if":
            # if (....) xyz
            p = self._skipOverParenArguments(styles, text, pos+1)
            self._addCodePiece(styles, text, p)
        elif keyword == "else":
            pos += 1
            # Check for: 'else if (....) xyz'
            if pos &lt; len(styles) and styles[pos] == self.JS_WORD and \
               text[pos] == "if":
                pos = self._skipOverParenArguments(styles, text, pos+1)
            self._addCodePiece(styles, text, pos)
        else:
            log.debug("_addCodePiece: Unhandled keyword:%r", keyword)
    elif firstStyle == self.JS_IDENTIFIER:
        isLocal = False
        if self.in_variable_definition:
            if self.currentScope != self.cile and \
               ((pos &gt; 0 and text[pos-1] == ",") or
                (self.lastText and self.lastText[-1] == ",")):
                isLocal = True
            else:
                self.in_variable_definition = False
        # Defining scope for action
        namelist, p = self._getIdentifiersFromPos(styles, text, pos)
        self._variableHandler(lineno, styles, text, p, namelist,
                              allowedAssignmentChars=":=",
                              isLocal=isLocal)
    elif firstStyle == self.JS_OPERATOR:
        if self.lastText and self.lastText[-1] == "{" and \
           text[:2] == ['(', ')'] and isinstance(self.lastScope, JSFunction):
            # It's a closure
            log.debug("Found a closure: function: %r", self.lastScope.name)
            self._convertFunctionToClosureVariable(self.lastScope)
        else:
            # We don't do anything here
            log.debug("Ignoring when starting with an operator")
    elif firstStyle in self.JS_STRINGS:
        # Check for object string names, see below:
        #   "element1": [ 1, "one" ],
        #   "field1": "name",
        #print "String assignment: %r" % (text[pos], )
        #print "Text: %r" % (text, )
        if pos+1 &lt; len(styles) and \
           styles[pos+1] == self.JS_OPERATOR and text[pos+1] == ":":
            self._variableHandler(lineno, styles, text, pos+1,
                                  text[pos:pos+1],
                                  allowedAssignmentChars=":",
                                  isLocal=False)
    else:
        log.debug("Unhandled first style:%d", firstStyle)

    self._resetState()
    #if log.level == logging.DEBUG:
    #    print
    #    print '\n'.join(self.cile.outline())
    #    print

</t>
<t tx="ekr.20080121105837.1213">def _chooseBestVariable(self, jsvar1, jsvar2):
    # 1. Choose the one with a jsdoc.
    if jsvar1.jsdoc and not jsvar2.jsdoc:
        return jsvar1
    if jsvar2.jsdoc and not jsvar1.jsdoc:
        return jsvar2
    # 2. Choose the one with the a citdl.
    if jsvar1.type and not jsvar2.type:
        return jsvar1
    if jsvar2.type and not jsvar1.type:
        return jsvar2
    # 3. Choose the one with the best citdl. We prefer the one
    #    that is not a standard type, because standard types
    #    can be null or boring :D
    citdl1 = standardizeJSType(jsvar1.type)
    citdl2 = standardizeJSType(jsvar2.type)
    if citdl1 in known_javascript_types and \
       not citdl2 in known_javascript_types:
        return jsvar2
    if citdl2 in known_javascript_types and \
       not citdl1 in known_javascript_types:
        return jsvar1
    # 4. Default to the first one given.
    return jsvar1

</t>
<t tx="ekr.20080121105837.1214">def _copyObjectToAnother(self, jsobject, jsother):
    #print
    #print "Full outline:"
    #print '\n'.join(self.cile.outline())
    #print
    #print "jsobject:"
    #print '\n'.join(jsobject.outline())
    #print
    #print "jsother:"
    #print '\n'.join(jsother.outline())

    appliedToGlobalScope = False
    if jsother == self.cile:
        appliedToGlobalScope = True

    for fieldname in ('classes', 'members', 'variables', 'functions', ):
        d_obj = getattr(jsobject, fieldname, {})
        d_oth = getattr(jsother, fieldname, {})
        for name, jsobj in d_obj.items():
            # Check the parents are not the same.
            if jsobj.parent == jsother:
                parent = jsobj.parent
                log.warn("%s %r has parent %s %r, file: %s#%d",
                         parent.cixname, parent.name, jsother.cixname,
                         jsother.name, self.cile.name, self.lineno)
            jsobj.parent = jsother
            if appliedToGlobalScope:
                # Remove the __local__ and private attributes
                if "__local__" in jsobj.attributes:
                    jsobj.attributes.remove("__local__")
                if "private" in jsobj.attributes:
                    jsobj.attributes.remove("private")
        d_oth.update(d_obj)
    # Ensure the variables are not already known as member variables.
    d_members = getattr(jsother, "members", {})
    d_variables = getattr(jsother, "variables", {})
    
    for name, jsobj in d_variables.items():
        if name in d_members:
            # Decide which one to keep then, remove the variable and then
            # replace the member with the best choice.
            del d_variables[name]
            d_members[name] = self._chooseBestVariable(d_members[name],
                                                       jsobj)
            log.info("Dupe found: %s %r has both variable and member %r, "
                     "keeping %r", jsother.cixname, jsother.name, name,
                     d_members[name])

</t>
<t tx="ekr.20080121105837.1215">def _handleYAHOOExtension(self, styles, text, p):
    # text example:
    #   ['(', 'Dog', ',', 'Mammal', ',', '{', ')']
    #print "YAHOO!!!!!!"
    #print "len(self.objectArguments): %d" % (len(self.objectArguments), )
    if p+5 &lt; len(styles) and text[p] == "(" and len(self.objectArguments) == 1:
        extendClassNamelist, p = self._getIdentifiersFromPos(styles, text, p+1)
        log.debug("_handleYAHOOExtension:: extendClassNamelist: %r", extendClassNamelist)
        parentClassNamelist, p = self._getIdentifiersFromPos(styles, text, p+1)
        if extendClassNamelist and parentClassNamelist:
            # Add class parent reference
            #print "Extending %r, parent %r" % (extendClassNamelist, parentClassNamelist)
            jsclass = self._addClassPart(".".join(parentClassNamelist), self.ADD_CLASS_PARENT, extendClassNamelist)
            # Now add all information from objectArguments
            self._copyObjectToAnother(self.objectArguments[0][1], jsclass)
    #log.setLevel(logging.WARN)

</t>
<t tx="ekr.20080121105837.1216">def _removeObjectFromScope(self, jsobject):
    removename = jsobject.name
    parent = jsobject.parent
    if parent:
        searchScopeNames = ("variables", "functions", "classes",)
        if not isinstance(parent, JSFile):
            searchScopeNames += ("members", )
        for scopeName in searchScopeNames:
            scope = getattr(parent, scopeName)
            if removename in scope and scope[removename] == jsobject:
                log.debug("Removing %r from scope: %s in %r",
                          removename, scopeName, parent.name)
                scope.pop(removename)

</t>
<t tx="ekr.20080121105837.1217">def _handleFunctionApply(self, namelist=None):
    """Everything in the function is applied to the supplied scope/namelist"""
    # XXX : TODO
    #       Not everything should be applied. Only the "this." items get
    #       applied!
    # Examples:
    #   (function() { this.xyz = 1; }).apply(namelist);
    #   // Giving namelist an xyz member.

    if namelist is None:
        scope = self.cile
    else:
        # Find the scope
        scope = self._findOrCreateScope(namelist, attrlist=('variables', 'classes', 'functions', ))
    if self.lastScope and isinstance(self.lastScope, JSFunction):
        applyFrom = self.lastScope
        parent = applyFrom.parent
        if isinstance(parent, JSClass) and \
           parent.name == applyFrom.name:
            # We apply everything from the parent then, except the function
            # itself, start by copying everything inside the function.
            self._copyObjectToAnother(applyFrom, scope)
            # Remove the function now
            del parent.functions[applyFrom.name]
            # The class/parent becomes our next target to copy
            applyFrom = parent
        # Copy across everything in the applyFrom object
        self._copyObjectToAnother(applyFrom, scope)
        # We need to remove the applyFrom object, it's life is done
        self._removeObjectFromScope(applyFrom)

</t>
<t tx="ekr.20080121105837.1218">def _handleFunctionWithArguments(self):
    styles = self.styles
    if len(styles) == 0:
        return
    text = self.text
    lineno = self.lineno

    log.debug("*** _handleFunctionWithArguments line: %d ***", lineno)
    #log.debug("Styles: %r", self.styles)
    log.debug("Text: %r", self.text)
    #log.debug("Comment: %r", self.comment)
    #log.debug("")

    pos = 0
    firstStyle = styles[pos]
    getsetPos = None
    try:
        getsetPos = text.index("__defineGetter__")
    except ValueError:
        try:
            getsetPos = text.index("__defineSetter__")
        except ValueError:
            pass
    if getsetPos is not None and len(styles) &gt; getsetPos+3 and \
       styles[getsetPos+2] in self.JS_STRINGS:
        scopeNames, p = self._getIdentifiersFromPos(styles, text, pos)
        namelist = [ self._unquoteJsString(text[getsetPos+2]) ]
        if scopeNames and scopeNames[0] != "this":
            namelist = scopeNames[:-1] + namelist
        if text[getsetPos] == "__defineSetter__":
            self.addSetter(namelist, doc=self.comment)
        else:
            # Getter is different, it can have a type.
            citdl = None
            for i, scope in self.objectArguments:
                if isinstance(scope, JSFunction):
                    self.lineno = scope.line
                    citdl = scope.getReturnType()
                    break
            if citdl:
                self.addGetter(namelist, [citdl], doc=self.comment)
            else:
                self.addGetter(namelist, [], doc=self.comment)
    elif firstStyle == self.JS_IDENTIFIER:
        namelist, p = self._getIdentifiersFromPos(styles, text, pos)
        #print "namelist: %r" % (namelist, )
        if namelist and namelist[0] == "YAHOO" and \
           namelist[1:] in (["extend"], ["lang", "extend"]):
            # XXX - Should YAHOO API catalog be enabled then?
            self._handleYAHOOExtension(styles, text, p)
    elif firstStyle == self.JS_OPERATOR:
        if text[:4] == [")", ".", "apply", "("]:
            # Special case for function apply
            namelist, p = self._getIdentifiersFromPos(styles, text, pos+4)
            if namelist:
                self._handleFunctionApply(namelist)
            elif text[3:5] == ["(", ")"]:
                # Applied to the global namespace
                self._handleFunctionApply()

</t>
<t tx="ekr.20080121105837.1219">def _resetState(self, newstate=S_DEFAULT):
    self.state = newstate
    self.bracket_depth = 0
    self.styles = []
    self.lastText = self.text
    self.text = []
    if self.comment:
        self.last_comment_and_jsdoc = [self.comment, None]
    self.comment = []
    self.argumentPosition = 0
    self.argumentTextPosition = 0
    self.objectArguments = []
    #log.debug("Set state %d, line: %d", self.state, self.lineno, )

</t>
<t tx="ekr.20080121105837.1220">def _popPreviousState(self, keep_style_and_text=False):
    current_styles = self.styles
    current_text = self.text
    current_arguments = self.objectArguments
    previous_state = self.state
    if len(self.state_stack) &gt;= 1:
        # Reset to previous state
        self.state, self.bracket_depth, self.styles, \
            self.text, self.lastText, self.comment, \
            self.argumentPosition, self.argumentTextPosition, \
            self.objectArguments, \
            self.in_variable_definition = self.state_stack.pop()
    else:
        # Reset them all
        self._resetState()
    log.debug("_popPreviousState:: previous: %d, current: %d",
              previous_state, self.state)
    if keep_style_and_text:
        self.styles += current_styles
        self.text += current_text
        self.objectArguments = current_arguments

</t>
<t tx="ekr.20080121105837.1221">def _pushAndSetState(self, newstate=S_DEFAULT):
    self.state_stack.append((self.state, self.bracket_depth, self.styles,
                             self.text, self.lastText, self.comment,
                             self.argumentPosition,
                             self.argumentTextPosition,
                             self.objectArguments,
                             self.in_variable_definition))
    self._resetState(newstate)
    self.in_variable_definition = False

</t>
<t tx="ekr.20080121105837.1222">def _endOfScanReached(self):
    """Ensure any remaining text is included in the cile"""
    if len(self.styles) &gt; 0:
        self._addCodePiece(self.styles, self.text, pos=0)

</t>
<t tx="ekr.20080121105837.1223">def token_next(self, style, text, start_column, start_line, **other_args):
    """Loops over the styles in the document and stores important info.
    
    When enough info is gathered, will perform a call to analyze the code
    and generate subsequent language structures. These language structures
    will later be used to generate XML output for the document."""

    if style in self.JS_CILE_STYLES:
        # We keep track of these styles and the text associated with it.
        # When we gather enough info, these will be sent to the
        # _addCodePiece() function which will analyze the info.

        #print "state: %d, text: %r" % (self.state, self.text, )
        #log.debug("state: %d, line: %d, text: %r", self.state, start_line, self.text)
        # We want to use real line numbers starting from 1 (not 0)
        start_line += 1
        if self.state == S_DEFAULT and len(self.styles) &gt; 0 and \
           self.last_lineno &lt; start_line:
            # We have moved down line(s) and we have data, check if we
            # need to add code from the previous line(s)
            # XXX: Need to be careful with e4x!
            if ((style != self.JS_OPERATOR or text[0] not in "({[.,=") and
                (self.styles[-1] != self.JS_OPERATOR or
                 self.text[-1] not in "({[.,=")):
                self._addCodePiece(self.styles, self.text, pos=0)
                self.in_variable_definition = False
        self.lineno = start_line
        if style != self.JS_OPERATOR:
            self.styles.append(style)
            self.text.append(text)
        else:
            if text == "(": # Only the "(", it's like above
                # Check if this is of the form "(function { .... })"
                # This is a fix for self invoking functions/closures
                #   http://bugs.activestate.com/show_bug.cgi?id=63297
                if not self.text:
                    log.debug("Ignoring initial brace: '(' on line %d",
                              self.lineno)
                    return
            #log.debug("token_next: line %d, %r, text: %r" % (self.lineno, text, self.text))
            for op in text:
                self.styles.append(style)
                self.text.append(op)
                #if self.state == S_OBJECT_ARGUMENT:
                #    if op not in "{}":
                #        continue
                if op == "(":
                    if self.bracket_depth == 0:
                        # We can start defining arguments now
                        log.debug("Entering S_IN_ARGS state, line: %d, col: %d", start_line, start_column)
                        self._pushAndSetState(S_IN_ARGS)
                        self.argumentTextPosition = len(self.text)
                    self.bracket_depth += 1
                elif op == ")":
                    self.bracket_depth -= 1
                    if self.bracket_depth &lt;= 0:
                        # Pop the state, but keep the style and text of
                        # the arguments
                        last_state = self.state
                        self._popPreviousState(keep_style_and_text=True)
                        if self.state != S_IN_ARGS and last_state == S_IN_ARGS:
                            self._handleFunctionWithArguments()
                        log.debug("Entering state %d, line: %d, col: %d", self.state, start_line, start_column)
                #elif op == "=":
                #    if text == op:
                #        log.debug("Entering S_IN_ASSIGNMENT state, line: %d, col: %d", start_line, start_column)
                #        self.state = S_IN_ASSIGNMENT
                elif op == "{":
                    # Increasing depth/scope, could be an argument object
                    if self.state == S_IN_ARGS:
                        # __defineGetter__("num", function() { return this._num });
                        argTextPos = self.argumentTextPosition
                        if len(self.text) &gt; argTextPos and \
                           self.styles[argTextPos] == self.JS_WORD and \
                           self.text[argTextPos] == "function" and \
                           self.text[-2] == ")":
                            # Passing a function as one of the arguments,
                            # need to create a JSFunction scope for this,
                            # as various information may be needed, i.e.
                            # a getter function return type.
                            obj = self.createFunctionArgument(styles, text)
                            self.currentScope = obj
                            self.objectArguments.append((self.argumentPosition, obj))
                            self._pushAndSetState(S_DEFAULT)
                        elif len(self.text) &gt;= 2 and \
                           ((self.text[-2] == "(" and
                             self.argumentPosition == 0) or
                            (self.text[-2] == "," and
                             self.argumentPosition &gt; 0)):
                            # It's an object argument
                            log.debug("Entering S_OBJECT_ARGUMENT state, line: %d, col: %d", start_line, start_column)
                            #print "Entering S_OBJECT_ARGUMENT state, line: %d, col: %d" % (start_line, start_column)
                            obj = self.createObjectArgument(self.styles, self.text)
                            self.currentScope = obj
                            self._pushAndSetState(S_OBJECT_ARGUMENT)
                        else:
                            self._pushAndSetState(S_IN_ARGS)
                    else:
                        self._addCodePiece(self.styles, self.text, pos=0)
                        self._pushAndSetState(S_DEFAULT)
                    self.incBlock()
                elif op == "}":
                    # Decreasing depth/scope
                    previous_state = self.state
                    if self.state != S_IN_ARGS:
                        # only add this piece if we're not in an arg state
                        self._addCodePiece(self.styles, self.text, pos=0)
                    self._popPreviousState()
                    if self.state == S_IN_ARGS:
                        self.objectArguments.append((self.argumentPosition, self.currentScope))
                        log.debug("Leaving S_OBJECT_ARGUMENT state, entering S_IN_ARGS state, line: %d, col: %d", start_line, start_column)
                        #print "Leaving S_OBJECT_ARGUMENT state, entering S_IN_ARGS state, line: %d, col: %d" % (start_line, start_column)
                    self.decBlock()
                elif op == "," and self.text[0] not in ("var", "const"):
                    # Ignore when it's inside arguments
                    if self.state == S_IN_ARGS:
                        self.argumentPosition += 1
                        self.argumentTextPosition = len(self.text)
                    else:
                        self._addCodePiece(self.styles, self.text, pos=0)
                elif op == ";":
                    # Statement is done
                    if self.state != S_IN_ARGS:
                        # only add this piece if we're not in an arg state
                        self._addCodePiece(self.styles, self.text, pos=0)
                    self.in_variable_definition = False
        # Remember the last code line we looked at
        self.last_lineno = self.lineno
    elif style in self.JS_COMMENT_STYLES:
        self.comment.append(text)

</t>
<t tx="ekr.20080121105837.1224">def scan_puretext(self, content, updateAllScopeNames=True):
    """Scan the given pure javascript content"""

    #XXX Should eventually use lang_javascript.JavaScriptLexer()
    #    because (1) it's word lists might differ and (2) the
    #    codeintel system manages one instance of it.
    JavaScriptLexer().tokenize_by_style(content, self.token_next)
    # Ensure we take notice of any text left in the ciler
    self._endOfScanReached()
    if updateAllScopeNames:
        # We've parsed up the JavaScript, fix any variables types
        self.cile.updateAllScopeNames()

</t>
<t tx="ekr.20080121105837.1225">def convertToElementTreeFile(self, cixelement, file_lang):
    """Store JS information into the cixelement as a file(s) sub element"""
    self.cile.convertToElementTreeFile(cixelement, file_lang)

</t>
<t tx="ekr.20080121105837.1226">def convertToElementTreeModule(self, cixmodule):
    """Store JS information into already created cixmodule"""
    self.cile.convertToElementTreeModule(cixmodule)



</t>
<t tx="ekr.20080121105837.1227">#---- internal support stuff

def _isident(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" or char == "_"

</t>
<t tx="ekr.20080121105837.1228">def _isdigit(char):
    return "0" &lt;= char &lt;= "9"

</t>
<t tx="ekr.20080121105837.1229">def _walk_js_scopes(scope, lpath=None):
    """Walk the subscopes of the given element.
    Note that in JavaScript &lt;variable&gt; elements with children are
    considered a scope.  Yields (scope, lpath) depth-first.  The given
    top-level element is not yielded.
    """
    if lpath is None: lpath = []
    for subscope in scope:
        if subscope.tag == "variable" and not subscope: continue
        sublpath = lpath + [subscope.get("name")]
        yield (subscope, sublpath)
        for r in _walk_js_scopes(subscope, sublpath):
            yield r

</t>
<t tx="ekr.20080121105837.1230">def _walk_js_symbols(elem, _prefix=None):
    if _prefix:
        lpath = _prefix + (elem.get("name"), )
    else:
        lpath = (elem.get("name"), )
    yield lpath
    if not (elem.tag == "scope" and elem.get("ilk") == "function"):
        for child in elem:
            for child_lpath in _walk_js_symbols(child, lpath):
                yield child_lpath


</t>
<t tx="ekr.20080121105837.1231">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=JavaScriptLexer(),
                      buf_class=JavaScriptBuffer,
                      langintel_class=JavaScriptLangIntel,
                      import_handler_class=JavaScriptImportHandler,
                      cile_driver_class=JavaScriptCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1232">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1233">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Mason support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "Mason"
log = logging.getLogger("codeintel.mason")



</t>
<t tx="ekr.20080121105837.1234">#---- language support

class MasonLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1235">class MasonBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Perl"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    #TODO: adjust for Perl, if necessary
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"



</t>
<t tx="ekr.20080121105837.1236">class MasonCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "Perl"



</t>
<t tx="ekr.20080121105837.1237">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=MasonLexer(),
                      buf_class=MasonBuffer,
                      import_handler_class=None,
                      cile_driver_class=MasonCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1238">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1239">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Perl support for CodeIntel"""

import os
from os.path import (normpath, join, exists, splitext, basename, isdir,
                     normcase, dirname, islink, isabs)
import sys
import logging
import time
from glob import glob
import re
from pprint import pprint, pformat
import weakref

import process
from ciElementTree import Element, SubElement, tostring
import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

from codeintel2.common import *
from codeintel2.citadel import ImportHandler, CitadelBuffer, CitadelEvaluator
from codeintel2.citadel_common import ScanRequest
from codeintel2.parseutil import urlencode_path
from codeintel2 import perlcile
from codeintel2.util import isident, isdigit, banner, indent, markup_text
from codeintel2.tree_perl import (PerlTreeEvaluator,
                                  PerlPackageSubsTreeEvaluator,
                                  PerlPackageMembersTreeEvaluator)
from codeintel2.langintel import (LangIntel, ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

line_end_re = re.compile("(?:\r\n|\r)")

lang = "Perl"
log = logging.getLogger("codeintel.perl")
CACHING = True #XXX obsolete, kill it

gDoOldPerlWay = False #XXX Hook this in for moving to new perlcile


</t>
<t tx="ekr.20080121105837.1240">#---- language support

class PerlLexer(Lexer):
    lang = "Perl"
    @others
</t>
<t tx="ekr.20080121105837.1241">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_PERL)
    self._keyword_lists = [
        SilverCity.WordList(SilverCity.Keywords.perl_keywords)
    ]


</t>
<t tx="ekr.20080121105837.1242">#TODO: Merge handling of perl-complete-module-exports in with this one.
#      Will just need a boolean flag (on the trigger) indicating that
#      submodules should NOT be included.
class PerlImportsEvaluator(Evaluator):
    @others
</t>
<t tx="ekr.20080121105837.1243">def __str__(self):
    return "Perl imports"

</t>
<t tx="ekr.20080121105837.1244">def eval(self, mgr):
    try:
        prefix = self.trg.extra["prefix"]
        if prefix:
            self.ctlr.set_desc("subimports of '%s'" % prefix)
            prefix_tuple = tuple(prefix.split("::"))
        else:
            self.ctlr.set_desc("available imports")
            prefix_tuple = ()

        all_imports = set()
        for lib in self.buf.libs:
            # Reminder: A codeintel "blob" corresponds to a Perl module.
            all_imports.update(lib.get_blob_imports(prefix_tuple))
        
        if all_imports:
            cplns = [((is_dir_import and "directory" or "module"), name)
                     for name, is_dir_import in all_imports]
            cplns.sort(key=lambda i: i[1].upper())
            self.ctlr.set_cplns(cplns)
    finally:
        self.ctlr.done("success")


</t>
<t tx="ekr.20080121105837.1245">class PerlLangIntel(LangIntel,
                    ParenStyleCalltipIntelMixin,
                    ProgLangTriggerIntelMixin):
    # Add '=' to the default set for Perl. For example:
    #   my $foo =
    #     ^     ^
    #     |     `-- terminate calltip here
    #     `-- calltip triggers here
    # Because Perl doesn't have keywords args to functions this can work.
    calltip_region_terminators = tuple(']});=')
    preceding_trg_terminators = {';':None, '=':None}

    #XXX This cog regen is out-of-date. Re-write to parse perl.cix?
    # To regenerate this block:
    # - install the cog Python tool:
    #   http://www.nedbatchelder.com/code/cog/index.html
    # - run "cog -r lang_perl.py"
    #[[[cog
    #import cog
    #import os, sys
    #sys.path.insert(0, os.path.join(os.pardir, "codeintel"))
    #import cidb
    #dbpath = cidb.find_komodo_cidb_path()
    #sql = """SELECT symbol.name FROM file,scan,module,symbol
    #          WHERE file.compare_path LIKE '%perl.cix'
    #            AND scan.file_id=file.id AND module.scan_id=scan.id
    #            AND symbol.module_id=module.id AND symbol.type=0"""
    #cog.outl('_allow_trg_on_space_from_identifier = {')
    #for line in cidb.query(dbpath, 3, sql, "csv"):
    #    cog.outl('    "%s": 1,' % line.strip())
    #cog.outl('}')
    #]]]
    _allow_trg_on_space_from_identifier = {
        "-r": 1,
        "-w": 1,
        "-x": 1,
        "-o": 1,
        "-R": 1,
        "-W": 1,
        "-X": 1,
        "-O": 1,
        "-e": 1,
        "-z": 1,
        "-s": 1,
        "-f": 1,
        "-d": 1,
        "-l": 1,
        "-p": 1,
        "-S": 1,
        "-b": 1,
        "-c": 1,
        "-t": 1,
        "-u": 1,
        "-g": 1,
        "-k": 1,
        "-T": 1,
        "-B": 1,
        "-M": 1,
        "-A": 1,
        "-C": 1,
        "abs": 1,
        "accept": 1,
        "alarm": 1,
        "atan2": 1,
        "bind": 1,
        "binmode": 1,
        "bless": 1,
        "caller": 1,
        "chdir": 1,
        "chmod": 1,
        "chomp": 1,
        "chop": 1,
        "chown": 1,
        "chr": 1,
        "chroot": 1,
        "close": 1,
        "closedir": 1,
        "connect": 1,
        "continue": 1,
        "cos": 1,
        "crypt": 1,
        "dbmclose": 1,
        "dbmopen": 1,
        "defined": 1,
        "delete": 1,
        "die": 1,
        "do": 1,
        "dump": 1,
        "each": 1,
        "eof": 1,
        "eval": 1,
        "exec": 1,
        "exists": 1,
        "exit": 1,
        "exp": 1,
        "fcntl": 1,
        "fileno": 1,
        "flock": 1,
        "fork": 1,
        "format": 1,
        "formline": 1,
        "getc": 1,
        "getlogin": 1,
        "getpeername": 1,
        "getpgrp": 1,
        "getppid": 1,
        "getpriority": 1,
        "getpwnam": 1,
        "getgrnam": 1,
        "gethostbyname": 1,
        "getnetbyname": 1,
        "getprotobyname": 1,
        "getpwuid": 1,
        "getgrgid": 1,
        "getservbyname": 1,
        "gethostbyaddr": 1,
        "getnetbyaddr": 1,
        "getprotobynumber": 1,
        "getservbyport": 1,
        "getpwent": 1,
        "getgrent": 1,
        "gethostent": 1,
        "getnetent": 1,
        "getprotoent": 1,
        "getservent": 1,
        "setpwent": 1,
        "setgrent": 1,
        "sethostent": 1,
        "setnetent": 1,
        "setprotoent": 1,
        "setservent": 1,
        "endpwent": 1,
        "endgrent": 1,
        "endhostent": 1,
        "endnetent": 1,
        "endprotoent": 1,
        "endservent": 1,
        "getsockname": 1,
        "getsockopt": 1,
        "glob": 1,
        "gmtime": 1,
        "goto": 1,
        "grep": 1,
        "hex": 1,
        "import": 1,
        "index": 1,
        "int": 1,
        "ioctl": 1,
        "join": 1,
        "keys": 1,
        "kill": 1,
        "last": 1,
        "lc": 1,
        "lcfirst": 1,
        "length": 1,
        "link": 1,
        "listen": 1,
        "local": 1,
        "localtime": 1,
        "lock": 1,
        "log": 1,
        "lstat": 1,
        "m": 1,
        "map": 1,
        "mkdir": 1,
        "msgctl": 1,
        "msgget": 1,
        "msgrcv": 1,
        "msgsnd": 1,
        "my": 1,
        "next": 1,
        "no": 1,
        "oct": 1,
        "open": 1,
        "opendir": 1,
        "ord": 1,
        "our": 1,
        "pack": 1,
        "package": 1,
        "pipe": 1,
        "pop": 1,
        "pos": 1,
        "print": 1,
        "printf": 1,
        "prototype": 1,
        "push": 1,
        "q": 1,
        "qq": 1,
        "qr": 1,
        "qx": 1,
        "qw": 1,
        "quotemeta": 1,
        "rand": 1,
        "read": 1,
        "readdir": 1,
        "readline": 1,
        "readlink": 1,
        "readpipe": 1,
        "recv": 1,
        "redo": 1,
        "ref": 1,
        "rename": 1,
        "reset": 1,
        "return": 1,
        "reverse": 1,
        "rewinddir": 1,
        "rindex": 1,
        "rmdir": 1,
        "s": 1,
        "scalar": 1,
        "seek": 1,
        "seekdir": 1,
        "select": 1,
        "semctl": 1,
        "semget": 1,
        "semop": 1,
        "send": 1,
        "setpgrp": 1,
        "setpriority": 1,
        "setsockopt": 1,
        "shift": 1,
        "shmctl": 1,
        "shmget": 1,
        "shmread": 1,
        "shmwrite": 1,
        "shutdown": 1,
        "sin": 1,
        "sleep": 1,
        "socket": 1,
        "socketpair": 1,
        "sort": 1,
        "splice": 1,
        "split": 1,
        "sprintf": 1,
        "sqrt": 1,
        "srand": 1,
        "stat": 1,
        "study": 1,
        "substr": 1,
        "symlink": 1,
        "syscall": 1,
        "sysopen": 1,
        "sysread": 1,
        "sysseek": 1,
        "system": 1,
        "syswrite": 1,
        "tell": 1,
        "telldir": 1,
        "tie": 1,
        "tied": 1,
        "time": 1,
        "times": 1,
        "tr": 1,
        "truncate": 1,
        "uc": 1,
        "ucfirst": 1,
        "umask": 1,
        "undef": 1,
        "unlink": 1,
        "unpack": 1,
        "untie": 1,
        "unshift": 1,
        "utime": 1,
        "values": 1,
        "vec": 1,
        "wait": 1,
        "waitpid": 1,
        "wantarray": 1,
        "warn": 1,
        "write": 1,
        "y": 1,
    }
    #[[[end]]]

    # Match a subroutine definition. Used by trg_from_pos()
    _sub_pat = re.compile(r"\bsub\s+(\w+(::|'))*\w+$")
    # All Perl trigger points occur at one of these characters:
    #   ' ' (space)         only supported for built-in functions
    #   '(' (open paren)
    #   '&gt;' (greater than)  "-&gt;" actually
    #   ':' (colon)         "::" actually
    trg_chars = tuple(' (&gt;:')
    calltip_trg_chars = tuple(' (')

    @others
</t>
<t tx="ekr.20080121105837.1246">def trg_from_pos(self, buf, pos, implicit=True):
    """
    Implemented triggers
        calltip-space-call-signature
        calltip-call-signature
        complete-package-members
        complete-*-subs meaning the actual trigger is one of:
            complete-package-subs
            complete-object-subs
        complete-available-imports

    Not yet implemented:
        complete-module-exports
    """
    DEBUG = False  # not using 'logging' system, because want to be fast
    if DEBUG:
        print banner("trg_from_pos(pos=%r, implicit=%r)"
                     % (pos, implicit))

    accessor = buf.accessor
    last_pos = pos - 1
    last_ch = accessor.char_at_pos(last_pos)
    if DEBUG:
        print "  last_pos: %s" % last_pos
        print "  last_ch: %r" % last_ch

    # All Perl trigger points occur at one of the trg_chars.
    if last_ch not in self.trg_chars:
        if DEBUG:
            print "no: %r is not in %r" % (last_ch, self.trg_chars)
        return None
    elif last_ch == ':' \
         and not (last_pos &gt; 0
                  and accessor.char_at_pos(last_pos-1) == ':'):
        if DEBUG:
            penultimate_ch = (last_pos &gt; 0
                              and accessor.char_at_pos(last_pos-1) or '')
            print "no: %r is not '::'" % (penultimate_ch+last_ch)
        return None
    elif last_ch == '&gt;' \
         and not (last_pos &gt; 0 and accessor.char_at_pos(last_pos-1) == '-'):
        if DEBUG:
            penultimate_ch = (last_pos &gt; 0
                              and accessor.char_at_pos(last_pos-1) or '')
            print "no: %r is not '-&gt;'" % (penultimate_ch+last_ch)
        return None

    # We should never trigger in some styles (strings, comments, etc.).
    last_style = accessor.style_at_pos(last_pos)
    if DEBUG:
        last_style_names = buf.style_names_from_style_num(last_style)
        print "  style: %s %s" % (last_style, last_style_names)
    if (implicit and last_style in buf.implicit_completion_skip_styles
        or last_style in buf.completion_skip_styles):
        if DEBUG:
            print "no: completion is suppressed "\
                  "in style at %s: %s %s"\
                  % (last_pos, last_style, last_style_names)
        return None

    WHITESPACE = tuple(' \t\n\r')
    if last_ch == ' ':
        # This can be either "calltip-space-call-signature",
        # "complete-available-imports", or None (or
        # "complete-module-exports" when that is implemented).
        #
        # calltip-call-signature:
        #   Perl syntax allows a parameter list to be passed to a
        #   function name without enclosing parens. From a quick perusal
        #   of sample Perl code (from a default ActivePerl install)
        #   calling function this way seems to be limited to a number of
        #   core Perl built-ins or some library methods. For efficiency
        #   Komodo will maintain an explicit list of such function names
        #   for which a calltip with trigger without parentheses.
        #   XXX May want to make this a user-configurable list.
        # 
        # complete-available-imports:
        #   After 'use', 'require' or 'no' by itself on a line.
        #
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        if i &gt;= 0 and not (isident(text[i]) or isdigit(text[i])):
            if DEBUG:
                print "no: two before trigger point is not "\
                      "an ident char: '%s'" % text[i]
            return None
        while i &gt;= 0: # parse out the preceding identifier
            if not isident(text[i]):
                identifier = text[i+1:]
                # Whitespace is allowed between a Perl variable special
                # char and the variable name, e.g.: "$ myvar", "@  mylist"
                j = i
                while j &gt;= 0 and text[j] in WHITESPACE: # parse off whitespace
                    j -= 1
                if j &gt;= 0:
                    preceding_ch = text[j]
                else:
                    preceding_ch = None
                break
            i -= 1
        else:
            preceding_ch = None
            identifier = text
        if DEBUG: print "  identifier: %r" % identifier
        if not identifier:
            if DEBUG:
                print "no: no identifier preceding trigger point"
            return None
        if DEBUG: print "  preceding char: %r" % preceding_ch
        if identifier in ("use", "require", "no"):
            return Trigger("Perl", TRG_FORM_CPLN,
                           "available-imports", pos, implicit, prefix="")
        if preceding_ch and preceding_ch in "$@&amp;%\\*": # indicating a Perl variable
            if DEBUG:
                print "no: triggering on space after Perl "\
                      "variables not supported"
            return None
        if identifier not in self._allow_trg_on_space_from_identifier:
            if DEBUG:
                print ("no: identifier not in set for which "
                       "space-triggering is supported "
                       "(_allow_trg_on_space_from_identifier)")
            return None
        # Specifically disallow trigger on defining a sub matching one of
        # space-trigger names, i.e.: 'sub split &lt;|&gt;'. Optmization: Assume
        # that there is exacly one space between 'sub' and the subroutine
        # name. Almost all examples in the Perl lib seem to follow this.
        if i &gt;= 3 and text[i-3:i+1] == "sub ":
            if DEBUG:
                print "no: do not trigger in sub definition"
            return None
        if DEBUG: print "calltip-space-call-signature"
        return Trigger("Perl", TRG_FORM_CALLTIP,
                       "space-call-signature", pos, implicit)

    elif last_ch == '(':
        # This can be either "calltip-call-signature" or None (or
        # "complete-module-exports" when that is implemented).
        LIMIT = 100
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        while i &gt;= 0 and text[i] in WHITESPACE: # parse off whitespace
            i -= 1
        if i &gt;= 0 and not (isident(text[i]) or isdigit(text[i])):
            if DEBUG:
                print "no: first non-ws char before "\
                      "trigger point is not an ident char: '%s'" % text[i]
            return None
        end = i+1
        while i &gt;= 0: # parse out the preceding identifier
            if not isident(text[i]):
                identifier = text[i+1:end]
                # Whitespace is allowed between a Perl variable special
                # char and the variable name, e.g.: "$ myvar", "@  mylist"
                j = i
                while j &gt;= 0 and text[j] in WHITESPACE: # parse off whitespace
                    j -= 1
                if j &gt;= 0:
                    preceding_ch = text[j]
                else:
                    preceding_ch = None
                break
            i -= 1
        else:
            preceding_ch = None
            identifier = text[:end]
        if DEBUG: print "  identifier: %r" % identifier
        if DEBUG:
            assert ' ' not in identifier, "parse error: space in identifier: %r" % identifier
        if not identifier:
            if DEBUG:
                print "no: no identifier preceding trigger point"
            return None
        if DEBUG: print "  preceding char: %r" % preceding_ch
        if preceding_ch and preceding_ch in "$@%\\*":
            # '&amp;foo(' *is* a trigger point, but the others -- '$foo(',
            # '&amp;$foo(', etc. -- are not because current CodeIntel wouldn't
            # practically be able to determine the method to which $foo
            # refers.
            if DEBUG:
                print "no: calltip trigger on Perl var not supported"
            return None
        if identifier in ("if", "else", "elsif", "while", "for",
                          "sub", "unless", "my", "our"):
            if DEBUG:
                print "no: no trigger on anonymous sub or control structure"
            return None
        # Now we want to rule out the subroutine definition lines, e.g.:
        #    sub FOO(&lt;|&gt;
        #    sub FOO::BAR(&lt;|&gt;
        #    sub FOO'BAR(&lt;|&gt;
        #    sub FOO::BAR::BAZ(&lt;|&gt;
        # Note: Frankly 80/20 rules out the last three.
        line = text[:end].splitlines(0)[-1]
        if DEBUG:
            print "  trigger line: %r" % line
        if "sub " in line: # only use regex if "sub " on that line
            if DEBUG:
                print "  *could* be a subroutine definition"
            if self._sub_pat.search(line):
                if DEBUG:
                    print "no: no trigger on Perl sub definition"
                return None
        if DEBUG: print "calltip-call-signature"
        return Trigger("Perl", TRG_FORM_CALLTIP, "call-signature",
                       pos, implicit)

    elif last_ch == '&gt;':
        # Must be "complete-package-subs", "complete-object-subs"
        # or None. Note that we have already checked (above) that the
        # trigger string is '-&gt;'. Basically, as long as the first
        # non-whitespace char preceding the '-&gt;' is an identifier char,
        # then this is a trigger point.
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-1-LIMIT), last_pos-1) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        while i &gt;= 0 and text[i] in WHITESPACE: # parse off whitespace
            i -= 1
        if i &lt; 0:
            if DEBUG:
                print "no: no non-whitespace text preceding '-&gt;'"
            return None
        elif not isident(text[i]):
            if DEBUG:
                print "no: first non-ws char before "\
                      "trigger point is not an ident char: '%s'" % text[i]
            return None
        # At this point we know it is either "complete-package-subs"
        # or "complete-object-subs". We don't really care to take
        # the time to distinguish now -- trg_from_pos is supposed to be
        # quick -- and we don't have to. 
        if DEBUG: print "complete-*-subs"
        return Trigger("Perl", TRG_FORM_CPLN, "*-subs", pos, implicit,
                       length=2)

    elif last_ch == ':':
        # Must be "complete-package-members" or
        # "complete-available-imports" or None. Note that we have
        # already checked (above) that the trigger string is '::'.
        # Basically, as long as the first char preceding the '::' is
        # an identifier char or one of Perl's funny variable
        # identifying characters, then this is a trigger point.
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-1-LIMIT), last_pos-1) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        if i &lt; 0:
            if DEBUG:
                print "no: no text preceding '::'"
            return None
        ch = text[i]
        if not (isident(ch) or isdigit(ch) or ch == '$'):
            # Technically should allow '@', '%' and '&amp;' in there, but
            # there a total of 5 of all of this in the Perl std lib.
            # 80/20 rule.
            if DEBUG:
                print "no: first char before trigger "\
                      "point is not an ident char or '$': '%s'" % ch
            return None
        # Check if this is in a 'use' or 'require' statement.
        while i &gt; 0 and text[i-1] not in WHITESPACE: # skip to whitespace
            i -= 1
        prefix = text[i:pos-2]
        while i &gt; 0 and text[i-1]     in WHITESPACE: # skip over whitespace
            i -= 1
        start_idx = end_idx = i
        while start_idx &gt; 0 and (isident(text[start_idx-1])
                                 or text[start_idx-1] in '$@%'):
            start_idx -= 1
        ident = text[start_idx:end_idx]
        if ident in ("use", "require", "no"):
            if DEBUG:
                print "complete-available-imports (prefix=%r)" % prefix
            return Trigger("Perl", TRG_FORM_CPLN, "available-imports",
                           pos, implicit, length=2, prefix=prefix)
        if DEBUG: print "complete-package-members (prefix=%r)" % prefix
        return Trigger("Perl", TRG_FORM_CPLN, "package-members", pos,
                       implicit, length=2, prefix=prefix)

    return None


</t>
<t tx="ekr.20080121105837.1247">_perl_var_pat = re.compile(
    r"((?P&lt;prefix&gt;[$@%\\*&amp;]+)\s*)?(?P&lt;scope&gt;(::)?\b((?!\d)\w*?(::|'))*)(?P&lt;name&gt;(?!\d)\w+)$")
def citdl_expr_and_prefix_filter_from_trg(self, buf, trg):
    """Parse out the Perl expression at the given trigger and return
    a CITDL expression for it (and possibly a variable prefixj
    filter).
    
    Returns a 2-tuple:
        (&lt;CITDL-expression&gt;, &lt;variable-prefix-filter&gt;)

    For all triggers except TRG_FORM_DEFN, we parse out the Perl
    expression preceding the trigger position, simplify the
    expression (by removing whitespace, etc.) and translate that to
    an appropriate CITDL (*) expression. Set to None if there is no
    appropriate such expression. For TRG_FORM_DEFN triggers we first
    move forward to the end of the current word.
    
    As well, a variable prefix filter may be returned, useful for
    post-processing of completions. For example:
    
        Perl code           CITDL expression    prefix filter
        ---------           ----------------    -------------
        Foo::Bar&lt;|&gt;::       Foo::Bar            None
        $Foo::Bar&lt;|&gt;::      Foo::Bar            $

    Optimization Notes:
    - We can throw out Perl expressions with function calls
      because CodeIntel does not currently handle return values.
    - We can throw out Perl exprs that span an EOL: 80/20 rule. (We
      currently don't throw these away, though.)
    - Abort at hash and list indexing: the types of elements in these
      objects are not tracked by CodeIntel.
    - Punt on Perl references, e.g. \$foo, \@bar. XXX I wonder if I can
      just ignore references and assume the user is doing the right
      thing. I.e. I just presume that a reference is dereferenced
      properly when required. Dunno.
    - Currently we don't really make use of the styling info because we
      abort at indexing, function call arguments, etc. where recognizing
      string/number/regex boundaries would be useful. This info might be
      useful later if this algorithm is beefed up.
    
    Examples:
   
        GIVEN                       LEADING EXPR            CITDL EXPR
        -----                       ------------            ----------
        split &lt;|&gt;                   split                   split
        chmod(&lt;|&gt;                   chmod                   chmod
        $Foo::bar(&lt;|&gt;               $Foo::bar               Foo.$bar
        &amp;$make_coffee(&lt;|&gt;           &amp;$make_coffee           &amp;$make_coffee
        Win32::OLE-&gt;&lt;|&gt;             Win32::OLE              Win32::OLE
        Win32::OLE-&gt;GetObject(&lt;|&gt;   Win32::OLE-&gt;GetObject   Win32::OLE.GetObject
        split join &lt;|&gt;              join                    join
        foo-&gt;bar(&lt;|&gt;                foo-&gt;bar                foo.bar

    Note that the trigger character is sometimes necessary to resolve
    ambiguity. Given "Foo::Bar" without the trailing trigger char, we
    cannot know if the CITDL should be "Foo.Bar" or "Foo::Bar":

        GIVEN               CITDL EXPR
        -----               ----------
        Foo::Bar::&lt;|&gt;       Foo::Bar
        $Foo::Bar::&lt;|&gt;      Foo::Bar
        Foo::Bar-&gt;&lt;|&gt;       Foo::Bar
        Foo::Bar(&lt;|&gt;        Foo.Bar
        Foo::Bar &lt;|&gt;        Foo.Bar
        $Foo::Bar-&gt;&lt;|&gt;      Foo.$Bar
        $Foo::Bar(&lt;|&gt;       Foo.$Bar
        $Foo::Bar &lt;|&gt;       Foo.$Bar

    * http://specs.tl.activestate.com/kd/kd-0100.html#citdl
    """
    DEBUG = False
    if DEBUG:
        print
        print banner("citdl_expr_and_prefix_filter_from_trg @ %d"
                     % trg.pos)
        print markup_text(buf.accessor.text, trg_pos=trg.pos)
        print banner(None, '-')

    if trg.implicit:
        skip_styles = buf.implicit_completion_skip_styles
    else:
        skip_styles = {}
    filter, citdl = None, []

    accessor = buf.accessor
    LIMIT = max(0, trg.pos-100) # working text area
    if trg.form == TRG_FORM_DEFN:
        # "Go to Definition" triggers can be in the middle of an
        # expression. If so we want to move forward to the end of
        # the current *part*. E.g., given:
        #   $fo&lt;+&gt;o-&gt;bar()
        # move forward to:
        #   $foo&lt;|&gt;-&gt;bar()
        # and NOT to:
        #   $foo-&gt;bar&lt;|&gt;()
        #
        # Perl package names are considered one "part":
        #   $Fo&lt;+&gt;o::Bar-&gt;blah()           $Foo::Bar&lt;|&gt;-&gt;blah()
        #
        # Note: I suspect there are some problems with the
        # subsequent parsing on when/if to convert "Foo::Bar" to
        # "Foo.Bar" since codeintel2 changed Perl cpln eval.
        p = trg.pos
        length = accessor.length()
        while p &lt; length:
            if not _is_perl_var_char(accessor.char_at_pos(p)):
                break
            p += 1
        # Gracefully handle some situations where we are positioned
        # after a trigger string. E.g. "Foo::Bar::&lt;|&gt; "
        if p &gt;= 2 and accessor.text_range(p-2, p) in ("-&gt;", "::"):
            p = p - 2

        if DEBUG:
            print "'defn'-trigger: adjust position %d" % (p-trg.pos)
    else:
        p = trg.pos - trg.length

    p -= 1
    while p &gt;= LIMIT:
        # Parse off a perl variable/identifier.
        if DEBUG:
            print "look for Perl var at end of %r"\
                  % accessor.text_range(LIMIT, p+1)
        match = self._perl_var_pat.search(
            accessor.text_range(LIMIT, p+1))
        if not match:
            if DEBUG:
                if p-LIMIT &gt; 20:
                    segment = '...'+accessor.text_range(p-20, p+1)
                else:
                    segment = accessor.text_range(LIMIT, p+1)
                print "could not match a Perl var off %r" % segment
            citdl = None
            break
        prefix = match.group("prefix") or ""
        scope = match.group("scope")
        name = match.group("name")

        trg_ch = None
        try:
            #TODO:PERF: Use the available faster accessor methods here.
            trg_ch = accessor.char_at_pos(p+1)
        except IndexError, ex:
            if trg.form != TRG_FORM_DEFN:
                log.warn("text does not include trailing trigger "
                         "char to resolve possible ambiguities in '%s'",
                         match.group(0))
        if trg_ch == ':':
            #XXX fix off-by-one here
            # Foo::Bar&lt;|&gt;::       Foo::Bar
            # $Foo::Bar&lt;|&gt;::      Foo::Bar
            citdl.insert(0, scope+name) # intentionally drop prefix
            # The prefix string is relevant for filtering the list of
            # members for AutoComplete. E.g. if the prefix char is '&amp;' then
            # only subs should be shown. If '%', then only hashes.
            filter = prefix
        elif trg_ch == '-' and not prefix:
            #XXX fix off-by-one here
            # Foo::Bar&lt;|&gt;-&gt;       Foo::Bar
            citdl.insert(0, scope+name)
        else:
            #XXX fix off-by-one here
            # Foo::Bar&lt;|&gt;(        Foo.Bar
            # Foo::Bar&lt;|&gt;         Foo.Bar         # trigger char is a space here
            # $Foo::Bar&lt;|&gt;-&gt;      Foo.$Bar
            # $Foo::Bar&lt;|&gt;(       Foo.$Bar
            # $Foo::Bar&lt;|&gt;        Foo.$Bar        # trigger char is a space here
            citdl.insert(0, prefix+name)
            if scope:
                scope = scope[:-2] # drop trailing '::'
                if scope:
                    citdl.insert(0, scope)
        p -= len(match.group(0))
        if DEBUG:
            print "parse out Perl var: %r (prefix=%r, scope=%r, "\
                  "name=%r): %r" % (match.group(0), prefix, scope,
                                    name, citdl)

        # Preceding characters will determine if we stop or continue.
        WHITESPACE = tuple(" \t\n\r\v\f")
        while p &gt;= LIMIT and accessor.char_at_pos(p) in WHITESPACE:
            #if DEBUG: print "drop whitespace: %r" % text[p]
            p -= 1
        if p &gt;= LIMIT and accessor.style_at_pos(p) in skip_styles:
            if DEBUG:
                style = accessor.style_at_pos(p)
                style_names = buf.style_names_from_style_num(style)
                print "stop at style to ignore: %r (%s %s)"\
                      % (accessor.char_at_pos(p), style, style_names)
            break
        elif p &gt;= LIMIT+1 and accessor.text_range(p-1, p+1) == '-&gt;':
            if DEBUG: print "parse out '-&gt;'"
            p -= 2
            while p &gt;= LIMIT and accessor.char_at_pos(p) in WHITESPACE:
                #if DEBUG: print "drop whitespace: %r" % text[p]
                p -= 1
            continue
        else:
            break

    if citdl:
        retval = ('.'.join(citdl), filter)
    else:
        retval = (None, filter)
    if DEBUG:
        print "returning: %r" % (retval,)
        banner("done")
    return retval

</t>
<t tx="ekr.20080121105837.1248">def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    assert trg.lang == "Perl"
    ctlr.start(buf, trg)

    if trg.id == ("Perl", TRG_FORM_CPLN, "available-imports"):
        evalr = PerlImportsEvaluator(ctlr, buf, trg)
        buf.mgr.request_eval(evalr)
        return

    # Remaining triggers all use this parsed CITDL expr.
    # Extract the leading CITDL expression (and possible filter,
    # i.e. '$', '@', ...).
    try:
        citdl_expr, filter \
            = self.citdl_expr_and_prefix_filter_from_trg(buf, trg)
    except CodeIntelError, ex:
        ctlr.error(str(ex))
        ctlr.done("error")
        return

    # Perl's trg_from_pos doesn't distinguish btwn "package-subs" 
    # and "object-subs" trigger type -- calling them both "*-subs".
    # Let's do so here.
    if trg.type == "*-subs":
        assert citdl_expr
        if isident(citdl_expr[0]):
            trg.type = "package-subs"
        else:
            trg.type = "object-subs"

    if trg.id == ("Perl", TRG_FORM_CPLN, "package-members"):
        # [prefix]SomePackage::&lt;|&gt;
        # Note: This trigger has the "prefix" extra attr which could
        #       be used instead of the leading CITDL expr parse.
        line = buf.accessor.line_from_pos(trg.pos)
        evalr = PerlPackageMembersTreeEvaluator(ctlr, buf, trg, citdl_expr,
                                                line, filter)
        buf.mgr.request_eval(evalr)
    elif trg.id == ("Perl", TRG_FORM_CPLN, "package-subs"):
        # SomePackage-&gt;&lt;|&gt;
        assert not filter, "shouldn't be Perl filter prefix for " \
            "'complete-package-subs': %r" % filter
        line = buf.accessor.line_from_pos(trg.pos)
        evalr = PerlPackageSubsTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)
    #TODO: Might want to handle TRG_FORM_DEFN differently.
    else:
        if citdl_expr is None:
            ctlr.info("no CITDL expression found for %s" % trg)
            ctlr.done("no trigger")
            return
        line = buf.accessor.line_from_pos(trg.pos)
        evalr = PerlTreeEvaluator(ctlr, buf, trg, citdl_expr,
                                  line, filter)
        buf.mgr.request_eval(evalr)


</t>
<t tx="ekr.20080121105837.1249">def libs_from_buf(self, buf):
    env = buf.env

    # A buffer's libs depend on its env and the buf itself so
    # we cache it on the env and key off the buffer.
    if "perl-buf-libs" not in env.cache:
        env.cache["perl-buf-libs"] = weakref.WeakKeyDictionary()
    cache = env.cache["perl-buf-libs"] # &lt;buf-weak-ref&gt; -&gt; &lt;libs&gt;

    if buf not in cache:
        # - curdirlib
        # Using the dirname of this buffer isn't always right, but
        # hopefully is a good first approximation.
        cwd = dirname(buf.path)
        if cwd == "&lt;Unsaved&gt;":
            libs = []
        else:
            libs = [ self.mgr.db.get_lang_lib("Perl", "curdirlib",
                                              [dirname(buf.path)]) ]

        libs += self._buf_indep_libs_from_env(env)
        cache[buf] = libs
    return cache[buf]

</t>
<t tx="ekr.20080121105837.1250">def _perl_from_env(self, env):
    import which
    path = [d.strip() 
            for d in env.get_envvar("PATH", "").split(os.pathsep)
            if d.strip()]
    try:
        return which.which("perl", path=path) 
    except which.WhichError:
        return None

</t>
<t tx="ekr.20080121105837.1251">def _perl_info_from_perl(self, perl, env):
    """Call the given Perl and return:
        (&lt;version&gt;, &lt;config_dirs&gt;, &lt;import_path&gt;)
    where &lt;config_dirs&gt; is a dict with (relevant) dirs from
    Config.pm.
    """
    import process

    info_cmd = (r'use Config;'
                r'print "version:$Config{version}\n";'
                r'print "siteprefix:$Config{siteprefix}\n";'
                r'print "archlib:$Config{archlib}\n";'
                r'print "privlib:$Config{privlib}\n";'
                r'print "vendorarch:$Config{vendorarch}\n";'
                r'print "vendorlib:$Config{vendorlib}\n";'
                r'print join("\n", @INC);')
    argv = [perl, "-e", info_cmd]
    log.debug("run `%s -e ...'", perl)
    p = process.ProcessOpen(argv, env=env.get_all_envvars())
    stdout_lines = p.stdout.read().splitlines(0)
    stderr = p.stderr.read()
    retval = p.wait()
    p.close()
    if retval:
        log.warn("failed to determine Perl info:\n"
                 "  path: %s\n"
                 "  retval: %s\n"
                 "  stdout:\n%s\n"
                 "  stderr:\n%s\n",
                 perl, retval, indent('\n'.join(stdout_lines)),
                 indent(stderr))

    perl_ver = stdout_lines[0].split(':', 1)[1]
    config_dirs = dict(
        siteprefix = stdout_lines[1].split(':', 1)[1],
        archlib    = stdout_lines[2].split(':', 1)[1],
        privlib    = stdout_lines[3].split(':', 1)[1],
        vendorarch = stdout_lines[4].split(':', 1)[1],
        vendorlib  = stdout_lines[5].split(':', 1)[1],
    )
    import_path = stdout_lines[6:]

    return perl_ver, config_dirs, import_path

</t>
<t tx="ekr.20080121105837.1252">def _extra_dirs_from_env(self, env):
    extra_dirs = set()
    for pref in env.get_all_prefs("perlExtraPaths"):
        if not pref: continue
        extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                          if exists(d.strip()))
    return tuple(extra_dirs)

</t>
<t tx="ekr.20080121105837.1253">def _buf_indep_libs_from_env(self, env):
    """Create the buffer-independent list of libs."""
    cache_key = "perl-libs"
    if cache_key not in env.cache:
        env.add_pref_observer("perl", self._invalidate_cache)
        env.add_pref_observer("perlExtraPaths",
                              self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("codeintel_selected_catalogs",
                              self._invalidate_cache)
        db = self.mgr.db

        # Gather information about the current perl.
        perl = None
        if env.has_pref("perl"):
            perl = env.get_pref("perl").strip() or None
        if not perl or not exists(perl):
            perl = self._perl_from_env(env)
        if not perl:
            log.warn("no Perl was found from which to determine the "
                     "import path")
            perl_ver, config_dirs, import_path = None, {}, []
        else:
            perl_ver, config_dirs, import_path \
                = self._perl_info_from_perl(perl, env)
            
        libs = []

        # - extradirslib
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            log.debug("Perl extra lib dirs: %r", extra_dirs)
            libs.append( db.get_lang_lib("Perl", "extradirslib",
                            extra_dirs) )
        
        # Figuring out where the lib and sitelib dirs are is hard --
        # or at least complex from my P.O.V.
        # - For ActivePerl (on Linux, at least):
        #      $ perl -e 'print join "\n", @INC'
        #      /home/trentm/opt/ActivePerl-5.8.8.818/site/lib
        #           (sitearch, sitelib, siteprefix)
        #      /home/trentm/opt/ActivePerl-5.8.8.818/lib
        #           (archlib, privlib)
        #      . (???, we'll handle with curdirlib)
        # - For /usr/bin/perl on skink (ubuntu 6):
        #      $ /usr/bin/perl -e 'print join "\n", @INC'
        #      /etc/perl (???)
        #      /usr/local/lib/perl/5.8.7 (sitearch, siteprefix)
        #      /usr/local/share/perl/5.8.7 (sitelib, siteprefix)
        #      /usr/lib/perl5 (vendorarch)
        #      /usr/share/perl5 (vendorlib)
        #      /usr/lib/perl/5.8 (archlib)
        #      /usr/share/perl/5.8 (privlib)
        #      /usr/local/lib/site_perl (???, siteprefix)
        paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
        for dir in import_path:
            dir = normpath(dir)
            if dir == ".": # -&gt; curdirlib (handled separately)
                continue
            if islink(dir):
                # Note: this doesn't handle multiple levels of
                # links.
                link_value = os.readlink(dir)
                if isabs(link_value):
                    dir = link_value
                else:
                    dir = normpath(join(dirname(dir), link_value))

            if not isdir(dir):
                log.debug("perl @INC value '%s' is not a dir: dropping it",
                          dir)
                continue
            for config_dir_name in ("archlib", "privlib",
                                    "vendorarch", "vendorlib"):
                if config_dirs[config_dir_name] \
                   and dir.startswith(config_dirs[config_dir_name]):
                    paths_from_libname["stdlib"].append(dir)
                    break
            else:
                if config_dirs["siteprefix"] \
                     and dir.startswith(config_dirs["siteprefix"]):
                    paths_from_libname["sitelib"].append(dir)
                else:
                    paths_from_libname["envlib"].append(dir)
        log.debug("Perl %s paths for each lib:\n%s",
                  perl_ver, indent(pformat(paths_from_libname)))

        # - envlib, sitelib, cataloglib, stdlib
        if paths_from_libname["envlib"]:
            libs.append( db.get_lang_lib("Perl", "envlib", 
                            paths_from_libname["envlib"]) )
        if paths_from_libname["sitelib"]:
            libs.append( db.get_lang_lib("Perl", "sitelib", 
                            paths_from_libname["sitelib"]) )
        catalog_selections = env.get_pref("codeintel_selected_catalogs")
        libs += [
            db.get_catalog_lib("Perl", catalog_selections),
            db.get_stdlib("Perl", perl_ver)
        ]
        env.cache[cache_key] = libs

    return env.cache[cache_key]

</t>
<t tx="ekr.20080121105837.1254">def _invalidate_cache(self, env, pref_name):
    for key in ("perl-buf-libs", "perl-libs"):
        if key in env.cache:
            log.debug("invalidate '%s' cache on %r", key, env)
            del env.cache[key]

</t>
<t tx="ekr.20080121105837.1255">def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
    self._invalidate_cache(env, pref_name)
    extra_dirs = self._extra_dirs_from_env(env)
    if extra_dirs:
        extradirslib = self.mgr.db.get_lang_lib(
            "Perl", "extradirslib", extra_dirs)
        request = PreloadLibRequest(extradirslib)
        self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1256">#---- code browser integration
cb_import_group_title = "Uses and Requires"   

def cb_import_data_from_elem(self, elem):
    alias = elem.get("alias")
    symbol = elem.get("symbol")
    module = elem.get("module")
    if symbol:
        if symbol == "*":
            name = module
            detail = "use %s" % module
        elif symbol == "**":
            name = module
            detail = "use %s qw(:&lt;tag&gt;)" % module
        else:
            name = "::".join([module, symbol])
            detail = "use %s qw(%s)" % (module, symbol)
    else:
        name = module
        # This is either "use Foo ();" or "require Foo;". A search
        # the of the Perl 5.8 site lib should that the latter is about
        # 6 times more likely -- lets use that.
        detail = "require %s" % module
    return {"name": name, "detail": detail}


</t>
<t tx="ekr.20080121105837.1257">class PerlBuffer(CitadelBuffer):
    lang = "Perl"
    sce_prefixes = ["SCE_PL_"]

    cb_show_if_empty = True

    # 'cpln_fillup_chars' exclusions for Perl:
    # - cannot be '-' for "complete-*-subs" because:
    #       attributes::-&gt;import(__PACKAGE__, \$x, 'Bent');
    # - cannot be '{' for "complete-object-subs" because:
    #       my $d = $self-&gt;{'escape'};
    # - shouldn't be ')' because:
    #       $dumper-&gt;dumpValue(\*::);
    # - shouldn't be ':' (bug 65292)
    cpln_fillup_chars = "~`!@#$%^&amp;*(=+}[]|\\;'\",.&lt;&gt;?/ "
    cpln_stop_chars = "-~`!@#$%^&amp;*()=+{}[]|\\;:'\",.&lt;&gt;?/ "

    @others
</t>
<t tx="ekr.20080121105837.1258">def __init__(self, mgr, accessor, env=None, path=None):
    CitadelBuffer.__init__(self, mgr, accessor, env, path)

    # Some Perl styles in addition to the usual comment and string styles
    # in which completion triggering should not happen.
    self.completion_skip_styles[ScintillaConstants.SCE_PL_REGEX] = True

</t>
<t tx="ekr.20080121105837.1259">@property
def libs(self):
    return self.langintel.libs_from_buf(self)

</t>
<t tx="ekr.20080121105837.1260">@property
def stdlib(self):
    return self.libs[-1]


</t>
<t tx="ekr.20080121105837.1261">class PerlImportHandler(ImportHandler):
    PATH_ENV_VAR = "PERL5LIB"
    sep = "::"

    @others
</t>
<t tx="ekr.20080121105837.1262"># Try to speed up self._getPath() a little bit. This is called
# *very* frequently for Perl.
def __init__(self, mgr):
    ImportHandler.__init__(self, mgr)
    self._pathCache = None
    self._findModuleOnDiskCache = {}

</t>
<t tx="ekr.20080121105837.1263">if CACHING:
    def _getPath(self, cwd=None):
        if self._pathCache is None:
            self._pathCache = ImportHandler._getPath(self) # intentionally exclude cwd
        if cwd:
            return [cwd] + self._pathCache
        else:
            return self._pathCache

def _shellOutForPath(self, compiler):
    import process
    sep = "--WomBa-woMbA--"
    argv = [compiler, "-e", "print join('%s', @INC);" % sep]
    env = dict(os.environ)
    if "PERL5LIB" in env: del env["PERL5LIB"]
    if "PERLLIB" in env: del env["PERLLIB"]

    p = process.ProcessOpen(argv, env=env)
    retval = p.wait()
    output = p.stdout.read()
    error = p.stderr.read()
    retval = p.wait()
    p.close()
    if retval:
        raise CodeIntelError("could not determine Perl import path: %s"
                             % error)
    path = [normpath(d) for d in output.split(sep)]
    # cwd handled separately
    path = [p for p in path if p not in (os.curdir, os.getcwd())]
    return path

</t>
<t tx="ekr.20080121105837.1264">def setCorePath(self, compiler=None, extra=None):
    if compiler is None:
        import which
        compiler = which.which("perl")
    self.corePath = self._shellOutForPath(compiler)

</t>
<t tx="ekr.20080121105837.1265">def findModule(self, cu, factory, moduleName, dummy, cwd=None):
    XXX
    log.debug("   PerlImportHandler.findModule(module=%r, "
              "submodule=%r, cwd=%r)", moduleName, dummy, cwd)
    
    if CACHING:
        key = (moduleName, cwd)
        retval = factory.perlFindModuleCache.get(key, None)
        if retval is not None:
            return retval

    # Look for the appropriate file on disk, using the import path.
    modfile, kind, scannable = self.findModuleOnDisk(moduleName, dummy, cwd)
    
    # If found, see if we have this file and module in the CIDB.
    module = file_id = None
    if modfile:
        cu.execute("SELECT * FROM module "
                   "WHERE file_id=(SELECT id FROM file WHERE compare_path=?) "
                   "AND name=? LIMIT 1",
                   (canonicalizePath(modfile), moduleName))
        for row in cu:
            module = factory.createScope(row[M_FILE_ID], "module",
                                         row[M_ID], row)
            break

    if CACHING and module:
        # Only insert into the cache here, and NOT if the retval
        # is gotten via the fallback because that probably means the
        # module just isn't scanned yet.
        # - There are exceptions, e.g. HTML::FormatText, HTML::FormatPS,
        #   that defy existence.
        factory.perlFindModuleCache[key] = (module, "module")
        factory.perlFindModuleCacheIndex[module.file_id] = key

    ## If haven't found a matching module row yet then just look for any
    ## loaded Perl module of the same name. First one wins.
    ## PERF: Is this crucial? I don't think it is. Because of that and
    ##       because it is difficult to cache the case of modules that
    ##       are NEVER found (e.g. HTML::FormatText) this is currently
    ##       being removed.
    #if not module:
    #    sql = "SELECT module.* FROM language, file, module"\
    #          " WHERE language.name='Perl' "\
    #          "   AND language.id=file.language_id "\
    #          "   AND module.file_id=file.id "\
    #          "   AND module.name=? LIMIT 1"
    #    cu.execute(sql, (moduleName,))
    #    for row in cu:
    #        module = factory.createScope(row[M_FILE_ID], "module",
    #                                     row[M_ID], row)
    #        kind = "module"
    #        break

    log.debug("   PerlImportHandler.findModule: '%s' -&gt; %r",
              moduleName, module)
    if not module:
        raise NoModuleEntry(moduleName, modfile)
    else:
        return (module, "module")

</t>
<t tx="ekr.20080121105837.1266">def findModuleOnDisk(self, module, dummy, cwd=None):
    #XXX Should handle some of the weird "module" values possible with
    #    Perl require statements:
    #       require 'MyModule.pm';      # module: 'MyModule.pm'
    #       require "MyModule.pm";      # module: "MyModule.pm"
    #       require $filename;          # module: $filename
    
    if CACHING:
        # The findModuleOnDisk cache is a time-based cache. I.e. it make
        # the presumption that the file system hasn't changed
        # significantly in the last N seconds.
        N = 300 # 5 minutes
        key = (module, cwd)
        if key in self._findModuleOnDiskCache\
           and self._findModuleOnDiskCache[key][0] &gt; time.time() - N:
            return self._findModuleOnDiskCache[key][1]

    path = self._getPath(cwd)
    mname = module.replace("::", os.sep) + ".pm"
    for dname in path:
        mpath = join(dname, mname)
        if exists(mpath):
            break
    else:
        log.debug("   PerlImportHandler.findModuleOnDisk: could not "
                  "find '%s' in path: %s", module, path)
        retval = (None, None, None)
        if CACHING:
            self._findModuleOnDiskCache[key] = (time.time(), retval)
        return retval
    log.debug("   PerlImportHandler.findModuleOnDisk: '%s' -&gt; '%s'",
              module, mpath)
    retval = (mpath,
              "module", # The "submodule"-thing isn't relevant in Perl
              True)     # only handling .pm files, so always scannable
    if CACHING:
        self._findModuleOnDiskCache[key] = (time.time(), retval)
    return retval

</t>
<t tx="ekr.20080121105837.1267">def findSubImportsOnDisk(self, module, cwd):
    path = self._getPath(cwd)
    mrelpath = module.replace("::", os.sep)
    subimports = {} # use a dict to get a unique list
    for dname in path:
        submodules = glob(join(dname, mrelpath, "*.pm"))
        for submodule in submodules:
            subimport = splitext(basename(submodule))[0]
            subimports[subimport] = 1
    return subimports.keys()

</t>
<t tx="ekr.20080121105837.1268">def _findScannableFiles(self,
                        (files, searchedDirs, skipTheseDirs, skipRareImports),
                        dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    if skipRareImports:
        # Skip .pl files when scanning a Perl lib/sitelib.
        scannableExts = (".pm",)
    else:
        scannableExts = (".pl", ".pm")
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = join(dirname, names[i])
        if isdir(path):
            if normcase(path) in skipTheseDirs:
                del names[i]
            elif skipRareImports and not ('A' &lt;= names[i][0] &lt;= 'Z'):
                # Perl good practice dictates that all module directories
                # begin with a capital letter. Therefore, we skip dirs
                # that start with a lower case.
                del names[i]
        elif splitext(names[i])[1] in scannableExts:
            #XXX The list of extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs.
            #XXX This check for files should probably include
            #    scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            files.append(path)

</t>
<t tx="ekr.20080121105837.1269">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        if dirname == os.curdir:
            # Do NOT traverse the common '.' element of @INC. It is
            # environment-dependent so not useful for the typical call
            # of this method.
            continue
        skipTheseDirs = [join(dirname, "auto")]
        skipTheseDirs = [normcase(d) for d in skipTheseDirs]
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs, skipTheseDirs,
                      skipRareImports))
        for file in files:
            yield file

</t>
<t tx="ekr.20080121105837.1270">def find_importables_in_dir(self, dir):
    """See citadel.py::ImportHandler.find_importables_in_dir() for
    details.

    Importables for Perl look like this:
        {"Shell": ("Shell.pm", None, False),
         "LWP":   ("LWP.pm",   None, True),
         "XML":   (None,       None, True)}

    Notes:
    - Drop the "auto" dir (it holds the binary module bits).
    - Keep non-capitalized dirs and modules (e.g. want "strict" in
      cplns for "use &lt;|&gt;").
    """
    from os.path import join, isdir, splitext

    if dir == "&lt;Unsaved&gt;":
        #TODO: stop these getting in here.
        return {}

    #TODO: log the fs-stat'ing a la codeintel.db logging.
    try:
        names = os.listdir(dir)
    except OSError, ex:
        return {}
    dirs, nondirs = set(), set()
    for name in names:
        if isdir(join(dir, name)):
            dirs.add(name)
        else:
            nondirs.add(name)

    importables = {}
    dirs.discard("auto")
    for name in nondirs:
        base, ext = splitext(name)
        if ext != ".pm":
            continue
        if base in dirs:
            importables[base] = (name, None, True)
            dirs.remove(base)
        else:
            importables[base] = (name, None, False)
    for name in dirs:
        importables[name] = (None, None, True)

    return importables


</t>
<t tx="ekr.20080121105837.1271">class PerlCILEDriver(CILEDriver):
    lang = lang
    @others
</t>
<t tx="ekr.20080121105837.1272">def __init__(self, mgr):
    CILEDriver.__init__(self, mgr)
    if gDoOldPerlWay:
        # Find the 'perlcile' executable to use as the Language Engine.
        dname = os.path.normpath(os.path.dirname(__file__))
        if sys.platform.startswith("win"):
            self.perlcile = os.path.join(dname, "perlcile.exe")
            self.scineplex = os.path.join(dname, "scineplex.exe")
        else:
            self.perlcile = os.path.join(dname, "perlcile")
            self.scineplex = os.path.join(dname, "scineplex")
        if not os.path.exists(self.perlcile):
            raise CodeIntelError("could not find the Perl CILE "
                                 "component '%s'\n" % self.perlcile)
        if not os.path.exists(self.scineplex):
            raise CodeIntelError("could not find the Perl CILE "
                                 "component '%s'\n" % self.scineplex)

</t>
<t tx="ekr.20080121105837.1273">def scan(self, request):
    request.calculateMD5()
    if gDoOldPerlWay:
        argv = [self.perlcile,
                "--scineplex", self.scineplex,
                "--filename", urlencode_path(request.path.encode('utf-8')),
                "--mtime", str(request.mtime),
                "--md5", request.md5sum]
        
        # Run language engine and report any errors.
        p = process.ProcessOpen(argv)
        content = line_end_re.sub("\n", request.content)
        p.stdin.write(content)
        p.stdin.close()
        # Lots of stderr output mixed with stdout can cause a full read of
        # stdout to block, presumably because of a full system stderr buffer.
        # There is probably a more correct fix at the process.py-level.
        p.stderr.close()
        stdout = p.stdout.read()
        p.close()
        return stdout.decode("utf-8")
    else:
        return perlcile.scan(request.content, request.path,
                             request.md5sum, request.mtime)

</t>
<t tx="ekr.20080121105837.1274">def scan_purelang(self, buf):
    return perlcile.scan_purelang(buf)

</t>
<t tx="ekr.20080121105837.1275">def scan_multilang(self, buf, csl_cile_driver=None):
    """Scan the given multilang (UDL-based) buffer and return a CIX
    element tree, and shuffle any CSL tokens to the CSL CileDriver.
    """
    tree = Element("codeintel", version="2.0")
    path = buf.path
    if sys.platform == "win32":
        path = path.replace('\\', '/')
    file_node = SubElement(tree, "file", lang=buf.lang, path=path)
    # module = SubElement(file_node, "scope", ilk="blob", lang="Perl", name=basename(path))
    csl_tokens, has_perl_code = perlcile.scan_multilang(buf.accessor.gen_tokens(), file_node)
    blob_node = file_node.getchildren()[0]
    if not has_perl_code:
        assert len(blob_node) == 0
        # The CILE clients don't want to hear there's no perl code in the buffer
        file_node.remove(blob_node)
    else:
        blob_node.set('name', basename(path))
    if csl_cile_driver and csl_tokens:
        csl_cile_driver.scan_csl_tokens(file_node, basename(buf.path),
                                        csl_tokens)
    return tree



</t>
<t tx="ekr.20080121105837.1276">#---- internal support stuff

def _is_perl_var_char(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" \
           or char in "_:$%@"



</t>
<t tx="ekr.20080121105837.1277">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PerlLexer(),
                      buf_class=PerlBuffer,
                      langintel_class=PerlLangIntel,
                      import_handler_class=PerlImportHandler,
                      cile_driver_class=PerlCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1278">@language python
@tabwidth -4
@others
@ignore</t>
<t tx="ekr.20080121105837.1279">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Shane Caraveo (ShaneC@ActiveState.com)
#   Trent Mick (TrentM@ActiveState.com)
#   Todd Whiteman (ToddW@ActiveState.com)

"""codeintel support for PHP"""

import os
from os.path import isdir, join
import sys
import md5
import re
import logging
import time
import warnings
from cStringIO import StringIO
import weakref
from os.path import basename, splitext
from glob import glob

from SilverCity.ScintillaConstants import (SCE_UDL_SSL_DEFAULT,
                                           SCE_UDL_SSL_OPERATOR,
                                           SCE_UDL_SSL_IDENTIFIER,
                                           SCE_UDL_SSL_WORD,
                                           SCE_UDL_SSL_VARIABLE,
                                           SCE_UDL_SSL_STRING,
                                           SCE_UDL_SSL_NUMBER,
                                           SCE_UDL_SSL_COMMENT,
                                           SCE_UDL_SSL_COMMENTBLOCK)

from codeintel2.parseutil import *
from codeintel2.citadel import ImportHandler
from codeintel2.udl import UDLBuffer, UDLLexer, UDLCILEDriver, is_udl_csl_style, XMLParsingBufferMixin
from codeintel2.common import *
from codeintel2 import util
from codeintel2.indexer import PreloadBufLibsRequest
from codeintel2.gencix_utils import *
from codeintel2.tree_php import PHPTreeEvaluator
from codeintel2.langintel import (LangIntel, ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)
from codeintel2.accessor import AccessorCache

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- global data

lang = "PHP"
log = logging.getLogger("codeintel.php")
#log.setLevel(logging.DEBUG)


#---- language support


# XXX later these need to be centralized.
# XXX - Move this crud!!
keywords = [
            # new to php5
            "public", "private", "protected", "final",
            "abstract", "interface", "implements",
            "try", "catch", "throw", "instanceof",
            # existed in php4
            "define", "true", "false", 
            "int", "integer", "real", "double",
            "float", "string",  "object", "bool", "boolean",
            "this", "self", "virtual", "parent", "null",
            # http://www.php.net/manual/en/reserved.php#reserved.keywords
            "and", "or", "xor", "__file__", "__line__",
            "array", "as", "break", "case", "cfunction",
            "class", "const", "continue", "declare"
            "default", "die", "do", "echo", "else",
            "elseif", "empty", "enddeclare", "endfor", "endforeach",
            "endif", "endswitch", "endwhile", "eval", "exit",
            "extends", "for", "foreach", "function", "global",
            "if", "include", "include_once", "isset", "list",
            "new", "old_function", "print", "require", "require_once",
            "return", "static", "switch", "unset", "use",
            "var", "while", "_function_", "_class_",
            # http://www.php.net/manual/en/reserved.constants.core.php
            "php_version",
            "php_os",
            "default_include_path",
            "pear_install_dir",
            "pear_extension_dir",
            "php_extension_dir",
            "php_bindir",
            "php_libdir",
            "php_datadir",
            "php_sysconfdir",
            "php_localstatedir",
            "php_config_file_path",
            "php_output_handler_start",
            "php_output_handler_cont",
            "php_output_handler_end",
            "e_error",
            "e_warning",
            "e_parse",
            "e_notice",
            "e_core_error",
            "e_core_warning",
            "e_compile_error",
            "e_compile_warning",
            "e_user_error",
            "e_user_warning",
            "e_user_notice",
            "e_all",
            # http://www.php.net/manual/en/reserved.constants.standard.php
            "extr_overwrite",
            "extr_skip",
            "extr_prefix_same",
            "extr_prefix_all",
            "extr_prefix_invalid",
            "extr_prefix_if_exists",
            "extr_if_exists",
            "sort_asc",
            "sort_desc",
            "sort_regular",
            "sort_numeric",
            "sort_string",
            "case_lower",
            "case_upper",
            "count_normal",
            "count_recursive",
            "assert_active",
            "assert_callback",
            "assert_bail",
            "assert_warning",
            "assert_quiet_eval",
            "connection_aborted",
            "connection_normal",
            "connection_timeout",
            "ini_user",
            "ini_perdir",
            "ini_system",
            "ini_all",
            "m_e",
            "m_log2e",
            "m_log10e",
            "m_ln2",
            "m_ln10",
            "m_pi",
            "m_pi_2",
            "m_pi_4",
            "m_1_pi",
            "m_2_pi",
            "m_2_sqrtpi",
            "m_sqrt2",
            "m_sqrt1_2",
            "crypt_salt_length",
            "crypt_std_des",
            "crypt_ext_des",
            "crypt_md5",
            "crypt_blowfish",
            "directory_separator",
            "seek_set",
            "seek_cur",
            "seek_end",
            "lock_sh",
            "lock_ex",
            "lock_un",
            "lock_nb",
            "html_specialchars",
            "html_entities",
            "ent_compat",
            "ent_quotes",
            "ent_noquotes",
            "info_general",
            "info_credits",
            "info_configuration",
            "info_modules",
            "info_environment",
            "info_variables",
            "info_license",
            "info_all",
            "credits_group",
            "credits_general",
            "credits_sapi",
            "credits_modules",
            "credits_docs",
            "credits_fullpage",
            "credits_qa",
            "credits_all",
            "str_pad_left",
            "str_pad_right",
            "str_pad_both",
            "pathinfo_dirname",
            "pathinfo_basename",
            "pathinfo_extension",
            "char_max",
            "lc_ctype",
            "lc_numeric",
            "lc_time",
            "lc_collate",
            "lc_monetary",
            "lc_all",
            "lc_messages",
            "abday_1",
            "abday_2",
            "abday_3",
            "abday_4",
            "abday_5",
            "abday_6",
            "abday_7",
            "day_1",
            "day_2",
            "day_3",
            "day_4",
            "day_5",
            "day_6",
            "day_7",
            "abmon_1",
            "abmon_2",
            "abmon_3",
            "abmon_4",
            "abmon_5",
            "abmon_6",
            "abmon_7",
            "abmon_8",
            "abmon_9",
            "abmon_10",
            "abmon_11",
            "abmon_12",
            "mon_1",
            "mon_2",
            "mon_3",
            "mon_4",
            "mon_5",
            "mon_6",
            "mon_7",
            "mon_8",
            "mon_9",
            "mon_10",
            "mon_11",
            "mon_12",
            "am_str",
            "pm_str",
            "d_t_fmt",
            "d_fmt",
            "t_fmt",
            "t_fmt_ampm",
            "era",
            "era_year",
            "era_d_t_fmt",
            "era_d_fmt",
            "era_t_fmt",
            "alt_digits",
            "int_curr_symbol",
            "currency_symbol",
            "crncystr",
            "mon_decimal_point",
            "mon_thousands_sep",
            "mon_grouping",
            "positive_sign",
            "negative_sign",
            "int_frac_digits",
            "frac_digits",
            "p_cs_precedes",
            "p_sep_by_space",
            "n_cs_precedes",
            "n_sep_by_space",
            "p_sign_posn",
            "n_sign_posn",
            "decimal_point",
            "radixchar",
            "thousands_sep",
            "thousep",
            "grouping",
            "yesexpr",
            "noexpr",
            "yesstr",
            "nostr",
            "codeset",
            "log_emerg",
            "log_alert",
            "log_crit",
            "log_err",
            "log_warning",
            "log_notice",
            "log_info",
            "log_debug",
            "log_kern",
            "log_user",
            "log_mail",
            "log_daemon",
            "log_auth",
            "log_syslog",
            "log_lpr",
            "log_news",
            "log_uucp",
            "log_cron",
            "log_authpriv",
            "log_local0",
            "log_local1",
            "log_local2",
            "log_local3",
            "log_local4",
            "log_local5",
            "log_local6",
            "log_local7",
            "log_pid",
            "log_cons",
            "log_odelay",
            "log_ndelay",
            "log_nowait",
            "log_perror"
            ]

PHP_KEYWORDS_LOOKUP = util.make_short_name_dict(keywords, length=2)

</t>
<t tx="ekr.20080121105837.1280">class PHPLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1281">class PHPLangIntel(LangIntel, ParenStyleCalltipIntelMixin,
                   ProgLangTriggerIntelMixin):
    # Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos()
    trg_chars = tuple('$&gt;:(, ')
    calltip_trg_chars = tuple('(')

    # named styles used by the class
    whitespace_style = SCE_UDL_SSL_DEFAULT
    operator_style   = SCE_UDL_SSL_OPERATOR
    identifier_style = SCE_UDL_SSL_IDENTIFIER
    keyword_style    = SCE_UDL_SSL_WORD
    variable_style   = SCE_UDL_SSL_VARIABLE
    ignore_styles    = (SCE_UDL_SSL_COMMENT, SCE_UDL_SSL_COMMENTBLOCK)
    # ignore_styles_ws, includes whitespace styles
    ignore_styles_ws = ignore_styles + (whitespace_style, )

    @others
</t>
<t tx="ekr.20080121105837.1282">def cb_variable_data_from_elem(self, elem):
    """Use the 'constant' image in the Code Browser for a variable constant.
    """
    data = LangIntel.cb_variable_data_from_elem(self, elem)
    if elem.get("ilk") == "constant":
        data["img"] = "constant"
    return data

</t>
<t tx="ekr.20080121105837.1283">def _functionCalltipTrigger(self, ac, pos, DEBUG=False):
    # Implicit calltip triggering from an arg separater ",", we trigger a
    # calltip if we find a function open paren "(" and function identifier
    #   http://bugs.activestate.com/show_bug.cgi?id=70470
    if DEBUG:
        print "Arg separater found, looking for start of function"
    # Move back to the open paren of the function
    paren_count = 0
    p = pos
    min_p = max(0, p - 200) # look back max 200 chars
    while p &gt; min_p:
        p, c, style = ac.getPrecedingPosCharStyle(ignore_styles=self.ignore_styles)
        if style == self.operator_style:
            if c == ")":
                paren_count += 1
            elif c == "(":
                if paren_count == 0:
                    # We found the open brace of the func
                    trg_from_pos = p+1
                    p, ch, style = ac.getPrevPosCharStyle()
                    if DEBUG:
                        print "Function start found, pos: %d" % (p, )
                    if style in self.ignore_styles_ws:
                        # Find previous non-ignored style then
                        p, c, style = ac.getPrecedingPosCharStyle(style, self.ignore_styles_ws)
                    if style in (self.identifier_style, self.keyword_style):
                        return Trigger(lang, TRG_FORM_CALLTIP,
                                       "call-signature",
                                       trg_from_pos, implicit=True)
                else:
                    paren_count -= 1
            elif c in ";{}":
                # Gone too far and noting was found
                if DEBUG:
                    print "No function found, hit stop char: %s at p: %d" % (c, p)
                return None
    # Did not find the function open paren
    if DEBUG:
        print "No function found, ran out of chars to look at, p: %d" % (p,)
    return None

</t>
<t tx="ekr.20080121105837.1284">#@util.hotshotit
def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False, ac=None):
    #DEBUG = True
    if pos &lt; 4:
        return None

    #DEBUG = True
    # Last four chars and styles
    if ac is None:
        ac = AccessorCache(buf.accessor, pos, fetchsize=4)
    last_pos, last_char, last_style = ac.getPrevPosCharStyle()
    prev_pos, prev_char, prev_style = ac.getPrevPosCharStyle()
    # Bump up how much text is retrieved when cache runs out
    ac.setCacheFetchSize(20)

    if DEBUG:
        print "\nphp trg_from_pos"
        print "  last_pos: %s" % last_pos
        print "  last_char: %s" % last_char
        print "  last_style: %r" % last_style
        ac.dump()

    try:
        if last_style == self.whitespace_style:
            if DEBUG:
                print "Whitespace style"
            WHITESPACE = tuple(" \t\n\r\v\f")
            if not implicit:
                # If we're not already at the keyword style, find it
                if prev_style != self.keyword_style:
                    prev_pos, prev_char, prev_style = ac.getPrecedingPosCharStyle(last_style, self.ignore_styles)
                    if DEBUG:
                        print "Explicit: prev_pos: %d, style: %d, ch: %r" % (prev_pos, prev_style, prev_char)
            else:
                prev_pos = pos - 2
            if last_char in WHITESPACE and \
                (prev_style == self.keyword_style or
                 (prev_style == self.operator_style and prev_char == ",")):
                p = prev_pos
                style = prev_style
                ch = prev_char
                #print "p: %d" % p
                while p &gt; 0 and style == self.operator_style and ch == ",":
                    p, ch, style = ac.getPrecedingPosCharStyle(style, self.ignore_styles_ws)
                    #print "p 1: %d" % p
                    if p &gt; 0 and style == self.identifier_style:
                        # Skip the identifier too
                        p, ch, style = ac.getPrecedingPosCharStyle(style, self.ignore_styles_ws)
                        #print "p 2: %d" % p
                if DEBUG:
                    ac.dump()
                p, text = ac.getTextBackWithStyle(style, self.ignore_styles, max_text_len=len("implements"))
                if DEBUG:
                    print "ac.getTextBackWithStyle:: pos: %d, text: %r" % (p, text)
                if text in ("new", "extends"):
                    return Trigger(lang, TRG_FORM_CPLN, "classes", pos, implicit)
                elif text in ("implements", ):
                    return Trigger(lang, TRG_FORM_CPLN, "interfaces", pos, implicit)
                elif prev_style == self.operator_style and \
                     prev_char == "," and implicit:
                    return self._functionCalltipTrigger(ac, prev_pos, DEBUG)
        elif last_style == self.operator_style:
            if DEBUG:
                print "  lang_style is operator style"
                print "Prev char: %r" % (prev_char)
                ac.dump()
            if last_char == ":":
                if not prev_char == ":":
                    return None
                ac.setCacheFetchSize(10)
                p, c, style = ac.getPrecedingPosCharStyle(prev_style, self.ignore_styles)
                if DEBUG:
                    print "Preceding: %d, %r, %d" % (p, c, style)
                if style is None:
                    return None
                elif style == self.keyword_style:
                    # Check if it's a "self::" or "parent::" expression
                    p, text = ac.getTextBackWithStyle(self.keyword_style,
                                                      # Ensure we don't go too far
                                                      max_text_len=6)
                    if DEBUG:
                        print "Keyword text: %d, %r" % (p, text)
                        ac.dump()
                    if text not in ("parent", "self"):
                        return None
                return Trigger(lang, TRG_FORM_CPLN, "static-members",
                               pos, implicit)
            elif last_char == "&gt;":
                if prev_char == "-":
                    p, c, style = ac.getPrecedingPosCharStyle(prev_style, self.ignore_styles)
                    if style in (self.variable_style, self.identifier_style):
                        return Trigger(lang, TRG_FORM_CPLN, "object-members",
                                       pos, implicit)
                    elif DEBUG:
                        print "Preceding style is not a variable, pos: %d, style: %d" % (p, style)
            elif last_char in "(,":
                # where to trigger from, updated by "," calltip handler
                if DEBUG:
                    print "Checking for function calltip"

                # Implicit calltip triggering from an arg separater ","
                #   http://bugs.activestate.com/show_bug.cgi?id=70470
                if implicit and last_char == ',':
                    return self._functionCalltipTrigger(ac, prev_pos, DEBUG)

                if prev_style in self.ignore_styles_ws:
                    # Find previous non-ignored style then
                    p, c, prev_style = ac.getPrecedingPosCharStyle(prev_style, self.ignore_styles_ws)
                if prev_style in (self.identifier_style, self.keyword_style):
                    return Trigger(lang, TRG_FORM_CALLTIP, "call-signature",
                                   pos, implicit)
        elif last_style == self.variable_style:
            if DEBUG:
                print "Variable style"
            # Completion for variables (builtins and user defined variables),
            # must occur after a "$" character.
            if not implicit and last_char == '$':
                # Explicit call, move ahead one for real trigger position
                pos += 1
            if not implicit or prev_char == "$":
                return Trigger(lang, TRG_FORM_CPLN, "variables",
                               pos-1, implicit)
        elif last_style in (self.identifier_style, self.keyword_style):
            if DEBUG:
                if last_style == self.identifier_style:
                    print "Identifier style"
                else:
                    print "Identifier keyword style"
            # Completion for keywords,function and class names
            # Works after first 3 characters have been typed
            #if DEBUG:
            #    print "identifier_style: pos - 4 %s" % (accessor.style_at_pos(pos - 4))
            #third_char, third_style = last_four_char_and_styles[2]
            #fourth_char, fourth_style = last_four_char_and_styles[3]
            if prev_style == last_style:
                trig_pos, ch, style = ac.getPrevPosCharStyle()
                if style == last_style:
                    p, ch, style = ac.getPrevPosCharStyle(ignore_styles=self.ignore_styles)
                    # style is None if no change of style (not ignored) was
                    # found in the last x number of chars
                    #if not implicit and style == last_style:
                    #    if DEBUG:
                    #        print "Checking back further for explicit call"
                    #    p, c, style = ac.getPrecedingPosCharStyle(style, max_look_back=100)
                    #    if p is not None:
                    #        trg_pos = p + 3
                    if style in (None, self.whitespace_style,
                                 self.operator_style):
                        # Ensure we are not in another trigger zone, we do
                        # this by checking that the preceeding text is not
                        # one of "-&gt;", "::", "new", "function", "class", ...
                        if style == self.whitespace_style:
                            p, c, style = ac.getPrecedingPosCharStyle(self.whitespace_style, max_look_back=30)
                        if style is None:
                            return Trigger(lang, TRG_FORM_CPLN, "functions",
                                           trig_pos, implicit)
                        prev_text = ac.getTextBackWithStyle(style, max_text_len=15)
                        if DEBUG:
                            print "prev_text: %r" % (prev_text, )
                        if prev_text[1] not in ("-&gt;", "::", "new", "function",
                                                "class", "interface", "implements",
                                                "public", "private", "protected",
                                                "final", "abstract", "instanceof",):
                            return Trigger(lang, TRG_FORM_CPLN, "functions",
                                           trig_pos, implicit)
                    # If we want implicit triggering on more than 3 chars
                    #elif style == self.identifier_style:
                    #    p, c, style = ac.getPrecedingPosCharStyle(self.identifier_style)
                    #    return Trigger(lang, TRG_FORM_CPLN, "functions",
                    #                   p+1, implicit)
                    elif DEBUG:
                        print "identifier preceeded by an invalid style: " \
                              "%r, p: %r" % (style, p, )

                elif last_char == '_' and prev_char == '_' and \
                     style == self.whitespace_style:
                    # XXX - Check the php version, magic methods only
                    #       appeared in php 5.
                    p, ch, style = ac.getPrevPosCharStyle(ignore_styles=self.ignore_styles)
                    if style == self.keyword_style and \
                       ac.getTextBackWithStyle(style, max_text_len=9)[1] == "function":
                        if DEBUG:
                            print "triggered:: complete magic-methods"
                        return Trigger(lang, TRG_FORM_CPLN, "magic-methods",
                                       prev_pos, implicit)
        elif DEBUG:
            print "trg_from_pos: no handle for style: %d" % last_style
    except IndexError:
        # Not enough chars found, therefore no trigger
        pass

    return None

</t>
<t tx="ekr.20080121105837.1285">#@util.hotshotit
def preceding_trg_from_pos(self, buf, pos, curr_pos,
                           preceding_trg_terminators=None, DEBUG=False):
    #DEBUG = True
    # Try the default preceding_trg_from_pos handler
    trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
            self, buf, pos, curr_pos, preceding_trg_terminators,
            DEBUG=DEBUG)
    if trg is not None:
        return trg

    # Else, let's try to work out some other options
    accessor = buf.accessor
    prev_style = accessor.style_at_pos(curr_pos - 1)
    if prev_style in (self.identifier_style, self.keyword_style):
        # We don't know what to trigger here... could be one of:
        # functions:
        #   apache&lt;$&gt;&lt;|&gt;_getenv()...
        #   if(get_e&lt;$&gt;&lt;|&gt;nv()...
        # classes:
        #   new Exce&lt;$&gt;&lt;|&gt;ption()...
        #   extends Exce&lt;$&gt;&lt;|&gt;ption()...
        # interfaces:
        #   implements apache&lt;$&gt;&lt;|&gt;_getenv()...
        ac = AccessorCache(accessor, curr_pos)
        pos_before_identifer, ch, prev_style = \
                 ac.getPrecedingPosCharStyle(prev_style)
        if DEBUG:
            print "\nphp preceding_trg_from_pos, first chance for identifer style"
            print "  curr_pos: %d" % (curr_pos)
            print "  pos_before_identifer: %d" % (pos_before_identifer)
            print "  ch: %r" % ch
            print "  prev_style: %d" % prev_style
            ac.dump()
        if pos_before_identifer &lt; pos:
            resetPos = min(pos_before_identifer + 4, accessor.length() - 1)
            ac.resetToPosition(resetPos)
            if DEBUG:
                print "preceding_trg_from_pos:: reset to position: %d, ac now:" % (resetPos)
                ac.dump()
            # Trigger on the third identifier character
            return self.trg_from_pos(buf, resetPos,
                                     implicit=False, DEBUG=DEBUG, ac=ac)
        elif DEBUG:
            print "Out of scope of the identifier"


</t>
<t tx="ekr.20080121105837.1286">#@util.hotshotit
def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    pos = trg.pos
    ctlr.start(buf, trg)
    #print "trg.type: %r" % (trg.type)
    if trg.type in ("classes", "interfaces"):
        # Triggers from zero characters, thus calling citdl_expr_from_trg
        # is no help
        line = buf.accessor.line_from_pos(pos)
        evalr = PHPTreeEvaluator(ctlr, buf, trg, "", line)
        buf.mgr.request_eval(evalr)
    else:
        try:
            citdl_expr = self.citdl_expr_from_trg(buf, trg)
        except CodeIntelError, ex:
            ctlr.error(str(ex))
            ctlr.done("error")
            return
        line = buf.accessor.line_from_pos(pos)
        evalr = PHPTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)

</t>
<t tx="ekr.20080121105837.1287">def _citdl_expr_from_pos(self, buf, pos, implicit=True,
                         include_forwards=False, DEBUG=False):
    #DEBUG = True
    #PERF: Would dicts be faster for all of these?
    WHITESPACE = tuple(" \t\n\r\v\f")
    EOL = tuple("\r\n")
    BLOCKCLOSES = tuple(")}]")
    STOPOPS = tuple("({[,&amp;$+=^|%/&lt;;:-&gt;!.@?")
    EXTRA_STOPOPS_PRECEDING_IDENT = BLOCKCLOSES # Might be others.

    #TODO: This style picking is a problem for the LangIntel move.
    if implicit:
        skip_styles = buf.implicit_completion_skip_styles
    else:
        skip_styles = buf.completion_skip_styles

    citdl_expr = []
    accessor = buf.accessor

    # Use a cache of characters, easy to keep track this way
    i = pos
    ac = AccessorCache(accessor, i)

    if include_forwards:
        try:
            # Move ahead to include forward chars as well
            lastch_was_whitespace = False
            while 1:
                i, ch, style = ac.getNextPosCharStyle()
                if DEBUG:
                    print "include_forwards:: i now: %d, ch: %r" % (i, ch)
                if ch in WHITESPACE:
                    lastch_was_whitespace = True
                    continue
                lastch_was_whitespace = False
                if ch in STOPOPS:
                    if DEBUG:
                        print "include_forwards:: ch in STOPOPS, i:%d ch:%r" % (i, ch)
                    break
                elif ch in BLOCKCLOSES:
                    if DEBUG:
                        print "include_forwards:: ch in BLOCKCLOSES, i:%d ch:%r" % (i, ch)
                    break
                elif lastch_was_whitespace:
                    # Two whitespace separated words
                    if DEBUG:
                        print "include_forwards:: ch separated by whitespace, i:%d ch:%r" % (i, ch)
                    break
            # Move back to last valid char
            i -= 1
            if DEBUG:
                if i &gt; pos:
                    print "include_forwards:: Including chars from pos %d up to %d" % (pos, i)
                else:
                    print "include_forwards:: No valid chars forward from pos %d, i now: %d" % (pos, i)
        except IndexError:
            # Nothing forwards, user what we have then
            i = min(i, accessor.length() - 1)
            if DEBUG:
                print "include_forwards:: No more buffer, i now: %d" % (i)
        ac.resetToPosition(i)

    ch = None
    try:
        while i &gt;= 0:
            if ch == None and include_forwards:
                i, ch, style = ac.getCurrentPosCharStyle()
            else:
                i, ch, style = ac.getPrevPosCharStyle()
            if DEBUG:
                print "i now: %d, ch: %r" % (i, ch)

            if ch in WHITESPACE:
                while ch in WHITESPACE:
                    # drop all whitespace
                    next_char = ch
                    i, ch, style = ac.getPrevPosCharStyle()
                    if ch in WHITESPACE \
                       or (ch == '\\' and next_char in EOL):
                        if DEBUG:
                            print "drop whitespace: %r" % ch
                # If there are two whitespace-separated words then this is
                # (likely or always?) a language keyword or declaration
                # construct at which we want to stop. E.g.
                #   if foo&lt;|&gt; and ...
                #   def foo&lt;|&gt;(...
                if citdl_expr and _isident(citdl_expr[-1]) \
                   and (_isident(ch) or _isdigit(ch)):
                    if DEBUG:
                        print "stop at (likely?) start of keyword or "\
                              "declaration: %r" % ch
                    break
                # Not whitespace anymore, move into the main checks below
                if DEBUG:
                    print "Out of whitespace: i now: %d, ch: %s" % (i, ch)

            if style in skip_styles: # drop styles to ignore
                while i &gt;= 0 and style in skip_styles:
                    i, ch, style = ac.getPrevPosCharStyle()
                    if DEBUG:
                        print "drop char of style to ignore: %r" % ch
            elif ch in ":&gt;" and i &gt; 0:
                # Next char has to be ":" or "-" respectively
                prev_pos, prev_ch, prev_style = ac.getPrevPosCharStyle()
                if (ch == "&gt;" and prev_ch == "-") or \
                   (ch == ":" and prev_ch == ":"):
                    citdl_expr.append(".")
                    if DEBUG:
                        print "Turning member accessor '%s%s' into '.'" % (prev_ch, ch)
                    i -= 2
                else:
                    if DEBUG:
                        print "citdl_expr: %r" % (citdl_expr)
                        print "stop at special stop-operator %d: %r" % (i, ch)
                    break
            elif (ch in STOPOPS or ch in EXTRA_STOPOPS_PRECEDING_IDENT) and \
                 (ch != ")" or (citdl_expr and citdl_expr[-1] != ".")):
                if DEBUG:
                    print "citdl_expr: %r" % (citdl_expr)
                    print "stop at stop-operator %d: %r" % (i, ch)
                break
            elif ch in BLOCKCLOSES:
                if DEBUG:
                    print "found block at %d: %r" % (i, ch)
                citdl_expr.append(ch)
    
                BLOCKS = { # map block close char to block open char
                    ')': '(',
                    ']': '[',
                    '}': '{',
                }
                stack = [] # stack of blocks: (&lt;block close char&gt;, &lt;style&gt;)
                stack.append( (ch, style, BLOCKS[ch], i) )
                while i &gt;= 0:
                    i, ch, style = ac.getPrevPosCharStyle()
                    if DEBUG:
                        print "finding matching brace: ch %r (%s), stack %r"\
                              % (ch, ', '.join(buf.style_names_from_style_num(style)), stack)
                    if ch in BLOCKS and style not in skip_styles:
                        stack.append( (ch, style, BLOCKS[ch]) )
                    elif ch == stack[-1][2] and style not in skip_styles:
                        #XXX Replace the second test with the following
                        #    when LexPython+SilverCity styling bugs are fixed
                        #    (spurious 'stderr' problem):
                        #       and style == stack[-1][1]:
                        stack.pop()
                        if not stack:
                            if DEBUG:
                                print "jump to matching brace at %d: %r" % (i, ch)
                            citdl_expr.append(ch)
                            break
                else:
                    # Didn't find the matching brace.
                    if DEBUG:
                        print "couldn't find matching brace"
                    raise EvalError("could not find matching brace for "
                                    "'%s' at position %d"
                                    % (stack[-1][0], stack[-1][3]))
    
            else:
                if DEBUG:
                    style_names = buf.style_names_from_style_num(style)
                    print "add char: %r (%s)" % (ch, ', '.join(style_names))
                citdl_expr.append(ch)
                i -= 1
    except IndexError:
        # Nothing left to consume, return what we have
        pass

    # Remove any unecessary starting dots
    while citdl_expr and citdl_expr[-1] == ".":
        citdl_expr.pop()
    citdl_expr.reverse()
    citdl_expr = ''.join(citdl_expr)
    if DEBUG:
        print "return: %r" % citdl_expr
        print util.banner("done")
    return citdl_expr

</t>
<t tx="ekr.20080121105837.1288">def citdl_expr_from_trg(self, buf, trg):
    """Return a PHP CITDL expression preceding the given trigger.

    The expression drops newlines, whitespace, and function call
    arguments -- basically any stuff that is not used by the codeintel
    database system for determining the resultant object type of the
    expression. For example (in which &lt;|&gt; represents the given position):
    
        GIVEN                       RETURN
        -----                       ------
        foo-&lt;|&gt;&gt;                    foo
        Foo:&lt;|&gt;:                    Foo
        foo(bar-&lt;|&gt;&gt;                bar
        foo(bar,blam)-&lt;|&gt;&gt;          foo()
        foo(bar,                    foo()
            blam)-&lt;|&gt;&gt;
        foo(arg1, arg2)-&gt;bar-&lt;|&gt;&gt;   foo().bar
        Foo(arg1, arg2)::bar-&lt;|&gt;&gt;   Foo().bar
    """
    #DEBUG = True
    DEBUG = False
    if DEBUG:
        print util.banner("%s citdl_expr_from_trg @ %r" % (buf.lang, trg))

    if trg.form == TRG_FORM_CPLN:
        # "-&gt;" or "::"
        if trg.type in ("classes"):
            i = trg.pos + 1
        elif trg.type in ("functions"):
            i = trg.pos + 3   # 3-char trigger, skip over it
        elif trg.type in ("variables"):
            i = trg.pos + 1   # triggered on the $, skip over it
        else:
            i = trg.pos - 2 # skip past the trigger char
        return self._citdl_expr_from_pos(buf, i, trg.implicit, DEBUG=DEBUG)
    elif trg.form == TRG_FORM_DEFN:
        return self.citdl_expr_under_pos(buf, trg.pos, DEBUG)
    else:   # trg.form == TRG_FORM_CALLTIP:
        # (&lt;|&gt;
        return self._citdl_expr_from_pos(buf, trg.pos-1, trg.implicit,
                                         DEBUG=DEBUG)

</t>
<t tx="ekr.20080121105837.1289">def citdl_expr_under_pos(self, buf, pos, DEBUG=False):
    """Return a PHP CITDL expression around the given pos.

    Similar to citdl_expr_from_trg(), but looks forward to grab additional
    characters.

        GIVEN                       RETURN
        -----                       ------
        foo-&lt;|&gt;&gt;                    foo
        F&lt;|&gt;oo::                    Foo
        foo-&gt;ba&lt;|&gt;r                 foo.bar
        f&lt;|&gt;oo-&gt;bar                 foo
        foo(bar-&lt;|&gt;&gt;                bar
        foo(bar,blam)-&lt;|&gt;&gt;          foo()
        foo(bar,                    foo()
            blam)-&lt;|&gt;&gt;
        foo(arg1, arg2)-&gt;bar-&lt;|&gt;&gt;   foo().bar
        Foo(arg1, arg2)::ba&lt;|&gt;r-&gt;   Foo().bar
        Fo&lt;|&gt;o(arg1, arg2)::bar-&gt;   Foo
    """
    #DEBUG = True
    expr = self._citdl_expr_from_pos(buf, pos-1, implicit=True,
                                     include_forwards=True, DEBUG=DEBUG)
    if expr:
        # Chop off any trailing "." characters
        return expr.rstrip(".")
    return expr


</t>
<t tx="ekr.20080121105837.1290">def libs_from_buf(self, buf):
    env = buf.env

    # A buffer's libs depend on its env and the buf itself so
    # we cache it on the env and key off the buffer.
    if "php-buf-libs" not in env.cache:
        env.cache["php-buf-libs"] = weakref.WeakKeyDictionary()
    cache = env.cache["php-buf-libs"] # &lt;buf-weak-ref&gt; -&gt; &lt;libs&gt;

    if buf not in cache:
        # - curdirlib
        # Using the dirname of this buffer isn't always right, but
        # hopefully is a good first approximation.
        cwd = dirname(buf.path)
        if cwd == "&lt;Unsaved&gt;":
            libs = []
        else:
            libs = [ self.mgr.db.get_lang_lib("PHP", "curdirlib",
                                      [dirname(buf.path)], "PHP") ]

        libs += self._buf_indep_libs_from_env(env)
        cache[buf] = libs
    return cache[buf]

</t>
<t tx="ekr.20080121105837.1291">def _php_from_env(self, env):
    import which
    path = [d.strip() 
            for d in env.get_envvar("PATH", "").split(os.pathsep)
            if d.strip()]
    for exe_name in ("php", "php4", "php-cgi", "php-cli"):
        try:
            return which.which(exe_name, path=path) 
        except which.WhichError:
            pass
    return None

</t>
<t tx="ekr.20080121105837.1292">def _php_info_from_php(self, php, env):
    """Call the given PHP and return:
        (&lt;version&gt;, &lt;include_path&gt;)
    Returns (None, []) if could not determine.
    """
    import process

    # Use a marker to separate the start of output from possible
    # leading lines of PHP loading errors/logging.
    marker = "--- Start of Good Stuff ---"
    info_cmd = (r'&lt;?php '
                + r'echo("%s\n");' % marker
                + r'echo(phpversion()."\n");'
                + r'echo(ini_get("include_path")."\n");'
                + r' ?&gt;')
    argv = [php]
    envvars = env.get_all_envvars()
    php_ini_path = env.get_pref("phpConfigFile")
    if php_ini_path:
        envvars["PHPRC"] = php_ini_path

    log.debug("run `%s &lt; ...'", php)
    p = process.ProcessOpen(argv, env=env.get_all_envvars())
    p.stdin.write(info_cmd)
    p.stdin.close()
    stdout_lines = p.stdout.read().splitlines(0)
    stderr = p.stderr.read()
    retval = p.wait()
    p.close()
    if retval:
        log.warn("failed to determine PHP info:\n"
                 "  path: %s\n"
                 "  retval: %s\n"
                 "  stdout:\n%s\n"
                 "  stderr:\n%s\n",
                 php, retval, util.indent('\n'.join(stdout_lines)),
                 util.indent(stderr))
        return None, []

    stdout_lines = stdout_lines[stdout_lines.index(marker)+1:]
    php_ver = stdout_lines[0]
    include_path = [p.strip() for p in stdout_lines[1].split(os.pathsep)
                    if p.strip()]

    return php_ver, include_path

</t>
<t tx="ekr.20080121105837.1293">def _extra_dirs_from_env(self, env):
    extra_dirs = set()
    proj_base_dir = env.get_proj_base_dir()
    if proj_base_dir is not None:
        extra_dirs.add(proj_base_dir)  # Bug 68850.
    for pref in env.get_all_prefs("phpExtraPaths"):
        if not pref: continue
        extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                          if exists(d.strip()))
    if extra_dirs:
        log.debug("PHP extra lib dirs: %r", extra_dirs)
        max_depth = env.get_pref("codeintel_max_recursive_dir_depth", 10)
        php_assocs = env.assoc_patterns_from_lang("PHP")
        extra_dirs = tuple(
            util.gen_dirs_under_dirs(extra_dirs,
                max_depth=max_depth,
                interesting_file_patterns=php_assocs)
        )
    else:
        extra_dirs = () # ensure retval is a tuple
    return extra_dirs

</t>
<t tx="ekr.20080121105837.1294">def _buf_indep_libs_from_env(self, env):
    """Create the buffer-independent list of libs."""
    cache_key = "php-libs"
    if cache_key not in env.cache:
        env.add_pref_observer("php", self._invalidate_cache)
        env.add_pref_observer("phpExtraPaths",
            self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("phpConfigFile",
                              self._invalidate_cache)
        env.add_pref_observer("codeintel_selected_catalogs",
                              self._invalidate_cache)
        env.add_pref_observer("codeintel_max_recursive_dir_depth",
                              self._invalidate_cache)
        # (Bug 68850) Both of these 'live_*' prefs on the *project*
        # prefset can result in a change of project base dir. It is
        # possible that we can false positives here if there is ever
        # a global pref of this name.
        env.add_pref_observer("import_live",
            self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("import_dirname",
            self._invalidate_cache_and_rescan_extra_dirs)

        db = self.mgr.db

        # Gather information about the current php.
        php = None
        if env.has_pref("php"):
            php = env.get_pref("php").strip() or None
        if not php or not exists(php):
            php = self._php_from_env(env)
        if not php:
            log.warn("no PHP was found from which to determine the "
                     "import path")
            php_ver, include_path = None, []
        else:
            php_ver, include_path \
                = self._php_info_from_php(php, env)
            
        libs = []

        # - extradirslib
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            libs.append( db.get_lang_lib("PHP", "extradirslib",
                                         extra_dirs, "PHP") )

        # - inilib (i.e. dirs in the include_path in PHP.ini)
        include_dirs = [d for d in include_path
                        if d != '.'  # handled separately
                        if exists(d)]
        if include_dirs:
            max_depth = env.get_pref("codeintel_max_recursive_dir_depth", 10)
            php_assocs = env.assoc_patterns_from_lang("PHP")
            include_dirs = tuple(
                util.gen_dirs_under_dirs(include_dirs,
                    max_depth=max_depth,
                    interesting_file_patterns=php_assocs)
            )
            if include_dirs:
                libs.append( db.get_lang_lib("PHP", "inilib",
                                             include_dirs, "PHP") )

        # Warn the user if there is a huge number of import dirs that
        # might slow down completion.
        num_import_dirs = len(extra_dirs) + len(include_dirs)
        if num_import_dirs &gt; 100:
            db.report_event("This buffer is configured with %d PHP "
                            "import dirs: this may result in poor "
                            "completion performance" % num_import_dirs)

        # - cataloglib, stdlib
        catalog_selections = env.get_pref("codeintel_selected_catalogs")
        libs += [
            db.get_catalog_lib("PHP", catalog_selections),
            db.get_stdlib("PHP", php_ver)
        ]
        env.cache[cache_key] = libs

    return env.cache[cache_key]

</t>
<t tx="ekr.20080121105837.1295">def _invalidate_cache(self, env, pref_name):
    for key in ("php-buf-libs", "php-libs"):
        if key in env.cache:
            log.debug("invalidate '%s' cache on %r", key, env)
            del env.cache[key]

</t>
<t tx="ekr.20080121105837.1296">def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
    self._invalidate_cache(env, pref_name)
    extra_dirs = self._extra_dirs_from_env(env)
    if extra_dirs:
        extradirslib = self.mgr.db.get_lang_lib(
            "PHP", "extradirslib", extra_dirs)
        request = PreloadLibRequest(extradirslib)
        self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1297">#---- code browser integration
cb_import_group_title = "Includes and Requires"   

def cb_import_data_from_elem(self, elem):
    #XXX Not handling symbol and alias
    module = elem.get("module")
    detail = 'include "%s"' % module
    return {"name": module, "detail": detail}


</t>
<t tx="ekr.20080121105837.1298">class PHPBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "PHP"

    cb_show_if_empty = True

    #cpln_fillup_chars = "" #XXX none for now, should probably add some.
    # Fillup chars for PHP: basically, any non-identifier char.
    #cpln_fillup_chars = "("
    cpln_fillup_chars = ""
    #TODO: c.f. cpln_stop_chars stuff in lang_html.py
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    cpln_stop_chars = "~`!@#$%^&amp;*()-=+{}]|\\;:'\",.&lt;&gt;?/ "

    @others
</t>
<t tx="ekr.20080121105837.1299">def __init__(self, *args, **kwargs):
    super(PHPBuffer, self).__init__(*args, **kwargs)

    # Encourage the database to pre-scan dirs relevant to completion
    # for this buffer -- because of recursive-dir-include-everything
    # semantics for PHP this first-time scan can take a while.
    request = PreloadBufLibsRequest(self)
    self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1300">@property
def libs(self):
    return self.langintel.libs_from_buf(self)

</t>
<t tx="ekr.20080121105837.1301">@property
def stdlib(self):
    return self.libs[-1]


</t>
<t tx="ekr.20080121105837.1302">class PHPImportHandler(ImportHandler):
    sep = '/'

    @others
</t>
<t tx="ekr.20080121105837.1303">def setCorePath(self, compiler=None, extra=None):
    #XXX To do this independent of Komodo this would need to do all
    #    the garbage that koIPHPInfoEx is doing to determine this. It
    #    might also require adding a "rcfile" argument to this method
    #    so the proper php.ini file is used in the "_shellOutForPath".
    #    This is not crucial now because koCodeIntel._Manager() handles
    #    this for us.
    if not self.corePath:
        raise CodeIntelError("Do not know how to determine the core "
                             "PHP include path. 'corePath' must be set "
                             "manually.")

</t>
<t tx="ekr.20080121105837.1304">def _findScannableFiles(self, (files, searchedDirs), dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = os.path.join(dirname, names[i])
        if os.path.isdir(path):
            pass
        elif os.path.splitext(names[i])[1] in (".php", ".inc",
                                               ".module", ".tpl"):
            #XXX The list of extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs. ".module" and ".tpl" are for
            #    drupal-nerds until CodeIntel gets this right.
            #XXX This check for files should probably include
            #    scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            files.append(path)

</t>
<t tx="ekr.20080121105837.1305">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        if dirname == os.curdir:
            # Do NOT traverse '.' if it is in the include_path. Not sure
            # if this is at all common for PHP.
            continue
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs))
        for file in files:
            yield file

</t>
<t tx="ekr.20080121105837.1306">def find_importables_in_dir(self, dir):
    """See citadel.py::ImportHandler.find_importables_in_dir() for
    details.

    Importables for PHP look like this:
        {"foo.php": ("foo.php", None, False),
         "bar.inc": ("bar.inc", None, False),
         "somedir": (None,      None, True)}

    TODO: log the fs-stat'ing a la codeintel.db logging.
    """
    from os.path import join, isdir
    from fnmatch import fnmatch

    if dir == "&lt;Unsaved&gt;":
        #TODO: stop these getting in here.
        return {}

    try:
        names = os.listdir(dir)
    except OSError, ex:
        return {}
    dirs, nondirs = set(), set()
    for name in names:
        if isdir(join(dir, name)):
            dirs.add(name)
        else:
            nondirs.add(name)

    importables = {}
    patterns = self.mgr.env.assoc_patterns_from_lang("PHP")
    for name in nondirs:
        for pattern in patterns:
            if fnmatch(name, pattern):
                break
        else:
            continue
        if name in dirs:
            importables[name] = (name, None, True)
            dirs.remove(name)
        else:
            importables[name] = (name, None, False)
    for name in dirs:
        importables[name] = (None, None, True)
    return importables


</t>
<t tx="ekr.20080121105837.1307">class PHPCILEDriver(UDLCILEDriver):
    lang = lang
    ssl_lang = "PHP"
    csl_lang = "JavaScript"

    @others
</t>
<t tx="ekr.20080121105837.1308">def XXXscan_purelang(self, buf):
  try:
    #XXX Remove md5sum and mtime when move to CIX 2.0.
    mtime = "XXX"
    phpciler = PHPParser(buf.path, buf.accessor.text, mtime)
    phpciler.scan_multilang_content(buf.accessor.text)
    # Get the CIX tree.
    tree = createCixRoot()
    phpciler.convertToElementTreeFile(tree)
    return tree
  except Exception, e:
      import traceback
      traceback.print_exc()
      raise

</t>
<t tx="ekr.20080121105837.1309">def scan_multilang(self, buf, csl_cile_driver=None):
  #try:
    """Scan the given multilang (UDL-based) buffer and return a CIX
    element tree.

        "buf" is the multi-lang Buffer instance (e.g.
            lang_rhtml.RHTMLBuffer for RHTML).
        "csl_cile_driver" (optional) is the CSL (client-side language)
            CILE driver. While scanning, CSL tokens should be gathered and,
            if any, passed to the CSL scanner like this:
                csl_cile_driver.scan_csl_tokens(
                    file_elem, blob_name, csl_tokens)
            The CSL scanner will append a CIX &lt;scope ilk="blob"&gt; element
            to the &lt;file&gt; element.
    """
    # Create the CIX tree.
    mtime = "XXX"
    fullpath = buf.path
    cixtree = createCixRoot()
    cixfile = createCixFile(cixtree, fullpath, lang=buf.lang)
    if sys.platform.startswith("win"):
        fullpath = fullpath.replace('\\', '/')
    basepath = os.path.basename(fullpath)
    cixblob = createCixModule(cixfile, basepath, "PHP", src=fullpath)

    phpciler = PHPParser(fullpath, buf.accessor.text, mtime)
    csl_tokens = phpciler.scan_multilang_content(buf.accessor.text)
    phpciler.convertToElementTreeModule(cixblob)

    # Hand off the csl tokens if any
    if csl_cile_driver and csl_tokens:
        csl_cile_driver.scan_csl_tokens(cixfile, basepath, csl_tokens)

    return cixtree

  #except Exception, e:
  #    print "\nPHP cile exception"
  #    import traceback
  #    traceback.print_exc()
  #    print
  #    raise



</t>
<t tx="ekr.20080121105837.1310">#---- internal routines and classes


# States used by PHP scanner when parsing information
S_DEFAULT = 0
S_IN_ARGS = 1
S_IN_ASSIGNMENT = 2
S_IGNORE_SCOPE = 3
S_OBJECT_ARGUMENT = 4
S_GET_HEREDOC_MARKER = 5
S_IN_HEREDOC = 6
# Special tags for multilang handling (i.e. through UDL)
S_OPEN_TAG  = 10
S_CHECK_CLOSE_TAG = 11
S_IN_SCRIPT = 12

# Types used by JavaScriptScanner when parsing information
TYPE_NONE = 0
TYPE_FUNCTION = 1
TYPE_VARIABLE = 2
TYPE_GETTER = 3
TYPE_SETTER = 4
TYPE_MEMBER = 5
TYPE_OBJECT = 6
TYPE_CLASS = 7
TYPE_PARENT = 8


def _sortByLineCmp(val1, val2):
    try:
    #if hasattr(val1, "line") and hasattr(val2, "line"):
        return cmp(val1.linestart, val2.linestart)
    except AttributeError:
        return cmp(val1, val2)

</t>
<t tx="ekr.20080121105837.1311">def sortByLine(seq):
    seq.sort(_sortByLineCmp)
    return seq


</t>
<t tx="ekr.20080121105837.1312">class PHPArgs:
    @others
</t>
<t tx="ekr.20080121105837.1313">def __init__(self, arglist, typelist=None, optionalArgs=None):
    """Set function arguments:
@param arglist {list} of argument names
@param typelist {list} of argument types
@param optionalArgs {list} of lists [arg name, arg default value, arg type]
"""
    if arglist is None:
        arglist = []
    if optionalArgs is None:
        optionalArgs = []
    self.args = arglist
    self.typelist = typelist
    self.optionalArgs = optionalArgs
    arglineValues = arglist[:]
    for optArg, optArgValue, optArgType in optionalArgs:
        arglineValues.append("%s=%s" % (optArg, optArgValue))
    self.argline = ", ".join(arglineValues)

</t>
<t tx="ekr.20080121105837.1314">def __repr__(self):
    args = []
    for arg in self.args:
        args.append(repr(arg))
    return string.join(args, ', ')

</t>
<t tx="ekr.20080121105837.1315">def toElementTree(self, cixelement):
    for argIndex in range(len(self.args)):
        arg = self.args[argIndex]
        typename = None
        if self.typelist:
            typename = self.typelist[argIndex]
        addCixArgument(cixelement, arg, argtype=typename)
    for optArg, optArgValue, optArgType in self.optionalArgs:
        cixarg = addCixArgument(cixelement, optArg, argtype=optArgType)
        cixarg.attrib["default"] = optArgValue


</t>
<t tx="ekr.20080121105837.1316">class PHPVariable:
    @others
</t>
<t tx="ekr.20080121105837.1317">def __init__(self, name, line, vartype='', attributes=''):
    self.name = name
    self.types = [(line, vartype)]
    self.linestart = line
    if attributes:
        if not isinstance(attributes, list):
            attributes = attributes.strip().split()
        self.attributes = ' '.join(attributes)
    else:
        self.attributes = None

</t>
<t tx="ekr.20080121105837.1318">def addType(self, line, type):
    self.types.append((line, type))

</t>
<t tx="ekr.20080121105837.1319">def __repr__(self):
    return "var %s line %s type %s attributes %s\n"\
           % (self.name, self.linestart, self.types, self.attributes)

</t>
<t tx="ekr.20080121105837.1320">def toElementTree(self, cixblob):
    vartype = None
    # Work out the best vartype
    if self.types:
        d = {}
        max_count = 0
        for line, vtype in self.types:
            if vtype:
                count = d.get(vtype, 0) + 1
                d[vtype] = count
                if count &gt; max_count:
                    # Best found so far
                    vartype = vtype
                    max_count = count
    cixelement = createCixVariable(cixblob, self.name, vartype=vartype,
                                   attributes=self.attributes)
    cixelement.attrib["line"] = str(self.linestart)
    return cixelement

</t>
<t tx="ekr.20080121105837.1321">class PHPConstant(PHPVariable):
    @others
</t>
<t tx="ekr.20080121105837.1322">def __init__(self, name, line, vartype=''):
    PHPVariable.__init__(self, name, line, vartype)

</t>
<t tx="ekr.20080121105837.1323">def __repr__(self):
    return "constant %s line %s type %s\n"\
           % (self.name, self.linestart, self.types)

</t>
<t tx="ekr.20080121105837.1324">def toElementTree(self, cixblob):
    cixelement = PHPVariable.toElementTree(self, cixblob)
    cixelement.attrib["ilk"] = "constant"
    return cixelement

</t>
<t tx="ekr.20080121105837.1325">class PHPFunction:
    @others
</t>
<t tx="ekr.20080121105837.1326">def __init__(self, funcname, args, optionalArgs, lineno, depth=0,
             attributes=None, doc=None, classname='', classparent='',
             returnType=None):
    self.name = funcname
    self.linestart = lineno
    self.lineend = None
    self.depth = depth
    self.classname = classname
    self.classparent = classparent
    self.returnType = returnType
    self.variables = {} # all variables used in class
    # build the signature before we add any attributes that are not part
    # of the signature
    self.signature = '%s' % (self.name)
    if attributes:
        attrs = ' '.join(attributes)
        self.shortSig = '%s %s' % (attrs, self.name)
    else:
        self.shortSig = self.name
    # both php 4 and 5 constructor methods
    if funcname == '__construct' or (classname and funcname.lower() == classname.lower()):
        attributes.append('__ctor__')
# if we add destructor attributes...
#        elif funcname == '__destruct':
#            attributes += ['__dtor__']
    self.attributes = ' '.join(attributes)
    self.doc = None

    # Setup the function arguments
    if args:
        argTypes = [None] * len(args)
    else:
        argTypes = []
    if doc:
        if isinstance(doc, list):
            doc = "".join(doc)
        docinfo = parseDocString(doc)
        self.doc = docinfo[0]
        if docinfo[1]:
            for argInfo in docinfo[1]:
                try:
                    argIndex = args.index(argInfo[1])
                    argTypes[argIndex] = argInfo[0]
                except ValueError:
                    # No such element, see if it's an optional argument
                    for optArgInfo in optionalArgs:
                        if optArgInfo[0] == argInfo[1]:
                            optArgInfo[2] = argInfo[0]
                            break
                    else:
                        args.append(argInfo[1])
                        argTypes.append(argInfo[0])
        if docinfo[2]:
            self.returnType = docinfo[2][0]
    self.signature += "("
    if args or optionalArgs:
        self.args = PHPArgs(args, argTypes, optionalArgs)
        self.signature += self.args.argline
    else:
        self.args = None
    self.signature += ")"

</t>
<t tx="ekr.20080121105837.1327">def addReturnType(self, returnType):
    if self.returnType is None:
        self.returnType = returnType

</t>
<t tx="ekr.20080121105837.1328">def __str__(self):
    return self.signature
    # The following is busted and outputting multiple lines from __str__
    # and __repr__ is bad form: make debugging prints hard.
    #if self.doc:
    #    if self.args:
    #        return "%s(%s)\n%s" % (self.shortSig, self.args.argline, self.doc)
    #    else:
    #        return "%s()\n%s" % (self.shortSig, self.doc)
    #return "%s(%s)" % (self.shortSig, self.argline)

</t>
<t tx="ekr.20080121105837.1329">def __repr__(self):
    return self.signature

</t>
<t tx="ekr.20080121105837.1330">def toElementTree(self, cixblob):
    cixelement = createCixFunction(cixblob, self.name,
                                   attributes=self.attributes)
    cixelement.attrib["line"] = str(self.linestart)
    if self.lineend is not None:
        cixelement.attrib['lineend'] = str(self.lineend)
    setCixSignature(cixelement, self.signature)
    if self.doc:
        setCixDoc(cixelement, self.doc)
    if self.args:
        self.args.toElementTree(cixelement)
    if self.returnType:
        addCixReturns(cixelement, self.returnType)
    # Add a "this" and "self" member for class functions
    #if self.classname:
    #    createCixVariable(cixelement, "this", vartype=self.classname)
    #    createCixVariable(cixelement, "self", vartype=self.classname)
    # Add a "parent" member for class functions that have a parent
    #if self.classparent:
    #    createCixVariable(cixelement, "parent", vartype=self.classparent)

    # XXX for variables inside functions
    for v in self.variables.values():
        v.toElementTree(cixelement)

</t>
<t tx="ekr.20080121105837.1331">class PHPInterface:
    @others
</t>
<t tx="ekr.20080121105837.1332">def __init__(self, name, extends, lineno, depth, doc=None):
    self.name = name
    self.extends = extends
    self.linestart = lineno
    self.lineend = None
    self.depth = depth
    self.constants = {} # declared class constants
    self.members = {} # declared class variables
    self.variables = {} # all variables used in class
    self.functions = {}
    self.doc = None
    if doc:
        self.doc = uncommentDocString(doc)

</t>
<t tx="ekr.20080121105837.1333">def __repr__(self):
    # dump our contents to human readable form
    r = "INTERFACE %s" % self.name
    if self.extends:
        r += " EXTENDS %s" % self.extends
    r += '\n'

    if self.constants:
        r += "Constants:\n"
        for m in self.constants:
            r += "    var %s line %s\n"  % (m, self.constants[m])

    if self.members:
        r += "Members:\n"
        for m in self.members:
            r += "    var %s line %s\n"  % (m, self.members[m])

    if self.functions:            
        r += "functions:\n"
        for f in self.functions.values():
            r += "    %r" % f

    if self.variables:
        r += "variables:\n"
        for v in self.variables.values():
            r += "    %r" % v
        
    return r + '\n'

</t>
<t tx="ekr.20080121105837.1334">def toElementTree(self, cixblob):
    cixelement = createCixInterface(cixblob, self.name)
    cixelement.attrib["line"] = str(self.linestart)
    if self.lineend is not None:
        cixelement.attrib["lineend"] = str(self.lineend)
    signature = "%s" % (self.name)
    if self.extends:
        signature += " extends %s" % (self.extends)
        for name in self.extends.split(","):
            addInterfaceRef(cixelement, name.strip())
        #SubElement(cixelement, "classref", name=self.extends)
    cixelement.attrib["signature"] = signature

    if self.doc:
        setCixDoc(self.doc)

    allValues = self.functions.values() + self.constants.values() + \
                self.members.values() + self.variables.values()
    for v in sortByLine(allValues):
        v.toElementTree(cixelement)

</t>
<t tx="ekr.20080121105837.1335">class PHPClass:
    @others
</t>
<t tx="ekr.20080121105837.1336">def __init__(self, name, extends, lineno, depth, attributes=None,
             interfaces=None, doc=None):
    self.name = name
    self.extends = extends
    self.linestart = lineno
    self.lineend = None
    self.depth = depth
    self.constants = {} # declared class constants
    self.members = {} # declared class variables
    self.variables = {} # all variables used in class
    self.functions = {}
    if interfaces:
        self.interfaces = interfaces.split(',')
    else:
        self.interfaces = []
    if attributes:
        self.attributes = ' '.join(attributes)
    else:
        self.attributes = None
    self.doc = None
    if doc:
        if isinstance(doc, list):
            doc = "".join(doc)
        self.doc = uncommentDocString(doc)

</t>
<t tx="ekr.20080121105837.1337">def __repr__(self):
    # dump our contents to human readable form
    r = "CLASS %s" % self.name
    if self.extends:
        r += " EXTENDS %s" % self.extends
    r += '\n'

    if self.constants:
        r += "Constants:\n"
        for m in self.constants:
            r += "    var %s line %s\n"  % (m, self.constants[m])

    if self.members:
        r += "Members:\n"
        for m in self.members:
            r += "    var %s line %s\n"  % (m, self.members[m])

    if self.functions:            
        r += "functions:\n"
        for f in self.functions.values():
            r += "    %r" % f

    if self.variables:
        r += "variables:\n"
        for v in self.variables.values():
            r += "    %r" % v
        
    return r + '\n'

</t>
<t tx="ekr.20080121105837.1338">def toElementTree(self, cixblob):
    cixelement = createCixClass(cixblob, self.name)
    cixelement.attrib["line"] = str(self.linestart)
    if self.lineend is not None:
        cixelement.attrib["lineend"] = str(self.lineend)
    if self.attributes:
        cixelement.attrib["attributes"] = self.attributes

    if self.doc:
        setCixDoc(cixelement, self.doc)

    if self.extends:
        addClassRef(cixelement, self.extends)

    for i in self.interfaces:
        addInterfaceRef(cixelement, i.strip())

    allValues = self.functions.values() + self.constants.values() + \
                self.members.values() + self.variables.values()
    for v in sortByLine(allValues):
        v.toElementTree(cixelement)

</t>
<t tx="ekr.20080121105837.1339">class PHPFile:
    """CIX specifies that a &lt;file&gt; tag have zero or more
    &lt;scope ilk="blob"&gt; children.  In PHP this is a one-to-one
    relationship, so this class represents both (and emits the XML tags
    for both).
    """
    @others
</t>
<t tx="ekr.20080121105837.1340">def __init__(self, filename, content=None, mtime=None):
    self.filename = filename
    self.content = content
    self.mtime = mtime
    self.error = None
    
    self.content = content
    if mtime is None:
        self.mtime = int(time.time())

    self.functions = {} # functions declared in file
    self.classes = {} # classes declared in file
    self.variables = {} # all variables used in file
    self.constants = {} # all constants used in file
    self.includes = {} # files included into this file
    self.interfaces = {} # interfaces declared in file

</t>
<t tx="ekr.20080121105837.1341">def __repr__(self):
    # dump our contents to human readable form
    r = "FILE %s\n" % self.filename

    for f, l in self.includes.items():
        r += "include %s on line %d\n" % (f, l)

    r += "constants:\n"
    for v in self.constants.values():
        r += "    %r" % v

    r += "functions:\n"
    for f in self.functions.values():
        r += "    %r" % f

    r += "variables:\n"
    for v in self.variables.values():
        r += "    %r" % v

    r += "classes:\n"
    for c in self.classes.values():
        r += repr(c)

    return r + '\n'

</t>
<t tx="ekr.20080121105837.1342">def convertToElementTreeModule(self, cixmodule):
    for fn in self.includes:
        SubElement(cixmodule, "import", module=fn, line=str(self.includes[fn]))

    allValues = self.constants.values() + self.functions.values() + \
                self.interfaces.values() + self.variables.values() + \
                self.classes.values()
    for v in sortByLine(allValues):
        v.toElementTree(cixmodule)

</t>
<t tx="ekr.20080121105837.1343">def convertToElementTreeFile(self, cix):
    if sys.platform.startswith("win"):
        path = self.filename.replace('\\', '/')
    else:
        path = self.filename
    cixfile = createCixFile(cix, path, lang="PHP", mtime=str(self.mtime))
    if self.error:
        cixfile.attrib["error"] = self.error
    cixmodule = createCixModule(cixfile, os.path.basename(self.filename),
                                "PHP")
    self.convertToElementTreeModule(cixmodule)

</t>
<t tx="ekr.20080121105837.1344">class PHPcile:
    @others
</t>
<t tx="ekr.20080121105837.1345">def __init__(self):
    # filesparsed contains all files parsed
    self.filesparsed={}
    # needfile contains a list of files included by the file that is the key
    self.needfile={}
    # infile contains a list of files that the key file is included in 
    self.infile={}
    # classindex tells us what file a class definition is contained in
    self.classindex={}
    # functionindex tells us what file a function is defined in
    self.functionindex={}
    # interfaceindex tells us what file an interface definition is contained in
    self.interfaceindex={}

</t>
<t tx="ekr.20080121105837.1346">def _clearindex(self, filename, index):
    tmp = [k for k in index if index[k] == filename]
    for k in tmp:
        del index[k]
    
</t>
<t tx="ekr.20080121105837.1347">def clear(self, filename):
    # clear include links from the cache
    if filename not in self.filesparsed:
        return
    del self.filesparsed[filename]
    
    if filename in self.needfile:
        for f in self.needfile[filename]:
            i = self.infile[f].index(filename)
            del self.infile[f][i]
        del self.needfile[filename]
    
    self._clearindex(filename, self.classindex)
    self._clearindex(filename, self.functionindex)
    self._clearindex(filename, self.interfaceindex)
    
</t>
<t tx="ekr.20080121105837.1348">def __repr__(self):
    r = ''
    for f in self.filesparsed:
        r += repr(self.filesparsed[f])
    return r + '\n'

</t>
<t tx="ekr.20080121105837.1349">#def toElementTree(self, cix):
#    for f in self.filesparsed.values():
#        f.toElementTree(cix)

def convertToElementTreeModule(self, cixmodule):
    for f in self.filesparsed.values():
        f.convertToElementTreeModule(cixmodule)

</t>
<t tx="ekr.20080121105837.1350">def convertToElementTreeFile(self, cix):
    for f in self.filesparsed.values():
        f.convertToElementTreeFile(cix)


</t>
<t tx="ekr.20080121105837.1351">class PHPParser:

    PHP_COMMENT_STYLES = (SCE_UDL_SSL_COMMENT, SCE_UDL_SSL_COMMENTBLOCK)

    @others
</t>
<t tx="ekr.20080121105837.1352">def __init__(self, filename, content=None, mtime=None):
    self.filename = filename
    self.cile = PHPcile()
    self.fileinfo = PHPFile(self.filename, content, mtime)

    # Working variables, used in conjunction with state
    self.classStack = []
    self.currentClass = None
    self.currentInterface = None
    self.currentFunction = None
    self.csl_tokens = []
    self.lineno = 0
    self.depth = 0
    self.styles = []
    self.linenos = []
    self.text = []
    self.comment = []
    self.heredocMarker = None

    # state : used to store the current JS lexing state
    # return_to_state : used to store JS state to return to
    # multilang_state : used to store the current UDL lexing state
    self.state = S_DEFAULT
    self.return_to_state = S_DEFAULT
    self.multilang_state = S_DEFAULT

    self.PHP_WORD        = SCE_UDL_SSL_WORD
    self.PHP_IDENTIFIER  = SCE_UDL_SSL_IDENTIFIER
    self.PHP_VARIABLE    = SCE_UDL_SSL_VARIABLE
    self.PHP_OPERATOR    = SCE_UDL_SSL_OPERATOR
    self.PHP_STRINGS     = (SCE_UDL_SSL_STRING,)
    self.PHP_NUMBER      = SCE_UDL_SSL_NUMBER

    # XXX bug 44775
    # having the next line after scanData below causes a crash on osx
    # in python's UCS2 to UTF8.  leaving this here for later
    # investigation, see bug 45362 for details.
    self.cile.filesparsed[self.filename] = self.fileinfo

</t>
<t tx="ekr.20080121105837.1353">def idfunc(self, m):
    log.debug("ID: %r",m.group(0))
    return m.group(0)

</t>
<t tx="ekr.20080121105837.1354"># parses included files
def include_file(self, filename):
    # XXX Very simple prevention of include looping.  Really should
    # recurse the indices to make sure we are not creating a loop
    if self.filename == filename:
        return ""

    # add the included file to our list of included files
    if filename not in self.fileinfo.includes:
        self.fileinfo.includes[filename] = self.lineno

    # add the included file to our list of included files
    if self.filename not in self.cile.needfile:
        self.cile.needfile[self.filename] = []
    try:
        self.cile.needfile[self.filename].index(filename)
    except ValueError, e:
        self.cile.needfile[self.filename].append(filename)

    # add this file to the infile list
    if filename not in self.cile.infile:
        self.cile.infile[filename] = []
    try:
        self.cile.infile[filename].index(self.filename)
    except ValueError, e:
        self.cile.infile[filename].append(self.filename)

</t>
<t tx="ekr.20080121105837.1355">def incBlock(self):
    self.depth = self.depth+1
    # log.debug("depth at %d", self.depth)

</t>
<t tx="ekr.20080121105837.1356">def decBlock(self):
    self.depth = self.depth-1
    # log.debug("depth at %d", self.depth)
    if self.currentClass and self.currentClass.depth == self.depth:
        # log.debug("done with class %s at depth %d", self.currentClass.name, self.depth)
        self.currentClass.lineend = self.lineno
        self.currentClass = self.classStack.pop()
    if self.currentInterface and self.currentInterface.depth == self.depth:
        # log.debug("done with interface %s at depth %d", self.currentClass.name, self.depth)
        self.currentInterface.lineend = self.lineno
        self.currentInterface = None
    elif self.currentFunction and self.currentFunction.depth == self.depth:
        self.currentFunction.lineend = self.lineno
        # XXX stacked functions used to work in php, need verify still is
        self.currentFunction = None

</t>
<t tx="ekr.20080121105837.1357">def addFunction(self, name, args=None, optionalArgs=None, attributes=None,
                doc=None):
    log.debug("FUNC: %s(%r %r) on line %d", name, args, optionalArgs, self.lineno)
    classname = ''
    extendsName = ''
    if self.currentClass:
        classname = self.currentClass.name
        extendsName = self.currentClass.extends
    elif self.currentInterface:
        classname = self.currentInterface.name
        extendsName = self.currentInterface.extends
    self.currentFunction = PHPFunction(name,
                                       args,
                                       optionalArgs,
                                       self.lineno,
                                       self.depth,
                                       attributes=attributes,
                                       doc=doc,
                                       classname=classname,
                                       classparent=extendsName)
    if self.currentClass:
        self.currentClass.functions[self.currentFunction.name] = self.currentFunction
    elif self.currentInterface:
        self.currentInterface.functions[self.currentFunction.name] = self.currentFunction
    else:
        self.fileinfo.functions[self.currentFunction.name] = self.currentFunction
        self.cile.functionindex[self.currentFunction.name] = self.fileinfo.filename
    if self.currentInterface or self.currentFunction.attributes.find('abstract') &gt;= 0:
        self.currentFunction.lineend = self.lineno
        self.currentFunction = None

</t>
<t tx="ekr.20080121105837.1358">def addReturnType(self, typeName):
    if self.currentFunction:
        log.debug("RETURN TYPE: %r on line %d", typeName, self.lineno)
        self.currentFunction.addReturnType(typeName)
    else:
        log.debug("addReturnType: No current function for return value!?")

</t>
<t tx="ekr.20080121105837.1359">def addClass(self, name, extends=None, attributes=None, interfaces=None, doc=None):
    if name not in self.fileinfo.classes:
        # push the current class onto the class stack
        self.classStack.append(self.currentClass)
        # make this class the current class
        self.currentClass = PHPClass(name,
                                     extends,
                                     self.lineno,
                                     self.depth,
                                     attributes,
                                     interfaces,
                                     doc=doc)
        self.fileinfo.classes[self.currentClass.name] = self.currentClass
        # log.debug("adding classindex[%s]=%s", m.group('name'), self.fileinfo.filename)
        self.cile.classindex[self.currentClass.name]=self.fileinfo.filename
        log.debug("CLASS: %s extends %s interfaces %s attributes %s on line %d in %s at depth %d\nDOCS: %s",
                 self.currentClass.name, self.currentClass.extends, 
                 self.currentClass.interfaces, self.currentClass.attributes,
                 self.currentClass.linestart, self.filename, self.depth,
                 self.currentClass.doc)
    else:
        # shouldn't ever get here
        pass

</t>
<t tx="ekr.20080121105837.1360">def addClassMember(self, name, vartype, attributes=None, doc=None, forceToClass=False):
    if self.currentFunction and not forceToClass:
        if name not in self.currentFunction.variables:
            phpVariable = self.currentClass.members.get(name)
            if phpVariable is None:
                log.debug("Class FUNC variable: %r", name)
                self.currentFunction.variables[name] = PHPVariable(name,
                                                                   self.lineno,
                                                                   vartype)
            elif vartype:
                log.debug("Adding type information for VAR: %r, vartype: %r",
                          name, vartype)
                phpVariable.addType(self.lineno, vartype)
    elif self.currentClass:
        phpVariable = self.currentClass.members.get(name)
        if phpVariable is None:
            log.debug("CLASSMBR: %r", name)
            self.currentClass.members[name] = PHPVariable(name, self.lineno,
                                                          vartype,
                                                          attributes)
        elif vartype:
            log.debug("Adding type information for CLASSMBR: %r, vartype: %r",
                      name, vartype)
            phpVariable.addType(self.lineno, vartype)

</t>
<t tx="ekr.20080121105837.1361">def addClassConstant(self, name, vartype, doc=None):
    """Add a constant variable into the current class."""

    if self.currentClass:
        phpConstant = self.currentClass.constants.get(name)
        if phpConstant is None:
            log.debug("CLASS CONST: %r", name)
            self.currentClass.constants[name] = PHPConstant(name, self.lineno,
                                                          vartype)
        elif vartype:
            log.debug("Adding type information for CLASS CONST: %r, "
                      "vartype: %r", name, vartype)
            phpConstant.addType(self.lineno, vartype)

</t>
<t tx="ekr.20080121105837.1362">def addInterface(self, name, extends=None, doc=None):
    if name not in self.fileinfo.classes:
        # push the current class onto the class stack
        self.classStack.append(self.currentClass)
        # make this class the current class
        self.currentInterface = PHPInterface(name,extends, self.lineno, self.depth)
        self.fileinfo.interfaces[name] = self.currentInterface
        # log.debug("adding classindex[%s]=%s", name, self.fileinfo.filename)
        self.cile.interfaceindex[name] = self.fileinfo.filename
        log.debug("INTERFACE: %s extends %s on line %d in %s at depth %d",
                 name, extends, self.lineno, self.filename, self.depth)
    else:
        # shouldn't ever get here
        pass

</t>
<t tx="ekr.20080121105837.1363">def addVariable(self, name, vartype='', attributes=None, doc=None):
    log.debug("VAR: %r type: %r on line %d", name, vartype, self.lineno)
    if self.currentFunction:
        phpVariable = self.currentFunction.variables.get(name)
        if phpVariable is None:
            self.currentFunction.variables[name] = PHPVariable(name, self.lineno, vartype, attributes)
        elif vartype:
            log.debug("Adding type information for VAR: %r, vartype: %r",
                      name, vartype)
            phpVariable.addType(self.lineno, vartype)
    elif self.currentClass:
        pass
        # XXX this variable is local to a class method, what to do with it?
        #if m.group('name') not in self.currentClass.variables:
        #    self.currentClass.variables[m.group('name')] =\
        #        PHPVariable(m.group('name'), self.lineno)
    else:
        phpVariable = self.fileinfo.variables.get(name)
        if phpVariable is None:
            self.fileinfo.variables[name] = PHPVariable(name, self.lineno, vartype, attributes)
        elif vartype:
            log.debug("Adding type information for VAR: %r, vartype: %r",
                      name, vartype)
            phpVariable.addType(self.lineno, vartype)

</t>
<t tx="ekr.20080121105837.1364">def addConstant(self, name, vartype='', doc=None):
    """Add a constant at the global scope level."""

    log.debug("CONSTANT: %r type: %r on line %d", name, vartype, self.lineno)
    phpConstant = self.fileinfo.constants.get(name)
    # Add it if it's not already defined
    if phpConstant is None:
        if vartype and isinstance(vartype, (list, tuple)):
            vartype = ".".join(vartype)
        self.fileinfo.constants[name] = PHPConstant(name, self.lineno,
                                                    vartype)

</t>
<t tx="ekr.20080121105837.1365">def _getArgumentsFromPos(self, styles, text, pos):
    """Return a tuple (arguments, optional arguments, next position)
    
    arguments: list of argument names
    optional arguments: list of lists [arg name, arg default value, arg type]
    """

    # Arguments can be of the form:
    #  foo($a, $b, $c)
    #  foo(&amp;$a, &amp;$b, &amp;$c)
    #  foo($a, &amp;$b, $c)
    #  foo($a = "123")
    #  makecoffee($types = array("cappuccino"), $coffeeMaker = NULL)

    log.debug("_getArgumentsFromPos: text: %r", text[pos:])
    if pos &lt; len(styles) and styles[pos] == self.PHP_OPERATOR and text[pos] == "(":
        ids = []
        optionals = []
        pos += 1
        start_pos = pos
        while pos &lt; len(styles):
            if styles[pos] == self.PHP_VARIABLE:
                varname = self._removeDollarSymbolFromVariableName(text[pos])
                if pos + 3 &lt; len(styles) and text[pos+1] == "=":
                    # It's an optional argument
                    valueType, p = self._getVariableType(styles, text, pos+1)
                    if valueType:
                        valueType = valueType[0]
                    if valueType == "array" and text[pos+3] == "(":
                        # special handling for array initializers
                        value_pos = pos+2
                        pos = self._skipPastParenArguments(styles, text, pos+4)
                        if pos &lt; len(styles):
                            optionals.append([varname, "".join(text[value_pos:pos]), valueType])
                    else:
                        optionals.append([varname, text[pos+2], valueType])
                        pos += 2
                else:
                    ids.append(varname)
            elif styles[pos] != self.PHP_OPERATOR or text[pos] not in "&amp;,":
                break
            pos += 1
        return ids, optionals, pos
    return None, None, pos

</t>
<t tx="ekr.20080121105837.1366">def _getIdentifiersFromPos(self, styles, text, pos, identifierStyle=None):
    if identifierStyle is None:
        identifierStyle = self.PHP_IDENTIFIER
    log.debug("_getIdentifiersFromPos: text: %r", text[pos:])
    start_pos = pos
    ids = []
    last_style = self.PHP_OPERATOR
    while pos &lt; len(styles):
        style = styles[pos]
        #print "Style: %d, Text[%d]: %r" % (style, pos, text[pos])
        if style == identifierStyle:
            if last_style != self.PHP_OPERATOR:
                break
            ids.append(text[pos])
        elif style == self.PHP_OPERATOR:
            t = text[pos]
            if ((t != "&amp;" or last_style != self.PHP_OPERATOR) and \
                (t != ":" or last_style != identifierStyle)):
                break
        else:
            break
        pos += 1
        last_style = style
    return ids, pos

</t>
<t tx="ekr.20080121105837.1367">def _skipPastParenArguments(self, styles, text, p):
    paren_count = 1
    while p &lt; len(styles):
        if styles[p] == self.PHP_OPERATOR:
            if text[p] == "(":
                paren_count += 1
            elif text[p] == ")":
                if paren_count == 1:
                    return p+1
                paren_count -= 1
        p += 1
    return p

</t>
<t tx="ekr.20080121105837.1368">def _getVariableType(self, styles, text, p, assignmentChar="="):
    """Set assignmentChar to None to skip over looking for this char first"""

    log.debug("_getVariableType: text: %r", text[p:])
    typeNames = []
    if p+1 &lt; len(styles) and (assignmentChar is None or \
                              (styles[p] == self.PHP_OPERATOR and \
                               text[p] == assignmentChar)):
        # Assignment to the variable
        if assignmentChar is not None:
            p += 1
            if p+1 &gt;= len(styles):
                return typeNames, p

        if styles[p] == self.PHP_OPERATOR and text[p] == '&amp;':
            log.debug("_getVariableType: skipping over reference char '&amp;'")
            p += 1
            if p+1 &gt;= len(styles):
                return typeNames, p

        if styles[p] == self.PHP_WORD:
            # Keyword
            keyword = text[p]
            p += 1
            if keyword == "new":
                typeNames, p = self._getIdentifiersFromPos(styles, text, p)
                #if not typeNames:
                #    typeNames = ["object"]
            elif keyword in ("true", "false"):
                typeNames = ["boolean"];
            elif keyword == "array":
                typeNames = ["array()"];
        elif styles[p] in self.PHP_STRINGS:
            p += 1
            typeNames = ["string"]
        elif styles[p] == self.PHP_NUMBER:
            p += 1
            typeNames = ["int"]
        elif styles[p] == self.PHP_IDENTIFIER:
            # PHP Uses mixed upper/lower case for boolean values.
            if text[p].lower() in ("true", "false"):
                p += 1
                typeNames = ["boolean"]
            else:
                typeNames, p = self._getIdentifiersFromPos(styles, text, p)
                # Don't record null, as it doesn't help us with anything
                if typeNames == ["NULL"]:
                    typeNames = []
                elif typeNames and p &lt; len(styles) and \
                   styles[p] == self.PHP_OPERATOR and text[p][0] == "(":
                    typeNames[-1] += "()"
        elif styles[p] == self.PHP_VARIABLE:
            typeNames, p = self._getIdentifiersFromPos(styles, text, p, self.PHP_VARIABLE)
            if typeNames:
                typeNames[0] = self._removeDollarSymbolFromVariableName(typeNames[0])
            log.debug("p: %d, text left: %r", p, text[p:])
            # Grab additional fields
            # Example: $x = $obj&lt;p&gt;-&gt;getFields()-&gt;field2
            while p+2 &lt; len(styles) and styles[p] == self.PHP_OPERATOR and \
                  text[p] in (":-&gt;"):
                p += 1
                log.debug("while:: p: %d, text left: %r", p, text[p:])
                if styles[p] == self.PHP_IDENTIFIER:
                    additionalNames, p = self._getIdentifiersFromPos(styles, text, p)
                    log.debug("p: %d, additionalNames: %r", p, additionalNames)
                    if additionalNames:
                        typeNames.append(additionalNames[0])
                        if p &lt; len(styles) and \
                           styles[p] == self.PHP_OPERATOR and text[p][0] == "(":
                            typeNames[-1] += "()"
                            p = self._skipPastParenArguments(styles, text, p+1)
                            log.debug("_skipPastParenArguments:: p: %d, text left: %r", p, text[p:])
                
    return typeNames, p

</t>
<t tx="ekr.20080121105837.1369">def _getKeywordArguments(self, styles, text, p, keywordName):
    arguments = None
    while p &lt; len(styles):
        if styles[p] == self.PHP_WORD and text[p] == keywordName:
            # Grab the definition
            p += 1
            arguments = []
            last_style = self.PHP_OPERATOR
            while p &lt; len(styles):
                if styles[p] == self.PHP_IDENTIFIER and \
                   last_style == self.PHP_OPERATOR:
                    arguments.append(text[p])
                elif styles[p] != self.PHP_OPERATOR or text[p] != ",":
                    break
                last_style = styles[p]
                p += 1
            arguments = ", ".join(arguments)
            break
        p += 1
    return arguments

</t>
<t tx="ekr.20080121105837.1370">def _getExtendsArgument(self, styles, text, p):
    return self._getKeywordArguments(styles, text, p, "extends")

</t>
<t tx="ekr.20080121105837.1371">def _getImplementsArgument(self, styles, text, p):
    return self._getKeywordArguments(styles, text, p, "implements")

</t>
<t tx="ekr.20080121105837.1372">def _unquoteString(self, s):
    """Return the string without quotes around it"""
    if len(s) &gt;= 2 and s[0] in "\"'":
        return s[1:-1]
    return s

</t>
<t tx="ekr.20080121105837.1373">def _removeDollarSymbolFromVariableName(self, name):
    if name[0] == "$":
        return name[1:]
    return name

</t>
<t tx="ekr.20080121105837.1374">def _getIncludePath(self, styles, text, p):
    """Work out the include string and return it (without the quotes)"""

    # Some examples (include has identical syntax):
    #   require 'prepend.php';
    #   require $somefile;
    #   require ('somefile.txt');
    # From bug: http://bugs.activestate.com/show_bug.cgi?id=64208
    # We just find the first string and use that
    #   require_once(CEON_CORE_DIR . 'core/datatypes/class.CustomDT.php');
    # Skip over first brace if it exists
    if p &lt; len(styles) and \
       styles[p] == self.PHP_OPERATOR and text[p] == "(":
        p += 1
    while p &lt; len(styles):
        if styles[p] in self.PHP_STRINGS:
            requirename = self._unquoteString(text[p])
            if requirename:
                # Return with the first string found, we could do better...
                return requirename
        p += 1
    return None

</t>
<t tx="ekr.20080121105837.1375">def _getConstantNameAndType(self, styles, text, p):
    """Work out the constant name and type is, returns these as tuple"""

    # Some examples (include has identical syntax):
    #   define('prepend', 1);
    #   define ('somefile', "file.txt");
    constant_name = None
    constant_type = None
    if p+4 &lt; len(styles) and \
       styles[p] == self.PHP_OPERATOR and text[p] == "(" and \
       styles[p+1] in self.PHP_STRINGS:
        constant_name = self._unquoteString(text[p+1])
        if text[p+2] == ",":
            constant_type, p = self._getVariableType(styles, text, p+3,
                                                     assignmentChar=None)
    return constant_name, constant_type

</t>
<t tx="ekr.20080121105837.1376">def _addAllVariables(self, styles, text, p):
    while p &lt; len(styles):
        if styles[p] == self.PHP_VARIABLE:
            namelist, p = self._getIdentifiersFromPos(styles, text, p, self.PHP_VARIABLE)
            if len(namelist) == 1:
                name = self._removeDollarSymbolFromVariableName(namelist[0])
                # Don't add special internal variable names
                if name in ("this", "self"):
                    # Lets see what we are doing with this
                    if p+3 &lt; len(styles) and "".join(text[p:p+2]) in ("-&gt;", "::"):
                        # Get the variable the code is accessing
                        namelist, p = self._getIdentifiersFromPos(styles, text, p+2)
                        typeNames, p = self._getVariableType(styles, text, p)
                        if len(namelist) == 1 and typeNames:
                            log.debug("Assignment through %r for variable: %r", name, namelist)
                            self.addClassMember(namelist[0],
                                                ".".join(typeNames),
                                                doc=self.comment,
                                                forceToClass=True)
                elif name is not "parent":
                    # If next text/style is not an "=" operator, then add
                    # __not_defined__, which means the variable was not yet
                    # defined at the position it was ciled.
                    attributes = None
                    if p &lt; len(styles) and text[p] != "=":
                        attributes = "__not_yet_defined__"
                    self.addVariable(name, attributes=attributes)
        p += 1

</t>
<t tx="ekr.20080121105837.1377">def _variableHandler(self, styles, text, p, attributes, doc=None,
                     style="variable"):
    log.debug("_variableHandler:: style: %r, text: %r, attributes: %r",
              style, text[p:], attributes)
    classVar = False
    if attributes:
        classVar = True
        if "var" in attributes:
            attributes.remove("var")  # Don't want this in cile output
    if style == "const":
        if self.currentClass is None:
            log.debug("Ignoring const %r, as not defined in a "
                      "class context.", text)
            return
        classVar = True
    looped = False
    while p &lt; len(styles):
        if looped:
            if text[p] != ",":  # Variables need to be comma delimited.
                p += 1
                continue
            p += 1
        else:
            looped = True
        if style == "const":
            namelist, p = self._getIdentifiersFromPos(styles, text, p,
                                                      self.PHP_IDENTIFIER)
        else:
            namelist, p = self._getIdentifiersFromPos(styles, text, p,
                                                      self.PHP_VARIABLE)
        if not namelist:
            break
        log.debug("namelist:%r, p:%d", namelist, p)
        # Remove the dollar sign
        name = self._removeDollarSymbolFromVariableName(namelist[0])
        # Parse special internal variable names
        if name == "parent":
            continue
        if name in ("this", "self", ):
            classVar = True
            if p+3 &lt; len(styles) and text[p:p+2] in (["-", "&gt;"], [":", ":"]):
                namelist, p = self._getIdentifiersFromPos(styles, text, p+2,
                                                          self.PHP_IDENTIFIER)
                log.debug("namelist:%r, p:%d", namelist, p)
                if not namelist:
                    continue
                name = namelist[0]
            else:
                continue
        if len(namelist) != 1:
            log.info("warn: invalid variable namelist (ignoring): "
                     "%r, line: %d in file: %r", namelist,
                     self.lineno, self.filename)
            continue

        assignChar = text[p]
        typeNames = []
        # Work out the citdl
        if p+1 &lt; len(styles) and styles[p] == self.PHP_OPERATOR and \
                                     assignChar in "=":
            # Assignment to the variable
            typeNames, p = self._getVariableType(styles, text, p, assignChar)
            log.debug("typeNames: %r", typeNames)
            # Skip over paren arguments from class, function calls.
            if typeNames and p &lt; len(styles) and \
               styles[p] == self.PHP_OPERATOR and text[p] == "(":
                p = self._skipPastParenArguments(styles, text, p+1)

        # Create the variable cix information.
        if p &lt; len(styles) and styles[p] == self.PHP_OPERATOR and \
                                     text[p] in ",;":
            log.debug("Line %d, variable definition: %r",
                     self.lineno, namelist)
            if style == "const":
                self.addClassConstant(name, ".".join(typeNames),
                                      doc=self.comment)
            elif classVar and self.currentClass is not None:
                self.addClassMember(name, ".".join(typeNames),
                                    attributes=attributes, doc=self.comment)
            else:
                self.addVariable(name, ".".join(typeNames),
                                 attributes=attributes, doc=self.comment)

</t>
<t tx="ekr.20080121105837.1378">def _addCodePiece(self, newstate=S_DEFAULT, varnames=None):
    styles = self.styles
    if len(styles) == 0:
        return
    text = self.text
    lines = self.linenos

    log.debug("*** Line: %d ********************************", self.lineno)
    #log.debug("Styles: %r", self.styles)
    log.debug("Text: %r", self.text)
    #log.debug("Comment: %r", self.comment)
    #log.debug("")

    pos = 0
    attributes = []
    firstStyle = styles[pos]

    try:
        # Eat special attribute keywords
        while firstStyle == self.PHP_WORD and \
              text[pos] in ("var", "public", "protected", "private",
                            "final", "static", "abstract"):
            attributes.append(text[pos])
            pos += 1
            firstStyle = styles[pos]

        if firstStyle == self.PHP_WORD:
            keyword = text[pos]
            pos += 1
            if pos &gt;= len(lines):
                # Nothing else here, go home
                return
            self.lineno = lines[pos]
            if keyword in ("require", "include", "require_once", "include_once"):
                # Some examples (include has identical syntax):
                # require 'prepend.php';
                # require $somefile;
                # require ('somefile.txt');
                # XXX - Below syntax is not handled...
                # if ((include 'vars.php') == 'OK') {
                namelist = None
                if pos &lt; len(styles):
                    requirename = self._getIncludePath(styles, text, pos)
                    if requirename:
                        self.include_file(requirename)
                    else:
                        log.debug("Could not work out requirename. Text: %r",
                                  text[pos:])
            elif keyword == "define":
                # Defining a constant
                #   define("FOO",     "something");
                #   define('TEST_CONSTANT', FALSE);
                name, citdl = self._getConstantNameAndType(styles, text, pos)
                if name:
                    self.addConstant(name, citdl)

            elif keyword == "const":
                # Defining a class constant
                #   const myconstant = x;
                self._variableHandler(styles, text, pos, attributes,
                                      doc=self.comment, style="const")

            elif keyword == "function":
                namelist, p = self._getIdentifiersFromPos(styles, text, pos)
                log.debug("namelist:%r, p:%d", namelist, p)
                if namelist:
                    args, optionals, p = self._getArgumentsFromPos(styles, text, p)
                    log.debug("Line %d, function: %r(%r, optionals: %r)",
                             self.lineno, namelist, args, optionals)
                    if len(namelist) != 1:
                        log.info("warn: invalid function name (ignoring): "
                                 "%r, line: %d in file: %r", namelist,
                                 self.lineno, self.filename)
                        return
                    self.addFunction(namelist[0], args, optionals, attributes, doc=self.comment)
            elif keyword == "class":
                # Examples:
                #   class SimpleClass {
                #   class SimpleClass2 extends SimpleClass {
                #   class MyClass extends AbstractClass implements TestInterface, TestMethodsInterface {
                #
                namelist, p = self._getIdentifiersFromPos(styles, text, pos)
                if namelist and "{" in text:
                    if len(namelist) != 1:
                        log.info("warn: invalid class name (ignoring): %r, "
                                 "line: %d in file: %r", namelist,
                                 self.lineno, self.filename)
                        return
                    extends = self._getExtendsArgument(styles, text, p)
                    implements = self._getImplementsArgument(styles, text, p)
                    #print "extends: %r" % (extends)
                    #print "implements: %r" % (implements)
                    self.addClass(namelist[0], extends=extends,
                                  attributes=attributes,
                                  interfaces=implements, doc=self.comment)
            elif keyword == "interface":
                # Examples:
                #   interface Foo {
                #   interface SQL_Result extends SeekableIterator, Countable {
                #
                namelist, p = self._getIdentifiersFromPos(styles, text, pos)
                if namelist and "{" in text:
                    if len(namelist) != 1:
                        log.info("warn: invalid interface name (ignoring): "
                                 "%r, line: %d in file: %r", namelist,
                                 self.lineno, self.filename)
                        return
                    extends = self._getExtendsArgument(styles, text, p)
                    self.addInterface(namelist[0], extends, doc=self.comment)
            elif keyword == "return":
                # Returning value for a function call
                #   return 123;
                #   return $x;
                typeNames, p = self._getVariableType(styles, text, pos, assignmentChar=None)
                log.debug("typeNames:%r", typeNames)
                if typeNames:
                    self.addReturnType(".".join(typeNames))
            else:
                log.debug("Ignoring keyword: %s", keyword)
                self._addAllVariables(styles, text, pos)

        elif firstStyle == self.PHP_IDENTIFIER:
            log.debug("Ignoring when starting with identifier")
        elif firstStyle == self.PHP_VARIABLE:
            # Defining scope for action
            self._variableHandler(styles, text, pos, attributes,
                                  doc=self.comment)
        else:
            log.debug("Unhandled first style:%d", firstStyle)
    finally:
        self._resetState(newstate)

</t>
<t tx="ekr.20080121105837.1379">def _resetState(self, newstate=S_DEFAULT):
    self.state = newstate
    self.styles = []
    self.linenos = []
    self.text = []
    self.comment = []

</t>
<t tx="ekr.20080121105837.1380">def token_next(self, style, text, start_column, start_line, **other_args):
    """Loops over the styles in the document and stores important info.
    
    When enough info is gathered, will perform a call to analyze the code
    and generate subsequent language structures. These language structures
    will later be used to generate XML output for the document."""
    #log.debug("text: %r", text)

    if self.state == S_GET_HEREDOC_MARKER:
        if not text.strip():
            log.debug("Ignoring whitespace after &lt;&lt;&lt;: %r", text)
            return
        self.heredocMarker = text
        log.debug("getting heredoc marker: %r, now in heredoc state", text)
        self._resetState(S_IN_HEREDOC)

    elif self.state == S_IN_HEREDOC:
        # Heredocs *must* be on the start of a newline
        if text == self.heredocMarker and self.lastText and \
           self.lastText[-1] in "\r\n":
            log.debug("end of heredoc: %r", self.heredocMarker)
            self._resetState(self.return_to_state)
        else:
            log.debug("ignoring heredoc material")

    elif (style in (self.PHP_WORD, self.PHP_IDENTIFIER,
                  self.PHP_OPERATOR, self.PHP_NUMBER, self.PHP_VARIABLE) or
        style in (self.PHP_STRINGS)):
        # We keep track of these styles and the text associated with it.
        # When we gather enough info, these will be sent to the
        # _addCodePiece() function which will analyze the info.
        self.lineno = start_line + 1

        if style != self.PHP_OPERATOR:
            # Have to trim whitespace, as the identifier style is
            # also the default whitespace style... ugly!
            if style == self.PHP_IDENTIFIER:
                text = text.strip()
            if text:
                self.text.append(text)
                self.styles.append(style)
                self.linenos.append(self.lineno)
                #print "Text:", text
        else:
            # Do heredoc parsing, since UDL cannot as yet
            if text == "&lt;&lt;&lt;":
                self.return_to_state = self.state
                self.state = S_GET_HEREDOC_MARKER
            # Remove out any "&lt;?php" and "?&gt;" tags, see syntax description:
            #   http://www.php.net/manual/en/language.basic-syntax.php
            elif text.startswith("&lt;?"):
                if text.startswith("&lt;?php"):
                    text = text[len("&lt;?php"):]
                elif text.startswith("&lt;?="):
                    text = text[len("&lt;?="):]
                else:
                    text = text[len("&lt;?"):]
            elif text.startswith("&lt;%"):
                if text.startswith("&lt;%="):
                    text = text[len("&lt;%="):]
                else:
                    text = text[len("&lt;%"):]
            if text.endswith("?&gt;"):
                text = text[:-len("?&gt;")]
            elif text.endswith("&lt;%"):
                text = text[:-len("%&gt;")]

            col = start_column + 1
            #for op in text:
            #    self.styles.append(style)
            #    self.text.append(op)
            #log.debug("token_next: line %d, %r" % (self.lineno, text))
            for op in text:
                self.styles.append(style)
                self.text.append(op)
                self.linenos.append(self.lineno)
                if op == "(":
                    # We can start defining arguments now
                    #log.debug("Entering S_IN_ARGS state")
                    self.return_to_state = self.state
                    self.state = S_IN_ARGS
                elif op == ")":
                    #log.debug("Entering state %d", self.return_to_state)
                    self.state = self.return_to_state
                elif op == "=":
                    if text == op:
                        #log.debug("Entering S_IN_ASSIGNMENT state")
                        self.state = S_IN_ASSIGNMENT
                elif op == "{":
                    # Increasing depth/scope, could be an argument object
                    self._addCodePiece()
                    self.incBlock()
                elif op == "}":
                    # Decreasing depth/scope
                    self._addCodePiece()
                    self.decBlock()
                elif op == ";":
                    # Statement is done
                    self._addCodePiece()
                col += 1
    elif style in self.PHP_COMMENT_STYLES:
        self.comment.append(text)
    elif is_udl_csl_style(style):
        self.csl_tokens.append({"style": style,
                                "text": text,
                                "start_column": start_column,
                                "start_line": start_line})
    self.lastText = text

</t>
<t tx="ekr.20080121105837.1381">def scan_multilang_content(self, content):
    """Scan the given PHP content, only processes SSL styles"""
    PHPLexer().tokenize_by_style(content, self.token_next)
    return self.csl_tokens

</t>
<t tx="ekr.20080121105837.1382">def convertToElementTreeFile(self, cixelement):
    """Store PHP information into the cixelement as a file(s) sub element"""
    self.cile.convertToElementTreeFile(cixelement)

</t>
<t tx="ekr.20080121105837.1383">def convertToElementTreeModule(self, cixblob):
    """Store PHP information into already created cixblob"""
    self.cile.convertToElementTreeModule(cixblob)


</t>
<t tx="ekr.20080121105837.1384">#---- internal utility functions

def _isident(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" or char == "_"

</t>
<t tx="ekr.20080121105837.1385">def _isdigit(char):
    return "0" &lt;= char &lt;= "9"


</t>
<t tx="ekr.20080121105837.1386">#---- public module interface


#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PHPLexer(),
                      buf_class=PHPBuffer,
                      langintel_class=PHPLangIntel,
                      import_handler_class=PHPImportHandler,
                      cile_driver_class=PHPCILEDriver,
                      is_cpln_lang=True)
</t>
<t tx="ekr.20080121105837.1387">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Python support for CodeIntel"""

@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;

#---- globals
lang = "Python"
log = logging.getLogger("codeintel.python")
#log.setLevel(logging.DEBUG)

CACHING = True #DEPRECATED: kill it

# See http://effbot.org/zone/pythondoc.htm
_g_pythondoc_tags = list(sorted(
    "param keyparam return exception def defreturn see link linkplain".split()))

@others
</t>
<t tx="ekr.20080121105837.1388">import os
from os.path import (isfile, isdir, exists, dirname, abspath, splitext,
                     join, basename, isfile, normcase)
import sys
import logging
import random
import parser
from glob import glob
import weakref
from pprint import pprint, pformat

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants
from SilverCity.Keywords import python_keywords

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer, CitadelEvaluator, ImportHandler
from codeintel2 import pythoncile
from codeintel2.util import banner, indent, markup_text, isident, isdigit
from codeintel2 import tree
from codeintel2.tree_python import PythonTreeEvaluator
from codeintel2.langintel import (LangIntel, ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin,
                                  PythonCITDLExtractorMixin)

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False
</t>
<t tx="ekr.20080121105837.1389">#---- language support

class PythonLexer(Lexer):
    lang = lang
    @others
</t>
<t tx="ekr.20080121105837.1390">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_PYTHON)
    self._keyword_lists = [
        SilverCity.WordList(python_keywords),
        SilverCity.WordList(""), # hilighted identifiers
    ]


</t>
<t tx="ekr.20080121105837.1391">class PythonImportsEvaluator(Evaluator):
    @others
</t>
<t tx="ekr.20080121105837.1392">def __str__(self):
    return "Python imports"
</t>
<t tx="ekr.20080121105837.1393">def eval(self, mgr):
    try:
        imp_prefix = self.trg.extra["imp_prefix"]
        if imp_prefix:
            self.ctlr.set_desc("subimports of '%s'" % '.'.join(imp_prefix))
            cplns = []
            for lib in self.buf.libs:
                imports = lib.get_blob_imports(imp_prefix)
                if imports:
                    cplns.extend(
                        ((is_dir_import and "directory" or "module"), name)
                        for name, is_dir_import in imports
                    )
                    
                if self.trg.type == "module-members":
                    # Also add top-level members of the specified module.
                    dotted_prefix = '.'.join(imp_prefix)
                    if lib.has_blob(dotted_prefix):
                        blob = lib.get_blob(dotted_prefix)
                        for name in blob.names:
                            elem = blob.names[name]
                            cplns.append((elem.get("ilk") or elem.tag, name))
                        #TODO: Should also add symbols from
                        #      top-level imports in this blob.
                        #TODO: Consider using the value of __all__
                        #      if defined.
                if cplns:
                    break
            
        else:
            self.ctlr.set_desc("available imports")
            all_imports = set()
            for lib in self.buf.libs:
                all_imports.update(lib.get_blob_imports(imp_prefix))
            cplns = [((is_dir_import and "directory" or "module"), name)
                     for name, is_dir_import in all_imports]
        if cplns:
            cplns.sort(key=lambda i: i[1].upper())
            self.ctlr.set_cplns(cplns)
    finally:
        self.ctlr.done("success")


</t>
<t tx="ekr.20080121105837.1394">class PythonLangIntel(LangIntel, ParenStyleCalltipIntelMixin,
                      ProgLangTriggerIntelMixin,
                      PythonCITDLExtractorMixin):
    @others
</t>
<t tx="ekr.20080121105837.1395">def __init__(self, mgr):
    LangIntel.__init__(self, mgr)

</t>
<t tx="ekr.20080121105837.1396"># Used by ProgLangTriggerIntelMixin.preceding_trg_from_pos().
trg_chars = tuple(" (.")

def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    ctlr.start(buf, trg)
    if trg.type in ("object-members", "call-signature",
                    "literal-members") or \
       trg.form == TRG_FORM_DEFN:
        line = buf.accessor.line_from_pos(trg.pos)
        if trg.type == "literal-members":
            # We could leave this to citdl_expr_from_trg, but this is a
            # little bit faster, since we already know the citdl expr.
            citdl_expr = trg.extra.get("citdl_expr")
        else:
            try:
                citdl_expr = self.citdl_expr_from_trg(buf, trg)
            except CodeIntelError, ex:
                ctlr.error(str(ex))
                ctlr.done("error")
                return
        evalr = PythonTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)
    elif trg.id == ("Python", TRG_FORM_CPLN, "pythondoc-tags"):
        #TODO: Would like a "tag" completion image name.
        cplns = [("variable", t) for t in _g_pythondoc_tags]
        ctlr.set_cplns(cplns)
        ctlr.done("success")
    elif trg.type in ("available-imports", "module-members"):
        evalr = PythonImportsEvaluator(ctlr, buf, trg)
        buf.mgr.request_eval(evalr)
    else:
        raise NotImplementedError("not yet implemented: completion for "
                                  "Python '%s' trigger" % trg.name)

</t>
<t tx="ekr.20080121105837.1397">def _python_from_env(self, env):
    import which
    path = [d.strip() 
            for d in env.get_envvar("PATH", "").split(os.pathsep)
            if d.strip()]
    try:
        return which.which("python", path=path) 
    except which.WhichError:
        return None

</t>
<t tx="ekr.20080121105837.1398">def _python_info_from_python(self, python, env):
    """Call the given Python and return:
        (&lt;version&gt;, &lt;sys.prefix&gt;, &lt;lib-dir&gt;, &lt;site-lib-dir&gt;, &lt;sys.path&gt;)

    TODO: Unicode path issues?
    """
    import process

    # Python 1.5.2 does not support sys.version_info.
    info_cmd = (
        r"import sys;"
        r"import string;"
        r"paren = string.find(sys.version, '(');"
        r"version = string.strip(sys.version[:paren]);"
        r"sys.stdout.write(version+'\n');"
        r"sys.stdout.write(sys.prefix+'\n');"
        r"sys.stdout.write('\n'.join(sys.path));")

    argv = [python, "-c", info_cmd]
    log.debug("run `%s -c ...'", python)
    p = process.ProcessOpen(argv, env=env.get_all_envvars())
    stdout_lines = p.stdout.read().splitlines(0)
    stderr = p.stderr.read()
    retval = p.wait()
    p.close()
    if retval:
        log.warn("failed to determine Python info:\n"
                 "  path: %s\n"
                 "  retval: %s\n"
                 "  stdout:\n%s\n"
                 "  stderr:\n%s\n",
                 python, retval, indent('\n'.join(stdout_lines)),
                 indent(stderr))

    # We are only to rely on the first 2 digits being in the form x.y.
    ver_match = re.search("([0-9]+.[0-9]+)", stdout_lines[0])
    if ver_match:
        ver = ver_match.group(1)
    else:
        ver = None
    prefix = stdout_lines[1]
    if sys.platform == "win32":
        libdir = join(prefix, "Lib")
    else:
        libdir = join(prefix, "lib", "python"+ver)
    sitelibdir = join(libdir, "site-packages")
    sys_path = stdout_lines[2:]
    return ver, prefix, libdir, sitelibdir, sys_path

</t>
<t tx="ekr.20080121105837.1399">def _gen_python_import_paths_from_dirs(self, dirs):
    """Generate all Python import paths from a given list of dirs.
    
    This involves handling .pth files on the given dirs. It generates
    import "paths" rather than "dirs" because Python .egg files can be
    returned.
    
    Dev Notes:
    - Python's .pth files can have *executable* Python code. This
      currently is not handled (those kinds of lines are skipped).
    """
    for dir in dirs:
        if not exists(dir):
            continue
        yield dir
        try:
            for pth_path in glob(join(dir, "*.pth")):
                for p in self._gen_python_import_paths_from_pth_path(pth_path):
                    yield p
        except EnvironmentError, ex:
            log.warn("error analyzing .pth files in '%s': %s", dir, ex)

</t>
<t tx="ekr.20080121105837.1400">def _gen_python_import_paths_from_pth_path(self, pth_path):
    pth_dir = dirname(pth_path)
    for line in open(pth_path, 'r'):
        line = line.strip()
        if line.startswith("#"): # comment line
            continue
        path = join(pth_dir, line)
        if exists(path):
            yield path

</t>
<t tx="ekr.20080121105837.1401">def _extra_dirs_from_env(self, env):
    extra_dirs = set()
    for pref in env.get_all_prefs("pythonExtraPaths"):
        if not pref: continue
        extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                          if exists(d.strip()))
    if extra_dirs:
        extra_dirs = set(
            self._gen_python_import_paths_from_dirs(extra_dirs)
        )                
        log.debug("Python extra lib dirs: %r", extra_dirs)
    return tuple(extra_dirs)

</t>
<t tx="ekr.20080121105837.1402">def _buf_indep_libs_from_env(self, env):
    """Create the buffer-independent list of libs."""
    cache_key = "python-libs"
    if cache_key not in env.cache:
        env.add_pref_observer("python", self._invalidate_cache)
        env.add_pref_observer("pythonExtraPaths",
                              self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("codeintel_selected_catalogs",
                              self._invalidate_cache)
        db = self.mgr.db

        # Gather information about the current python.
        python = None
        if env.has_pref("python"):
            python = env.get_pref("python").strip() or None
        if not python or not exists(python):
            python = self._python_from_env(env)
        if not python:
            log.warn("no Python was found from which to determine the "
                     "import path")
            ver, prefix, libdir, sitelibdir, sys_path \
                = None, None, None, None, []
        else:
            ver, prefix, libdir, sitelibdir, sys_path \
                = self._python_info_from_python(python, env)
        libs = []

        # - extradirslib
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            libs.append( db.get_lang_lib("Python", "extradirslib",
                            extra_dirs) )

        # Figure out which sys.path dirs belong to which lib.
        paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
        STATE = "envlib"
        canon_sitelibdir = sitelibdir and normcase(sitelibdir) or None
        canon_prefix = prefix and normcase(prefix) or None
        for dir in sys_path:
            canon_dir = normcase(dir)
            if dir == "": # -&gt; curdirlib (already handled)
                continue
            elif canon_dir.endswith(".zip") and isfile(dir):
                log.warn("`%s': not handling .zip file on Python sys.path",
                         dir)
                continue
            elif canon_dir.endswith(".egg") and isfile(dir):
                #log.warn("`%s': not handling .egg file on Python sys.path",
                #         dir)
                continue
            elif canon_dir.startswith(canon_sitelibdir):
                STATE = "sitelib"
            elif canon_dir.startswith(canon_prefix):
                STATE = "stdlib"
            if not exists(dir):
                continue
            paths_from_libname[STATE].append(dir)
        log.debug("Python %s paths for each lib:\n%s",
                  ver, indent(pformat(paths_from_libname)))

        # - envlib, sitelib, cataloglib, stdlib
        if paths_from_libname["envlib"]:
            libs.append( db.get_lang_lib("Python", "envlib", 
                            paths_from_libname["envlib"]) )
        if paths_from_libname["sitelib"]:
            libs.append( db.get_lang_lib("Python", "sitelib", 
                            paths_from_libname["sitelib"]) )
        catalog_selections = env.get_pref("codeintel_selected_catalogs")
        libs += [
            db.get_catalog_lib("Python", catalog_selections),
            db.get_stdlib("Python", ver)
        ]
        env.cache[cache_key] = libs

    return env.cache[cache_key]

</t>
<t tx="ekr.20080121105837.1403">def libs_from_buf(self, buf):
    env = buf.env

    # A buffer's libs depend on its env and the buf itself so
    # we cache it on the env and key off the buffer.
    if "python-buf-libs" not in env.cache:
        env.cache["python-buf-libs"] = weakref.WeakKeyDictionary()
    cache = env.cache["python-buf-libs"] # &lt;buf-weak-ref&gt; -&gt; &lt;libs&gt;

    if buf not in cache:
        # - curdirlib
        # Using the dirname of this buffer isn't always right, but
        # hopefully is a good first approximation.
        cwd = dirname(buf.path)
        if cwd == "&lt;Unsaved&gt;":
            libs = []
        else:
            libs = [ self.mgr.db.get_lang_lib("Python", "curdirlib",
                                              [dirname(buf.path)]) ]

        libs += self._buf_indep_libs_from_env(env)
        cache[buf] = libs
    return cache[buf]

</t>
<t tx="ekr.20080121105837.1404">def _invalidate_cache(self, env, pref_name):
    for key in ("python-buf-libs", "python-libs"):
        if key in env.cache:
            log.debug("invalidate '%s' cache on %r", key, env)
            del env.cache[key]

</t>
<t tx="ekr.20080121105837.1405">def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
    self._invalidate_cache(env, pref_name)
    extra_dirs = self._extra_dirs_from_env(env)
    if extra_dirs:
        extradirslib = self.mgr.db.get_lang_lib(
            "Python", "extradirslib", extra_dirs)
        request = PreloadLibRequest(extradirslib)
        self.mgr.idxr.stage_request(request, 1.0)


</t>
<t tx="ekr.20080121105837.1406">#class PythonCitadelEvaluator(CitadelEvaluator):
#    def post_process_cplns(self, cplns):
#        """Drop special __FOO__ methods.
#        
#        Note: Eventually for some Python completions we might want to leave
#        these in. For example:
#        
#            class Bar(Foo):
#                def __init__(self):
#                    Foo.&lt;|&gt;    # completions should include "__init__" here
#        """
#        for i in range(len(cplns)-1, -1, -1):
#            value = cplns[i][1]
#            if value.startswith("__") and value.endswith("__"):
#                del cplns[i]
#        cplns.sort(key=lambda c: c[1].upper())
#        return cplns


class PythonBuffer(CitadelBuffer):
    lang = lang
    # Fillup chars for Python: basically, any non-identifier char.
    # - remove '*' from fillup chars because: "from foo import &lt;|&gt;*"
    cpln_fillup_chars = "~`!@#$%^&amp;()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    cpln_stop_chars = "~`!@#$%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    sce_prefixes = ["SCE_P_"]

    cb_show_if_empty = True

    @others
</t>
<t tx="ekr.20080121105837.1407">@property
def libs(self):
    return self.langintel.libs_from_buf(self)

</t>
<t tx="ekr.20080121105837.1408">def trg_from_pos(self, pos, implicit=True):
    """Python trigger types:

    python-complete-object-members
    python-calltip-call-signature
    python-complete-pythondoc-tags
    complete-available-imports
    complete-module-members
    
    Not yet implemented:
        complete-available-classes
        calltip-base-signature
    """
    DEBUG = False # not using 'logging' system, because want to be fast
    if DEBUG:
        print "\n----- Python trg_from_pos(pos=%r, implicit=%r) -----"\
              % (pos, implicit)

    if pos == 0:
        return None
    accessor = self.accessor
    last_pos = pos - 1
    last_char = accessor.char_at_pos(last_pos)
    if DEBUG:
        print "  last_pos: %s" % last_pos
        print "  last_char: %r" % last_char

    # Quick out if the preceding char isn't a trigger char.
    if last_char not in " .(@":
        if DEBUG:
            print "trg_from_pos: no: %r is not in ' .(@'" % last_char
        return None

    style = accessor.style_at_pos(last_pos)
    if DEBUG:
        style_names = self.style_names_from_style_num(style)
        print "  style: %s (%s)" % (style, ", ".join(style_names))

    if last_char == "@":
        # Possibly python-complete-pythondoc-tags (the only trigger
        # on '@').
        #
        # Notes:
        # - PythonDoc 2.1b6 started allowing pythondoc tags in doc
        #   strings which we are yet supporting here.
        # - Trigger in comments should only happen if the comment
        #   begins with the "##" pythondoc signifier. We don't
        #   bother checking that (PERF).
        if style in self.comment_styles():
            # Only trigger at start of comment line.
            WHITESPACE = tuple(" \t")
            SENTINEL = 20
            i = last_pos-1
            while i &gt;= max(0, last_pos-SENTINEL):
                ch = accessor.char_at_pos(i)
                if ch == "#":
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "pythondoc-tags", pos, implicit)
                elif ch in WHITESPACE:
                    pass
                else:
                    return None
                i -= 1
        return None

    # Remaing triggers should never trigger in some styles.
    if (implicit and style in self.implicit_completion_skip_styles
        or style in self.completion_skip_styles):
        if DEBUG:
            print "trg_from_pos: no: completion is suppressed "\
                  "in style at %s: %s (%s)"\
                  % (last_pos, style, ", ".join(style_names))
        return None

    if last_char == " ":
        # used for complete-available-imports and complete-module-members

        # Triggering examples ('_' means a space here):
        #   import_                 from_
        # Non-triggering examples:
        #   from FOO import_        Ximport_
        # Not bothering to support:
        #;  if FOO:import_          FOO;import_

        # Typing a space is very common so lets have a quick out before
        # doing the more correct processing:
        if last_pos-1 &lt; 0 or accessor.char_at_pos(last_pos-1) not in "tm,":
            return None

        working_text = accessor.text_range(max(0,last_pos-200),
                                           last_pos)
        line = self._last_logical_line(working_text).strip()
        if not line: return None
        ch = line[-1]
        line = line.replace('\t', ' ')

        # from &lt;|&gt;
        # import &lt;|&gt;
        if line == "from" or line == "import":
            return Trigger(self.lang, TRG_FORM_CPLN,
                           "available-imports", pos, implicit,
                           imp_prefix=())

        # is it "from FOO import &lt;|&gt;" ?
        if line.endswith(" import"):
            if line.startswith('from '):
                imp_prefix = tuple(line[len('from '):-len(' import')].strip().split('.'))
                return Trigger(self.lang, TRG_FORM_CPLN,
                           "module-members", pos, implicit,
                           imp_prefix=imp_prefix)

        if ch == ',':
            # is it "from FOO import BAR, &lt;|&gt;" ?
            if line.startswith('from ') and ' import ' in line:
                imp_prefix = tuple(line[len('from '):line.index(' import')].strip().split('.'))
                # Need better checks
                return Trigger(self.lang, TRG_FORM_CPLN,
                           "module-members", pos, implicit,
                           imp_prefix=imp_prefix)

    elif last_char == '.': # must be "complete-object-members" or None
        # If the first non-whitespace character preceding the '.' in the
        # same statement is an identifer character then trigger, if it
        # is a ')', then _maybe_ we should trigger (yes if this is
        # function call paren).
        #
        # Triggering examples:
        #   FOO.            FOO .                       FOO; BAR.
        #   FOO().          FOO.BAR.                    FOO(BAR, BAZ.
        #   FOO().BAR.      FOO("blah();", "blam").     FOO = {BAR.
        #   FOO(BAR.        FOO[BAR.
        #   ...more cases showing possible delineation of expression
        # Non-triggering examples:
        #   FOO..
        #   FOO[1].         too hard to determine sequence element types
        #   from FOO import (BAR.         
        # Not sure if want to support:
        #   "foo".          do we want to support literals? what about
        #                   lists? tuples? dicts?
        working_text = accessor.text_range(max(0,last_pos-200),
                                           last_pos)
        line = self._last_logical_line(working_text).strip()
        if line:
            ch = line[-1]
            if (isident(ch) or isdigit(ch) or ch == ')'):
                line = line.replace('\t', ' ')
                if line.startswith('from '):
                    if ' import ' in line:
                        # we're in "from FOO import BAR." territory,
                        # which is not a trigger
                        return None
                    # from FOO.
                    imp_prefix = tuple(line[len('from '):].strip().split('.'))
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "available-imports", pos, implicit,
                                   imp_prefix=imp_prefix)
                elif line.startswith('import '):
                    # import FOO.
                    # figure out the dotted parts of "FOO" above
                    imp_prefix = tuple(line[len('import '):].strip().split('.'))
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "available-imports", pos, implicit,
                                   imp_prefix=imp_prefix)
                else:
                    return Trigger(self.lang, TRG_FORM_CPLN,
                                   "object-members", pos, implicit)
            elif ch in ("\"'"):
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "literal-members", pos, implicit,
                               citdl_expr="str")
        else:
            ch = None
        if DEBUG:
            print "trg_from_pos: no: non-ws char preceding '.' is not "\
                  "an identifier char or ')': %r" % ch
        return None

    elif last_char == '(':
        # If the first non-whitespace character preceding the '(' in the
        # same statement is an identifer character then trigger calltip,
        #
        # Triggering examples:
        #   FOO.            FOO (                       FOO; BAR(
        #   FOO.BAR(        FOO(BAR, BAZ(               FOO = {BAR(
        #   FOO(BAR(        FOO[BAR(
        # Non-triggering examples:
        #   FOO()(      a function call returning a callable that is
        #               immediately called again is too rare to bother
        #               with
        #   def foo(    might be a "calltip-base-signature", but this
        #               trigger is not yet implemented
        #   import (    will be handled by complete_members
        #   class Foo(  is an "complete-available-classes" trigger,
        #               but this is not yet implemented
        working_text = accessor.text_range(max(0,last_pos-200), last_pos)
        line = self._last_logical_line(working_text).rstrip()
        if line:
            ch = line[-1]
            if isident(ch) or isdigit(ch):
                # If this is:
                #   def foo(
                # then this might be the (as yet unimplemented)
                # "calltip-base-signature" trigger or it should not be a
                # trigger point.
                #
                # If this is:
                #   class Foo(
                # then this should be the (as yet unimplemented)
                # "complete-available-classes" trigger.
                line = line.replace('\t', ' ')
                lstripped = line.lstrip()
                if lstripped.startswith("def"):
                    if DEBUG: print "trg_from_pos: no: point is function declaration"
                elif lstripped.startswith("class") and '(' not in lstripped:
                    # Second test is necessary to not exclude:
                    #   class Foo(bar(&lt;|&gt;
                    if DEBUG: print "trg_from_pos: no: point is class declaration"
                elif lstripped.startswith('from ') and ' import' in lstripped:
                    # Need better checks
                    # is it "from FOO import (&lt;|&gt;" ?
                    imp_prefix = tuple(lstripped[len('from '):lstripped.index(' import')].split('.'))
                    if DEBUG: print "trg_from_pos: from FOO import ("
                    return Trigger(self.lang, TRG_FORM_CPLN,
                               "module-members", pos, implicit,
                               imp_prefix=imp_prefix)
                else:
                    return Trigger(self.lang, TRG_FORM_CALLTIP,
                                   "call-signature", pos, implicit)
            else:
                if DEBUG:
                    print "trg_from_pos: no: non-ws char preceding "\
                          "'(' is not an identifier char: %r" % ch
        else:
            if DEBUG: print "trg_from_pos: no: no chars preceding '('"
        return None

</t>
<t tx="ekr.20080121105837.1409">def _last_logical_line(self, text):
    lines = text.splitlines(0) or ['']
    logicalline = lines.pop()
    while lines and lines[-1].endswith('\\'):
        logicalline = lines.pop()[:-1] + ' ' + logicalline
    return logicalline



</t>
<t tx="ekr.20080121105837.1410">class PythonImportHandler(ImportHandler):
    lang = lang #XXX do this for other langs as well
    PATH_ENV_VAR = "PYTHONPATH"
    sep = '.'

    @others
</t>
<t tx="ekr.20080121105837.1411">def __init__(self, mgr):
    ImportHandler.__init__(self, mgr)
    self.__stdCIXScanId = None

</t>
<t tx="ekr.20080121105837.1412">def _shellOutForPath(self, compiler):
    import process
    argv = [compiler, "-c", "import sys; print '\\n'.join(sys.path)"]
    # Can't use -E to ignore PYTHONPATH because older versions of
    # Python don't have it (e.g. v1.5.2).
    env = dict(os.environ)
    if "PYTHONPATH" in env: del env["PYTHONPATH"]
    if "PYTHONHOME" in env: del env["PYTHONHOME"]
    if "PYTHONSTARTUP" in env: del env["PYTHONSTARTUP"]

    p = process.ProcessOpen(argv, env=env)
    retval = p.wait()
    output = p.stdout.read()
    p.close()
    path = [line for line in output.splitlines(0)]
    if path and (path[0] == "" or path[0] == os.getcwd()):
        del path[0] # cwd handled separately
    return path

</t>
<t tx="ekr.20080121105837.1413">def setCorePath(self, compiler=None, extra=None):
    if compiler is None:
        import which
        compiler = which.which("python")
    self.corePath = self._shellOutForPath(compiler)

</t>
<t tx="ekr.20080121105837.1414">def _getStdCIXScanId(self, cu):
    if not self.__stdCIXScanId:
        cu.execute("SELECT scan.id FROM scan, file, language "
                   " WHERE language.name='Python'"
                   "   AND language.id=file.language_id"
                   "   AND scan.file_id=file.id"
                   "   AND scan.generator='StdCIX' LIMIT 1")
        for row in cu:
            self.__stdCIXScanId = row[0]
            break
    return self.__stdCIXScanId

</t>
<t tx="ekr.20080121105837.1415">def findModule(self, cu, factory, moduleName, submodule, cwd=None):
    """Algorithm:
    - Look for the appropriate file on disk, using the import path.
    - If found, see if we have this file in the CIDB.
        - If it's in the CIDB, then find the module with the appropriate
          name from that file.
    - If haven't found a matching module row yet, then lookup the full
      import path (and language) in the 'module' table and get all hits.
      This has the potential to "hit" modules that aren't in the search
      path, but a false positive is better than nothing in this case.
    - If still no hits, then raise an error that describes the problem
      in as helpful a way as possible for the user.
    """
    XXX
    module = kind = None

    if CACHING:
        key = (moduleName, submodule, cwd)
        retval = factory.pythonFindModuleCache.get(key, None)
        if retval is not None:
            return retval

    # Some specific modules are much better defined in 'python.cix'
    # than a scan of the associated .py file.
    #XXX The _correct_ algorithm would probably be to (1) find the
    #    proper file to import via findModuleOnDisk and (2) if that
    #    file was from the stdlib that the overrides represent, only
    #    _then_ would the override take effect. Currently this will
    #   override a user's own os.py. This is not deemed a big deal.
    overrides = ["os", "os.path", "re"]
    if moduleName in overrides:
        stdCIXScanId = self._getStdCIXScanId(cu)
        if stdCIXScanId:
            sql = "SELECT * FROM module WHERE scan_id=? AND name=? LIMIT 1"
            if submodule:
                cu.execute(sql, (stdCIXScanId, moduleName+'.'+submodule))
                for row in cu:
                    module = factory.createScope(row[M_FILE_ID], "module",
                                                 row[M_ID], row)
                    kind = "submodule"
                    break
            if not module:
                cu.execute(sql, (stdCIXScanId, moduleName))
                for row in cu:
                    module = factory.createScope(row[M_FILE_ID], "module",
                                                 row[M_ID], row)
                    kind = "module"
                    break
    
    if not module:
        # Look for the appropriate file on disk, using the import path.
        modfile, kind, scannable = self.findModuleOnDisk(moduleName,
                                                         submodule, cwd)

        # If found, see if we have this file and module in the CIDB.
        file_id = None
        if modfile:
            if kind == "module":
                modname = moduleName.split('.')[-1]
            elif kind == "submodule":
                modname = submodule
            cu.execute("SELECT * FROM module "
                       "WHERE file_id=(SELECT id FROM file WHERE compare_path=?) "
                       "AND name=? LIMIT 1",
                       (canonicalizePath(modfile), modname))
            for row in cu:
                module = factory.createScope(row[M_FILE_ID], "module",
                                             row[M_ID], row)
                break

    if CACHING and module:
        # Only insert into the cache here, and NOT if the retval
        # is gotten via the fallback.
        factory.pythonFindModuleCache[key] = (module, kind)
        factory.pythonFindModuleCacheIndex[module.file_id] = key

    # Fallback: If haven't found a matching module row yet, then lookup
    # the full import path (and language) in the 'module' table and get
    # all hits. First one wins.
    if not module:
        #XXX Might want database index specifically for this?
        sql = "SELECT module.* FROM language, module, file "\
              " WHERE language.name='Python' "\
              "   AND language.id=file.language_id "\
              "   AND module.file_id=file.id "\
              "   AND module.name=? LIMIT 1"
        if submodule:
            cu.execute(sql, (moduleName+'.'+submodule,))
            for row in cu:
                module = factory.createScope(row[M_FILE_ID], "module",
                                             row[M_ID], row)
                kind = "submodule"
                break
        if not module:
            cu.execute(sql, (moduleName,))
            for row in cu:
                module = factory.createScope(row[M_FILE_ID], "module",
                                             row[M_ID], row)
                kind = "module"
                break

    if not module:
        name = (submodule and "%s.%s" % (moduleName, submodule)
                or moduleName)
        raise NoModuleEntry(name, modfile)
    else:
        return (module, kind)

</t>
<t tx="ekr.20080121105837.1416">def findModuleOnDisk(self, module, submodule, cwd=None):
    r"""        
        &gt;&gt;&gt; h = PythonImportHandler()
        &gt;&gt;&gt; h.findModuleOnDisk("cmd", None)
        ('C:\\Python24\\lib\\cmd.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml", None)
        ('C:\\Python24\\lib\\xml\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml", "sax")
        ('C:\\Python24\\lib\\xml\\sax\\__init__.py', 'submodule', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml", "*")
        ('C:\\Python24\\lib\\xml\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml", "__version__")
        ('C:\\Python24\\lib\\xml\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml.sax", None)
        ('C:\\Python24\\lib\\xml\\sax\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml.sax", "handler")
        ('C:\\Python24\\lib\\xml\\sax\\handler.py', 'submodule', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml.sax", "parse")
        ('C:\\Python24\\lib\\xml\\sax\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("xml.sax", "*")
        ('C:\\Python24\\lib\\xml\\sax\\__init__.py', 'module', True)
        &gt;&gt;&gt; h.findModuleOnDisk("_tkinter", "*")
        ('C:\\Python24\\DLLs\\_tkinter.pyd', 'module', False)
    """
    if isinstance(cwd, unicode):
        try:
            cwd = str(cwd) # imp.find_module() doesn't like unicode paths
        except:
            log.warn("could not convert unicode CWD to string for Python"
                     "module lookup: lookup might fail: cwd=%r" % cwd)
            cwd = None
    path = self._getPath(cwd)

    import imp
    try:
        modparts = module.split('.')
        modpath = description = None
        for i in range(len(modparts)):
            modpart = modparts[i]
            fin, modpath, desc = imp.find_module(modpart, path)
            if fin: fin.close()
            path = [modpath]
        kind = "module"
        
        # Check to see if the given sub-module can be tacked on.
        if submodule:
            try:
                sfin, smodpath, sdesc = imp.find_module(submodule, [modpath])
                if sfin: sfin.close()
            except ImportError:
                pass
            else:
                kind = "submodule"
                modpath = smodpath
                desc = sdesc

        # If the "module path" is a package directory, then convert it to
        # the appropriate _file_.
        if desc[2] == imp.PKG_DIRECTORY:
            fin, modpath, desc = imp.find_module("__init__", [modpath])

        # The import is scannable if it is a plain Python source file.
        suffix, mode, type = desc
        scannable = type == imp.PY_SOURCE

        return (modpath, kind, scannable)
    except ImportError:
        return (None, None, None)

</t>
<t tx="ekr.20080121105837.1417">def _findScannableFiles(self,
                        (files, searchedDirs, skipRareImports,
                         importableOnly),
                        dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    if skipRareImports:
        if (os.path.basename(dirname) == "encodings"
            and "undefined.py" in names):
            # Skip most of the specific encoding definitions (saves
            # about 50 files).
            names = [n for n in names if n == "__init__.py"
                     or os.path.splitext(n)[0].endswith("_codec")]
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = os.path.join(dirname, names[i])
        if os.path.isdir(path):
            if skipRareImports:
                # Skip Python's test package (saves over 200 files)
                # and other likely test dirs.
                if names[i] in ("test", "tests"):
                    del names[i]
                    continue
            if importableOnly:
                possibles = [os.path.join(path, "__init__.py"),
                             os.path.join(path, "__init__.pyc"),
                             os.path.join(path, "__init__.pyo")]
                for possible in possibles:
                    if os.path.isfile(possible):
                        break
                else:
                    del names[i] # don't traverse non-package dirs
                    continue
            if path.endswith(os.path.join("win32com", "gen_py")):
                del names[i]
                continue
        elif os.path.splitext(names[i])[1] in (".py", ".pyw"):
            #XXX The list of Python extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs.
            #XXX This check for "Python" files should probably include
            #    python scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            files.append(path)

</t>
<t tx="ekr.20080121105837.1418">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        #XXX Use os.walk().
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs, skipRareImports,
                      importableOnly))
        for file in files:
            yield file

</t>
<t tx="ekr.20080121105837.1419">def find_importables_in_dir(self, dir):
    """See citadel.py::ImportHandler.find_importables_in_dir() for
    details.

    Importables for Python look like this:
        {"foo":    ("foo.py",             None,       False),
         "foolib": ("foolib/__init__.py", "__init__", False)}

    TODO: consider *.pyd/so files when have a story for binary modules
          on the fly
    """
    if dir == "&lt;Unsaved&gt;":
        #TODO: stop these getting in here.
        return {}
    importables = {}
    for path in glob(join(dir, "*.py")):
        base = basename(path)
        sans_ext = splitext(base)[0]
        if sans_ext == '__init__': continue # no need for these
        importables[sans_ext] = (base, None, False)
    for path in glob(join(dir, "*", "__init__.py")):
        base = path[len(dir)+1:]
        importables[dirname(base)] = (base, "__init__", False)
    return importables




</t>
<t tx="ekr.20080121105837.1420">class PythonCILEDriver(CILEDriver):
    lang = lang

    @others
</t>
<t tx="ekr.20080121105837.1421">def scan_purelang(self, buf):

    #log.warn("TODO: python cile that uses elementtree")
    cix = pythoncile.scan(buf.accessor.text, buf.path)
    from codeintel2.tree import tree_from_cix
    return tree_from_cix(cix)



</t>
<t tx="ekr.20080121105837.1422">#---- internal support stuff

#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=PythonLexer(),
                      buf_class=PythonBuffer,
                      langintel_class=PythonLangIntel,
                      import_handler_class=PythonImportHandler,
                      cile_driver_class=PythonCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1423">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1424">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""RHTML support for CodeIntel"""

import os
from os.path import (isfile, isdir, exists, dirname, abspath, splitext,
                     join, basename)
import sys
from cStringIO import StringIO
import logging
import re
import traceback
from pprint import pprint
from glob import glob

from codeintel2.common import *
from codeintel2.lang_ruby_common import RubyCommonBufferMixin
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin
from codeintel2.citadel import CitadelEvaluator

#---- globals

lang = "RHTML"
log = logging.getLogger("codeintel.rhtml")
</t>
<t tx="ekr.20080121105837.1425">#log.setLevel(logging.DEBUG)

#---- language support

class RHTMLLexer(UDLLexer):
    lang = lang
    

</t>
<t tx="ekr.20080121105837.1426"># Dev Notes:
# - DO_NOT_PUT_IN_FILLUPS = '!'
# - curr_calltip_arg_range (will need to pass in trigger when get to
#    this point)
class RHTMLBuffer(UDLBuffer, XMLParsingBufferMixin, RubyCommonBufferMixin):
    @others
    lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Ruby"
    tpl_lang = "RHTML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    # - TODO: adjust for Ruby, if necessary
    # - TODO: adjust for RHTML, if necessary
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"
    

</t>
<t tx="ekr.20080121105837.1427">def __init__(self, mgr, accessor, env=None, path=None):
    UDLBuffer.__init__(self, mgr, accessor, env, path)
    self.check_for_rails_app_path(path)
    
</t>
<t tx="ekr.20080121105837.1428">class RHTMLCILEDriver(UDLCILEDriver):
    lang = lang
    ssl_lang = "Ruby"
    csl_lang = "JavaScript"



</t>
<t tx="ekr.20080121105837.1429">#---- internal support stuff

def _isident(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" or char == "_"

</t>
<t tx="ekr.20080121105837.1430">def _isdigit(char):
    return "0" &lt;= char &lt;= "9"



</t>
<t tx="ekr.20080121105837.1431">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=RHTMLLexer(),
                      buf_class=RHTMLBuffer,
                      cile_driver_class=RHTMLCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1432">@language python
@tabwidth -4
@others
@ignore ## &lt;&lt;%r&gt;&gt; causes problems.</t>
<t tx="ekr.20080121105837.1433">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Ruby support for CodeIntel"""

import os
from os.path import basename, splitext, isdir, join, normcase, normpath
import time
import sys
import logging
from pprint import pformat
from glob import glob
import weakref

from ciElementTree import Element, SubElement, tostring
import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity.ScintillaConstants import (
    SCLEX_RUBY, SCE_RB_DEFAULT,
    SCE_RB_REGEX, SCE_RB_IDENTIFIER, SCE_RB_WORD, SCE_RB_OPERATOR,
    SCE_UDL_M_OPERATOR, SCE_UDL_SSL_DEFAULT, SCE_UDL_SSL_IDENTIFIER,
    SCE_UDL_SSL_OPERATOR, SCE_UDL_SSL_VARIABLE, SCE_UDL_SSL_WORD,
    SCE_UDL_TPL_OPERATOR
)
from SilverCity.Keywords import ruby_keywords

from codeintel2.common import *
from codeintel2.citadel import ImportHandler, CitadelBuffer, CitadelEvaluator
from codeintel2.citadel_common import ScanRequest
from codeintel2.parseutil import urlencode_path
from codeintel2.udl import UDLBuffer
from codeintel2.accessor import AccessorCache
from codeintel2 import rubycile
from codeintel2.langintel import (LangIntel, ParenStyleCalltipIntelMixin,
                                  ProgLangTriggerIntelMixin)

from codeintel2.lang_ruby_common import RubyCommonBufferMixin
from codeintel2.util import isident, isdigit, banner, indent, markup_text, hotshotit
from codeintel2.tree import tree_2_0_from_tree_0_1
from codeintel2.tree_ruby import RubyTreeEvaluator

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False



#---- globals

lang = "Ruby"
log = logging.getLogger("codeintel.ruby")
#log.setLevel(logging.DEBUG)
CACHING = True #XXX obsolete, kill it

_trg_type_to_trg_char = {'lib-paths': ['\'', True],
                         'lib-subpaths': ['/', True],
                         'object-methods': ['.', False],
                         'literal-methods': ['.', False],
                         'available-modules': [' ', False],
                         'available-modules-and-classes': ['&lt;', False],
                         'module-names': [':', False],
                         'instance-vars': ['@', True],
                         'class-vars': ['@', True],
                         'global-vars': ['$', True],
                         }


</t>
<t tx="ekr.20080121105837.1434">#---- language support

class RubyLexer(Lexer):
    lang = "Ruby"
    @others
</t>
<t tx="ekr.20080121105837.1435">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(SCLEX_RUBY)
    self._keyword_lists = [
        SilverCity.WordList(ruby_keywords)
    ]


</t>
<t tx="ekr.20080121105837.1436">class RubyCitadelEvaluator(CitadelEvaluator):
    @others
</t>
<t tx="ekr.20080121105837.1437">def __init__(self, ctlr, buf, trg, expr, line, converted_dot_new=None):
    CitadelEvaluator.__init__(self, ctlr, buf, trg, expr, line)
    self.converted_dot_new = converted_dot_new

</t>
<t tx="ekr.20080121105837.1438">def post_process_calltips(self, calltips):
    if self.converted_dot_new:
        # "Foo.new(" is really using "Foo.initialize(". We swapped
        # that for calltip evaluation, now swap it back.
        for i, c in enumerate(calltips):
            if c.startswith("initialize"):
                calltips[i] = "new" + c[len("initialize"):]
    return calltips

</t>
<t tx="ekr.20080121105837.1439">def post_process_cplns(self, cplns):
    """Skip operator-typical methods like "+", "===", etc.

    XXX Should we skip methods beginning with "_" and or "__foo__"
        as well?
    """
    cplns = [c for c in cplns if isident(c[1][0])]
    cplns.sort(key=lambda c: c[1].upper())
    return cplns


</t>
<t tx="ekr.20080121105837.1440">class RubyImportsEvaluator(Evaluator):
    @others
</t>
<t tx="ekr.20080121105837.1441">def __init__(self, ctlr, buf, trg, import_handler, prefix):
    Evaluator.__init__(self, ctlr, buf, trg)
    self.import_handler = import_handler
    self.prefix = prefix

</t>
<t tx="ekr.20080121105837.1442">def __str__(self):
    return "Ruby subimports of '%s'" % self.prefix

</t>
<t tx="ekr.20080121105837.1443">def eval(self, mgr):
    self.ctlr.set_desc("subimports of '%s'" % self.prefix)
    cwd = dirname(self.buf.path) #XXX Should eventually use relevant env
    subimports = self.import_handler.findSubImportsOnDisk(
        self.prefix, cwd)
    if subimports:
        cplns = []
        for subimport in subimports:
            if subimport[-1] == '/':
                cplns.append( ("directory", subimport[:-1]) )
            else:
                cplns.append( ("module", subimport) )
        cplns.sort(key=lambda c: c[1].upper())
        self.ctlr.set_cplns(cplns)
    self.ctlr.done("success")


</t>
<t tx="ekr.20080121105837.1444">class RubyBuffer(CitadelBuffer, RubyCommonBufferMixin):
    lang = "Ruby"
    sce_prefixes = ["SCE_RB_"]

    cb_show_if_empty = True

    # Characters that should automatically invoke the current completion item:
    #XXX Figure out the appropriate set (get Eric to help).
    # - Cannot be '!' or '?' or '=' (I think) because those can be part of a
    #   method name.
    # - Cannot be "'" or '"' because that can get in the way. E.g.:
    #       require 'cgi&lt;|&gt;
    #   At this point the selected item can be "cgi-lib". Filling up
    #   with a quote would select "cgi-lib" instead of the possibly
    #   intended "cgi".
    # - Cannot be '.' because of '..' operator for ranges. E.g.:
    #       1..1000
    #   would result in (or whatever the first Fixnum method is):
    #       1.abs.1000
    cpln_fillup_chars = "~`@#$%^&amp;*(+}[]|\\;:,&lt;&gt;/ "
    cpln_stop_chars = cpln_fillup_chars + "'\"."

    @others
</t>
<t tx="ekr.20080121105837.1445">def __init__(self, mgr, accessor, env=None, path=None):
    CitadelBuffer.__init__(self, mgr, accessor, env, path)
    self.check_for_rails_app_path(path)

    # Skip styles are a bit different for Ruby:
    # - for *some* cases autocomplete *is* automatically triggered
    #   in a string
    # - you *can* trigger on a number
    self.implicit_completion_skip_styles = dict(
        (s, True) for s in self.comment_styles())
    self.completion_skip_styles = self.implicit_completion_skip_styles.copy()
    self.completion_skip_styles[SCE_RB_REGEX] = True

</t>
<t tx="ekr.20080121105837.1446">@property
def libs(self):
    return self.langintel.libs_from_buf(self)

</t>
<t tx="ekr.20080121105837.1447">class _CommonStyleClassifier(object):
    @others
</t>
<t tx="ekr.20080121105837.1448">def __init__(self, buf):
    self.buf = buf
    
</t>
<t tx="ekr.20080121105837.1449">@property
def ignore_styles(self):
    return self.ignoreStyles

</t>
<t tx="ekr.20080121105837.1450">class _RubyStyleClassifier(_CommonStyleClassifier):
    @others
    ignoreStyles =  (ScintillaConstants.SCE_RB_DEFAULT,
                     ScintillaConstants.SCE_RB_COMMENTLINE)

</t>
<t tx="ekr.20080121105837.1451"># This class delegates mostly to its Buffer object.
# class-specific methods first...

def is_ruby_style_at_pos(self, pos):
    # All chars are in Ruby code in pure Ruby buffers,
    # no need to get the style at position pos
    return True

</t>
<t tx="ekr.20080121105837.1452">def is_identifier_or_word_style(self, style):
    return style == SCE_RB_IDENTIFIER or style == SCE_RB_WORD

</t>
<t tx="ekr.20080121105837.1453">def is_identifier_style(self, style):
    return style == SCE_RB_IDENTIFIER

</t>
<t tx="ekr.20080121105837.1454">def is_operator_style(self, style):
    return style == SCE_RB_OPERATOR

</t>
<t tx="ekr.20080121105837.1455">def is_default_style(self, style):
    return style == SCE_RB_DEFAULT

</t>
<t tx="ekr.20080121105837.1456">def __getattr__(self, name):
    return getattr(self.buf, name)

</t>
<t tx="ekr.20080121105837.1457">class _UDLStyleClassifier(_CommonStyleClassifier):
    @others
    ignoreStyles =  (ScintillaConstants.SCE_UDL_SSL_DEFAULT,
                     ScintillaConstants.SCE_UDL_SSL_COMMENT)

</t>
<t tx="ekr.20080121105837.1458">def __init__(self, buf):
    _CommonStyleClassifier.__init__(self, buf)
    self._implicit_completion_skip_styles = None
    self._completion_skip_styles = None

</t>
<t tx="ekr.20080121105837.1459">def is_ruby_style_at_pos(self, pos):
    style = self.buf.accessor.style_at_pos(pos)
    return SCE_UDL_SSL_DEFAULT &lt;= style &lt;= SCE_UDL_SSL_VARIABLE

</t>
<t tx="ekr.20080121105837.1460">@property
def implicit_completion_skip_styles(self):
    if self._implicit_completion_skip_styles is None:
        #XXX - do we have access to the language info?
        self._implicit_completion_skip_styles = {

            ScintillaConstants.SCE_UDL_SSL_COMMENT : True,
            ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK : True,
            }
    return self._implicit_completion_skip_styles

</t>
<t tx="ekr.20080121105837.1461">@property
def completion_skip_styles(self):
    if self._completion_skip_styles is None:
        self._completion_skip_styles = {

            ScintillaConstants.SCE_UDL_SSL_COMMENT : True,
            ScintillaConstants.SCE_UDL_SSL_COMMENTBLOCK : True,
            ScintillaConstants.SCE_UDL_SSL_REGEX : True,
            }
    return self._completion_skip_styles

</t>
<t tx="ekr.20080121105837.1462">def is_identifier_or_word_style(self, style):
    return style == SCE_UDL_SSL_IDENTIFIER or style == SCE_UDL_SSL_WORD

</t>
<t tx="ekr.20080121105837.1463">def is_identifier_style(self, style):
    return style == SCE_UDL_SSL_IDENTIFIER

</t>
<t tx="ekr.20080121105837.1464">def is_operator_style(self, style):
    return style == SCE_UDL_SSL_OPERATOR

</t>
<t tx="ekr.20080121105837.1465"># These aren't properties in buffer.py, so they can't be here either.
def comment_styles(self):
    return (ScintillaConstants.SCE_UDL_SSL_COMMENT,)

</t>
<t tx="ekr.20080121105837.1466">def number_styles(self):
    return (ScintillaConstants.SCE_UDL_SSL_NUMBER,)

</t>
<t tx="ekr.20080121105837.1467">def string_styles(self):
    return (ScintillaConstants.SCE_UDL_SSL_STRING, )

</t>
<t tx="ekr.20080121105837.1468">def is_default_style(self, style):
    return style == SCE_UDL_SSL_DEFAULT

</t>
<t tx="ekr.20080121105837.1469">class RubyLangIntel(LangIntel,
                    ParenStyleCalltipIntelMixin,
                    ProgLangTriggerIntelMixin):

    calltip_region_terminators = tuple(']});\r\n')
    @others
</t>
<t tx="ekr.20080121105837.1470"># newlines are for ending calltips triggered on a space

def libs_from_buf(self, buf):
    env = buf.env

    # A buffer's libs depend on its env and the buf itself so
    # we cache it on the env and key off the buffer.
    if "ruby-buf-libs" not in env.cache:
        env.cache["ruby-buf-libs"] = weakref.WeakKeyDictionary()
    cache = env.cache["ruby-buf-libs"] # &lt;buf-weak-ref&gt; -&gt; &lt;libs&gt;

    if buf not in cache:
        libs = self._buf_indep_libs_from_env(env)[:]

        # - curdirlib (in Ruby '.' is *last* in the import path)
        cwd = dirname(buf.path)
        if cwd != "&lt;Unsaved&gt;":
            libs.append( self.mgr.db.get_lang_lib("Ruby", "curdirlib",
                                              [dirname(buf.path)]) )

        cache[buf] = libs
    return cache[buf]

</t>
<t tx="ekr.20080121105837.1471">def _ruby_from_env(self, env):
    import which
    path = [d.strip() 
            for d in env.get_envvar("PATH", "").split(os.pathsep)
            if d.strip()]
    try:
        return which.which("ruby", path=path) 
    except which.WhichError:
        return None

</t>
<t tx="ekr.20080121105837.1472">def _ruby_info_from_ruby(self, ruby, env):
    """Call the given Ruby and return:
        (&lt;version&gt;, &lt;lib-dir&gt;, &lt;site-lib-dir&gt;, &lt;import-dirs&gt;, &lt;gem-dirs&gt;)

    TODO: Unicode path issues?
    """
    import process

    # Ruby 1.5.2 does not support sys.version_info.
    info_cmd = "puts RUBY_VERSION; puts $:"
    argv = [ruby, "-e", info_cmd]
    log.debug("run `%s -e ...'", ruby)
    p = process.ProcessOpen(argv, env=env.get_all_envvars())
    stdout_lines = p.stdout.read().splitlines(0)
    stderr = p.stderr.read()
    retval = p.wait()
    p.close()
    if retval:
        log.warn("failed to determine Ruby info:\n"
                 "  path: %s\n"
                 "  retval: %s\n"
                 "  stdout:\n%s\n"
                 "  stderr:\n%s\n",
                 ruby, retval, indent('\n'.join(stdout_lines)),
                 indent(stderr))

    ruby_ver = stdout_lines[0]
    short_ver = '.'.join(ruby_ver.split('.', 2)[:2])

    prefix = dirname(dirname(ruby))
    libdir = join(prefix, "lib", "ruby", short_ver)
    sitelibdir = join(prefix, "lib", "ruby", "site_ruby")
    # Need to normpath() these because they come out, e.g.:
    #   c:/ruby184/lib/ruby/site_ruby/1.8
    # on Windows. 
    import_path = [normpath(p) for p in stdout_lines[1:]]

    # Get the list of relevant Gem lib dirs.
    def gem_ver_from_ver_str(ver_str):
        parts = ver_str.split('.')
        try:
            parts = map(int, parts)
        except ValueError:
            return ver_str
        else:
            return tuple(parts)
    gems_dir = join(prefix, "lib", "ruby", "gems", short_ver, "gems")
    gem_ver_and_dir_from_name = {
        # "actionmailer": ((1,2,5), ".../actionmailer-1.2.5"),
    }
    for dir in glob(join(gems_dir, "*-*")):
        if not isdir(dir):
            continue
        name, ver_str = basename(dir).split('-', 1)
        gem_ver = gem_ver_from_ver_str(ver_str)
        if name in gem_ver_and_dir_from_name:
            if gem_ver &gt; gem_ver_and_dir_from_name[name][0]:
                gem_ver_and_dir_from_name[name] = (gem_ver, dir)
        else:
            gem_ver_and_dir_from_name[name] = (gem_ver, dir)
    log.debug("ruby gem dir info: %s", pformat(gem_ver_and_dir_from_name))
    gem_lib_dirs = []
    for name, (gem_ver, dir) in sorted(gem_ver_and_dir_from_name.items()):
        gem_lib_dir = join(dir, "lib")
        if isdir(gem_lib_dir):
            gem_lib_dirs.append(gem_lib_dir)

    return ruby_ver, libdir, sitelibdir, import_path, gem_lib_dirs

</t>
<t tx="ekr.20080121105837.1473">def _extra_dirs_from_env(self, env):
    extra_dirs = set()
    for pref in env.get_all_prefs("rubyExtraPaths"):
        if not pref: continue
        #TODO: need to support Gems specially?
        extra_dirs.update(d.strip() for d in pref.split(os.pathsep)
                          if exists(d.strip()))
    return tuple(extra_dirs)

</t>
<t tx="ekr.20080121105837.1474">def _buf_indep_libs_from_env(self, env):
    """Create the buffer-independent list of libs."""
    cache_key = "ruby-libs"
    if cache_key not in env.cache:
        env.add_pref_observer("ruby", self._invalidate_cache)
        env.add_pref_observer("rubyExtraPaths",
                              self._invalidate_cache_and_rescan_extra_dirs)
        env.add_pref_observer("codeintel_selected_catalogs",
                              self._invalidate_cache)
        db = self.mgr.db

        # Gather information about the current ruby.
        ruby = None
        if env.has_pref("ruby"):
            ruby = env.get_pref("ruby").strip() or None
        if not ruby or not exists(ruby):
            ruby = self._ruby_from_env(env)
        if not ruby:
            log.warn("no Ruby was found from which to determine the "
                     "import path")
            ver, libdir, sitelibdir, import_path, gem_lib_dirs \
                = None, None, None, [], []
        else:
            ver, libdir, sitelibdir, import_path, gem_lib_dirs \
                = self._ruby_info_from_ruby(ruby, env)

        libs = []

        # - extradirslib
        extra_dirs = self._extra_dirs_from_env(env)
        if extra_dirs:
            log.debug("Ruby extra lib dirs: %r", extra_dirs)
            libs.append( db.get_lang_lib("Ruby", "extradirslib",
                            extra_dirs) )

        # Figure out which sys.path dirs belong to which lib.
        paths_from_libname = {"sitelib": [], "envlib": [], "stdlib": []}
        STATE = "envlib"
        canon_libdir = libdir and normcase(libdir) or None
        canon_sitelibdir = sitelibdir and normcase(sitelibdir) or None
        for dir in import_path:
            canon_dir = normcase(dir)
            if dir == ".": # -&gt; curdirlib (handled separately)
                continue
            #TODO: need to support gems specially?
            elif dir.startswith(sitelibdir):
                STATE = "sitelib"
            elif dir.startswith(libdir):
                STATE = "stdlib"
            if not exists(dir):
                continue
            paths_from_libname[STATE].append(dir)
        log.debug("Ruby %s paths for each lib:\n%s", ver, indent(pformat(paths_from_libname)))

        # - envlib, sitelib, gemlib, cataloglib, stdlib
        if paths_from_libname["envlib"]:
            libs.append( db.get_lang_lib("Ruby", "envlib", 
                            paths_from_libname["envlib"]) )
        if paths_from_libname["sitelib"]:
            libs.append( db.get_lang_lib("Ruby", "sitelib", 
                            paths_from_libname["sitelib"]) )
        if gem_lib_dirs:
            libs.append( db.get_lang_lib("Ruby", "gemlib", gem_lib_dirs) )
        catalog_selections = env.get_pref("codeintel_selected_catalogs")
        libs += [
            db.get_catalog_lib("Ruby", catalog_selections),
            db.get_stdlib("Ruby", ver)
        ]
        env.cache[cache_key] = libs

    return env.cache[cache_key]

</t>
<t tx="ekr.20080121105837.1475">def _invalidate_cache(self, env, pref_name):
    for key in ("ruby-buf-libs", "ruby-libs"):
        if key in env.cache:
            log.debug("invalidate '%s' cache on %r", key, env)
            del env.cache[key]

</t>
<t tx="ekr.20080121105837.1476">def _invalidate_cache_and_rescan_extra_dirs(self, env, pref_name):
    self._invalidate_cache(env, pref_name)
    extra_dirs = self._extra_dirs_from_env(env)
    if extra_dirs:
        extradirslib = self.mgr.db.get_lang_lib(
            "Ruby", "extradirslib", extra_dirs)
        request = PreloadLibRequest(extradirslib)
        self.mgr.idxr.stage_request(request, 1.0)

</t>
<t tx="ekr.20080121105837.1477"># All Ruby trigger points occur at one of these characters:
#   '.' (period)        [eval implemented]
#   ' ' (space)
#   '(' (open paren)    [eval implemented]
#   ':' (colon)         "::" actually [eval implemented]
#   '@' (at-sign)       "@..." for instance var,
#                       "@@..." for class vars
#   '$' (dollar sign)
#   "'" (single-quote)  [eval implemented]
#   '"' (double-quote)  [eval implemented]
#   '/' (slash)         [eval implemented]
#
#   At least three characters into an identifier (\w_)+
#
#   spaces -- for class inheritance, include, &amp; call-tips
#
trg_chars = tuple('. (:@$"\'/') # the full set
calltip_trg_chars = tuple('( ')
RUBY_KEYWORDS = dict((k, True) for k in ruby_keywords.split())

def _get_prev_token_skip_ws(self, pos, accessor, styleClassifier):       
    prev_start_pos, prev_end_pos = accessor.contiguous_style_range_from_pos(pos - 1)
    if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
        return prev_start_pos, prev_end_pos
    prev_style = accessor.style_at_pos(prev_start_pos)
    if styleClassifier.is_default_style(prev_style):
        prev_start_pos, prev_end_pos = accessor.contiguous_style_range_from_pos(prev_start_pos - 1)
    return prev_start_pos, prev_end_pos

</t>
<t tx="ekr.20080121105837.1478">def _get_token_before_namelist(self, pos, accessor, styleClassifier, lim=-1):
    """ Walk backwards skipping (name, comma) pairs.
    If lim is given and is positive stop once we reach 0, to avoid spending
    too much time here
    """
    while True:
        prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(pos, accessor, styleClassifier)
        if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
            return 0, 0
        prev_style = accessor.style_at_pos(prev_start_pos)
        if not styleClassifier.is_identifier_or_word_style(prev_style):
            return 0, 0
        prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(prev_start_pos, accessor, styleClassifier)
        if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
            return 0, 0
        elif not styleClassifier.is_operator_style(prev_style):
            return 0, 0
        op = accessor.text_range(prev_start_pos, prev_end_pos)
        if op != ",":
            return prev_start_pos, prev_end_pos
        lim -= 1
        if lim == 0:
            return 0, 0

</t>
<t tx="ekr.20080121105837.1479">def _is_completable_name(self, pos, accessor, styleClassifier):
    """
     Ensure we are not in another trigger zone, we do
     this by checking that the preceeding text is not
     one of "." or "::"
     Also ignore words in block var names:
     {do or "{"}, "|", {name, ","}*
    """
    if pos == 0:
        return True
    prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(pos, accessor, styleClassifier)
    if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
        return True
    prev_style = accessor.style_at_pos(prev_start_pos)
    if not styleClassifier.is_operator_style(prev_style):
        return True
    op = accessor.text_range(prev_start_pos, prev_end_pos)
    if op in (".", "::"):
        return False
    if op == ",":
        prev_start_pos, prev_end_pos = self._get_token_before_namelist(prev_start_pos,
                                                                       accessor, styleClassifier,
                                                                       lim=5)
        if prev_start_pos &lt;= 0:
            return False
        prev_style = accessor.style_at_pos(prev_start_pos)     
        if not styleClassifier.is_operator_style(prev_style):
            return True
        op = accessor.text_range(prev_start_pos, prev_end_pos)
    if op[-1] != "|": # last character
        return True
    elif op == "{|":
        # Special case due to the way the accessor combines tokens of same style
        return False
    # Now look back for either a brace or a 'do'
    prev_start_pos, prev_end_pos = self._get_prev_token_skip_ws(prev_start_pos, accessor, styleClassifier)
    if prev_start_pos == 0 or not styleClassifier.is_ruby_style_at_pos(prev_start_pos):
        return False
    op = accessor.text_range(prev_start_pos, prev_end_pos)
    return op not in ("{", "do")


</t>
<t tx="ekr.20080121105837.1480">def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
    """If the given position is a _likely_ trigger point, return the
    trigger type. Otherwise return None.
    """
    if pos &lt;= 0:
        return None

    styleClassifier = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                       or _RubyStyleClassifier)(buf)
    DEBUG = False  # not using 'logging' system, because want to be fast
    if DEBUG:
        print banner("Ruby trg_from_pos(pos=%r, implicit=%r)"
                     % (pos, implicit))

    accessor = buf.accessor
    last_pos = pos - 1
    last_ch = accessor.char_at_pos(last_pos)
    if DEBUG:
        print "  last_pos: %s" % last_pos
        print "  last_ch: %r" % last_ch

    # All Ruby trigger points occur at one of the trg_chars.
    # Also some require specific two (or more) character combos that
    # we can use to filter quickly.
    if last_ch not in self.trg_chars:
        # Can we do a complete-names?
        last_style = accessor.style_at_pos(last_pos)
        if last_ch.isalnum() or last_ch == '_':
            # Gather as long as they're identifier or word chars
            MIN_LENGTH = 3
            if styleClassifier.is_identifier_or_word_style(last_style):
                start_pos, end_pos = accessor.contiguous_style_range_from_pos(last_pos)
                #XXX Is end_pos pointing one past the end?
                if pos - start_pos == MIN_LENGTH or not implicit:
                    ident = accessor.text_range(start_pos, end_pos)
                    prefix = ident[:pos - start_pos]
                    if self._is_completable_name(start_pos, accessor, styleClassifier):
                        return Trigger("Ruby", TRG_FORM_CPLN,
                                       "names", 
                                       start_pos, implicit, length=0, prefix=prefix)
        if DEBUG:
            print "no: %r is not in %r"\
                  % (last_ch, self.trg_chars)
        return None
    elif last_ch == ' ':
        if last_pos &lt;= 0:
            return None
        penultimate_ch = accessor.char_at_pos(last_pos-1)
        prev_style = accessor.style_at_pos(last_pos - 1)
        # Complex conditions, so express them this way to simplify
        if styleClassifier.is_operator_style(prev_style) and penultimate_ch == "&lt;":
            pass
        elif styleClassifier.is_identifier_or_word_style(prev_style):
            #XXX Reject keywords
            pass
        else:
            if DEBUG:
                print "no: %r is not '&lt; ' or ending a word"\
                      "(i.e. 'include ')" % (penultimate_ch+last_ch)
            return None
    elif last_ch == ':' \
         and not (last_pos &gt; 0
                  and accessor.char_at_pos(last_pos-1) == ':'):
        if DEBUG:
            penultimate_ch = (last_pos &gt; 0 
                and accessor.char_at_pos(last_pos-1) or '')
            print "no: %r is not '::'"\
                  % (penultimate_ch+last_ch)
        return None

    # Suppress triggering in some styles.
    TRIGGER_IN_STRING_CHARS = tuple('\'"/')
    last_style = accessor.style_at_pos(last_pos)
    if DEBUG:
        style_names = buf.style_names_from_style_num(last_style)
        print "  style: %s %s" % (last_style, style_names)
    suppress = False
    if implicit:
        if last_style in styleClassifier.implicit_completion_skip_styles:
            suppress = True
        elif last_style in styleClassifier.string_styles():
            if last_ch not in TRIGGER_IN_STRING_CHARS:
                # The ', ", and / trigger chars *always* trigger in
                # a string.
                suppress = True
        elif last_ch in TRIGGER_IN_STRING_CHARS:
            supress = True
    elif last_style in styleClassifier.completion_skip_styles:
        # If the user requests code-completion and previous char is
        # in this style, suppress it.
        suppress = True

    if suppress:
        if DEBUG:
            print "no: completion is suppressed in style at %s: %s %s"\
                  % (last_pos, last_style, style_names)
        return None 

    WHITESPACE = tuple(' \t\n\r')
    EOL = tuple('\n\r')
    if last_ch == ' ':
        # This may be one of the following:
        #   class FOO &lt; |       complete-available-modules-and-classes
        #       not implemented yet, "&lt;" not in trg-char tuple.
        #   include |           complete-available-modules
        #   method              calltip-call-signature
        # Simplifying assumptions:
        # With whitespace allow for a completion list after '&lt;'
        # in {class Name &lt;}, but allow for any calltip after an identifier.
        #   (above) that the preceding char (stored in
        #   'penultimate_ch') is '&lt;' or a word or identifier.
        # - The construct doesn't have to be on one line.
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        while i &gt; 0: # Skip back to start of line.
            if text[i] in EOL: break
            i -= 1
        line = text[i:].lstrip()
        if DEBUG: print "  line: %r" % line
        if penultimate_ch == "&lt;":
            if not line.startswith("class"): 
                if DEBUG:
                    print "no: line does not start with 'class'"
                return None
            if DEBUG:
                print "complete-available-modules-and-classes"
            return Trigger("Ruby", TRG_FORM_CPLN,
                           "available-modules-and-classes", 
                           pos, implicit)
        elif line.strip() == "include":
            if DEBUG:
                print "complete-available-modules"
            return Trigger("Ruby", TRG_FORM_CPLN, "available-modules",
                           pos, implicit)
        else: # maybe a calltip on a paren-free call
            if DEBUG:                    
                print "calltip-call-signature"
            return Trigger("Ruby", TRG_FORM_CALLTIP, "call-signature",
                           pos, implicit)

    elif last_ch == '.':
        # This can be:
        #   FOO.|               complete-object-methods
        #   LITERAL.|           complete-literal-methods
        #   but bug62397: not for a fixnum
        # Examples:
        #   Foo.
        #   foo.
        #   @foo.
        #   ::foo.
        #   (foo + 1).    &lt;-- We don't bother with this one for now
        #                     because CITDL processing won't resolve
        #                     the expression anyway.
        #   foo2.
        # Allow literals too:
        #   0.      3.14.
        #   1e6.    [].
        #   {}.     'foo'.      "bar".
        # Weird literals (pickaxe p319):
        #   %W{...}   # also q, Q, r, w, x, &lt;empty&gt; instead of 'W'
        #   0d123456, 0xff, -0b10_1010  # specific base laterals
        #   ?\M-a     # char literals 
        #   here docs
        #   symbols
        # Counter examples:
        #   foo  .          Don't allow whitespace in between.
        #                   No examples in Ruby stdlib that I can
        #                   see and more often interferes with range
        #                   operator.
        #   foo['bar'].     would need to find matching '[' and
        #                   ensure no ident char immediately
        #                   preceding (that's a heuristic)
        #   %W{foo}.        don't want to go there yet
        #
        #  def\w+CLASSNAME. Don't trigger on CLASSNAME, as we're in
        #                   a definition context, not a use one.
        if last_pos &gt; 0:
            last_last_pos = last_pos - 1
            last_last_ch = accessor.char_at_pos(last_last_pos)
            if DEBUG:
                print "  prev char = %r" % last_last_ch
            if last_last_ch in '"\'':
                return Trigger("Ruby", TRG_FORM_CPLN,
                               "literal-methods", pos, implicit,
                               literal="String")
            elif last_last_ch == '}':
                # Might be Hash literal:
                #   @tk_windows = {}.&lt;|&gt;taint
                # Need to rule out counter examples:
                #   attributes.collect{|name, value| ...}.&lt;|&gt;to_s
                #   FileTest.exist?("#{@filename}.&lt;|&gt;#{i}")
                #   @result = Thread.new { perform_with_block }.&lt;|&gt;value
                # Simplifying assumption (because too many counter
                # examples are more common): only trigger on exactly
                #   {}.&lt;|&gt;
                if last_pos &gt; 1 \
                   and accessor.char_at_pos(last_pos-2) == '{':
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "literal-methods", pos, implicit,
                                   literal="Hash")
                else: 
                    return None
            elif last_last_ch == ']':
                # Might be Array literal:
                #   @tk_table_list = [].&lt;|&gt;taint
                #   [1,2,3].&lt;|&gt;
                # Need to rule out counter examples:
                #   @@services[host][port].stop
                #   foo[blah].bang
                # Algorithm: Look back on currently line for
                # matching '['. If the char before that is a space,
                # then consider it an Array. If can't find matching
                # '[' on this line, then consider it an Array.
                wrk_line = accessor.text_range(
                    accessor.line_start_pos_from_pos(last_pos),
                    last_last_pos)
                block_count = 1
                for ch in reversed(wrk_line):
                    if not block_count:
                        if ch in WHITESPACE or ch in '=,(':
                            return Trigger("Ruby", TRG_FORM_CPLN,
                                           "literal-methods", pos,
                                           implicit, literal="Array")
                        return None
                    if ch == '[':
                        block_count -= 1
                    elif ch == ']':
                        block_count += 1
                else:
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "literal-methods", pos,
                                   implicit, literal="Array")
                return None
            elif isident(last_last_ch):
                LIMIT = 50
                text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
                if text.find("def") &gt; -1:
                    # String.find fails faster than Regex.search
                    idx = max(text.rfind("\n"), text.rfind("\r"))
                    if idx &gt; -1:
                        line = text[idx + 1:]
                    else:
                        line = text
                    if self._method_def_header.search(line):
                        if DEBUG: print "==&gt; bailing out, defining something"
                        return None
                return Trigger("Ruby", TRG_FORM_CPLN,
                                   "object-methods", pos, implicit)
            elif isdigit(last_last_ch):
                # Could be a numeric literal or an ident.
                wrk_line = accessor.text_range(
                    accessor.line_start_pos_from_pos(last_pos),
                    last_pos)
                if DEBUG:
                    print "'&lt;digit&gt;.': numeric literal or identifier"
                    print "check for leading number in %r" % wrk_line
                if self._leading_float_re.search(wrk_line):
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "literal-methods", pos,
                                   implicit, literal="Float")
                elif self._leading_number_re.search(wrk_line):
                    return (not implicit and
                            Trigger("Ruby", TRG_FORM_CPLN,
                                    "literal-methods", pos,
                                    implicit, literal="Fixnum")) or None
                else:
                    return Trigger("Ruby", TRG_FORM_CPLN,
                                   "object-methods", pos, implicit)
            else:
                return None

    elif last_ch == '(':
        # This may be:
        #   FOO(|           calltip-call-signature
        # - Want to be sure to exclude precedence parens after
        #   keywords: "if (", "while (", etc.
        # - XXX Are there instances of this trigger that we just
        #   want to drop here because of practical limitations in the
        #   Ruby codeintel handling -- as there are with Perl?
        LIMIT = 100
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        while i &gt;= 0 and text[i] in WHITESPACE: # parse off whitespace
            i -= 1
        RUBY_SPECIAL_METHOD_END_CHARS = "?!" #XXX what about '='?
        if i &gt;= 0 and not (isident(text[i]) or isdigit(text[i])
                           or text[i] in RUBY_SPECIAL_METHOD_END_CHARS):
            if DEBUG:
                print "no: first non-ws char before "\
                      "trigger point is not an ident char: '%s'" % text[i]
            return None
        end = i+1
        if text[i] in RUBY_SPECIAL_METHOD_END_CHARS:
            i -= 1
        while i &gt;= 0: # parse out the preceding identifier
            if isdigit(text[i]):
                # might be an identifier, need to keep looking
                pass
            elif not isident(text[i]):
                # Identifier can be prefixed with '$', '@' or '@@'.
                if i &gt;= 1 and text[i-1:i+1] == "@@":
                    start = i-1
                elif text[i] in "$@":
                    start = i
                else:
                    start = i+1
                identifier = text[start:end]
                break
            i -= 1
        else:
            identifier = text[:end]
        if DEBUG: print "  identifier: %r" % identifier
        if not identifier:
            if DEBUG:
                print "no: no identifier preceding trigger point"
            return None
        elif isdigit(identifier[0]):
            if DEBUG:
                print "no: token preceding trigger "\
                      "point is not a legal identifier"
            return None
        if identifier in self.RUBY_KEYWORDS:
            if DEBUG:
                print "no: no trigger on paren "\
                      "after keyword: %r" % identifier
            return None
        # Now we want to rule out subroutine definition lines, e.g.:
        #    def foo(
        #    def ClassName.foo(
        #    def self.foo(
        #    def (wacked+out).foo(
        line = text[:end].splitlines(0)[-1]
        if DEBUG:
            print "  trigger line: %r" % line
        if line.lstrip().startswith("def"):
            if DEBUG:
                print "no: no trigger on Ruby func definition"
            return None
        if DEBUG: print "calltip-call-signature"
        return Trigger("Ruby", TRG_FORM_CALLTIP, "call-signature",
                       pos, implicit)

    elif last_ch in ('"', "'"):
        # This may be one of these:
        #   require '|              complete-lib-paths
        #   require "|              complete-lib-paths
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        i = len(text)-1
        # Parse off whitespace before quote.
        while i &gt;= 0 and text[i] in WHITESPACE:
            i -= 1
        # Ensure that the "require" keyword immediately precedes the
        # quote.
        #XXX *Could* consider allowing preceding ';' or '#' rather
        #    than just whitespace.
        LEN_REQUIRE = 7 # len("require")
        i += 1 # point to one past "require"; simplifies indexing
        if i &gt; LEN_REQUIRE and text[i-LEN_REQUIRE:i] == "require" \
           and text[i-1-LEN_REQUIRE] in WHITESPACE:
            pass
        elif i == LEN_REQUIRE and text[:i] == "require":
            pass
        else:
            if DEBUG:
                print "no: quote not preceded by bare 'require'"
            return None
        if DEBUG: print "complete-lib-paths"
        return Trigger("Ruby", TRG_FORM_CPLN, "lib-paths",
                       pos, implicit)

    elif last_ch == '/':
        # This may be one of these:
        #   require 'foo/|          complete-lib-subpaths
        #   require "foo/|          complete-lib-subpaths
        # Simplifying assumption: this must all be on the same line.
        LIMIT = 75
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        # Get the current line.
        i = len(text)-1
        while i &gt; 0: # Skip back to start of line.
            if text[i] in EOL: break
            elif not styleClassifier.is_ruby_style_at_pos(i):
                # Did we get back more than one char?
                if i &lt; last_pos:
                    i += 1
                break
            i -= 1
        line = text[i:].lstrip()
        if DEBUG: print "  line: %r" % line
        # Optimization: Just check that the line looks like a
        # require statement. This might miss things like:
        #       foo; require 'bar/baz'
        # but who does that? 80/20
        LEN_REQUIRE = 7 # len("require") == 7
        if not line.startswith("require") \
           or line[LEN_REQUIRE] not in WHITESPACE \
           or line[LEN_REQUIRE:].lstrip()[0] not in ("'", '"'):
            if DEBUG:
                print "no: line doesn't start with "\
                      "/require\\s+['\"]/: &lt;&lt;%r&gt;&gt;" % line ### EKR: &lt;&lt;%r&gt;&gt; causes problems
            return None
        if DEBUG:
            print "complete-lib-subpaths"
        return Trigger("Ruby", TRG_FORM_CPLN, "lib-subpaths",
                       pos, implicit)

    elif last_ch == ':':
        # This may be:
        #   MODULE::|           complete-module-names
        # We've already checked (above) that the preceding character
        # is ':'.
        LIMIT = 50
        text = accessor.text_range(max(0,last_pos-LIMIT), last_pos) # working text
        if DEBUG: print "  working text: %r" % text
        # Just walk over the preceding token until we are pretty
        # sure it can be a variable name: there is a letter or
        # underscore in it.
        i = len(text) - 2 # len('::') == 2
        while i &gt;= 0:
            if isident(text[i]):
                break # good enough, could be an identifier
            elif isdigit(text[i]):
                i -= 1 # might be an identifier, need to keep looking
            else:
                if DEBUG:
                    print "no: '::' not preceded with "\
                          "identifier: %r" % text[i]
                return None
        else:
            if DEBUG:
                print "no: '::' not preceded with "\
                      "identifier: %r" % text[i]
            return None
        if DEBUG:
            print "complete-module-names"
        return Trigger("Ruby", TRG_FORM_CPLN, "module-names",
                       pos, implicit, length=2)

    elif last_ch == '@':
        # Is likely (always?) one of:
        #       @@|             complete-class-vars
        #       @|              complete-instance-vars
        if (last_pos &gt; 0 and accessor.char_at_pos(last_pos-1) == '@'):
            if DEBUG: print "complete-class-vars"
            return Trigger("Ruby", TRG_FORM_CPLN, "class-vars",
                           pos, implicit, length=2)
        else:
            if DEBUG: print "complete-instance-vars"
            return Trigger("Ruby", TRG_FORM_CPLN, "instance-vars",
                           pos, implicit)

    elif last_ch == '$':
        # Is likely (always?) this:
        #       $|              complete-global-vars
        if DEBUG: print "complete-global-vars"
        return Trigger("Ruby", TRG_FORM_CPLN, "global-vars",
                       pos, implicit)

    return None


</t>
<t tx="ekr.20080121105837.1481"># Match a Ruby number literal.
# Limitations:
# - 0d123456, 0xff, -0b10_1010  # specific base laterals
_number_pat = r"""
      \d+\.\d+                  # float
    | \d+(\.\d+)?([eE][-+]?\d+)  # exp float
"""
_leading_float_re = re.compile("(?&lt;!\w)(%s)$" % _number_pat, re.X)
_leading_number_re = re.compile("(?&lt;!\w)\d+$")

_method_def_header = re.compile(r'\bdef\s+\w+$')

# Example Ruby "leading expressions":
#   send
#   File.open
#   Zlib::Deflate.deflate
#   0.step (XXX punt on numbers for now)
#   @assigned
#   @@foo
#   $blah
#   @assigned.foo
#   @ingredients.has_key?
#   $_  (XXX punt on the special vars for now)
_leading_citdl_expr_pat = re.compile(r"""
    (
        (       # the set of those with @, @@, $ prefix
            (@@|@|\$)%(ident)s(\.%(ident)s)*    
        )
        |
        (       # or, the set of those without the prefix
            %(ident)s(::%(ident)s)*(\.%(ident)s)*
        )
        |       # or a literal
        (
            (?P&lt;literal&gt;\]|\}|\'|\"|%(number)s|(?&lt;!\w)\d+)(?P&lt;literal_tail&gt;(\.%(ident)s)*)
        )
    )
    [?!]?       # methods can end with '?' or '!' (XXX what about '='?)
    \s*$        # anchored at the end of the string
    """ % {"ident": "((?!\d)\w+)", "number": _number_pat}, re.X)

#@hotshotit
def preceding_trg_from_pos(self, buf, pos, curr_pos, DEBUG=False):
    """ Cases where we're interested in continuing a trigger:

    Examples:
    
        GIVEN                                   TRG AT
        -----                                   ----------
    ident1.&lt;$&gt;iden&lt;|&gt;t2 ...                     .
       allow and ignore spaces after '.'
    ident1::&lt;$&gt;iden&lt;|&gt;t2 ...                    ::
       allow and ignore spaces after '::'
    class ident1 &lt;&lt;$&gt; ide&lt;|&gt;nt2                 ' ' after "&lt;"
       allow and ignore spaces after '&lt;'
    require '&lt;$&gt;no-slash-path&lt;|&gt;                '
    require 'path/&lt;$&gt;rest&lt;|&gt;                    /
    &lt;$&gt;iden&lt;|&gt;                                  start of word

    pos is marked by "&lt;$&gt;"
    curr_pos indicated by "&lt;|&gt;"
    """
    
    
    styleClassifierClass = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                            or _RubyStyleClassifier)
    preceding_trg_terminators = None
    if styleClassifierClass == _UDLStyleClassifier:
        preceding_trg_terminators = {"%" : SCE_UDL_TPL_OPERATOR}
    trg = ProgLangTriggerIntelMixin.preceding_trg_from_pos(
            self, buf, pos, curr_pos,
            preceding_trg_terminators=preceding_trg_terminators,
            DEBUG=DEBUG)
    if trg is not None:
        return trg
    if DEBUG:
        print "preceding_trg_from_pos: pos=%d, curr_pos=%d" % (pos, curr_pos)
    styleClassifier = styleClassifierClass(buf)
    # Assume we're on an identifier that doesn't follow a
    # trigger character.  Find its start.
    accessor = buf.accessor
    curr_style = accessor.style_at_pos(curr_pos - 1)
    if styleClassifier.is_identifier_or_word_style(curr_style):
        # Check for one of the following:
        # class ident1 &lt; ide&lt;|&gt;
        # ide&lt;|&gt;
        idx = curr_pos - 2
        for char_and_style in accessor.gen_char_and_style_back(idx, 0):
            if char_and_style[1] != curr_style:
                break
            idx -= 1
        if idx &lt;= 0:
            if DEBUG:
                print "Moved to beginning of buffer"
            return None
        trg = self.trg_from_pos(buf, curr_pos, implicit=False, DEBUG=DEBUG)
        return trg
    elif DEBUG:
        print "Ignore current style %d" % curr_style


</t>
<t tx="ekr.20080121105837.1482">def citdl_expr_from_trg(self, buf, trg):
    """Parse out the leading Ruby expression and return a CITDL
    expression for it.
    
    We parse out the Ruby expression preceding the given position
    (typically a calltip/autocomplete trigger position), simplify the
    expression (by removing whitespace, etc.) and translate that to an
    appropriate CITDL (*) expression. Returns None if there is no
    appropriate such expression.
    
    Optimization Notes:
    - We can throw out Ruby expressions with function calls
      because CodeIntel does not currently handle return values.
    - Abort at hash and list indexing: the types of elements in these
      objects are not tracked by CodeIntel.
    - Currently we don't really make use of the styling info because we
      abort at indexing, function call arguments, etc. where recognizing
      string/number/regex boundaries would be useful. This info might be
      useful later if this algorithm is beefed up.

    Examples:
    
        GIVEN                                   CITDL EXPR
        -----                                   ----------
        send(&lt;|&gt;                                send
        foo.instance_of?(&lt;|&gt;                    foo.instance_of?
        File.open(&lt;|&gt;                           File.open
        Zlib::Deflate.deflate(&lt;|&gt;               Zlib::Deflate.deflate
        @assigned.&lt;|&gt;                           @assigned
        @@foo.&lt;|&gt;                               @foo
        $blah.&lt;|&gt;                               @blah
        YAML::PRIVATE_TYPES[r].call(&lt;|&gt;         &lt;punt because of []&gt;
        [$2].pack(&lt;|&gt;                           &lt;punt&gt;
        @db_class::&lt;|&gt;WidgetClassName           &lt;punt: looks to be rare&gt;

        0.&lt;|&gt;                                   Fixnum
        '...'.&lt;|&gt;  "...".&lt;|&gt;                    String
        [].step(&lt;|&gt;                             Array.step
        {}.step(&lt;|&gt;                             Hash.step

    * http://specs.tl.activestate.com/kd/kd-0100.html#citdl
    """
    DEBUG = False
    pos = trg.pos
    styleClassifier = (isinstance(buf, UDLBuffer) and _UDLStyleClassifier
                       or _RubyStyleClassifier)(buf)
    accessor = buf.accessor
    last_pos = pos - 1

    buflen = accessor.length()
    end_pos = pos
    if trg.form == TRG_FORM_DEFN:
        # Move pos forward until at the end of the current expression
        trg_length = 0
        curr_style = accessor.style_at_pos(last_pos)
        if not styleClassifier.is_identifier_style(curr_style):
            return None
        idx = pos
        while idx &lt; buflen:
            new_style = accessor.style_at_pos(idx)
            if new_style != curr_style:
                end_pos = idx
                break
            idx += 1
    else:
        trg_length = trg.length
        end_pos = pos - trg_length
    wrk_text = buf.accessor.text_range(max(0, pos-100), end_pos)
    if DEBUG:
        print banner("Ruby citdl_expr_from_trg")
        if pos &gt; 100:
            print "...",
        print (wrk_text
               + "&lt;+&gt;")
        print banner(None, '-')

    # Parse off a Ruby leading expression.
    match = self._leading_citdl_expr_pat.search(wrk_text)
    if not match:
        if trg.type == "names" and not trg.implicit:
            citdl_expr = ""
            if DEBUG:
                print "trigger-type of current-names: match anything"
        else:
            citdl_expr = None
            if DEBUG:
                print "could not match a trailing Ruby var"
    elif match.group("literal"):
        literal = match.group("literal")
        literal_tail = match.group("literal_tail")
        ruby_type_from_literal = {']': "Array", '}': "Hash", 
                                  '"': "String", "'": "String"}
        if DEBUG:
            print "leading literal (part): %r (tail=%r)"\
                  % (literal, literal_tail)
        try:
            ruby_type = ruby_type_from_literal[match.group('literal')]
        except KeyError:
            if '.' in literal or 'e' in literal or 'E' in literal:
                ruby_type = "Float"
            else:
                ruby_type = "Fixnum"
        citdl_expr = ruby_type + literal_tail 
    else:
        citdl_expr = match.group(0)
        if DEBUG:
            print "parsed out leading Ruby citdl_expr: %r" % citdl_expr

    if DEBUG:
        print "returning: %r" % citdl_expr
        print banner(None, '-')
    return citdl_expr

</t>
<t tx="ekr.20080121105837.1483">_require_pat = re.compile(r'(?:require|load)\s+[\'"](.*?)$')
def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        trg = UnwrapObject(trg)
        ctlr = UnwrapObject(ctlr)
    ctlr.start(buf, trg)

    if trg.id == ("Ruby", TRG_FORM_CALLTIP, "call-signature"): # FOO(&lt;|&gt;
        line = buf.accessor.line_from_pos(trg.pos)
        citdl_expr = self.citdl_expr_from_trg(buf, trg)
        if citdl_expr is None:
            return None

        # Special case for class ".new" constructor:
        # "Foo.new(" is really using "Foo.initialize(".
        if citdl_expr.endswith(".new"):
            converted_dot_new = True 
            citdl_expr = citdl_expr[:-len(".new")] + ".initialize"
        else:
            converted_dot_new = False

        evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line,
                                  converted_dot_new=converted_dot_new)
        buf.mgr.request_eval(evalr)

    elif trg.form == TRG_FORM_DEFN or \
         (trg.form == TRG_FORM_CPLN and trg.type in (
            "object-methods",                   # FOO.|
            "module-names",                     # MODULE::|
            "literal-methods",		    # LITERAL.
         )):
        line = buf.accessor.line_from_pos(trg.pos)
        citdl_expr = self.citdl_expr_from_trg(buf, trg)
        if citdl_expr is None:
            ctlr.error("couldn't determine leading expression")
            ctlr.done("error")
            return
        evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)

    elif trg.form == TRG_FORM_CPLN and trg.type == "literal-methods":
        evalr = RubyLiteralEvaluator(ctlr, buf, trg, None, None)
        buf.mgr.request_eval(evalr)

    elif trg.form == TRG_FORM_CPLN and trg.type in (
            "lib-paths",                # require '|, require "|
            "lib-subpaths",             # require 'foo/|, require "foo/
         ):
        if trg.type == "lib-subpaths":
            accessor = buf.accessor
            line = accessor.text_range(
                accessor.line_start_pos_from_pos(trg.pos),
                trg.pos-trg.length)
            match = self._require_pat.search(line)
            if not match:
                return None # not a trigger point
            require_arg = match.group(1)
        else:
            require_arg = ""

        import_handler \
            = buf.mgr.citadel.import_handler_from_lang("Ruby")
        evalr = RubyImportsEvaluator(ctlr, buf, trg, import_handler,
                                     require_arg)
        buf.mgr.request_eval(evalr)

    elif trg.form == TRG_FORM_CPLN and trg.type == "names": # FOO|
        line = buf.accessor.line_from_pos(trg.pos)
        extra = trg.extra
        citdl_expr = extra.get("prefix")
        if citdl_expr is None:
            ctlr.error("couldn't determine leading expression")
            ctlr.done("error")
            return
        evalr = RubyTreeEvaluator(ctlr, buf, trg, citdl_expr, line)
        buf.mgr.request_eval(evalr)

    elif trg.form == TRG_FORM_CPLN and trg.type in (
            "available-modules-and-classes",    # class FOO &lt; |
            "class-vars",                       # @@|
            "instance-vars",                    # @|
            "available-modules",                # include |
            "global-vars",                      # $|
         ):
        #XXX NYI. Should disable these at trg_from_pos else will get
        #    statusbar warnings.
        return None

    else:
        raise CodeIntelError("unexpected ruby trigger: %r" % trg)


</t>
<t tx="ekr.20080121105837.1484">#---- code browser integration
cb_import_group_title = "Requires and Includes"   

def cb_import_data_from_elem(self, elem):
    # require 'zlib' -&gt; &lt;import module="zlib" symbol="*"/&gt;
    # include Comparable -&gt; &lt;import symbol="Comparable"/&gt;
    module = elem.get("module")
    symbol = elem.get("symbol")
    if not module:
        name = symbol
        detail = 'include %s' % symbol
    else:
        name = module
        detail = 'require "%s"' % module
    return {"name": name, "detail": detail}

</t>
<t tx="ekr.20080121105837.1485">def calltip_verify_termination(self, accessor, ch, trg_pos, curr_pos):
    """Terminate on a newline if the trigger was a space"""
    return ch not in ('\r', '\n') or accessor.char_at_pos(trg_pos - 1) == ' '

</t>
<t tx="ekr.20080121105837.1486">class RubyImportHandler(ImportHandler):
    PATH_ENV_VAR = "RUBYLIB"
    sep = '/'
    @others
</t>
<t tx="ekr.20080121105837.1487"># Dev Notes:
# - ruby -e "puts $:"
# - XXX What are the implications of Ruby GEMs?

# Try to speed up self._getPath() a little bit.
def __init__(self, mgr):
    ImportHandler.__init__(self, mgr)
    self._pathCache = None
    self._findModuleOnDiskCache = {}
</t>
<t tx="ekr.20080121105837.1488">if CACHING:
    def _getPath(self, cwd=None):
        if self._pathCache is None:
            self._pathCache = ImportHandler._getPath(self) # intentionally exclude cwd
        if cwd:
            return [cwd] + self._pathCache
        else:
            return self._pathCache

def _shellOutForPath(self, compiler):
    import process
    argv = [compiler, "-e", "puts $:"]
    # Ruby doesn't have an option (like Python's -E) to ignore env
    # vars.
    env = dict(os.environ)
    if "RUBYLIB" in env: del env["RUBYLIB"]
    if "RUBYLIB_PREFIX" in env: del env["RUBYLIB_PREFIX"]

    p = process.ProcessOpen(argv, env=env)
    retval = p.wait()
    output = p.stdout.read()
    p.close()
    path = [line for line in output.splitlines(0)]
    if sys.platform == "win32":
        path = [p.replace('/', '\\') for p in path]
    # Handle cwd separately.
    path = [p for p in path if p not in ("", ".", os.getcwd())]
    return path

</t>
<t tx="ekr.20080121105837.1489">def setCorePath(self, compiler=None, extra=None):
    if compiler is None:
        import which
        try:
            compiler = which.which("ruby")
        except which.WhichError, ex:
            self.corePath = [] # could not determine
            return
    self.corePath = self._shellOutForPath(compiler)

</t>
<t tx="ekr.20080121105837.1490">##    def _getStdCIXScanId(self, cu):
##        if not self.__stdCIXScanId:
##            cu.execute("SELECT scan.id FROM scan, file, language "
##                       " WHERE language.name='Ruby'"
##                       "   AND language.id=file.language_id"
##                       "   AND scan.file_id=file.id"
##                       "   AND scan.generator='StdCIX' LIMIT 1")
##            for row in cu:
##                self.__stdCIXScanId = row[0]
##                break
##        return self.__stdCIXScanId

def findModule(self, cu, factory, moduleName, dummy, cwd=None):
    XXX__lang_ruby__findModule_1 # line 1
    log.debug("   RubyImportHandler.findModule(module=%r, "
              "submodule=%r, cwd=%r)", moduleName, dummy, cwd)
    
    if CACHING:
        key = (moduleName, cwd)
        retval = factory.rubyFindModuleCache.get(key, None)
        if retval is not None:
            return retval

    # Look for the appropriate file on disk, using the import path.
    modfile, kind, scannable = self.findModuleOnDisk(moduleName, dummy, cwd)
    
    # If found, see if we have this file and module in the CIDB.
    module = file_id = None
    if modfile:
        cu.execute("SELECT * FROM module "
                   "WHERE file_id=(SELECT id FROM file WHERE compare_path=?) "
                   "AND name=? LIMIT 1",
                   (canonicalizePath(modfile), moduleName))
        for row in cu:
            module = factory.createScope(row[M_FILE_ID], "module",
                                         row[M_ID], row)
            break

    if CACHING and module:
        # Only insert into the cache here, and NOT if the retval
        # is gotten via the fallback because that probably means the
        # module just isn't scanned yet.
        # - There are exceptions, e.g. HTML::FormatText, HTML::FormatPS,
        #   that defy existence.
        factory.rubyFindModuleCache[key] = (module, "module")
        factory.rubyFindModuleCacheIndex[module.file_id] = key

    #XXX This block was removed from the Perl equiv for Perf
    #    reasons. Should the same be done here?
    # If haven't found a matching module row yet then just look for any
    # loaded Ruby module of the same name. First one wins.
    if not module:
        sql = "SELECT module.* FROM language, file, module"\
              " WHERE language.name='Ruby' "\
              "   AND language.id=file.language_id "\
              "   AND module.file_id=file.id "\
              "   AND module.name=? LIMIT 1"
        cu.execute(sql, (moduleName,))
        for row in cu:
            module = factory.createScope(row[M_FILE_ID], "module",
                                         row[M_ID], row)
            kind = "module"
            break

    log.debug("   RubyImportHandler.findModule: '%s' -&gt; %r",
              moduleName, module)
    if not module:
        raise NoModuleEntry(moduleName, modfile)
    else:
        return (module, "module")

</t>
<t tx="ekr.20080121105837.1491">def findModuleOnDisk(self, module, dummy, cwd=None):
    r"""
        &gt;&gt;&gt; h = RubyImportHandler()
        &gt;&gt;&gt; h.findModuleOnDisk("tempfile", None)
        ('c:\\ruby18\\lib\\ruby\\1.8\\tempfile.rb', 'module', 1)
    """
    from os.path import isabs, join, exists
    if CACHING:
        # The findModuleOnDisk cache is a time-based cache. I.e. it make
        # the presumption that the file system hasn't changed
        # significantly in the last N seconds.
        N = 300 # 5 minutes
        key = (module, cwd)
        if key in self._findModuleOnDiskCache\
           and self._findModuleOnDiskCache[key][0] &gt; time.time() - N:
            return self._findModuleOnDiskCache[key][1]

    exts = [".rb", ".so"]
    if sys.platform == "win32":
        module = module.replace("/", "\\")
    mpath = None
    if isabs(module):
        for ext in exts:
            if exists(module+ext):
                mpath = module+ext
                break
    else:
        path = self._getPath(cwd)
        for dname in path:
            base = join(dname, module)
            for ext in exts:
                if exists(base+ext):
                    mpath = base+ext
                    break
            if mpath:
                break
    if not mpath:
        log.debug("   RubyImportHandler.findModuleOnDisk: could not "
                  "find '%s' in path: %s", module, path)
        retval = (None, None, None)
        if CACHING:
            self._findModuleOnDiskCache[key] = (time.time(), retval)
        return retval

    log.debug("   RubyImportHandler.findModuleOnDisk: '%s' -&gt; '%s'",
              module, mpath)
    retval = (mpath,
              "module", # The "submodule"-thing isn't relevant in Ruby
              #XXX Perl only handles .pm files. Need we only handle .rb
              #    files here?
              mpath.endswith(".rb"))
    if CACHING:
        self._findModuleOnDiskCache[key] = (time.time(), retval)
    return retval

</t>
<t tx="ekr.20080121105837.1492">def findSubImportsOnDisk(self, module, cwd):
    from os.path import isdir, join, splitext, exists

    path = self._getPath(cwd)
    if os.sep != "/":
        mrelpath = module.replace("/", os.sep)
    else:
        mrelpath = module

    subimports = {} # use a dict to get a unique list
    for p in path:
        mdir = join(p, mrelpath)
        if not exists(mdir):
            continue
        for name in os.listdir(mdir):
            fullpath = join(mdir, name)
            if fullpath in path:
                # Don't show dirs that would just lead back to the
                # another dir on the import path.
                continue
            elif isdir(fullpath):
                subimports[name+"/"] = True
            elif splitext(name)[-1] in (".rb", ".so"):
                subimports[splitext(name)[0]] = True
    return subimports.keys()

</t>
<t tx="ekr.20080121105837.1493">def _findScannableFiles(self,
                        (files, searchedDirs, skipRareImports,
                         importableOnly),
                        dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    #XXX Handle skipRareImports???
    scannableExts = [".rb"]
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = os.path.join(dirname, names[i])
        if os.path.isdir(path):
            pass
        elif os.path.splitext(names[i])[1] in scannableExts:
            #XXX The list of extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs.
            #XXX This check for files should probably include
            #    scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            files.append(path)

</t>
<t tx="ekr.20080121105837.1494">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        if dirname in ("", "."):
            # Do NOT traverse the common '.' element of '$:'. It is
            # environment-dependent so not useful for the typical call
            # of this method.
            continue
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs, skipRareImports,
                      importableOnly))
        for file in files:
            yield file

</t>
<t tx="ekr.20080121105837.1495">def find_importables_in_dir(self, dir):
    """See citadel.py::ImportHandler.find_importables_in_dir() for
    details.

    Importables for Ruby look like this:
        {"shell":   ("shell.rb",   None, True),
         "weakref": ("weakref.rb", None, False),
         "rdoc":    (None,         None, True)}

    Notes:
    - Drop "plat" dir (e.g., "i686-linux" on linux). Using the
      existance of "$dir/rbconfig.rb" to indicate this is a plat
      dir. Optimization: Only look in dirs with a hyphen.

    TODO: log the fs-stat'ing a la codeintel.db logging.
    TODO: consider *.so files when have a story for binary modules
          on the fly
    """
    from os.path import join, isdir, splitext, exists

    if dir == "&lt;Unsaved&gt;":
        #TODO: stop these getting in here.
        return {}

    try:
        names = os.listdir(dir)
    except OSError, ex:
        return {}
    dirs, nondirs = set(), set()
    for name in names:
        if isdir(join(dir, name)):
            if '-' in name and exists(join(dir, name, "rbconfig.rb")):
                # Looks like a plat dir: skip it.
                continue
            dirs.add(name)
        else:
            nondirs.add(name)

    importables = {}
    for name in nondirs:
        base, ext = splitext(name)
        if ext != ".rb":
            continue
        if base in dirs:
            importables[base] = (name, None, True)
            dirs.remove(base)
        else:
            importables[base] = (name, None, False)
    for name in dirs:
        importables[name] = (None, None, True)

    return importables


</t>
<t tx="ekr.20080121105837.1496">def _blob_scope_from_codeintel_tree(tree):
    if tree.tag == "codeintel":
        node = tree.findall("file/scope")
    # node = tree.getroot().getchildren()[0].getchildren()[0].getchildren()[0];
    return node and node[0]

</t>
<t tx="ekr.20080121105837.1497">class RubyCILEDriver(CILEDriver):
    lang = lang

    @others
</t>
<t tx="ekr.20080121105837.1498">def scan(self, request):
    request.calculateMD5()
    return rubycile.scan(request.content, request.path,
                         request.md5sum, request.mtime)

</t>
<t tx="ekr.20080121105837.1499">def scan_purelang(self, buf):
    tree = rubycile.scan_purelang(buf.accessor.text, buf.path)
    blob_scope = _blob_scope_from_codeintel_tree(tree)
    rubycile.check_insert_rails_env(buf.path, blob_scope)
    return tree

</t>
<t tx="ekr.20080121105837.1500">def scan_multilang(self, buf, csl_cile_driver=None):
    """Scan the given multilang (UDL-based) buffer and return a CIX
    element tree.

        "buf" is the multi-lang Buffer instance (e.g.
            lang_rhtml.RHTMLBuffer for RHTML).
        "csl_cile_driver" (optional) is the CSL (client-side language)
            CILE driver. While scanning, CSL tokens should be gathered and,
            if any, passed to the CSL scanner like this:
                csl_cile_driver.scan_csl_tokens(
                    file_elem, blob_name, csl_tokens)
            The CSL scanner will append a CIX &lt;scope ilk="blob"&gt;
            element to the &lt;file&gt; element.
    """
    tree = Element("codeintel", version="2.0")
    path = buf.path
    if sys.platform == "win32":
        path = path.replace('\\', '/')
    file = SubElement(tree, "file", lang=buf.lang, path=path)
    module = SubElement(file, "scope", ilk="blob", lang="Ruby", 
                        name=basename(buf.path))

    #XXX When running inside Komodo we'll have to either implement
    #    SciMozAccessor.gen_tokens() or adapt rubycile to work with
    #    a SciMoz styled text stream. Whichever is easier and
    #    faster.
    csl_tokens, has_ruby_code = \
        rubycile.scan_multilang(buf.accessor.gen_tokens(), module)
    rubycile.check_insert_rails_env(path, module)

    # if the Ruby module node contains no children, remove it (bug 64897)
    if not has_ruby_code:
        assert len(module) == 0
        file.remove(module)
    
    if csl_cile_driver and csl_tokens:
        csl_cile_driver.scan_csl_tokens(file, basename(buf.path),
                                        csl_tokens)

    #XXX While still generating CIX 0.1, need to convert to CIX 2.0.
    #XXX Trent: This can all be deleted now, right?
    # tree = tree_2_0_from_tree_0_1(tree)

    return tree



</t>
<t tx="ekr.20080121105837.1501">#---- internal support stuff




#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=RubyLexer(),
                      buf_class=RubyBuffer,
                      langintel_class=RubyLangIntel,
                      import_handler_class=RubyImportHandler,
                      cile_driver_class=RubyCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1502">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1503">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Common routines for ruby and ruby/rhtml support for CodeIntel"""

import os.path
import logging

log = logging.getLogger("codeintel.ruby.common")
</t>
<t tx="ekr.20080121105837.1504">#log.setLevel(logging.DEBUG)
class RubyCommonBufferMixin:
    @others
</t>
<t tx="ekr.20080121105837.1505">def check_for_rails_app_path(self, path):
    self.framework_role = None
    if path is None:
        #log.debug("check_for_rails_app_path: no path given")
        return
    apath = os.path.abspath(path)
    aplist = apath.split(os.path.sep)
    role_root = "rails"
    if len(aplist) &lt; 3:
        return
    elif (aplist[-3] == "app" and
        (aplist[-2] == "controllers" and aplist[-1].endswith(".rb")
         or aplist[-2] == "helpers" and aplist[-1].endswith("_helper.rb")
         or aplist[-2] == "models" and aplist[-1].endswith(".rb"))):
        role = '.'.join((role_root, aplist[-2]))
    elif (len(aplist) &gt;= 4
          and aplist[-4] == "app" and aplist[-3] == "views"
          and aplist[-1].endswith(".rhtml")):
        role = '.'.join((role_root, aplist[-3], aplist[-2]))
    elif (aplist[-3] == "db" and aplist[-2] == "migrate"
          and aplist[-1][0].isdigit()
          and aplist[-1].endswith(".rb")):
        role = '.'.join((role_root, aplist[-3], aplist[-2]))        
    elif (aplist[-3] == "test"
          and aplist[-2] in ("functional", "unit")
          # integration tests not supported until we can find
          # ActionController::IntegrationTest
          and aplist[-1].endswith("_test.rb")):
        role = '.'.join((role_root, aplist[-3], aplist[-2]))        
    else:
        return
    self.framework_role = role


</t>
<t tx="ekr.20080121105837.1506">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1507">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Smarty support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "Smarty"
log = logging.getLogger("codeintel.smarty")



</t>
<t tx="ekr.20080121105837.1508">#---- language support

class SmartyLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1509">class SmartyBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "PHP"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    #TODO: adjust for PHP, if necessary
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"


</t>
<t tx="ekr.20080121105837.1510">class SmartyCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "PHP"



</t>
<t tx="ekr.20080121105837.1511">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=SmartyLexer(),
                      buf_class=SmartyBuffer,
                      import_handler_class=None,
                      cile_driver_class=SmartyCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1512">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1513">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""Tcl support for CodeIntel"""

import sys
import os
import logging
from pprint import pprint

import process

import SilverCity
from SilverCity.Lexer import Lexer
from SilverCity import ScintillaConstants

from codeintel2.citadel import ImportHandler, CitadelBuffer
from codeintel2.citadel_common import ScanRequest
from codeintel2.common import *
from codeintel2.parseutil import urlencode_path
from codeintel2.tree import tree_from_cix
from codeintel2.langintel import LangIntel


#---- globals

lang = "Tcl"
log = logging.getLogger("codeintel.tcl")

gUseOldTclcile = False #XXX Hook this in for moving to new tclcile

keywords = ["after", "append", "array", "auto_execok",
            "auto_import", "auto_load", "auto_load_index",
            "auto_qualify", "bgerror", "binary", "break", "case",
            "catch", "cd", "clear", "clock", "close", "concat",
            "continue", "else", "then", "elseif", "encoding",
            "eof", "error", "eval", "exec", "exit", "expr",
            "fblocked", "fconfigure", "fcopy", "file",
            "fileevent", "flush", "for", "foreach", "format",
            "gets", "glob", "global", "history", "if", "incr",
            "info", "interp", "join", "lappend", "lindex",
            "linsert", "list", "llength", "load", "lrange",
            "lreplace", "lsearch", "lsort", "namespace", "open",
            "package", "pid", "pkg_compareExtension",
            "pkg_mkIndex", "proc", "puts", "pwd", "read",
            "regexp", "regsub", "rename", "return", "scan",
            "seek", "set", "socket", "source", "split", "string",
            "subst", "switch", "tcl_unknown", "tell", "time",
            "trace", "unknown", "unset", "update", "uplevel",
            "upvar", "variable", "vwait", "while",
            "bell", "bind", "bindtags", "button", "canvas",
            "checkbutton", "clipboard", "destroy", "entry",
            "event", "focus", "font", "frame", "grab", "grid",
            "image", "label", "listbox", "lower", "menu",
            "menubutton", "message", "option", "pack", "place",
            "radiobutton", "raise", "registry", "scale",
            "scrollbar", "selection", "spinbox",
            "tcl_findLibrary", "text", "tk", "tk_chooseColor",
            "tk_chooseDirectory", "tk_getOpenFile",
            "tk_getSaveFile", "tk_menuSetFocus", "tk_messageBox",
            "tk_popup", "tk_textCopy", "tk_textCut",
            "tk_textPaste", "tkwait", "toplevel", "winfo", "wm"]

line_end_re = re.compile("(?:\r\n|\r)")

</t>
<t tx="ekr.20080121105837.1514">#---- language support

class TclLexer(Lexer):
    lang = "Tcl"
    @others
</t>
<t tx="ekr.20080121105837.1515">def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_TCL)
    self._keyword_lists = [
        SilverCity.WordList(' '.join(keywords))
    ]


</t>
<t tx="ekr.20080121105837.1516">class TclBuffer(CitadelBuffer):
    lang = "Tcl"
    cb_show_if_empty = True


</t>
<t tx="ekr.20080121105837.1517">class TclLangIntel(LangIntel):
    @others
</t>
<t tx="ekr.20080121105837.1518">def cb_import_data_from_elem(self, elem):
    #XXX Not handling symbol and alias
    module = elem.get("module")
    detail = "package require %s" % module
    return {"name": module, "detail": detail}    


</t>
<t tx="ekr.20080121105837.1519">class TclImportHandler(ImportHandler):
    # Tcl _does_ have a TCLLIBPATH environment variable for specifying
    # import path elements, but parsing isn't straighforward -- it uses
    # Tcl-syntax -- so we don't bother to separate "envPath" and "corePath"
    # for Tcl.
    PATH_ENV_VAR = None

    @others
</t>
<t tx="ekr.20080121105837.1520">def _shellOutForPath(self, compiler):
    import process
    argv = [compiler]
    p = process.ProcessOpen(argv)
    p.stdin.write("puts [join $auto_path \\n]")
    p.stdin.close()
    retval = p.wait()
    output = p.stdout.read()
    p.close()
    path = [os.path.normpath(line) for line in output.splitlines(0)]
    if path and (path[0] == "" or path[0] == os.getcwd()):
        del path[0] # cwd handled separately
    return path

</t>
<t tx="ekr.20080121105837.1521">def setCorePath(self, compiler=None, extra=None):
    if compiler is None:
        import which
        compiler = which.which("tclsh")
    self.corePath = self._shellOutForPath(compiler)

</t>
<t tx="ekr.20080121105837.1522">def _findScannableFiles(self, (files, searchedDirs, skipRareImports),
                        dirname, names):
    if sys.platform.startswith("win"):
        cpath = dirname.lower()
    else:
        cpath = dirname
    if cpath in searchedDirs:
        while names:
            del names[0]
        return
    else:
        searchedDirs[cpath] = 1
    for i in range(len(names)-1, -1, -1): # backward so can del from list
        path = os.path.join(dirname, names[i])
        if os.path.isdir(path):
            pass
        elif os.path.splitext(names[i])[1] in (".tcl",):
            #XXX The list of extensions should be settable on
            #    the ImportHandler and Komodo should set whatever is
            #    set in prefs.
            #XXX This check for files should probably include
            #    scripts, which might likely not have the
            #    extension: need to grow filetype-from-content smarts.
            if skipRareImports and names[i] == "pkgIndex.tcl":
                continue
            files.append(path)

</t>
<t tx="ekr.20080121105837.1523">def genScannableFiles(self, path=None, skipRareImports=False,
                      importableOnly=False):
    if path is None:
        path = self._getPath()
    searchedDirs = {}
    for dirname in path:
        if dirname == os.curdir:
            continue
        files = []
        os.path.walk(dirname, self._findScannableFiles,
                     (files, searchedDirs, skipRareImports))
        for file in files:
            yield file


</t>
<t tx="ekr.20080121105837.1524">class TclCILEDriverOld(CILEDriver):
    lang = lang
    @others
</t>
<t tx="ekr.20080121105837.1525">def __init__(self, mgr):
    CILEDriver.__init__(self, mgr)
    # Find the 'tclcile' executable to use as the Language Engine.
    dname = os.path.normpath(os.path.dirname(__file__))
    if sys.platform.startswith("win"):
        self.tclcile = os.path.join(dname, "tclcile.exe")
    else:
        self.tclcile = os.path.join(dname, "tclcile")
    if not os.path.exists(self.tclcile):
        raise CodeIntelError("could not find the Tcl CILE "
                             "component '%s'\n" % self.tclcile)

</t>
<t tx="ekr.20080121105837.1526">def scan(self, request):
    request.calculateMD5()
    
    argv = [self.tclcile,
            "--filename", urlencode_path(request.path.encode('utf-8')),
            "--mtime", str(request.mtime),
            "--md5", request.md5sum]
    #pprint(argv)

    env = dict(os.environ)
    # no access to prefs!
    # (Note: we *do* have such access now via 'env' attr)
    #if self.prefService.prefs.hasPref("tclExtraPaths"):
    #    tclExtraPaths = self.prefService.prefs.getStringPref("tclExtraPaths")
    #    # If TCLLIBPATH is set, then it must contain a valid Tcl
    #    # list giving directories to search during auto-load
    #    # operations. Directories must be specified in Tcl format,
    #    # using "/" as the path separator, regardless of platform.
    #    # This variable is only used when initializing the
    #    # auto_path variable.  Also escape spaces in paths.
    #    tclExtraPaths = tclExtraPaths.replace('\\', '/')
    #    tclExtraPaths = tclExtraPaths.replace(' ', '\ ')
    #    TCLLIBPATH = ' '.join(tclExtraPaths.split(os.pathsep))
    #    env["TCLLIBPATH"] = TCLLIBPATH

    # Run language engine and report any errors.
    p = process.ProcessOpen(argv, env=env)
    content = line_end_re.sub("\n", request.content)
    p.stdin.write(content)
    p.stdin.close()
    stdout = p.stdout.read()
    stderr = p.stderr.read()
    p.close()
    
    return stdout.decode("utf-8")

</t>
<t tx="ekr.20080121105837.1527">def scan_purelang(self, buf):
    #XXX Probably not going to get to a new in-process etree-based
    #    Tcl CILE soon, so fallback to old CILE for now.
    argv = [self.tclcile,
            "--filename", urlencode_path(buf.path.encode('utf-8')),
            "--mtime", "XXX",
            "--md5", "XXX"]
    #pprint(argv)

    env = dict(os.environ)
    # no access to prefs!
    # (Note: we *do* have such access now via 'env' attr)
    #if self.prefService.prefs.hasPref("tclExtraPaths"):
    #    tclExtraPaths = self.prefService.prefs.getStringPref("tclExtraPaths")
    #    # If TCLLIBPATH is set, then it must contain a valid Tcl
    #    # list giving directories to search during auto-load
    #    # operations. Directories must be specified in Tcl format,
    #    # using "/" as the path separator, regardless of platform.
    #    # This variable is only used when initializing the
    #    # auto_path variable.  Also escape spaces in paths.
    #    tclExtraPaths = tclExtraPaths.replace('\\', '/')
    #    tclExtraPaths = tclExtraPaths.replace(' ', '\ ')
    #    TCLLIBPATH = ' '.join(tclExtraPaths.split(os.pathsep))
    #    env["TCLLIBPATH"] = TCLLIBPATH

    # Run language engine and report any errors.
    p = process.ProcessOpen(argv, env=env)
    content = re.sub("(\r\n|\r)", "\n", buf.accessor.text)
    p.stdin.write(content)
    p.stdin.close()
    stdout = p.stdout.read()
    stderr = p.stderr.read()
    p.close()

    cix = stdout.decode("utf-8")
    return tree_from_cix(cix)


</t>
<t tx="ekr.20080121105837.1528">class TclCILEDriverNew(CILEDriver):
    lang = lang
    @others
</t>
<t tx="ekr.20080121105837.1529">def __init__(self, *args):
    CILEDriver.__init__(self, *args)
    # We have circular imports here, so load it at runtime
    from codeintel2 import tclcile
    self.tclcile = tclcile

</t>
<t tx="ekr.20080121105837.1530">def scan(self, request):
    request.calculateMD5()
    return self.tclcile.scan(request.content, request.path,
                         request.md5sum, request.mtime)

</t>
<t tx="ekr.20080121105837.1531">def scan_purelang(self, buf):
    return self.tclcile.scan_purelang(buf.accessor.text, buf.path)

</t>
<t tx="ekr.20080121105837.1532">if gUseOldTclcile:
    TclCILEDriver = TclCILEDriverOld
else:
    TclCILEDriver = TclCILEDriverNew



#---- internal support stuff



#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=TclLexer(),
                      buf_class=TclBuffer,
                      langintel_class=TclLangIntel,
                      import_handler_class=TclImportHandler,
                      cile_driver_class=TclCILEDriver)

</t>
<t tx="ekr.20080121105837.1533">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1534">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""TemplateToolkit support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "TemplateToolkit"
log = logging.getLogger("codeintel.templatetoolkit")



</t>
<t tx="ekr.20080121105837.1535">#---- language support

class TemplateToolkitLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1536">class TemplateToolkitBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    tpl_lang = lang
    m_lang = "HTML"
    css_lang = "CSS"
    csl_lang = "JavaScript"
    ssl_lang = "Perl"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    #TODO: adjust for Perl, if necessary
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"


</t>
<t tx="ekr.20080121105837.1537">class TemplateToolkitCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"
    ssl_lang = "Perl"



</t>
<t tx="ekr.20080121105837.1538">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=TemplateToolkitLexer(),
                      buf_class=TemplateToolkitBuffer,
                      import_handler_class=None,
                      cile_driver_class=TemplateToolkitCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1539">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1540">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""XBL support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin



#---- globals

lang = "XBL"
log = logging.getLogger("codeintel.xbl")



</t>
<t tx="ekr.20080121105837.1541">#---- language support

class XBLLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1542">class XBLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"
    css_lang = "CSS"
    csl_lang = "JavaScript"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"


</t>
<t tx="ekr.20080121105837.1543"># This gives global window completions but does not produce cile
# information, so completions for local variables and functions will
# not work.
class XBLCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"



</t>
<t tx="ekr.20080121105837.1544">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XBLLexer(),
                      buf_class=XBLBuffer,
                      import_handler_class=None,
                      cile_driver_class=XBLCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1545">@language python
@tabwidth -4
@others
@ignore  ### &lt;&lt;xmlns:pfx = &gt;&gt; causes problems</t>
<t tx="ekr.20080121105837.1546">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""XML support for CodeIntel"""

import os
from os.path import isfile, isdir, exists, dirname, abspath, splitext, join
import sys
from cStringIO import StringIO
import logging
import re
import traceback
from pprint import pprint

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer, CitadelEvaluator
from codeintel2.langintel import LangIntel
from codeintel2.udl import UDLBuffer, UDLLexer, XMLParsingBufferMixin

import koXMLTreeService, koXMLDatasetInfo
from koXMLDatasetInfo import getService
from HTMLTreeParser import html_optional_close_tags

from SilverCity.ScintillaConstants import (SCE_UDL_M_STAGO, SCE_UDL_M_DEFAULT,
                                           SCE_UDL_M_ETAGO, SCE_UDL_M_TAGNAME,
                                           SCE_UDL_M_ATTRNAME, SCE_UDL_M_TAGSPACE,
                                           SCE_UDL_M_STRING,
                                           SCE_UDL_M_PI,
                                           SCE_XML_DEFAULT,
                                           SCE_XML_START_TAG_NAME,
                                           SCE_XML_START_TAG_ATTR_NAME,
                                           SCE_XML_START_TAG_OPEN,
                                           SCE_XML_START_TAG_CLOSE,
                                           SCE_XML_START_TAG_WHITE_SPACE,
                                           SCE_XML_START_TAG_ATTR_QUOT_OPEN,
                                           SCE_XML_START_TAG_ATTR_APOS_OPEN,
                                           SCE_XML_START_TAG_ATTR_QUOT_CLOSE,
                                           SCE_XML_START_TAG_ATTR_APOS_CLOSE,
                                           SCE_XML_START_TAG_ATTR_EQUALS,
                                           SCE_XML_END_TAG_OPEN,
                                           SCE_XML_END_TAG_NAME,
                                           SCE_XML_END_TAG_CLOSE,
                                           SCE_XML_DATA_CHARS,
                                           SCE_XML_DATA_NEWLINE,
                                           SCE_XML_START_TAG_ATTR_APOS_CONTENT,
                                           SCE_XML_START_TAG_ATTR_QUOT_CONTENT,
                                           SCE_XML_PI_OPEN,
                                           )


try:
    from xpcom import components, _xpcom
    from xpcom.server import WrapObject, UnwrapObject
    from xpcom._xpcom import PROXY_SYNC, PROXY_ALWAYS, PROXY_ASYNC
    _xpcom_ = True
except ImportError:
    _xpcom_ = False

#---- globals

lang = "XML"
log = logging.getLogger("codeintel.xml")

STYLE_DEFAULT = 0
STYLE_START_TAG = 1
STYLE_END_TAG = 2
STYLE_TAG_NAME = 3
STYLE_ATTR_NAME = 4
STYLE_TAG_SPACE = 5
STYLE_STRING = 6
STYLE_PI_OPEN = 7
udl_styles = {
    STYLE_DEFAULT: (SCE_UDL_M_DEFAULT,),
    STYLE_START_TAG: SCE_UDL_M_STAGO,
    STYLE_END_TAG: SCE_UDL_M_ETAGO,
    STYLE_TAG_NAME: SCE_UDL_M_TAGNAME,
    STYLE_ATTR_NAME: SCE_UDL_M_ATTRNAME,
    STYLE_TAG_SPACE: SCE_UDL_M_TAGSPACE,
    STYLE_STRING: (SCE_UDL_M_STRING,),
    STYLE_PI_OPEN : SCE_UDL_M_PI,
}
# XXX FIXME for Lex_XML
pure_styles = {
    STYLE_DEFAULT: (SCE_XML_DEFAULT, SCE_XML_DATA_CHARS, SCE_XML_DATA_NEWLINE),
    STYLE_START_TAG: SCE_XML_START_TAG_OPEN,
    STYLE_END_TAG: SCE_XML_END_TAG_OPEN,
    STYLE_TAG_NAME: SCE_XML_START_TAG_NAME,
    STYLE_ATTR_NAME: SCE_XML_START_TAG_ATTR_NAME,
    STYLE_TAG_SPACE: SCE_XML_START_TAG_WHITE_SPACE,
    STYLE_STRING: (SCE_XML_START_TAG_ATTR_QUOT_OPEN,
                   SCE_XML_START_TAG_ATTR_APOS_OPEN,
                   SCE_XML_START_TAG_ATTR_APOS_CONTENT,
                   SCE_XML_START_TAG_ATTR_QUOT_CONTENT,
                  ),
    STYLE_PI_OPEN : SCE_XML_PI_OPEN,
}
common_namespace_cplns = [('namespace', x) for x in (
    'atom="http://purl.org/atom/ns#"',
    'blogChannel="http://backend.userland.com/blogChannelModule"',
    'dc="http://purl.org/dc/elements/1.1/"',
    'mml="http://www.w3.org/1998/Math/MathML"',
    'rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"',
    'rss="http://purl.org/rss/1.0/"',
    'xhtml="http://www.w3.org/TR/xhtml1/strict"',
    'xsd="http://www.w3.org/2000/10/XMLSchema"',
    'xsi="http://www.w3.org/2000/10/XMLSchema-instance"',
    'xs="http://schemas.xmlsoap.org/soap/envelope/"',
    'xsl="http://www.w3.org/1999/XSL/Transform"',
)]

trg_chars = tuple('&lt;: "\'/!')


</t>
<t tx="ekr.20080121105837.1547">#---- language support

class XMLLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1548">class XMLLangIntel(LangIntel):
    lang = lang
    @others
</t>
<t tx="ekr.20080121105837.1549">def trg_from_pos(self, buf, pos, implicit=True, DEBUG=False):
    """XML trigger types:

    xml-complete-tags-and-namespaces    &lt;|
    xml-complete-ns-tags                &lt;x:|  
    xml-complete-tag-attrs              &lt;x:foo |
    xml-complete-ns-tag-attrs           &lt;x:foo y:|
    xml-complete-attr-enum-values       &lt;x:foo y:bar="|
    xml-complete-end-tag                &lt;x ...&gt;...&lt;/|
    xml-complete-well-known-ns          &lt;x xmlns:|
    xml-gt-bang                         &lt;!|
    
    Not yet implemented:
        xml-complete-well-known-ns-value    &lt;x xmlns:x="|
        xml-complete-prolog                 &lt;?xml |
        xml-complete-doctype                &lt;!DOCTYPE |
    """
    #XXX Eventually we'll use UDL for pure XML too, so won't need
    #    this check.
    if isinstance(buf, UDLBuffer):
        styles = udl_styles
    else:
        styles = pure_styles

    if DEBUG:
        print "\n----- UDL %s trg_from_pos(pos=%r, implicit=%r) -----"\
              % (self.lang, pos, implicit)

    if pos == 0:
        return None
    accessor = buf.accessor
    buf_length = accessor.length()
    last_pos = pos - 1
    last_char = accessor.char_at_pos(last_pos)
    last_style = accessor.style_at_pos(last_pos)
    if DEBUG:
        print "  last_pos: %s" % last_pos
        print "  last_char: %r" % last_char
        print "  last_style: %r %s" \
              % (last_style, buf.style_names_from_style_num(last_style))
        #for i in xrange(pos):
            #print "style at pos %d (%c) : %d" % (i,
            #   accessor.char_at_pos(i), accessor.style_at_pos(i))

    if last_char == '&lt;' and \
       last_style in styles[STYLE_DEFAULT] or last_style == styles[STYLE_START_TAG]:
        return Trigger(self.lang, TRG_FORM_CPLN, "tags-and-namespaces",
                       pos, implicit)

    elif last_char == '/' and last_style == styles[STYLE_END_TAG]:
        return Trigger(self.lang, TRG_FORM_CPLN, "end-tag",
                       pos, implicit)

    elif last_char == ':':
        # x:|`` **** xml-complete-ns-tags
        # **** list valid tags in given namespace
        if last_style in (styles[STYLE_TAG_NAME], styles[STYLE_ATTR_NAME]):
            current_word = accessor.text_range(
                *accessor.contiguous_style_range_from_pos(last_pos))
            # Make sure it's the first ":" in the sequence
            if current_word.count(":") != 1:
                return None
            if current_word == "xmlns:" \
               and last_style == styles[STYLE_ATTR_NAME]:
                return Trigger(self.lang, TRG_FORM_CPLN, "well-known-ns",
                               pos, implicit)
            if last_style == styles[STYLE_TAG_NAME]:
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "ns-tags", pos, implicit)
            else:
                return Trigger(self.lang, TRG_FORM_CPLN,
                               "ns-tags-attrs", pos, implicit)

    elif last_char == "!" and pos &gt;= 2:
        last_last_char = accessor.char_at_pos(pos-2)
        last_last_style = accessor.style_at_pos(pos-2)
        if last_last_char == '&lt;' and last_last_style in styles[STYLE_DEFAULT]:
            return Trigger(self.lang, TRG_FORM_CPLN, "gt-bang",
                           pos, implicit)

    elif last_char in (' ', '\t', '\n') \
         and last_style == styles[STYLE_TAG_SPACE]:
        # See bug 65200 for reason for this check.
        have_trg = False
        while last_pos &gt; 0:
            last_pos -= 1
            last_style = accessor.style_at_pos(last_pos)
            if last_style in (styles[STYLE_TAG_SPACE],
                              styles[STYLE_DEFAULT]):
                pass
            elif last_style in styles[STYLE_STRING]:
                have_trg = True
                break
            elif last_style == styles[STYLE_TAG_NAME]:
                # Now move back looking for an STAGO, so we don't
                # trigger on a space after an end-tag
                while last_pos &gt; 0:
                    last_pos -= 1
                    last_style = accessor.style_at_pos(last_pos)
                    if last_style == styles[STYLE_TAG_NAME]:
                        # &lt;.... foo="val" &lt;|&gt;
                        pass
                    elif last_style == styles[STYLE_START_TAG]:
                        # &lt;foo &lt;|&gt;
                        have_trg = True
                        break
                    else:
                        # &lt;/foo &lt;|&gt;
                        break
                break
            else:
                return None
        if have_trg:
            return Trigger(self.lang, TRG_FORM_CPLN, "tag-attrs",
                           pos, implicit)
        else:
            return None
            

    elif last_char in ('\'', '"') and last_style in styles[STYLE_STRING] \
         and pos &gt;= 5:
        # Look back to determine if we're in an &lt;&lt;xmlns:pfx = &gt;&gt; situation
        prev_style = accessor.style_at_pos(pos - 2)
        if prev_style == last_style:
            # It's the end of the string, not the beginning
            return None
        else:
            return Trigger(self.lang, TRG_FORM_CPLN, "attr-enum-values",
                           pos, implicit)
    return None


</t>
<t tx="ekr.20080121105837.1550">def preceding_trg_from_pos(self, buf, pos, curr_pos, DEBUG=False):
    #XXX Eventually we'll use UDL for pure HTML too, so won't need
    #    this check.
    if isinstance(buf, UDLBuffer):
        styles = udl_styles
    else:
        styles = pure_styles

    accessor = buf.accessor
    #print "pos:", pos, ", curr_pos:", curr_pos
    for char, style in accessor.gen_char_and_style_back(pos-1, max(-1,pos-50)):
        #print "Style: %d char %s"% (style, char)
        if char == ":" and style in (styles[STYLE_TAG_NAME], styles[STYLE_ATTR_NAME]) or \
           char in ["&lt;","!"] and style in styles[STYLE_DEFAULT] or style == styles[STYLE_START_TAG] or \
           char in (' ', '\t', '\n') and style == styles[STYLE_TAG_SPACE] or \
           char in ('\'', '"') and style in styles[STYLE_STRING] or \
           char == '/' and style == styles[STYLE_END_TAG]:
            return self.trg_from_pos(buf, pos, implicit=False, DEBUG=DEBUG)
        pos -= 1
    return None

</t>
<t tx="ekr.20080121105837.1551">def async_eval_at_trg(self, buf, trg, ctlr):
    if _xpcom_:
        if hasattr(trg, "_comobj_"):
            trg = UnwrapObject(trg)
        if hasattr(ctlr, "_comobj_"):
            ctlr = UnwrapObject(ctlr)

    ctlr.start(buf, trg)
    type = trg.type
    if type == "tags-and-namespaces":
        # extract tag hierarchy context -&gt; context
        # pass context to schema-based-evaluator -&gt; completions
        cplns = _StartTagNameAutoComplete(buf, trg)
    elif type == "gt-bang":
        cplns = [
            ('doctype', 'DOCTYPE'),
            ('cdata', '[CDATA['),
            ('comment', '--'),
        ]
    elif type == "end-tag":
        cplns = _EndTagAutoComplete(buf, trg)
    elif type == "well-known-ns":
        # this is a hack, we should get this from the catalog, but
        # prefix names are *not* standardized.
        cplns = common_namespace_cplns
    elif type == "well-known-ns-uri":
        # we get all uri's known to our catalog system
        uris = getService().resolver.getWellKnownNamspaces()
        cplns = [('namespace', x) for x in uris]
    elif type == "ns-tags":
        cplns = _StartLocalTagNameAutoComplete(buf, trg)
    elif type == "ns-tags-attrs":
        cplns = _StartAttrAutoComplete(buf, trg)
    elif type == "tag-attrs":
        cplns = _StartAttrAutoComplete(buf, trg)
    elif type == "attr-enum-values":
        cplns = _StartAttrValueAutoComplete(buf, trg)
    else:
        ctlr.error("unknown UDL-based XML completion: %r" % (id,))
        ctlr.done("error")
        return
    if cplns:
        ctlr.set_cplns(cplns)
    ctlr.done("success")


</t>
<t tx="ekr.20080121105837.1552">class XMLBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"



</t>
<t tx="ekr.20080121105837.1553">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XMLLexer(),
                      buf_class=XMLBuffer,
                      langintel_class=XMLLangIntel,
                      import_handler_class=None,
                      cile_driver_class=None,
                      is_cpln_lang=True)


</t>
<t tx="ekr.20080121105837.1554">#---- internal support


def getTreeForDocument(accessor, uri=None):
    return koXMLTreeService.getService().getTreeForURI(uri, accessor.text)
    # XXX FIXME post beta 1
    #if not uri:
    #    return koXMLTreeService.getService().getTreeForContent(accessor.text)
    #
    #tree = koXMLTreeService.getService().treeFromCache(uri)
    #if not tree:
    #    tree = koXMLTreeService.getService().getTreeForURI(uri, accessor.text)
    #return tree

</t>
<t tx="ekr.20080121105837.1555">def getNodeForPosition(accessor, pos, uri=None):
    tree = getTreeForDocument(accessor, uri)
    if not tree:
        return None, None
    line, col = accessor.line_and_col_at_pos(pos)
    node = tree.locateNode(line, col)
    # XXX this needs to be worked out better
    last_start = accessor.text.rfind('&lt;', 0, pos)
    last_end = accessor.text.find('&gt;', last_start, pos)
    if node is None and last_start &gt;= 0:
        node = koXMLTreeService.elementFromText(tree, accessor.text[last_start:last_end], node)
    if node is None or node.start is None:
        return tree, node
    # elementtree line numbers are 1 based, convert to zero based
    node_pos = accessor.pos_from_line_and_col(node.start[0]-1, node.start[1])
    if last_end == -1 and last_start != node_pos:
        #print "try parse ls %d le %d np %d pos %d %r" % (last_start, last_end, node_pos, pos, accessor.text[last_start:pos])
        # we have a dirty tree, need to create a current node and add it
        newnode = koXMLTreeService.elementFromText(tree, accessor.text[last_start:pos], node)
        if newnode is not None:
            return tree, newnode
    return tree, node

</t>
<t tx="ekr.20080121105837.1556">def getDefaultCompletion(tree, node, buf, trg):
    #print "%s:%s node %r" % (buf.lang, trg.lang, node)
    datasetSvc = getService()
    if buf.lang == "XSLT":
        if node is not None and not tree.namespace(node):
            # Do we have an output element, if so, figure out if we're html.
            # Cheap way to get the output element.
            output = tree.tags.get(tree.namespace(tree.root), {}).get('output', None)
            if output is not None:
                lang = output.attrib.get('method').upper()
                publicId = output.attrib.get('doctype-public')
                systemId = output.attrib.get('doctype-system')
                if publicId or systemId:
                    default_dataset_info = (publicId, systemId, None)
                else:
                    default_dataset_info = (
                        datasetSvc.getDefaultPublicId(lang, buf.env),
                        None,
                        datasetSvc.getDefaultNamespace(lang, buf.env)
                    )
                #print "get output type %r" % (default_dataset_info,)
                return default_dataset_info
    
    return (datasetSvc.getDefaultPublicId(trg.lang, buf.env),
            None,
            datasetSvc.getDefaultNamespace(trg.lang, buf.env))

</t>
<t tx="ekr.20080121105837.1557">def getValidTagNames(accessor, pos, buf, trg, withPrefix=False):
    tree, node = getNodeForPosition(accessor, pos, buf.path)
    #print "getValidTagNames NODE %s:%s xmlns[%s] %r"%(tree.prefix(node),node.localName,node.ns,node.tag)
    default = getDefaultCompletion(tree, node, buf, trg)
    handlerclass = koXMLDatasetInfo.get_tree_handler(tree, node, default)
    isHTML = buf.lang_from_pos(pos) == "HTML"
    if node is None: # or not tree.parent(node):
        tagnames = handlerclass.dataset.all_element_types()
    else:
        tagnames = handlerclass.tagnames(tree, node)
        if isHTML:
            tagnames = set(tagnames)
            while node is not None and node.localName in html_optional_close_tags:
                node = tree.parent(node)
                if node is not None:
                    tagnames = tagnames.union(handlerclass.tagnames(tree, node))
    if not tagnames and hasattr(handlerclass, "dataset"):
        tagnames = handlerclass.dataset.all_element_types()
        if not tagnames:
            return None
    tagnames = list(tagnames)
    # XXX should be a pref
    if isHTML:
        tagnames = [t.lower() for t in tagnames]
    tagnames.sort()
    if withPrefix and node is not None:
        prefix = tree.prefix(node)
        if prefix:
            return ["%s:%s" % (prefix, name) for name in tagnames]
    return tagnames

</t>
<t tx="ekr.20080121105837.1558">def getValidAttributes(accessor, pos, buf, trg):
    """getValidAttributes
    get the current tag, and return the attributes that are allowed in that
    element
    """
    tree, node = getNodeForPosition(accessor, pos, buf.path)
    if node is None: return None
    #print "getValidAttributes NODE %s:%s xmlns[%s] %r"%(tree.prefix(node),node.localName,node.ns,node.tag)
    already_supplied = node.attrib.keys()
    default = getDefaultCompletion(tree, node, buf, trg)
    handlerclass = koXMLDatasetInfo.get_tree_handler(tree, node, default)
    attrs = handlerclass.attrs(tree, node)
    if not attrs:
        return None
    attrs = [name for name in attrs if name not in already_supplied]
    attrs.sort()
    return attrs

</t>
<t tx="ekr.20080121105837.1559">def getValidAttributeValues(accessor, pos, attr, buf, trg):
    """getValidAttributeValues
    get the current attribute, and return the values that are allowed in that
    attribute
    """
    tree, node = getNodeForPosition(accessor, pos, buf.path)
    if node is None: return None
    default = getDefaultCompletion(tree, node, buf, trg)
    handlerclass = koXMLDatasetInfo.get_tree_handler(tree, node, default)
    values = handlerclass.values(attr, tree, node)
    if not values:
        return None
    values.sort()
    return values


</t>
<t tx="ekr.20080121105837.1560">def _StartTagNameAutoComplete(buf, trg):
    accessor = buf.accessor
    lastpos = accessor.text.rfind("&lt;", 0, trg.pos)
    lastpos = max(lastpos, 0)
    tagnames = getValidTagNames(accessor, lastpos, buf, trg, withPrefix=True)
    if not tagnames:
        return []
    return [('element', tag) for tag in tagnames]

</t>
<t tx="ekr.20080121105837.1561">def _StartLocalTagNameAutoComplete(buf, trg):
    accessor = buf.accessor
    tagnames = getValidTagNames(accessor, trg.pos, buf, trg, withPrefix=False)
    if not tagnames:
        return []
    return [('element', tag) for tag in tagnames]

</t>
<t tx="ekr.20080121105837.1562">def _EndTagAutoComplete(buf, trg):
    accessor = buf.accessor

    tree, node = getNodeForPosition(accessor, trg.pos, buf.path)
    if node is None: return None
    tagName = tree.tagname(node)
    if not tagName:
        return []
    if buf.lang_from_pos(trg.pos-1) is not "HTML":
        return [('element',tagName+"&gt;")]

    # here on, we're only working with HTML documents
    line, col = accessor.line_and_col_at_pos(trg.pos)
    names = [tagName]
    # if this is an optional close node, get parents until a node that
    # requires close is found
    while node is not None and node.localName in html_optional_close_tags:
        node = tree.parent(node)
        if node is None:
            break
        if not node.end:
            names.append(tree.tagname(node))
            continue
    return [('element',tagName+"&gt;") for tagName in names]


</t>
<t tx="ekr.20080121105837.1563">def _StartAttrValueAutoComplete(buf, trg):
    accessor = buf.accessor
    attrName = accessor.text_range(*accessor.contiguous_style_range_from_pos(trg.pos-3))
    if not attrName:
        log.warn("no attribute name in _StartSuggestAutoComplete")
        return []

    values = getValidAttributeValues(accessor, trg.pos, attrName, buf, trg)
    if not values:
        return []

    return [('attribute_value', value) for value in values]

</t>
<t tx="ekr.20080121105837.1564">def _StartAttrAutoComplete(buf, trg):
    accessor = buf.accessor
    attrs = getValidAttributes(accessor, trg.pos, buf, trg)
    if not attrs:
        return []
    attrName = accessor.text_range(*accessor.contiguous_style_range_from_pos(trg.pos-1))
    if attrName:
        attrName = attrName.strip()
    if attrName:
        return [('attribute', attr+"=") for attr in attrs if attr.startswith(attrName)]
    return [('attribute', attr+"=") for attr in attrs]


</t>
<t tx="ekr.20080121105837.1565">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1566">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

"""XML support for CodeIntel"""

import logging
from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin

#---- globals

lang = "XSLT"
log = logging.getLogger("codeintel.xslt")

</t>
<t tx="ekr.20080121105837.1567">class XSLTLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1568">class XSLTBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = lang
    m_lang = "XML"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    cpln_stop_chars = "&gt;'\" "



</t>
<t tx="ekr.20080121105837.1569">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XSLTLexer(),
                      buf_class=XSLTBuffer,
                      import_handler_class=None,
                      cile_driver_class=None,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1570">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1571">#!/usr/bin/env python

"""XUL support for codeintel"""

import logging

from codeintel2.common import *
from codeintel2.udl import UDLLexer, UDLBuffer, UDLCILEDriver, XMLParsingBufferMixin


#---- globals

lang = "XUL"
log = logging.getLogger("codeintel.xul")



</t>
<t tx="ekr.20080121105837.1572">#---- language support

class XULLexer(UDLLexer):
    lang = lang

</t>
<t tx="ekr.20080121105837.1573">class XULBuffer(UDLBuffer, XMLParsingBufferMixin):
    lang = "XUL"
    m_lang = "XML"
    css_lang = "CSS"
    csl_lang = "JavaScript"

    # Characters that should close an autocomplete UI:
    # - wanted for XML completion: "&gt;'\" "
    # - wanted for CSS completion: " ('\";},.&gt;"
    # - wanted for JS completion:  "~`!@#%^&amp;*()-=+{}[]|\\;:'\",.&lt;&gt;?/ "
    # - dropping ':' because I think that may be a problem for XML tag
    #   completion with namespaces (not sure of that though)
    # - dropping '[' because need for "&lt;!&lt;|&gt;" -&gt; "&lt;![CDATA[" cpln
    cpln_stop_chars = "'\" (;},~`!@#%^&amp;*()-=+{}]|\\;,.&lt;&gt;?/"


</t>
<t tx="ekr.20080121105837.1574">class XULCILEDriver(UDLCILEDriver):
    lang = lang
    csl_lang = "JavaScript"



</t>
<t tx="ekr.20080121105837.1575">#---- registration

def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(lang,
                      silvercity_lexer=XULLexer(),
                      buf_class=XULBuffer,
                      import_handler_class=None,
                      cile_driver_class=XULCILEDriver,
                      is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1576">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1577">#!python

"""UDL (User-Defined Language) support for codeintel."""

import os
from os.path import dirname, join, abspath, normpath, basename
import sys
import re
import logging
import traceback

import SilverCity
from SilverCity import ScintillaConstants
from SilverCity.ScintillaConstants import * #XXX import only what we need
from SilverCity.Lexer import Lexer

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer
#from codeintel2.javascript_common import trg_from_pos as javascript_trg_from_pos

try:
    from xpcom import components
    from xpcom.server import UnwrapObject
    import directoryServiceUtils
    _xpcom_ = True
except ImportError:
    _xpcom_ = False

log = logging.getLogger("codeintel.udl")
#log.setLevel(logging.DEBUG)

#XXX We need to have a better mechanism for rationalizing and sharing
#    common lexer style classes. For now we'll just HACKily grab from
#    Komodo's styles.py. Some of this is duplicating logic in
#    KoLanguageServiceBase.py.
_ko_src_dir = normpath(join(dirname(__file__), *([os.pardir]*3)))
sys.path.insert(0, join(_ko_src_dir, "schemes"))
try:
    import styles
finally:
    del sys.path[0]
    del _ko_src_dir




</t>
<t tx="ekr.20080121105837.1578">#---- module interface

# Test 'udl/general/is_udl_x_style' tests these.
def is_udl_m_style(style):
    return (ScintillaConstants.SCE_UDL_M_DEFAULT &lt;= style
            &lt;= ScintillaConstants.SCE_UDL_M_COMMENT)
</t>
<t tx="ekr.20080121105837.1579">def is_udl_css_style(style):
    return (ScintillaConstants.SCE_UDL_CSS_DEFAULT &lt;= style
            &lt;= ScintillaConstants.SCE_UDL_CSS_OPERATOR)
</t>
<t tx="ekr.20080121105837.1580">def is_udl_csl_style(style):
    return (ScintillaConstants.SCE_UDL_CSL_DEFAULT &lt;= style
            &lt;= ScintillaConstants.SCE_UDL_CSL_REGEX)
</t>
<t tx="ekr.20080121105837.1581">def is_udl_ssl_style(style):
    return (ScintillaConstants.SCE_UDL_SSL_DEFAULT &lt;= style
            &lt;= ScintillaConstants.SCE_UDL_SSL_VARIABLE)
</t>
<t tx="ekr.20080121105837.1582">def is_udl_tpl_style(style):
    return (ScintillaConstants.SCE_UDL_TPL_DEFAULT &lt;= style
            &lt;= ScintillaConstants.SCE_UDL_TPL_VARIABLE)

</t>
<t tx="ekr.20080121105837.1583">#XXX Redundant code from koUDLLanguageBase.py::KoUDLLanguage
# Necessary because SilverCity.WordList splits input on white-space

_re_bad_filename_char = re.compile(r'([% 	\x80-\xff])')
def _lexudl_path_escape(m):
    return '%%%02X' % ord(m.group(1))
</t>
<t tx="ekr.20080121105837.1584">def _urlescape(s):
    return _re_bad_filename_char.sub(_lexudl_path_escape, s)

</t>
<t tx="ekr.20080121105837.1585">class UDLLexer(Lexer):
    """LexUDL wants the path to the .lexres file as the first element of
    the first keywords list.
    """
    @others
    if _xpcom_:
        # Presume we are running under Komodo. Look in the available
        # lexres dirs from extensions.

        def _gen_lexer_dirs(self):
            """Return all possible lexer resource directories (i.e. those ones
            that can include compiled UDL .lexres files).
    
            It yields directories that should "win" first.
    
            This doesn't filter out non-existant directories.
            """
            koDirs = components.classes["@activestate.com/koDirs;1"] \
                .getService(components.interfaces.koIDirs)
    
            yield join(koDirs.userDataDir, "lexers")    # user
            for extensionDir in directoryServiceUtils.getExtensionDirectories():
                yield join(extensionDir, "lexers")      # user-install extensions
            yield join(koDirs.commonDataDir, "lexers")  # site/common
            yield join(koDirs.supportDir, "lexers")     # factory

        def _get_lexres_path(self):
            for lexer_dir in self._gen_lexer_dirs():
                if not exists(lexer_dir):
                    continue
                candidate = join(lexer_dir, self.lang+".lexres")
                if exists(candidate):
                    return candidate
            else:
                raise CodeIntelError("could not find lexres file for %s: "
                                     "`%s.lexres' does not exist in any "
                                     "of the lexer dirs"
                                     % (self.lang, self.lang))
    else:
        def _get_lexres_path(self):
            candidate = join(dirname(__file__), "lexers", self.lang+".lexres")
            if not exists(candidate):
                raise CodeIntelError("could not find lexres file for %s: "
                                     "`%s' does not exist"
                                     % (self.lang, candidate))
            return candidate



</t>
<t tx="ekr.20080121105837.1586">
def __init__(self):
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_UDL)
    lexres_path = _urlescape(self._get_lexres_path())
    log.debug("escaped lexres_path: %r", lexres_path)
    self._keyword_lists = [
        SilverCity.WordList(lexres_path),
    ]

</t>
<t tx="ekr.20080121105837.1587">class UDLBuffer(CitadelBuffer):
    """A CodeIntel Buffer for a UDL-lexer-based language."""
    sce_prefixes = ["SCE_UDL_"]
    #XXX Not sure that this indirection will be useful, but we'll see.

    # Sub-classes must set the following of these that are appropriate:
    m_lang = None
    css_lang = None
    csl_lang = None
    ssl_lang = None
    tpl_lang = None

    @others
</t>
<t tx="ekr.20080121105837.1588">def lang_from_style(self, style):
    if (ScintillaConstants.SCE_UDL_M_DEFAULT &lt;= style
          &lt;= ScintillaConstants.SCE_UDL_M_COMMENT):
        return self.m_lang
    elif (ScintillaConstants.SCE_UDL_CSS_DEFAULT &lt;= style
          &lt;= ScintillaConstants.SCE_UDL_CSS_OPERATOR):
        return self.css_lang
    elif (ScintillaConstants.SCE_UDL_CSL_DEFAULT &lt;= style
          &lt;= ScintillaConstants.SCE_UDL_CSL_REGEX):
        return self.csl_lang
    elif (ScintillaConstants.SCE_UDL_SSL_DEFAULT &lt;= style
          &lt;= ScintillaConstants.SCE_UDL_SSL_VARIABLE):
        return self.ssl_lang
    elif (ScintillaConstants.SCE_UDL_TPL_DEFAULT &lt;= style
          &lt;= ScintillaConstants.SCE_UDL_TPL_VARIABLE):
        return self.tpl_lang
    else:
        raise ValueError("unknown UDL style: %r" % style)

</t>
<t tx="ekr.20080121105837.1589">def lang_from_pos(self, pos):
    style = self.accessor.style_at_pos(pos)
    return self.lang_from_style(style)

</t>
<t tx="ekr.20080121105837.1590">def scoperef_from_pos(self, pos):
    """Return the scoperef for the given position in this buffer.

    A "scoperef" is a 2-tuple:
        (&lt;blob&gt;, &lt;lpath&gt;)
    where &lt;blob&gt; is the ciElementTree blob for the buffer content
    and &lt;lpath&gt; is an ordered list of names into the blob
    identifying the scope.
    
    If no relevant scope is found (e.g. for example, in markup
    content in PHP) then None is returned.

    See Buffer.scoperef_from_pos() docstring for more details.
    """
    lang = self.lang_from_pos(pos)
    try:
        blob = self.blob_from_lang[lang]
    except KeyError:
        return None
    line = self.accessor.line_from_pos(pos) + 1 # convert to 1-based
    return self.scoperef_from_blob_and_line(blob, line)

</t>
<t tx="ekr.20080121105837.1591">def trg_from_pos(self, pos, implicit=True):
    if pos == 0:
        return None
    lang = self.lang_from_pos(pos-1)
    if lang is None:
        style = self.accessor.style_at_pos(pos)
        style_names = self.style_names_from_style_num(style)
        raise CodeIntelError("got unexpected style in `%s': %s %s"
                             % (basename(self.path), style, style_names))
    try:
        langintel = self.mgr.langintel_from_lang(lang)
    except KeyError:
        return None
    return langintel.trg_from_pos(self, pos, implicit=implicit)

</t>
<t tx="ekr.20080121105837.1592">def preceding_trg_from_pos(self, pos, curr_pos):
    if curr_pos == 0:
        return None
    lang = self.lang_from_pos(curr_pos-1)
    try:
        langintel = self.mgr.langintel_from_lang(lang)
    except KeyError:
        return None
    return langintel.preceding_trg_from_pos(self, pos, curr_pos)

</t>
<t tx="ekr.20080121105837.1593">def curr_calltip_arg_range(self, trg_pos, calltip, curr_pos):
    if curr_pos == 0:
        return None
    lang = self.lang_from_pos(curr_pos-1)
    try:
        langintel = self.mgr.langintel_from_lang(lang)
    except KeyError:
        return (-1, -1)
    try:
        return langintel.curr_calltip_arg_range(self, trg_pos, calltip,
                                                curr_pos)
    except AttributeError:
        # This can happen if we accidentally move into a non-programming
        # language during a calltip. E.g. bug 69529. Cancel the calltip
        # in this case.
        return (-1, -1)

</t>
<t tx="ekr.20080121105837.1594">def async_eval_at_trg(self, trg, ctlr):
    try:
        langintel = self.mgr.langintel_from_lang(trg.lang)
    except KeyError:
        return None
    return langintel.async_eval_at_trg(self, trg, ctlr)

</t>
<t tx="ekr.20080121105837.1595"># Override Citadel.defn_trg_from_pos()
def defn_trg_from_pos(self, pos, lang=None):
    # Work out the language from the position, as the citadel buffer will
    # use the buffer language, we want a language specific to this pos.
    return CitadelBuffer.defn_trg_from_pos(self, pos,
                                           lang=self.lang_from_pos(pos))

</t>
<t tx="ekr.20080121105837.1596">def libs(self):
    """A simple `.libs' property does not work for multi-lang buffers.
    Use `.libs_from_lang(lang)' instead.
    """
    raise RuntimeError("`.libs' invalid for multi-lang buffers: use "
                       "`mgr.langintel_from_lang(lang).libs_from_buf(buf)' "
                       "directly")

</t>
<t tx="ekr.20080121105837.1597">def style_names_from_style_num(self, style_num):
    #XXX Would like to have python-foo instead of p_foo or SCE_P_FOO, but
    #    that requires a more comprehensive solution for all langs and
    #    multi-langs.
    style_names = []

    # Get the constant name from ScintillaConstants.
    if "UDL" not in self._style_name_from_style_num_from_lang:
        name_from_num \
            = self._style_name_from_style_num_from_lang["UDL"] = {}
        if self.sce_prefixes is None:
            raise Error("'sce_prefixes' not set on class %s: cannot "
                        "determine style constant names"
                        % self.__class__.__name__)
        for attr in dir(ScintillaConstants):
            for sce_prefix in self.sce_prefixes:
                if attr.startswith(sce_prefix):
                    name_from_num[getattr(ScintillaConstants, attr)] = attr
    else:
        name_from_num \
            = self._style_name_from_style_num_from_lang["UDL"]
    const_name = self._style_name_from_style_num_from_lang["UDL"][style_num]
    style_names.append(const_name)
    
    # Get a style group from styles.py.
    if "UDL" in styles.StateMap:
        for style_group, const_names in styles.StateMap["UDL"].items():
            if const_name in const_names:
                style_names.append(style_group)
                break
    else:
        log.warn("lang '%s' not in styles.StateMap: won't have "
                 "common style groups in HTML output" % "UDL")
    
    return style_names

</t>
<t tx="ekr.20080121105837.1598">__string_styles = None
def string_styles(self):
    if self.__string_styles is None:
        state_map = styles.StateMap["UDL"]
        self.__string_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("strings", "stringeol")
            for style_name in state_map.get(style_class, [])
        ]
    return self.__string_styles

</t>
<t tx="ekr.20080121105837.1599">__comment_styles = None
def comment_styles(self):
    if self.__comment_styles is None:
        state_map = styles.StateMap["UDL"]
        self.__comment_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("comments", "here documents",
                                "data sections")
            for style_name in state_map.get(style_class, [])
        ]
    return self.__comment_styles

</t>
<t tx="ekr.20080121105837.1600">__number_styles = None
def number_styles(self):
    if self.__number_styles is None:
        state_map = styles.StateMap["UDL"]
        self.__number_styles = [
            getattr(ScintillaConstants, style_name)
            for style_class in ("numbers",)
            for style_name in state_map.get(style_class, [])
        ]
    return self.__number_styles


</t>
<t tx="ekr.20080121105837.1601">class XMLParsingBufferMixin(object):
    """A mixin for UDLBuffer-based buffers of XML-y/HTML-y languages to
    support the following:

    - An "xml_tree" attribute that is a XML parse tree of the document
      (lazily done from koXMLTreeService)
    - An "xml_parse()" method to force a re-parse of the document.

    TODO: locking?
    """
    _xml_tree_cache = None
    @others
</t>
<t tx="ekr.20080121105837.1602">@property
def xml_tree(self):
    if self._xml_tree_cache is None:
        self.xml_parse()
    return self._xml_tree_cache

</t>
<t tx="ekr.20080121105837.1603">def xml_parse(self):
    from koXMLTreeService import getService
    self._xml_tree_cache = getService().getTreeForURI(
            self.path, self.accessor.text)


</t>
<t tx="ekr.20080121105837.1604">class _NotYetSet(object):
    # Used below to distinguish from None.
    pass

</t>
<t tx="ekr.20080121105837.1605">class UDLCILEDriver(CILEDriver):
    ssl_lang = None   # Sub-classes must set one or both of these for
    csl_lang = None   #    citadel-scanning support.

    _master_cile_driver = None
    slave_csl_cile_driver = _NotYetSet # to distinguish from None

    @others
</t>
<t tx="ekr.20080121105837.1606">@property
def master_cile_driver(self):
    """The primary CILE driver for this multi-lang lang.

    This is the CILE driver for the SSL lang, if there is one, otherwise
    for the csl_lang.

    Side effect: `self.slave_csl_cile_driver' is determined the
    first time this is called. A little gross, I know, but it
    avoids having a separate property.
    """
    if self._master_cile_driver is None:
        if self.ssl_lang is not None:
            self._master_cile_driver \
                = self.mgr.citadel.cile_driver_from_lang(self.ssl_lang)
            self.slave_csl_cile_driver \
                = self.mgr.citadel.cile_driver_from_lang(self.csl_lang)
        else:
            self._master_cile_driver \
                = self.mgr.citadel.cile_driver_from_lang(self.csl_lang)
            self.slave_csl_cile_driver = None
    return self._master_cile_driver

</t>
<t tx="ekr.20080121105837.1607">def scan_purelang(self, buf):
    return self.master_cile_driver.scan_multilang(
                    buf, self.slave_csl_cile_driver)



</t>
<t tx="ekr.20080121105837.1608">"""The "Manager" is the controlling instance for a codeintel system."""

@language python
@tabwidth -4

#---- global variables
log = logging.getLogger("codeintel")
#log.setLevel(logging.INFO)

#---- public interface
class Manager(threading.Thread, Queue):
    @others
</t>
<t tx="ekr.20080121105837.1609">#!/usr/bin/env python
# ***** BEGIN LICENSE BLOCK *****

import os
from os.path import dirname, join, abspath, splitext, basename, isabs
import sys
import time
import md5
import pprint
import threading
import stat
import types
import imp
import shutil
import logging
from glob import glob
import threading
from Queue import Queue
import traceback

from SilverCity import ScintillaConstants

from codeintel2.common import *
from codeintel2.accessor import *
from codeintel2.citadel import Citadel
from codeintel2.database.database import Database
from codeintel2.environment import DefaultEnvironment
from codeintel2 import indexer
from codeintel2.util import guess_lang_from_path
from codeintel2.udl import XMLParsingBufferMixin, UDLBuffer

try:
    from xpcom import components
    from xpcom.client import WeakReference
    _xpcom_ = True
except ImportError:
    _xpcom_ = False
</t>
<t tx="ekr.20080121105837.1610"># See the module docstring for usage information.

def __init__(self, db_base_dir=None, on_scan_complete=None, langs=None,
             extra_lang_module_dirs=None, env=None,
             db_event_reporter=None, db_catalog_dirs=None,
             db_import_everything_langs=None):
    """Create a CodeIntel manager.
    
        "db_base_dir" (optional) specifies the base directory for
            the codeintel database. If not given it will default to
            '~/.codeintel'.
        "on_scan_complete" (optional) is a callback for Citadel scan
            completion. It will be passed the ScanRequest instance
            as an argument.
        "langs" (optional, default all) is a list of language names
            to register. By default all available supported languages are
            setup.
        "extra_lang_module_dirs" (optional) is a list of extra dirs
            in which to look for and use "lang_*.py" lang support
            modules.
        "env" (optional) is an Environment instance (or subclass).
            See environment.py for details.
        "db_event_reporter" (optional) is a callback that will be called
                db_event_reporter(&lt;event-desc-string&gt;)
            before "significant" long processing events in the DB. This
            may be useful to forward to a status bar in a GUI.
        "db_catalog_dirs" (optional) is a list of catalog dirs in
            addition to the std one to use for the CatalogsZone. All
            *.cix files in a catalog dir are made available.
        "db_import_everything_langs" (optional) is a set of langs for which
            the extra effort to support Database
            `lib.hits_from_lpath()' should be made. See class
            Database for more details.
    """
    
    threading.Thread.__init__(self, name="CodeIntel Manager")
    Queue.__init__(self)

    self.citadel = Citadel(self)

    # Language registry bits.
    self._attempted_registered_safe_lang = {}  # {safe-lang: True}
    self._registered_lang_from_safe_lang = {}
    self.silvercity_lexer_from_lang = {}
    self.buf_class_from_lang = {}
    self.langintel_class_from_lang = {}
    self._langintel_from_lang_cache = {}
    self.import_handler_class_from_lang = {}
    self._is_citadel_from_lang = {} # registered langs that are Citadel-based
    self._is_cpln_from_lang = {} # registered langs for which completion is supported

    self.register_langs(langs, extra_lang_module_dirs)
    self.env = env or DefaultEnvironment() 
    self.db = Database(self, base_dir=db_base_dir,
                       catalog_dirs=db_catalog_dirs,
                       event_reporter=db_event_reporter,
                       import_everything_langs=db_import_everything_langs)
    self.idxr = indexer.Indexer(self, on_scan_complete)

</t>
<t tx="ekr.20080121105837.1611">def upgrade(self):
    """Upgrade the database, if necessary.
    
    It blocks until the upgrade is complete.  Alternatively, if you
    want more control over upgrading use:
        Database.upgrade_info()
        Database.upgrade()
        Database.reset()
    """
    log.debug("upgrade db if necessary")
    status, reason = self.db.upgrade_info()
    if status == Database.UPGRADE_NECESSARY:
        log.info("db upgrade is necessary")
        self.db.upgrade()
    elif status == Database.UPGRADE_NOT_POSSIBLE:
        log.warn("%s (resetting db)", reason)
        log.info("reset db at `%s' (creating backup)", self.db.base_dir)
        self.db.reset()
    elif status == Database.UPGRADE_NOT_NECESSARY:
        log.debug("no upgrade necessary")
    else:
        raise CodeIntelError("unknown db upgrade status: %r" % status)

</t>
<t tx="ekr.20080121105837.1612">def initialize(self):
    """Initialize the codeintel system."""
    self.idxr.start()

</t>
<t tx="ekr.20080121105837.1613">def register_langs(self, langs=None, extra_lang_module_dirs=None):
    """Register languages.
    
    @param langs {list} is an optional list of language names
        to register. If not given, all available languages are
        registered.
    @param extra_lang_module_dirs {list} is an optional list of extra
        dirs in which to look for and use "lang_*.py" lang support
        modules. By default just the codeintel2 package directory is
        used.
        
    An "available" language is one for which there is a "lang_*.py"
    module.
    """
    dirs = [dirname(__file__)]
    if extra_lang_module_dirs:
        dirs += extra_lang_module_dirs
    remaining_langs = langs and set(langs) or None
    for dir in dirs:
        for module_path in glob(join(dir, "lang_*.py")):
            lang = basename(module_path)[5:-3]
            if langs and lang not in remaining_langs:
                continue
            self.register_lang(lang, module_path)
            if remaining_langs:
                remaining_langs.remove(lang)
    if remaining_langs:
        log.warn("could not find support modules for these langs: %s"
                 % ", ".join(remaining_langs))

</t>
<t tx="ekr.20080121105837.1614">def register_lang(self, lang, module_path):
    """Register the given language.
    
    @param lang {str} is the name of the language to register (e.g.
        "Python"). To support .initialize(lang='*') this argument may
        be the "safe lang" name (e.g. "python")
    @param module_path {str} is the path to the lang support module.

    This will import the given module path and call its top-level
    "register" function passing it the Manager instance. That is
    expected to callback to `mgr.set_lang_info()'. This can raise
    ImportError or CodeIntelError. This is a no-op if already called
    for a particular language.
    """
    safe_lang = lang.lower()
    if safe_lang in self._attempted_registered_safe_lang:
        return
    self._attempted_registered_safe_lang[safe_lang] = True
    module_dir, module_name = os.path.split(module_path)
    module_name = splitext(module_name)[0]
    iinfo = imp.find_module(module_name, [module_dir])
    module = imp.load_module(module_name, *iinfo)
    if hasattr(module, "register"):
        log.debug("register %s (%s) lang support", module.lang, safe_lang)
        try:
            module.register(self)
        except CodeIntelError, ex:
            log.warn("error registering %s (%s) lang (lang will be "
                     "disabled): %s", module.lang, safe_lang, ex)
        except:
            log.exception("error registering %s (%s) lang",
                          module.lang, safe_lang)
        else:
            self._registered_lang_from_safe_lang[safe_lang] = module.lang

</t>
<t tx="ekr.20080121105837.1615">def set_lang_info(self, lang, silvercity_lexer=None, buf_class=None,
                  import_handler_class=None, cile_driver_class=None,
                  is_cpln_lang=False, langintel_class=None):
    """Called by register() functions in language support modules."""
    if silvercity_lexer:
        self.silvercity_lexer_from_lang[lang] = silvercity_lexer
    if buf_class:
        self.buf_class_from_lang[lang] = buf_class
    if langintel_class:
        self.langintel_class_from_lang[lang] = langintel_class
    if import_handler_class:
        self.import_handler_class_from_lang[lang] = import_handler_class
    if cile_driver_class is not None:
        self._is_citadel_from_lang[lang] = True
        self.citadel.set_lang_info(lang, cile_driver_class,
                                   is_cpln_lang=is_cpln_lang)
    if is_cpln_lang:
        self._is_cpln_from_lang[lang] = True

</t>
<t tx="ekr.20080121105837.1616">def finalize(self, timeout=None):
    if self.citadel is not None:
        self.citadel.finalize()
    if self.isAlive():
        self.stop()
        self.join(timeout)
    self.idxr.finalize()
    if self.db is not None:
        try:
            self.db.save()
        except Exception:
            log.exception("error saving database")
        self.db = None # break the reference

</t>
<t tx="ekr.20080121105837.1617"># Proxy the batch update API onto our Citadel instance.
def batch_update(self, join=True, updater=None):
    return self.citadel.batch_update(join=join, updater=updater)

</t>
<t tx="ekr.20080121105837.1618">def is_registered_lang(self, lang):
    """Return true if this is a registered language."""
    safe_lang = lang.lower()
    return safe_lang in self._registered_lang_from_safe_lang

</t>
<t tx="ekr.20080121105837.1619">def is_multilang(self, lang):
    """Return True iff this is a multi-lang language.

    I.e. Is this a language that supports embedding of different
    programming languages. For example RHTML can have Ruby and
    JavaScript content, HTML can have JavaScript content.
    """
    return issubclass(self.buf_class_from_lang[lang], UDLBuffer)

</t>
<t tx="ekr.20080121105837.1620">def is_xml_lang(self, lang):
    try:
        buf_class = self.buf_class_from_lang[lang]
    except KeyError:
        return False
    return issubclass(buf_class, XMLParsingBufferMixin)

</t>
<t tx="ekr.20080121105837.1621">def is_cpln_lang(self, lang):
    """Return True iff codeintel supports completion (i.e. autocomplete
    and calltips) for this language."""
    return lang in self._is_cpln_from_lang
</t>
<t tx="ekr.20080121105837.1622">def get_cpln_langs(self):
    return self._is_cpln_from_lang.keys()

</t>
<t tx="ekr.20080121105837.1623">def is_citadel_lang(self, lang):
    """Returns True if the given lang has been registered and
    is a Citadel-based language.
    
    A "Citadel-based" language is one that uses CIX/CIDB/CITDL tech for
    its codeintel. Note that currently not all Citadel-based langs use
    the Citadel system for completion (e.g. PHP and Tcl).
    """
    return lang in self._is_citadel_from_lang
</t>
<t tx="ekr.20080121105837.1624">def get_citadel_langs(self):
    return self._is_citadel_from_lang.keys()

</t>
<t tx="ekr.20080121105837.1625">def langintel_from_lang(self, lang):
    if lang not in self._langintel_from_lang_cache:
        self._langintel_from_lang_cache[lang] \
            = self.langintel_class_from_lang[lang](self)
    return self._langintel_from_lang_cache[lang] 

</t>
<t tx="ekr.20080121105837.1626">#XXX
#XXX Cache bufs based on (path, lang) so can share bufs. (weakref)
#XXX 
def buf_from_koIDocument(self, doc, env=None):
    lang = doc.language
    path = doc.displayPath
    if doc.isUntitled:
        path = join("&lt;Unsaved&gt;", path)
    accessor = KoDocumentAccessor(doc,
        self.silvercity_lexer_from_lang.get(lang))
    buf = self.buf_class_from_lang[lang](self, accessor, env, path)
    return buf

</t>
<t tx="ekr.20080121105837.1627">def buf_from_content(self, content, lang, env=None, path=None):
    #XXX Need 'encoding' argument?
    lexer = self.silvercity_lexer_from_lang.get(lang)
    accessor = SilverCityAccessor(lexer, content)
    buf = self.buf_class_from_lang[lang](self, accessor, env, path)
    return buf

</t>
<t tx="ekr.20080121105837.1628">def buf_from_path(self, path, lang=None, env=None):
    if lang is None:
        lang = guess_lang_from_path(path)
    content = open(path, 'rb').read() #XXX i18n handling, guess encoding?

    #TODO: Re-instate this when have solution for CILE test failures
    #      that this causes.
    #if not isabs(path) and not path.startswith("&lt;Unsaved&gt;"):
    #    path = abspath(path)

    return self.buf_from_content(content, lang, env, path)


</t>
<t tx="ekr.20080121105837.1629">#---- Completion Evaluation Session/Queue handling

# The current eval session (an Evaluator instance). A current session's
# lifetime is as follows:
# - [self._get()] Starts when the evaluator thread (this class) takes it
#   off the queue.
# - [self._put()] Can be aborted (via sess.ctlr.abort()) if a new eval
#   request comes in.
# - [self._handle_eval_sess()] Done when the session completes either by
#   (1) an unexpected error during sess.eval() or (2) sess.ctlr.is_done()
#   after sess.eval().
_curr_eval_sess = None

def request_eval(self, evalr):
    """Request evaluation of the given completion.
    
        "evalr" is the Evaluator instance.

    The manager has an evaluation thread on which this evalr will be
    scheduled. Only one request is ever eval'd at one time. A new
    request will cause an existing on to be aborted and requests made in
    the interim will be trumped by this new one.

    Dev Notes:
    - XXX Add a timeout to the put and raise error on timeout?
    """
    #self._handle_eval_sess(evalr)
    self.put((evalr, False))

</t>
<t tx="ekr.20080121105837.1630">def request_reeval(self, evalr):
    """Occassionally evaluation will need to defer until something (e.g.
    scanning into the CIDB) is one. These sessions will re-request
    evaluation via this method.
    """
    self.put((evalr, True))

</t>
<t tx="ekr.20080121105837.1631">def stop(self):
    self.put((None, None)) # Sentinel to tell thread mainloop to stop.

</t>
<t tx="ekr.20080121105837.1632">def run(self):
    while 1:
        eval_sess, is_reeval = self.get()
        if eval_sess is None: # Sentinel to stop.
            break
        try:
            self._handle_eval_sess(eval_sess)
        except:
            exc_info = sys.exc_info()
            tb_path, tb_lineno, tb_func \
                = traceback.extract_tb(exc_info[2])[-1][:3]
            if hasattr(exc_info[0], "__name__"):
                exc_str = "%s: %s" % (exc_info[0].__name__, exc_info[1])
            else: # string exception
                exc_str = exc_info[0]
            eval_sess.ctlr.error("error evaluating %s: %s "
                                 "(%s#%s in %s)", eval_sess, exc_str,
                                 tb_path, tb_lineno, tb_func)
            log.exception("error evaluating %s" % eval_sess)
            eval_sess.ctlr.done("unexpected eval error")

</t>
<t tx="ekr.20080121105837.1633">def _handle_eval_sess(self, eval_sess):
    try:
        eval_sess.eval(self)
    except Exception:
        self._curr_eval_sess = None
        raise
    else:
        if eval_sess.ctlr.is_done():
            self._curr_eval_sess = None

</t>
<t tx="ekr.20080121105837.1634">def _put(self, (eval_sess, is_reeval)):
    # Only consider re-evaluation if we are still on the same eval
    # session.
    if is_reeval and self._curr_eval_sess is not eval_sess:
        return
    
    # We only allow *one* eval session at a time.
    # - Drop a possible accumulated eval session.
    if len(self.queue):
        self.queue.clear()
    # - Abort the current eval session.
    if not is_reeval and self._curr_eval_sess is not None:
        self._curr_eval_sess.ctlr.abort()

    # Lazily start the eval thread.
    if not self.isAlive():
        self.start()

    Queue._put(self, (eval_sess, is_reeval))
    assert len(self.queue) == 1

</t>
<t tx="ekr.20080121105837.1635">def _get(self):
    eval_sess, is_reeval = Queue._get(self)
    if is_reeval:
        assert self._curr_eval_sess is eval_sess
    else:
        self._curr_eval_sess = eval_sess
    return eval_sess, is_reeval



</t>
<t tx="ekr.20080121105837.1636">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1637"># 
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
# This code has intimate knowledge of the code objects defined in
# parser_data.py
# 

import os
from os.path import basename, splitext, isfile, isdir, join

from ciElementTree import Element, SubElement, tostring
from codeintel2 import util
from codeintel2.parseutil import getAttrStr, xmlencode, cdataescape



</t>
<t tx="ekr.20080121105837.1638">def get_common_attrs(node):
    attrs = {}
    attrs = {"name": node.name}
    try:
        attrs["line"] = str(node.line_num);
    except AttributeError:
        pass
    try:
        attrs["lineend"] = str(node.lineend);
    except AttributeError:
        pass
    try:
        if node.is_classmethod:
            attrs["attributes"] = "__classmethod__"
        elif node.is_constructor:
            attrs["attributes"] = "__ctor__"
        else:
            attrs["attributes"] = node.attributes;
    except AttributeError:
        pass
        
    return attrs

</t>
<t tx="ekr.20080121105837.1639">def sort_by_lines(adict):
    intermed = [(adict[k].line_num, adict[k].type, k) for k in adict.keys()]
    intermed.sort()
    return intermed


</t>
<t tx="ekr.20080121105837.1640">#### ElementTree-based CIX routines

def get_arguments_cix(parse_tree_node, cix_node):
    for c in parse_tree_node.args:
        attrs = get_common_attrs(c)
        attrs['name'] = c.get_full_name()
        if not c.arg_attrs is None:
            attrs['attributes'] = c.arg_attrs
        SubElement(cix_node, 'variable', ilk='argument', **attrs)

</t>
<t tx="ekr.20080121105837.1641">def get_docstring_cix(parse_tree_node, cix_node):
    if len(parse_tree_node.doc_lines) &gt;= 1:
        summarylines = util.parseDocSummary(parse_tree_node.doc_lines)
        if len(summarylines) &gt; 0:
            cix_node.set("doc", "\n".join(summarylines))

</t>
<t tx="ekr.20080121105837.1642">def get_imports_cix(parse_tree_node, cix_node):
    for imp in getattr(parse_tree_node, "imports", []):
        SubElement(cix_node, "import", module=imp.name, line=str(imp.line_num), symbol="*")

</t>
<t tx="ekr.20080121105837.1643"># These bring all the names in a namespace into the calling namespace.
def get_includes_cix(parse_tree_node, cix_node):
    for incl in getattr(parse_tree_node, "includes", []):
        SubElement(cix_node, "import", symbol=incl.name, line=str(incl.line_num))

</t>
<t tx="ekr.20080121105837.1644">def get_signature_cix(parse_tree_node, cix_node):
    signature = getattr(parse_tree_node, 'signature', '')
    if len(signature) &gt; 0:
        cix_node.set('signature', signature)
        

</t>
<t tx="ekr.20080121105837.1645">def get_var_cix(cix_node, var_type, **attrs):
    var_cix_node = SubElement(cix_node, 'variable', **attrs)
    if var_type:
        var_cix_node.set('citdl', var_type)

</t>
<t tx="ekr.20080121105837.1646">def _local_varname_test(var_name):
    return var_name[0].islower() or var_name[0] == "_"

</t>
<t tx="ekr.20080121105837.1647">def _local_varname_test_true(true):
    return True

</t>
<t tx="ekr.20080121105837.1648">def _get_vars_helper(parse_tree_node, cix_node, kind_name, attr_attrs=None,
                    var_test=_local_varname_test_true):
    for line_no, var_type, var_name in sort_by_lines(getattr(parse_tree_node,
                                                             kind_name, {})):
        attrs = {"name": var_name, "line":str(line_no)}
        if attr_attrs:
            if var_test(var_name):
                attrs["attributes"] = attr_attrs
        get_var_cix(cix_node, var_type, **attrs)

</t>
<t tx="ekr.20080121105837.1649">def get_globals_cix(parse_tree_node, cix_node):
    _get_vars_helper(parse_tree_node, cix_node, 'global_vars')

</t>
<t tx="ekr.20080121105837.1650">def get_vars_cix(parse_tree_node, cix_node):
    _get_vars_helper(parse_tree_node, cix_node, 'local_vars', "__local__",
                    _local_varname_test)
    _get_vars_helper(parse_tree_node, cix_node, 'aliases',
                    "__alias__")
    _get_vars_helper(parse_tree_node, cix_node, 'class_vars', "__local__")
    _get_vars_helper(parse_tree_node, cix_node, 'instance_vars',
                    "__instancevar__ __local__")

</t>
<t tx="ekr.20080121105837.1651">def common_module_class_cix(parse_tree_node, cix_node, class_ref_fn=None, **additional_attrs):
    attrs = get_common_attrs(parse_tree_node)
    attrs.update(additional_attrs)
    if not attrs.has_key('ilk'):
        attrs['ilk'] = 'class'
    class_cix_node = SubElement(cix_node, 'scope', **attrs)
    get_docstring_cix(parse_tree_node, class_cix_node)
    get_signature_cix(parse_tree_node, class_cix_node)
    get_imports_cix(parse_tree_node, class_cix_node)
    get_includes_cix(parse_tree_node, class_cix_node)
    get_vars_cix(parse_tree_node, class_cix_node)
    if class_ref_fn:
        class_ref_fn(parse_tree_node, class_cix_node)
    visit_children_get_cix(parse_tree_node, class_cix_node)

</t>
<t tx="ekr.20080121105837.1652">def classref_etree_cix(parse_tree_node, cix_node):
    classrefs = [(len(ref) &gt; 2 and ref[2] or ref[0])
                 for ref in parse_tree_node.classrefs]
    if len(classrefs) &gt; 0:
        cix_node.set('classrefs', " ".join(classrefs))
</t>
<t tx="ekr.20080121105837.1653">def class_etree_cix(parse_tree_node, cix_node):
    common_module_class_cix(parse_tree_node, cix_node, classref_etree_cix)

</t>
<t tx="ekr.20080121105837.1654">def method_etree_cix(parse_tree_node, cix_node):
    attrs = get_common_attrs(parse_tree_node)
    method_cix_node = SubElement(cix_node, 'scope', ilk='function', **attrs)
    get_docstring_cix(parse_tree_node, method_cix_node)
    get_signature_cix(parse_tree_node, method_cix_node)
    #XXX: Get classrefs, doc, symbols(?)
    get_arguments_cix(parse_tree_node, method_cix_node)
    get_imports_cix(parse_tree_node, method_cix_node)
    get_includes_cix(parse_tree_node, method_cix_node)
    get_vars_cix(parse_tree_node, method_cix_node)
    visit_children_get_cix(parse_tree_node, method_cix_node)

</t>
<t tx="ekr.20080121105837.1655">def module_etree_cix(parse_tree_node, cix_node):
    common_module_class_cix(parse_tree_node, cix_node, ilk='namespace')

</t>
<t tx="ekr.20080121105837.1656">cb_etree_hash = {"Module" : module_etree_cix,
                 "Class" : class_etree_cix,
                 "Method" : method_etree_cix}

def visit_children_get_cix(parse_tree_node, cix_node):
    for c in parse_tree_node.children:
        cb_etree_hash[c.class_name](c, cix_node)

</t>
<t tx="ekr.20080121105837.1657">def produce_elementTree_cix(parse_tree, filename, target_lang, gen_lang="Python"):
    cix_root = Element("codeintel", version="2.0")
    fileAttrs = {"lang": target_lang,
                 "path": filename,
                 }
    file_cix_node = SubElement(cix_root, "file", **fileAttrs)
    module_cix_node = SubElement(file_cix_node, "scope", ilk='blob',
                                 lang=gen_lang,
                                 name=splitext(basename(filename))[0])
    produce_elementTree_contents_cix(parse_tree, module_cix_node)
    return cix_root

</t>
<t tx="ekr.20080121105837.1658">def produce_elementTree_contents_cix(parse_tree, cix_node):
    get_docstring_cix(parse_tree, cix_node)
    get_imports_cix(parse_tree, cix_node)
    get_includes_cix(parse_tree, cix_node)
    get_globals_cix(parse_tree, cix_node)
    get_vars_cix(parse_tree, cix_node)
    visit_children_get_cix(parse_tree, cix_node)
    return cix_node
</t>
<t tx="ekr.20080121105837.1659">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1660"># 
# ***** BEGIN LICENSE BLOCK *****

# Contributors:
#   Eric Promislow (EricP@ActiveState.com)
#
# 

VAR_KIND_UNKNOWN = 0
VAR_KIND_GLOBAL = 1
VAR_KIND_CLASS = 2
VAR_KIND_CLASSVAR = 3
VAR_KIND_INSTANCE = 4
VAR_KIND_LOCAL = 5
VAR_KIND_ALIAS = 6

</t>
<t tx="ekr.20080121105837.1661">class Name_LineNum:
    @others
</t>
<t tx="ekr.20080121105837.1662">def __init__(self, name, line_num, type=None):
    self.line_num = line_num
    self.name = name
    self.type = type

</t>
<t tx="ekr.20080121105837.1663">class VarInfo:
    @others
</t>
<t tx="ekr.20080121105837.1664">def __init__(self, line_num, type=None):
    self.line_num = line_num
    self.type = type

</t>
<t tx="ekr.20080121105837.1665">def update_collection(coll, name, line_num, type=None, attributes=None):
    if not coll.has_key(name):
        coll[name] = VarInfo(line_num, type)
    elif coll[name].type is None and type is not None:
        coll[name].type = type
    if attributes and coll['attributes'] is None:
        coll['attributes'] = attributes

</t>
<t tx="ekr.20080121105837.1666">class Node:
    @others
</t>
<t tx="ekr.20080121105837.1667">def __init__(self, line_num, class_name=None):
    self.children = []
    self.line_num = line_num
    self.indentation = 0
    self.doc_lines = []
    self.imports = [] # require and load stmts
    self.includes = []  # include stmts

    self.class_vars = {}
    self.instance_vars = {}
    self.local_vars = {}
    self.aliases = {}
    if class_name: self.class_name = class_name
    
</t>
<t tx="ekr.20080121105837.1668">def append_node(self, new_node):
    self.children.append(new_node)

</t>
<t tx="ekr.20080121105837.1669">def set_line_end_num(self, line_end_num):
    self.lineend = line_end_num        

</t>
<t tx="ekr.20080121105837.1670">def dump_kids(self, indent_level):
    for c in self.children:
        c.dump(indent_level + 2)
        
</t>
<t tx="ekr.20080121105837.1671">def dump2(self, node_type_name, indent_level, *call_backs):
    print "%s %s %s - line %r:%r" % (" " * indent_level, node_type_name, self.name, self.line_num, getattr(self, 'lineend', '???'))
    if len(self.doc_lines) &gt; 0:
        print "%s Documentation: %s" % (" " * (indent_level + 2), "\n".join(self.doc_lines))
    if len(self.imports) &gt; 0:
        for m in self.imports:
            print "%s Import: %s" % (" " * (indent_level + 2), m.name)
    if len(self.includes) &gt; 0:
        for m in self.includes:
            print "%s Include: %s" % (" " * (indent_level + 2), m.name)
    self.dump_collection('Globals', 'global_vars', indent_level + 2)
    self.dump_collection('Locals', 'local_vars', indent_level + 2)
    self.dump_collection('Instance vars', 'instance_vars', indent_level + 2)
    self.dump_collection('Class vars', 'class_vars', indent_level + 2)
    for cb in call_backs:
        cb()
    self.dump_kids(indent_level)
    
</t>
<t tx="ekr.20080121105837.1672">def dump_collection(self, label, attr, indent_level):
    if hasattr(self, attr):
        collection = getattr(self, attr)
        if len(collection) &gt; 0:
            print "%s %s: " % (" " * indent_level, label)
            for name, varInfo in collection.items():
                line, type = varInfo.line_num, varInfo.type
                if type:
                    typeString = " [" + type + "]"
                else:
                    typeString = ""
                print "%s %s - line %s%s" % (" " * (indent_level + 2), name, line, typeString)
        

</t>
<t tx="ekr.20080121105837.1673">class ClassNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1674">def __init__(self, the_name, line_num, unused=False):
    self.name = the_name
    self.classrefs = []
    Node.__init__(self, line_num, "Class")
    
</t>
<t tx="ekr.20080121105837.1675">def add_classrefs(self, class_ref_name, line_num, classref_type=None):
    if class_ref_name not in [x[0] for x in self.classrefs]:
        self.classrefs.append([class_ref_name, line_num, classref_type])
        
</t>
<t tx="ekr.20080121105837.1676">def has_classref(self, name):
    return name in [x[0] for x in self.classrefs]
    
</t>
<t tx="ekr.20080121105837.1677">def dump(self, indent_level):
    def cb():
        classrefs = self.classrefs
        if len(classrefs) &gt; 0:
            for ref in classrefs:
                print "%sClassref %s - line %s" % (" " * (indent_level + 2),
                                                   ref[0], ref[1])
    self.dump2("Class", indent_level, cb)

</t>
<t tx="ekr.20080121105837.1678">class FileNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1679">def __init__(self):
    Node.__init__(self, 0)
    self.global_vars = {}  # Easy to get at
    
</t>
<t tx="ekr.20080121105837.1680">def dump(self):
    self.name = ""
    self.dump2("file", 0)
    return
    indent_level = 0
    if len(self.imports) &gt; 0:
        for m in self.imports:
            print "%s Import: %s" % (" " * (indent_level + 2), m.name)
    if len(self.includes) &gt; 0:
        for m in self.includes:
            print "%s Include: %s" % (" " * (indent_level + 2), m.name)
    self.dump_kids(0)
    
</t>
<t tx="ekr.20080121105837.1681">class ArgNode:
    @others
</t>
<t tx="ekr.20080121105837.1682">def __init__(self, name, extra_info, arg_attrs):
    self.name = name
    self.extra_info = extra_info
    self.arg_attrs = arg_attrs
</t>
<t tx="ekr.20080121105837.1683">def get_full_name(self):
    if self.extra_info:
        return self.extra_info + self.name
    return self.name

</t>
<t tx="ekr.20080121105837.1684">class MethodNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1685">def __init__(self, the_name, line_num, is_constructor=False):
    self.name = the_name
    self.is_constructor = is_constructor
    self.signature = ""
    self.args = []
    self.is_classmethod = False
    Node.__init__(self, line_num, "Method")

    # extra_info for Ruby, arg_attrs for Tcl's "args", like Ruby's "*args"
</t>
<t tx="ekr.20080121105837.1686">def add_arg(self, name, extra_info=None, arg_attrs=None):
    self.args.append(ArgNode(name, extra_info, arg_attrs))
    
</t>
<t tx="ekr.20080121105837.1687">def dump(self, indent_level):
    def cb():
        args = self.args
        for arg in args:
            print "%sArg %s" % (" " * (indent_level + 2), arg.get_full_name())
    self.dump2("Method", indent_level, cb)
    if len(self.signature) &gt; 0:
        print "%sSignature %s" % (" " * (indent_level + 2), self.signature)

</t>
<t tx="ekr.20080121105837.1688">class ModuleNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1689">def __init__(self, the_name, line_num, unused=False):
    self.name = the_name
    Node.__init__(self, line_num, "Module")
    
</t>
<t tx="ekr.20080121105837.1690">def dump(self, indent_level):
    self.dump2("Module", indent_level)

</t>
<t tx="ekr.20080121105837.1691">class VariableNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1692">def __init__(self, the_name, line_num):
    self.name = the_name
    Node.__init__(self, line_num, "Variable")
    
</t>
<t tx="ekr.20080121105837.1693">def dump(self, indent_level):
    self.dump2("Module", indent_level)

</t>
<t tx="ekr.20080121105837.1694">class BlockNode(Node):
    @others
</t>
<t tx="ekr.20080121105837.1695">def __init__(self, the_name, line_num):
    self.name = the_name
    Node.__init__(self, line_num, "Block")
    
</t>
<t tx="ekr.20080121105837.1696">def dump(self, indent_level):
    self.dump2("Module", indent_level)
</t>
<t tx="ekr.20080121105837.1697">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121105837.1698">#!/usr/bin/env python

# Some CILE parsing utils extracted originally from phpcile and jscile
# but mostly generally useful to CILEs implemented in Python.

import codecs
import locale
import re
import sys
import os

from codeintel2.common import CILEError



</t>
<t tx="ekr.20080121105837.1699">#---- exported routines

def tryEncoding(buffer, encoding):
    """ buffer, encoding -&gt; encoding_buffer

        Attempts to encode the buffer using the specified encoding

        Returns None on failure, a Unicode version of the buffer on success.
    """
    #log.info("_tryEncoding...%s",encoding)
    try:
        secret_decoder_ring = codecs.lookup(encoding)[1]
    except LookupError, e:
        # the encoding name doesn't exist, likely a pep263 failure
        # an example is using windows-1250 as the name
        return None
    try:
        (outdata,len) = secret_decoder_ring(buffer)
        return outdata
    except Exception, e: # Figure out the real exception types
        return None


</t>
<t tx="ekr.20080121105837.1700">_defaultEncoding = locale.getdefaultlocale()[1]
if _defaultEncoding is not None:
    _defaultEncoding = _defaultEncoding.lower()

def getEncodedBuffer(buffer):
    decodedBuffer = tryEncoding(buffer, 'utf-8')
    if decodedBuffer is not None:
        return (decodedBuffer, 'utf-8', '')
    if _defaultEncoding is not None:
        decodedBuffer = tryEncoding(buffer, _defaultEncoding)
        if decodedBuffer is not None:
            return (decodedBuffer, _defaultEncoding, '')
    return (tryEncoding(buffer, 'iso8859-1'), 'iso8859-1', '')             


</t>
<t tx="ekr.20080121105837.1701">def getAttrStr(attrs):
    """Construct an XML-safe attribute string from the given attributes
    
        "attrs" is a dictionary of attributes
    
    The returned attribute string includes a leading space, if necessary,
    so it is safe to use the string right after a tag name.
    """
    from xml.sax.saxutils import quoteattr
    s = u''
    for attr, value in attrs.items():
        if not isinstance(value, basestring):
            value = str(value)
        elif not isinstance(value, unicode):
            value = getEncodedBuffer(value)[0]
        s += u' %s=%s' % (attr, quoteattr(value))
    return s


</t>
<t tx="ekr.20080121105837.1702"># match 0x00-0x1f except TAB(0x09), LF(0x0A), and CR(0x0D)
_encre = re.compile('([\x00-\x08\x0b\x0c\x0e-\x1f])')
if sys.version_info &gt;= (2, 3):
    charrefreplace = 'xmlcharrefreplace'
else:
    # Python 2.2 doesn't have 'xmlcharrefreplace'. Fallback to a
    # literal '?' -- this is better than failing outright.
    charrefreplace = 'replace'

def xmlencode(s):
    """Encode the given string for inclusion in a UTF-8 XML document.
    
    Specifically, illegal or unpresentable characters are encoded as
    XML character entities.
    """
    # As defined in the XML spec some of the character from 0x00 to 0x19
    # are not allowed in well-formed XML. We replace those with entity
    # references here.
    #   http://www.w3.org/TR/2000/REC-xml-20001006#charsets
    #
    # Dev Notes:
    # - It would be nice if Python has a codec for this. Perhaps we
    #   should write one.
    # - Eric, at one point, had this change to '_xmlencode' for rubycile:
    #    p4 diff2 -du \
    #        //depot/main/Apps/Komodo-devel/src/codeintel/ruby/rubycile.py#7 \
    #        //depot/main/Apps/Komodo-devel/src/codeintel/ruby/rubycile.py#8
    #   but:
    #        My guess is that there was a bug here, and explicitly
    #        utf-8-encoding non-ascii characters fixed it. This was a year
    #        ago, and I don't recall what I mean by "avoid shuffling the data
    #        around", but it must be related to something I observed without
    #        that code.
    return _encre.sub(
               # replace with XML decimal char entity, e.g. '&amp;#7;'
               lambda m: '&amp;#%d;'%ord(m.group(1)),
               s.encode('utf-8', charrefreplace))


</t>
<t tx="ekr.20080121105837.1703">def cdataescape(s):
    """Return the string escaped for inclusion in an XML CDATA section.
    
    A CDATA section is terminated with ']]&gt;', therefore this token in the
    content must be escaped. To my knowledge the XML spec does not define
    how to do that. My chosen escape is (courteousy of EricP) is to split
    that token into multiple CDATA sections, so that, for example:
    
        blah...]]&gt;...blah
    
    becomes:
    
        blah...]]]]&gt;&lt;![CDATA[&gt;...blah
    
    and the resulting content should be copacetic:
    
        &lt;b&gt;&lt;![CDATA[blah...]]]]&gt;&lt;![CDATA[&gt;...blah]]&gt;&lt;/b&gt;
    """
    parts = s.split("]]&gt;")
    return "]]]]&gt;&lt;![CDATA[&gt;".join(parts)


</t>
<t tx="ekr.20080121105837.1704">def urlencode_path(s):
    """URL-encode the given path string.
    
    This URL-encoding attempts to NOT encode characters that are typically
    legal path characters, e.g. '/', '\\', ':'. This is so that the result
    can more naturally be used as a filepath argument.
    
    The string must be an 8-bit string (that is all that URL-encoding can
    handle).
    """
    from urllib import quote
    safe = os.sep + (os.altsep or '') + ":"
    return quote(s, safe=safe)


</t>
<t tx="ekr.20080121105837.1705">#---- javadoc parsing

_javadoc1 = re.compile(r'\s*\/\*(.*)\*\/', re.S)
_javadoc2 = re.compile(r'^(\s*\*)', re.M)
_linedoc = re.compile(r'^(\s*#|\s*\/\/)', re.M)
_indent = re.compile(r'^([ \t]*)', re.M)
_param = re.compile(r'^\s*@param\s+(?P&lt;type&gt;\w+)\s+\$?(?P&lt;name&gt;\w+)(?:\s+?(?P&lt;doc&gt;.*?))?', re.M|re.U)
_return = re.compile(r'^\s*@return\s+(?P&lt;type&gt;\w+)(?:\s+(?P&lt;doc&gt;.*))?', re.M|re.U)

def uncommentDocString(doc):
    # remove block style leading and end comments
    d = '\n'.join(re.findall(_javadoc1, doc))
    if d:
        # remove starting * if javadoc style
        d = re.sub(_javadoc2,'',d)
    else:
        d = doc
        # remove line style comments
        d = re.sub(_linedoc,'',d)


    # trim preceeding blank lines.  we dont want to trim the first non-blank line
    lines = d.split('\n')
    while len(lines) and not lines[0].strip():
        lines.pop(0)
    d = '\n'.join(lines)
    
    # trip any blank end lines
    d = d.rstrip()
    
    # guess the indent size    
    spaces = re.findall(_indent, d)
    indent = spaces[0]
    for s in spaces:
        if len(s) and len(s) &lt; indent:
            indent = len(s)

    # dedent the block
    if not indent:
        return d
    dedent = re.compile(r'^([ \t]{%d})' % indent, re.M)
    d = re.sub(dedent, '', d)
    return d

</t>
<t tx="ekr.20080121105837.1706">def parseDocString(doc):
    d = uncommentDocString(doc)
    params = re.findall(_param, d)
    result = re.findall(_return, d)
    if result:
        result = result[0]
    return (d, params, result)



</t>
<t tx="ekr.20080121105837.1707">SKIPTOK = 0x01 # don't consider this a token that is to be considered a part of the grammar, like '\n'
MAPTOK = 0x02  # use the token associated with the pattern when it matches
EXECFN= 0x04   # execute the function associated with the pattern when it matches
USETXT = 0x08  # if you match a single character and want its ascii value to be the token

class recollector:
    @others
</t>
<t tx="ekr.20080121105837.1708">def __init__(self):
    self.res = {}
    self.regs = {}
    
</t>
<t tx="ekr.20080121105837.1709">def add(self, name, reg, mods=None ):
    self.regs[name] = reg % self.regs
    #print "%s = %s" % (name, self.regs[name])
    if mods:
        self.res[name] = re.compile(self.regs[name], mods) # check that it is valid
    else:
        self.res[name] = re.compile(self.regs[name]) # check that it is valid

</t>
<t tx="ekr.20080121105837.1710"># Lexer class borrowed from the PyLRd project,
# http://starship.python.net/crew/scott/PyLR.html
class Lexer:
    eof = -1

    @others
</t>
<t tx="ekr.20080121105837.1711">def __init__(self):
    self.tokenmap = {}
    self.prgmap = {}
    self.prglist = []
    self.lasttok = -1
    self.text = ""
    self.textindex = 0
    self.tokennum2name = {}

</t>
<t tx="ekr.20080121105837.1712">def nexttok(self):
    self.lasttok = self.lasttok + 1
    return self.lasttok

</t>
<t tx="ekr.20080121105837.1713">def settext(self, t):
    self.text = t
    self.textindex = 0

</t>
<t tx="ekr.20080121105837.1714">def addmatch(self, prg, func=None, tokname="", attributes=MAPTOK|EXECFN):
    self.prglist.append(prg)
    tok = -2
    if not func:
        attributes = attributes &amp; ~EXECFN
    if not tokname:
        attributes = attributes &amp; ~MAPTOK
    if attributes &amp; MAPTOK:
        self.tokenmap[tokname] = tok = self.nexttok()
    else:
        tok = self.nexttok()
    self.prgmap[prg] = tok, attributes, func
    self.tokennum2name[tok] = tokname

</t>
<t tx="ekr.20080121105837.1715">def scan(self):
    for prg in self.prglist:
        mo = prg.match(self.text, self.textindex)
        if not mo: 
            continue
        self.textindex = self.textindex + len(mo.group(0))
        tmpres = mo.group(0)
        t, attributes, fn = self.prgmap[prg]
        #log.debug("'%s' token: %r", self.tokennum2name[t], tmpres)
        if attributes &amp; EXECFN:
            tmpres = apply(fn, (mo,))
        if attributes &amp; USETXT:
            t = ord(mo.group(0)[0])
        return (t, tmpres)
    if self.textindex &gt;= len(self.text):
        return (self.eof, "")
    raise CILEError("Syntax Error in lexer")

</t>
<t tx="ekr.20080121105837.1716">#!/usr/bin/env python

"""New citree-based codeintel evaluation engine.

A 'citree' is basically an ElementTree of a CIX document with some tweaks.
The idea is to use these for completion/calltip evaluation instead of the
CIDB. This is mainly about performance but also about fixing some
limitations, bugs, and having a better code design (i.e. where lang-specific
quirks can be dealt with cleanly).
"""

@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;

log = logging.getLogger("codeintel.tree")
CIX_VERSION = "2.0"

@others
</t>
<t tx="ekr.20080121105837.1717">import logging

import ciElementTree as ET

if not getattr(ET, "_patched_for_komodo_", False):
    import warnings
    warnings.warn("Not using codeintel's patched elementtree: "
                  "this may cause problems")

from codeintel2.common import *
from codeintel2.citadel import CitadelEvaluator
</t>
<t tx="ekr.20080121105837.1718">def tree_2_0_from_tree_0_1(tree):
    """Convert CIX 0.1 to CIX 2.0."""
    # - update some of the no longer used &lt;file&gt; attributes
    #   - drop "generator"
    try:
        del tree[0].attrib["generator"]
    except KeyError:
        pass
    #   - drop 'md5' and 'mtime' on the &lt;file&gt; tag
    try:
        del tree[0].attrib["md5"]
    except KeyError:
        pass
    try:
        del tree[0].attrib["mtime"]
    except KeyError:
        pass
    #   - move "language" attribute on &lt;file&gt; to "lang" and to "lang" on
    #     &lt;module&gt; (New multi-lang CIX output will allow one file to
    #     have modules of different langs.)
    for file in tree.getiterator("file"):
        lang = file.get("language")
        if lang is not None:
            file.set("lang", lang)
            for module in file.getiterator("module"):
                if module.get("lang") is None:
                    module.set("lang", lang)
            try:
                del file.attrib["language"]
            except KeyError:
                # Be tolerant of transitional CIX.
                pass

    # - move &lt;doc&gt; and &lt;signature&gt; optional sub tags into parent
    #   attribute
    #PERF: This could be done better.
    for tag in ("variable", "function", "class", "module", "interface",
                "argument", "classref", "iterfaceref"):
        for node in tree.getiterator(tag):
            for child in reversed(node):
                # reversed() so can modify while iterating over
                if child.tag == "signature":
                    if child.text: # be tolerant of &lt;signature /&gt;
                        node.set("signature", child.text)
                    node.remove(child)
                elif child.tag == "doc":
                    if child.text: # be tolerant of &lt;doc /&gt;
                        node.set("doc", child.text)
                    node.remove(child)
            if not node: # no children now
                node.text = None

    # - move non-variable tags to attributes
    #   (XXX currently &lt;classref&gt; and &lt;interfaceref&gt; tags are not moved)
    for tag in ("variable", "argument", "classref", "interfaceref"):
        for node in tree.getiterator(tag):
            for child in reversed(node):
                if child.tag == "type":
                    node.set("citdl", child.get("type"))
                    node.remove(child)
            if not node: # no remaining children
                node.text = None
            if tag == "argument":
                node.tag = "variable"
                node.set("ilk", "argument")

    # - move &lt;returns&gt; to a &lt;function&gt; attribute
    for node in tree.getiterator("function"):
        for child in reversed(node): #PERF: could just check last child
            if child.tag == "returns":
                assert child[0].tag == "type"
                node.set("returns", child[0].get("type"))
                node.remove(child)

    # - move classrefs and interfacerefs to attributes
    #   Note: &lt;classref attribute="__mixin__"&gt; =&gt; "mixinrefs" attribute.
    #   This is used by Ruby (though not used for eval, yet).
    for scope_ilk in ("class", "interface"):
        for node in tree.getiterator(scope_ilk):
            interfacerefs = []
            classrefs = []
            mixinrefs = []
            for child in reversed(node):
                if child.tag == "classref":
                    if "__mixin__" in child.get("attributes", ""):
                        mixinrefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    else:
                        classrefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    node.remove(child)
                elif child.tag == "interfaceref":
                    interfacerefs.append(child.get("citdl")
                                         or child.attrib["name"])
                    node.remove(child)
            if classrefs:
                classrefs.reverse()
                assert not [c for c in classrefs if ' ' in c]
                node.set("classrefs", ' '.join(classrefs))
            if interfacerefs:
                interfacerefs.reverse()
                assert not [i for i in interfacerefs if ' ' in i]
                node.set("interfacerefs", ' '.join(interfacerefs))
            if mixinrefs:
                mixinrefs.reverse()
                assert not [m for m in mixinrefs if ' ' in m]
                node.set("mixinrefs", ' '.join(mixinrefs))
            if len(node) == 0:
                node.text = None

    # - make all scope tags a "scope" tag (easier for elem.find() usage)
    for tag in ("class", "function", "interface", "module"):
        for node in tree.getiterator(tag):
            node.tag = "scope"
            if tag == "class" and "__namespace__" in node.get("attributes", ""):
                node.set("ilk", "namespace")
                attributes = node.get("attributes").split()
                attributes.remove("__namespace__")
                if not attributes:
                    del node.attrib["attributes"]
                else:
                    node.set("attributes", ' '.join(attributes))
            elif tag == "module":
                node.set("ilk", "blob")
            else:
                node.set("ilk", tag)

    tree.set("version", "2.0")
    return tree

</t>
<t tx="ekr.20080121105837.1719">def tree_from_cix_path(cix_path):
    """Return a (ci)tree for the CIX content in the given path.

    Raises pyexpat.ExpatError if the CIX content could not be parsed.
    """
    tree = ET.parse(cix_path).getroot()
    version = tree.get("version")
    if version == CIX_VERSION:
        return tree
    elif version == "0.1":
        return tree_2_0_from_tree_0_1(tree)
    else:
        raise CodeIntelError("unknown CIX version: %r" % version)


</t>
<t tx="ekr.20080121105837.1720">def tree_from_cix(cix):
    """Return a (ci)tree for the given CIX content.

    Raises pyexpat.ExpatError if the CIX content could not be parsed.
    """
    if isinstance(cix, unicode):
        cix = cix.encode("UTF-8", "xmlcharrefreplace")
    tree = ET.XML(cix)
    version = tree.get("version")
    if version == CIX_VERSION:
        return tree
    elif version == "0.1":
        return tree_2_0_from_tree_0_1(tree)
    else:
        raise CodeIntelError("unknown CIX version: %r" % version)


</t>
<t tx="ekr.20080121105837.1721">def pretty_tree_from_tree(tree, indent_width=2):
    """Add appropriate .tail and .text values to the given tree so that
    it will have a pretty serialization.

    Note: This modifies the tree *in-place*.
    Presumption: This is a CIX 2.0 tree.
    """
    INDENT = ' '*indent_width

    def _prettify(elem, indent_level=0):
        if elem: # i.e. has children
            elem.text = '\n' + INDENT*(indent_level+1)
            for child in elem:
                _prettify(child, indent_level+1)
            elem[-1].tail = '\n' + INDENT*indent_level
            elem.tail = '\n' + INDENT*indent_level
        else:
            elem.text = None
            elem.tail = '\n' + INDENT*indent_level

    _prettify(tree)
    return tree


</t>
<t tx="ekr.20080121105837.1722">def check_tree(tree):
    """Generate warnings/errors for common mistakes in CIX trees.

    Yields tuples of the form:
        ("warning|error", &lt;msg&gt;)
    """
    assert tree.tag == "codeintel",\
        "can only check starting from &lt;codeintel&gt; element"
    assert tree.get("version") == CIX_VERSION, \
        "can only check CIX v%s trees" % CIX_VERSION

    # - file 'lang' is set, not 'language' 
    file = tree[0]
    if not file.get("lang"):
        yield ("error", "no 'lang' attr on &lt;file&gt; element")
    if file.get("language"):
        yield ("warning", "'language' attr on &lt;file&gt; element is obsolete,"
                          "use 'lang'")

    for blob in file:
        if blob.get("ilk") != "blob":
            yield ("error", "element under &lt;file&gt; is not ilk=blob: %r" % blob)
        # - blob 'lang' is set
        if not blob.get("lang"):
            yield ("error", "no 'lang' attr on &lt;blob&gt; element: %r" % blob)

        # - classrefs are space separated, not with commas (warn)
        for class_elem in blob.getiterator("scope"):
            if class_elem.get("ilk") != "class": continue
            classrefs = class_elem.get("classrefs")
            if not classrefs: continue
            if ',' in classrefs:
                yield ("warning", "multiple class references in 'classrefs' "
                                  "attr on class scopes must be "
                                  "space-separated: %r may be using "
                                  "comma-separation: %r"
                                  % (class_elem, classrefs))


</t>
<t tx="ekr.20080121105837.1723">class TreeEvaluator(CitadelEvaluator):
    @others
</t>
<t tx="ekr.20080121105837.1724">def get_start_scoperef(self):
    linenum = self.line + 1 # convert to 1-based
    try:
        blob = self.buf.blob_from_lang[self.trg.lang]
    except KeyError:
        raise EvalError("no %s scan info for %r" % (self.lang, self.buf))
    return self.buf.scoperef_from_blob_and_line(blob, linenum)

</t>
<t tx="ekr.20080121105837.1725">def eval(self, mgr):
    self.mgr = mgr
    self.citadel = mgr.citadel

    if self.ctlr.is_aborted():
        self.ctlr.done("aborting")
        return
    self.ctlr.info("eval %s  %s", self, self.trg)

    self.pre_eval()

    try:
        if self.trg.form == TRG_FORM_CPLN:
            cplns = self.eval_cplns()
            if cplns:
                cplns = self.post_process_cplns(cplns)
            self.info("    cplns: %r", cplns)
            if cplns:
                self.ctlr.set_cplns(cplns)
        elif self.trg.form == TRG_FORM_CALLTIP:
            calltips = self.eval_calltips()
            if calltips:
                calltips = self.post_process_calltips(calltips)
            self.info("    calltips: %r", calltips)
            if calltips:
                self.ctlr.set_calltips(calltips)
        else:  # self.trg.form == TRG_FORM_DEFN
            defns = self.eval_defns()
            if defns:
                defns = self.post_process_defns(defns)
            self.info("    defns: %r", defns)
            if defns:
                self.ctlr.set_defns(defns)
        self.ctlr.done("success")
    except CodeIntelError, ex:
        #XXX Should we have an error handling hook here?
        self.ctlr.error("evaluating %s: %s", self, ex)
        self.ctlr.done("eval error")

</t>
<t tx="ekr.20080121105837.1726">def scope_stack_from_tree_and_linenum(self, tree, linenum):
    """Get the start scope for the given line.

        "linenum" appears to be 0-based, however all CIX line data
            is 1-based so we'll convert here.

    Dev Notes:
    - XXX Add built-in scope.
    """
    linenum += 1 # convert to 1-based
    #XXX This is presuming that the tree has only one blob.
    scope_stack = [tree.find("file/scope")]
    while True:
        next_scope_could_be = None
        # PERF: Could make this a binary search if a scope has *lots* of
        # subscopes.
        for scope in scope_stack[-1].findall("scope"):
            start = int(scope.get("line"))
            if start &lt;= linenum \
               and (not scope.get("lineend")
                    or linenum &lt;= int(scope.get("lineend"))):
                next_scope_could_be = scope
            elif start &gt; linenum:
                break
        if next_scope_could_be is not None:
            scope_stack.append(next_scope_could_be)
        else:
            break
    return scope_stack

</t>
<t tx="ekr.20080121105837.1727">#TODO: split out '()' as a separate token.
def _tokenize_citdl_expr(self, citdl):
    for token in citdl.split('.'):
        yield token
</t>
<t tx="ekr.20080121105837.1728">def _join_citdl_expr(self, tokens):
    return '.'.join(tokens)

</t>
<t tx="ekr.20080121105837.1729">def str_elem(self, elem):
    if elem.tag == "scope":
        return "%s %s" % (elem.get("ilk"), elem.get("name"))
    else:
        return "%s %s" % (elem.tag, elem.get("name"))
</t>
<t tx="ekr.20080121105837.1730">def str_elem_and_children(self, elem):
    s = [self.str_elem(elem)]
    for child in elem:
        s.append(self.str_elem(child))
    return "%s: %s" % (self.str_elem(elem),
                       ', '.join(self.str_elem(c) for c in elem))

</t>
<t tx="ekr.20080121105837.1731">def str_import(self, elem):
    # c.f. cb.py::getDescForImport()
    module = elem.get("module")
    symbol = elem.get("symbol")
    alias = elem.get("alias")
    if alias and symbol:
        s = "from %(module)s import %(symbol)s as %(alias)s" % locals()
    elif alias:
        s = "import %(module)s as %(alias)s" % locals()
    elif symbol:
        s = "from %(module)s import %(symbol)s" % locals()
    else:
        s = "import %(module)s" % locals()
    return s

</t>
<t tx="ekr.20080121105837.1732"># logging funcs (perhaps best on controller)
def log_start(self):
    self._log = []
</t>
<t tx="ekr.20080121105837.1733">def log(self, msg, *args, **kwargs):
    """
        kwargs:
            "cached" (boolean) indicates if result was from cache
    """
    log_indent = ' '*4
    if True:    # just print as we go
        s = [msg % args]
        if kwargs.get("cached"):
            s.append(" (cached)")
        self.info(''.join(s))
    else:       # capture log for latter printing
        self._log.append(msg, args, kwargs)

</t>
<t tx="ekr.20080121105837.1734">def pre_eval(self):
    self.curr_tree = self.buf.tree
    #ET.dump(self.curr_tree)

</t>
<t tx="ekr.20080121105837.1735">def _eval_citdl_expr(self, expr, scope_stack):
    """Return the citree node for the given CITDL expression.
    
        os.environ.get() -&gt; &lt;class 'str' on stdlib blob 'built-in'&gt;
    """
    tokens = list(self._tokenize_citdl_expr(expr))
    assert tokens, "have to adjust handling if no tokens"
    obj = self._eval_citdl_token(tokens[0], scope_stack)

    for i, token in enumerate(tokens[1:]):
        if token.endswith("()"):
            token = token[-2:]
            call = True
        else:
            call = False

        if obj.tag == "import":
            obj = self._eval_import_getattr(obj, token,
                    self._join_citdl_expr(tokens[:i+2]))
        else:
            obj = self._eval_getattr(obj, token,
                    self._join_citdl_expr(tokens[:i+2]))

        if call:
            raise CodeIntelError("_eval_citdl_expr(%r): not handling "
                                 "call on %r "
                                 % (expr, self.str_elem(obj)))

    if obj.tag == "import":
        raise CodeIntelError("_eval_citdl_expr: cannot return import "
                             "&lt;%s&gt;: need to resolve it"
                             % self.str_import(obj))
    return obj

</t>
<t tx="ekr.20080121105837.1736">def _resolve_import(self, module_name, symbol_name=None):
    """Return a loaded citree node for the given import info.

        "module_name" is the name of the module to import.
        "symbol_name" (if given) is the attribute on that module to
            return.
    """
    #TODO: get logging right
    #XXX All the logging stuff should go on the controller and that
    #    should get passed in here for appropriate logging of this
    #    eval.
    #XXX Will this screw up for, e.g. in Python:
    #    'import codeintel.utils'?
    import_handler = self.citadel.import_handler_from_lang(self.lang)
    module = import_handler.import_blob_name(
                module_name, self.buf.libs, self.ctlr)
    self.log("module '%s' imports &lt;%s&gt;", module_name,
             self.str_elem(module))

    if symbol_name:
        #XXX logging won't be right here
        return self._eval_getattr(module, symbol_name,
                "%s.%s" % (module_name, symbol_name))
        #XXX Here is the _eval_getattr code to duplicate.
        # self.log("lookup '%s' on &lt;%s&gt;:", name, self.str_elem(obj))
        # for child in obj:
        #     if child.get("name") == name:
        #         attr = child
        #         self.log("'%s' is &lt;%s&gt;", citdl_expr, self.str_elem(child))
        #         return attr
        # else:
        #     raise CodeIntelError("couldn't find '%s' attribute on &lt;%s&gt;"
        #                          % (name, self.str_elem(obj)))
    else:
        return module

</t>
<t tx="ekr.20080121105837.1737">def _eval_import(self, imp, name):
    """Return the object imported, if any, with the given import
    node (in a citree) and name.

    Return value: If successful it returns the citree node imported.
    If 'name' was not found in a '*'-import then None is returned
    (e.g. it is not exceptional that 'from os import *' does not
    import 'fuzzywuzzy'). If the import could not be resolved, but
    it looks like it should have been, then an error is raised.
    """
    # One of these:
    #   'os' may be from &lt;import os&gt;:
    #       ...
    #       'os' is &lt;blob os&gt;
    #   'os' is from &lt;import os&gt;: &lt;blob os&gt; (cached)
    #
    #Python
    #if non-* import and matches:
    # 'os' is from &lt;import os&gt;
    # is &lt;import os&gt; from &lt;project foo&gt;? no
    # ...
    # is &lt;import os&gt; from &lt;python-2.4-stdlib&gt;? yes: &lt;blob os&gt;
    # 'os' is &lt;blob os&gt;
    #
    # 'dirname' may be from &lt;from os.path import *&gt;:
    #     is &lt;from os.path import *&gt; from &lt;project foo&gt;? no
    #     ...
    #     is &lt;from os.path import *&gt; from &lt;python-2.4-stdlib&gt;? yes: &lt;blob os.path&gt;

    # TOTEST:
    # - 'from xml import dom', does that get it right? I doubt it.
    
    module_name = imp.get("module")
    symbol_name = imp.get("symbol")
    alias = imp.get("alias")
    obj = None
    if alias: 
        if alias == name:   # &lt;import foo as name&gt; or &lt;from foo import bar as name&gt;
            self.log("'%s' is from &lt;%s&gt;", name, self.str_import(imp))
            return self._resolve_import(module_name, symbol_name)
    elif symbol_name:
        assert symbol_name != "**", "only Perl should be using '**' for imports"
        if symbol_name == "*":   # &lt;from foo import *&gt;
            self.log("'%s' may be from &lt;%s&gt;", name, imp)
            #XXX some variation of _resolve_import to specify just
            #    importing the module.
            try:
                module = self._resolve_import(module_name)
            except CodeIntelError, ex: # use equivalent of NoModuleEntry?
                self.warn("could not resolve '%s' import to handle &lt;%s&gt;",
                          module_name, self.str_import(imp))
                return None
            #TODO:
            # see if name in export list (__all__ for Python,
            #   @EXPORT for Perl, default all top-level symbols)
            # if so, eval getattr of name on module object
            self.warn("not handling &lt;%s&gt;!", self.str_import(imp))
        if symbol_name == name:  # &lt;from foo import name&gt;
            self.log("'%s' is from &lt;%s&gt;", name, self.str_import(imp))
            return self._resolve_import(module_name, symbol_name)
    elif module_name == name:    # &lt;import foo&gt;
        self.log("'%s' is from &lt;%s&gt;", name, self.str_import(imp))
        return self._resolve_import(module_name)
    return None

</t>
<t tx="ekr.20080121105837.1738">def _eval_citdl_token(self, token, scope_stack):
    start_scope_str = self.str_elem(scope_stack[-1])
    self.log("eval '%s' at &lt;%s&gt;:", token, start_scope_str)

    while scope_stack:
        scope = scope_stack.pop()
        self.log("is '%s' accessible on &lt;%s&gt;?",
                 token, self.str_elem(scope))
        for child in reversed(scope):
            # Check children in reverse because last definition in
            # file wins. A correct refinement *for the top-level*
            # would be to skip anything defined later in the file
            # than the current start position.
            # TODO-PERF: The list of symbols on a scope should be a
            #            dict to speed up this loop. This is complicated
            #            by '*' imports.

            if child.tag == "import":
                obj = self._eval_import(child, token)
                if obj:
                    return obj
            elif child.get("name") == token:
                obj = child
                if obj.tag == "variable":
                    citdl = obj.get("citdl")
                    if not citdl:
                        self.log("'%s' is &lt;%s&gt; which is of unknown type",
                                 token, self.str_elem(obj))
                        raise CodeIntelError(
                            "don't know type of &lt;%s&gt; on &lt;%s&gt;"
                            % (self.str_elem(obj), self.str_elem(scope)))
                    else:
                        self.log("'%s' is &lt;%s&gt; which is '%s'", token,
                                 self.str_elem(obj), citdl)
                        obj = self._eval_citdl_expr(
                                citdl, scope_stack+[scope])
                        self.log("'%s' is &lt;%s&gt;", token,
                                 self.str_elem(obj))
                else:
                    self.log("'%s' is &lt;%s&gt;", token, self.str_elem(obj))
                return obj
        else:
            continue
    else:
        raise CodeIntelError("couldn't resolve '%s' starting at %s"
                             % (token, start_scope_str))

</t>
<t tx="ekr.20080121105837.1739">def _defn_from_hit(self, hit):
    elem, (blob, lpath) = hit
    #self.log("_defn_from_hit:: blob: %r", blob)
    #for attr_name, attr_value in blob.attrib.items():
    #    self.log("attr_name: %r, attr_value: %r", attr_name, attr_value)
    #self.log("_defn_from_hit:: elem: %r", elem)

    path = blob.get("src", None)
    name = elem.get("name", None)
    line = elem.get("line", None)
    if line is not None:
        try:
            line = int(line)
        except ValueError:
            line = None
    ilk = elem.get("ilk") or elem.tag
    citdl = elem.get("citdl", None)
    doc = elem.get("doc", None)
    signature = elem.get("signature", None)
    attributes = elem.get("attributes", None)
    returns = elem.get("returns", None)

    if path and sys.platform == "win32":
        path = path.replace('/', '\\') # unnormalize path
    defn = Definition(blob.get("lang"), path, blob.get("name"), lpath,
                      name, line, ilk, citdl, doc,
                      signature, attributes, returns)
    return defn

</t>
<t tx="ekr.20080121105837.1740"># The SENTINEL_MAX_EXPR_COUNT could probably be *reduced*.
# Note: This is an approximation that we are infinitely looping
# on the same evaluation. The *actual* appropriate key would be:
#
#   (expr, scoperef)
#
# but that is overkill for now, I think.
_SENTINEL_MAX_EXPR_COUNT = 10
_eval_count_from_expr = None
def _check_infinite_recursion(self, expr):
    if self._eval_count_from_expr is None:
        # Move this init into eval() when on TreeEvalutor.
        self._eval_count_from_expr = {}
    eval_count = self._eval_count_from_expr.get(expr, 0)
    eval_count += 1
    if eval_count &gt;= self._SENTINEL_MAX_EXPR_COUNT:
        raise EvalError("hit eval sentinel: expr '%s' eval count "
                        "is %d (abort)" % (expr, eval_count))
    self._eval_count_from_expr[expr] = eval_count


</t>
<t tx="ekr.20080121105837.1741">#---- internal support stuff

def _dump_element(elem, indent=''):
    """Dump an element tree without using ET.dump() which
    (1) uses XML syntax,
    (2) can blow up if an attribute is set to None accidentally.

    This is only useful for debugging.
    """
    s = "%selement '%s': %s" % (indent, elem.tag, elem.attrib)
    print s
    for child in elem:
        _dump_element(child, indent+'  ')





</t>
<t tx="ekr.20080121105837.1742">@language python
@tabwidth -4
@others
#---- mainline self-test

if __name__ == "__main__":
    import doctest
    doctest.testmod()

</t>
<t tx="ekr.20080121105837.1743">#!python
# ***** BEGIN LICENSE BLOCK *****

"""Code Intelligence: utility functions"""

import os
from os.path import basename
import sys
import md5
import re
import stat
import textwrap
import types
from pprint import pprint, pformat

from codeintel2.common import CodeIntelError

# Global dict for holding specific hotshot profilers
hotshotProfilers = {}

</t>
<t tx="ekr.20080121105837.1744">#---- general stuff

def isident(char):
    return "a" &lt;= char &lt;= "z" or "A" &lt;= char &lt;= "Z" or char == "_"

</t>
<t tx="ekr.20080121105837.1745">def isdigit(char):
    return "0" &lt;= char &lt;= "9"

</t>
<t tx="ekr.20080121105837.1746"># A "safe" language name for the given language where safe generally
# means safe for a file path.
_safe_lang_from_lang_cache = {
    "C++": "cpp",
}
def safe_lang_from_lang(lang):
    global _safe_lang_from_lang_cache
    try:
        return _safe_lang_from_lang_cache[lang]
    except KeyError:
        safe_lang = lang.lower().replace(' ', '_')
        _safe_lang_from_lang_cache[lang] = safe_lang
        return safe_lang


</t>
<t tx="ekr.20080121105837.1747">def guess_lang_from_path(path):
    lang_from_ext = {
        ".py": "Python",
        ".pl": "Perl",
        ".pm": "Perl",
        ".tcl": "Tcl",
        ".php": "PHP",
        ".inc": "PHP",
        ".rb": "Ruby",
        ".rhtml": "RHTML",
        ".js": "JavaScript",
        ".css": "CSS",
        ".xul": "XUL",
        ".xbl": "XBL",
        ".html": "HTML",
        ".xml": "XML",
        ".tpl": "Smarty",
        ".django.html": "Django",
        ".mason.html": "Mason",
        ".ttkt.html": "TemplateToolkit",
    }
    idx = 0
    base = basename(path)
    while base.find('.', idx) != -1:
        idx = base.find('.', idx)
        if idx == -1:
            break
        ext = base[idx:]
        if ext in lang_from_ext:
            return lang_from_ext[ext]
        idx += 1
    raise CodeIntelError("couldn't guess lang for `%s'" % path)


</t>
<t tx="ekr.20080121105837.1748">def gen_dirs_under_dirs(dirs, max_depth, interesting_file_patterns=None,
                        skip_scc_control_dirs=True):
    """Generate all dirs under the given dirs (including the given dirs
    themselves).
    
        "max_depth" is an integer maximum number of sub-directories that
            this method with recurse.
        "file_patterns", if given, is a sequence of glob patterns for
            "interesting" files. Directories with no interesting files are
            not included (though sub-directories of these may be).
        "skip_scc_control_dirs" is a boolean (default True) indicating if
            svn and cvs control dirs should be skipped.
    """
    from os.path import normpath, abspath, expanduser
    from fnmatch import fnmatch

    dirs_to_skip = skip_scc_control_dirs and ["CVS", ".svn"] or []
    for dir in dirs:
        norm_dir = normpath(abspath(expanduser(dir)))
        LEN_DIR = len(norm_dir)
        for dirpath, dirnames, filenames in os.walk(norm_dir):
            if dirpath[LEN_DIR:].count(os.sep) &gt;= max_depth:
                dirnames[:] = []  # hit max_depth
            else:
                for dir_to_skip in dirs_to_skip:
                    if dir_to_skip in dirnames:
                        dirnames.remove(dir_to_skip)
        
            if interesting_file_patterns:
                for pat, filename in (
                    (p,f) for p in interesting_file_patterns
                          for f in filenames):
                    if fnmatch(filename, pat):
                        break
                else:
                    # No interesting files in this dir.
                    continue
        
            yield dirpath



</t>
<t tx="ekr.20080121105837.1749">#---- standard module/class/function doc parsing

LINE_LIMIT = 5      # limit full number of lines this number
LINE_WIDTH = 60     # wrap doc summaries to this width

# Examples matches to this pattern:
#    foo(args)
#    foo(args) -&gt; retval
#    foo(args) -- description
#    retval = foo(args)
#    retval = foo(args) -- description
_gPySigLinePat = re.compile(r"^((?P&lt;retval&gt;[^=]+?)\s*=|class)?\s*(?P&lt;head&gt;[\w\.]+\s?\(.*?\))\s*(?P&lt;sep&gt;[:&lt;&gt;=-]*)\s*(?P&lt;tail&gt;.*)$")
_gSentenceSepPat = re.compile(r"(?&lt;=\.)\s+", re.M) # split on sentence bndry

def parseDocSummary(doclines, limit=LINE_LIMIT, width=LINE_WIDTH):
    """Parse out a short summary from the given doclines.
    
        "doclines" is a list of lines (without trailing newlines) to parse.
        "limit" is the number of lines to which to limit the summary.

    The "short summary" is the first sentence limited by (1) the "limit"
    number of lines and (2) one paragraph. If the first *two* sentences fit
    on the first line, then use both. Returns a list of summary lines.
    """
    # Skip blank lines.
    start = 0
    while start &lt; len(doclines):
        if doclines[start].strip():
            break
        start += 1

    desclines = []
    for i in range(start, len(doclines)):
        if len(desclines) &gt;= limit:
            break
        stripped = doclines[i].strip()
        if not stripped:
            break
        sentences = _gSentenceSepPat.split(stripped)
        if sentences and not sentences[-1].endswith('.'):
            del sentences[-1] # last bit might not be a complete sentence
        if not sentences:
            desclines.append(stripped + ' ')
            continue
        elif i == start and len(sentences) &gt; 1:
            desclines.append(' '.join([s.strip() for s in sentences[:2]]))
        else:
            desclines.append(sentences[0].strip())
        break
    if desclines:
        if desclines[-1][-1] == ' ':
            # If terminated at non-sentence boundary then have extraneous
            # trailing space.
            desclines[-1] = desclines[-1][:-1]
        desclines = textwrap.wrap(''.join(desclines), width)
    return desclines


</t>
<t tx="ekr.20080121105837.1750">def parsePyFuncDoc(doc, fallbackCallSig=None, scope="?", funcname="?"):
    """Parse the given Python function/method doc-string into call-signature
    and description bits.
    
        "doc" is the function doc string.
        "fallbackCallSig" (optional) is a list of call signature lines to
            fallback to if one cannot be determined from the doc string.
        "scope" (optional) is the module/class parent scope name. This
            is just used for better error/log reporting.
        "funcname" (optional) is the function name. This is just used for
            better error/log reporting.
    
    Examples of doc strings with call-signature info:
        close(): explicitly release resources held.
        x.__repr__() &lt;==&gt; repr(x)
        read([s]) -- Read s characters, or the rest of the string
        recv(buffersize[, flags]) -&gt; data
        replace (str, old, new[, maxsplit]) -&gt; string
        class StringIO([buffer])

    Returns a 2-tuple: (&lt;call-signature-lines&gt;, &lt;description-lines&gt;)
    """
    if doc is None or not doc.strip():
        return ([], [])
    
    limit = LINE_LIMIT
    doclines = doc.splitlines(0)
    index = 0
    siglines = []
    desclines = []

    # Skip leading blank lines.
    while index &lt; len(doclines):
        if doclines[index].strip():
            break
        index += 1

    # Parse out the call signature block, if it looks like there is one.
    if index &gt;= len(doclines):
        match = None
    else:
        first = doclines[index].strip()
        match = _gPySigLinePat.match(first)
    if match:
        # The 'doc' looks like it starts with a call signature block.
        for i, line in enumerate(doclines[index:]):
            if len(siglines) &gt;= limit:
                index = i
                break
            stripped = line.strip()
            if not stripped:
                index = i
                break
            match = _gPySigLinePat.match(stripped)
            if not match:
                index = i
                break
            # Now parse off what may be description content on the same line.
            #   ":", "-" or "--" separator: tail is description
            #   "--&gt;" or "-&gt;" separator: tail if part of call sig
            #   "&lt;==&gt;" separator: tail if part of call sig
            #   other separtor: leave as part of call sig for now
            descSeps = ("-", "--", ":")
            groupd = match.groupdict()
            retval, head, sep, tail = (groupd.get("retval"), groupd.get("head"),
                                       groupd.get("sep"), groupd.get("tail"))
            if retval:
                siglines.append(head + " -&gt; " + retval)
                if tail and sep in descSeps:
                    desclines.append(tail)
            elif tail and sep in descSeps:
                siglines.append(head)
                desclines.append(tail)
            else:
                siglines.append(stripped)
        else:
            index = len(doclines)
    if not siglines and fallbackCallSig:
        siglines = fallbackCallSig
    
    # Parse out the description block.
    if desclines:
        # Use what we have already. Just need to wrap it.
        desclines = textwrap.wrap(' '.join(desclines), LINE_WIDTH)
    else:
        limit -= len(siglines)
        desclines = parseDocSummary(doclines[index:], limit=limit)

    ## debug logging
    #f = open("parsePyFuncDoc.log", "a")
    #if 0:
    #    f.write("\n---- %s:\n" % funcname)
    #    f.write(pformat(siglines)+"\n")
    #    f.write(pformat(desclines)+"\n")
    #else:
    #    f.write("\n")
    #    if siglines:
    #        f.write("\n".join(siglines)+"\n")
    #    else:
    #        f.write("&lt;no signature for '%s.%s'&gt;\n" % (scope, funcname))
    #    for descline in desclines:
    #        f.write("\t%s\n" % descline)
    #f.close()

    return (siglines, desclines)


</t>
<t tx="ekr.20080121105837.1751">#---- debugging utilities

def unmark_text(markedup_text):
    """Parse text with potential markup as follows and return
    (&lt;text&gt;, &lt;data-dict&gt;).

        "&lt;|&gt;" indicates the current position (pos), defaults to the end
            of the text.
        "&lt;+&gt;" indicates the trigger position (trg_pos), if present.
        "&lt;$&gt;" indicates the start position (start_pos) for some kind of
            of processing, if present.
        "&lt;N&gt;" is a numbered marker. N can be any of 0-99. These positions
            are returned as the associate number key in &lt;data-dict&gt;.

    E.g.:
        &gt;&gt;&gt; unmark_text('foo.&lt;|&gt;')
        ('foo.', {'pos': 4})
        &gt;&gt;&gt; unmark_text('foo.&lt;|&gt;&lt;+&gt;')
        ('foo.', {'trg_pos': 4, 'pos': 4})
        &gt;&gt;&gt; unmark_text('foo.&lt;+&gt;ba&lt;|&gt;')
        ('foo.ba', {'trg_pos': 4, 'pos': 6})
        &gt;&gt;&gt; unmark_text('fo&lt;|&gt;o.&lt;+&gt;ba')
        ('foo.ba', {'trg_pos': 4, 'pos': 2})
        &gt;&gt;&gt; unmark_text('os.path.join&lt;$&gt;(&lt;|&gt;')
        ('os.path.join(', {'pos': 13, 'start_pos': 12})
        &gt;&gt;&gt; unmark_text('abc&lt;3&gt;defghi&lt;2&gt;jk&lt;4&gt;lm&lt;1&gt;nopqrstuvwxyz')
        ('abcdefghijklmnopqrstuvwxyz', {1: 13, 2: 9, 3: 3, 4: 11, 'pos': 26})
    
    See the matching markup_text() below.
    """
    splitter = re.compile(r"(&lt;(?:\+|\||\$|\d{1,2})&gt;)")
    text = ""
    data = {}
    for token in splitter.split(markedup_text):
        if token == "&lt;|&gt;":
            data["pos"] = len(text)
        elif token == "&lt;+&gt;":
            data["trg_pos"] = len(text)
        elif token == "&lt;$&gt;":
            data["start_pos"] = len(text)
        elif token and token[0] == '&lt;' and isdigit(token[1:-1])\
             and token[-1] == '&gt;':
            data[int(token[1:-1])] = len(text)
        else:
            text += token
    if "pos" not in data:
        data["pos"] = len(text)
    return text, data

</t>
<t tx="ekr.20080121105837.1752">def markup_text(text, pos=None, trg_pos=None, start_pos=None):
    """Markup text with position markers.

    See the matching unmark_text() above.
    """
    positions_and_markers = []
    if       pos is not None: positions_and_markers.append((      pos, '&lt;|&gt;'))
    if   trg_pos is not None: positions_and_markers.append((  trg_pos, '&lt;+&gt;'))
    if start_pos is not None: positions_and_markers.append((start_pos, '&lt;$&gt;'))
    positions_and_markers.sort()

    m_text = ""
    m_pos = 0
    for position, marker in positions_and_markers:
        m_text += text[m_pos:position] + marker
        m_pos = position
    m_text += text[m_pos:]
    return m_text

</t>
<t tx="ekr.20080121105837.1753"># Recipe: banner (1.0.1) in C:\trentm\tm\recipes\cookbook
def banner(text, ch='=', length=78):
    """Return a banner line centering the given text.
    
        "text" is the text to show in the banner. None can be given to have
            no text.
        "ch" (optional, default '=') is the banner line character (can
            also be a short string to repeat).
        "length" (optional, default 78) is the length of banner to make.

    Examples:
        &gt;&gt;&gt; banner("Peggy Sue")
        '================================= Peggy Sue =================================='
        &gt;&gt;&gt; banner("Peggy Sue", ch='-', length=50)
        '------------------- Peggy Sue --------------------'
        &gt;&gt;&gt; banner("Pretty pretty pretty pretty Peggy Sue", length=40)
        'Pretty pretty pretty pretty Peggy Sue'
    """
    if text is None:
        return ch * length
    elif len(text) + 2 + len(ch)*2 &gt; length:
        # Not enough space for even one line char (plus space) around text.
        return text
    else:
        remain = length - (len(text) + 2)
        prefix_len = remain / 2
        suffix_len = remain - prefix_len
        if len(ch) == 1:
            prefix = ch * prefix_len
            suffix = ch * suffix_len
        else:
            prefix = ch * (prefix_len/len(ch)) + ch[:prefix_len%len(ch)]
            suffix = ch * (suffix_len/len(ch)) + ch[:suffix_len%len(ch)]
        return prefix + ' ' + text + ' ' + suffix


</t>
<t tx="ekr.20080121105837.1754"># Recipe: dedent (0.1.2) in C:\trentm\tm\recipes\cookbook
def _dedentlines(lines, tabsize=8, skip_first_line=False):
    """_dedentlines(lines, tabsize=8, skip_first_line=False) -&gt; dedented lines
    
        "lines" is a list of lines to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    Same as dedent() except operates on a sequence of lines. Note: the
    lines list is modified **in-place**.
    """
    DEBUG = False
    if DEBUG: 
        print "dedent: dedent(..., tabsize=%d, skip_first_line=%r)"\
              % (tabsize, skip_first_line)
    indents = []
    margin = None
    for i, line in enumerate(lines):
        if i == 0 and skip_first_line: continue
        indent = 0
        for ch in line:
            if ch == ' ':
                indent += 1
            elif ch == '\t':
                indent += tabsize - (indent % tabsize)
            elif ch in '\r\n':
                continue # skip all-whitespace lines
            else:
                break
        else:
            continue # skip all-whitespace lines
        if DEBUG: print "dedent: indent=%d: %r" % (indent, line)
        if margin is None:
            margin = indent
        else:
            margin = min(margin, indent)
    if DEBUG: print "dedent: margin=%r" % margin

    if margin is not None and margin &gt; 0:
        for i, line in enumerate(lines):
            if i == 0 and skip_first_line: continue
            removed = 0
            for j, ch in enumerate(line):
                if ch == ' ':
                    removed += 1
                elif ch == '\t':
                    removed += tabsize - (removed % tabsize)
                elif ch in '\r\n':
                    if DEBUG: print "dedent: %r: EOL -&gt; strip up to EOL" % line
                    lines[i] = lines[i][j:]
                    break
                else:
                    raise ValueError("unexpected non-whitespace char %r in "
                                     "line %r while removing %d-space margin"
                                     % (ch, line, margin))
                if DEBUG:
                    print "dedent: %r: %r -&gt; removed %d/%d"\
                          % (line, ch, removed, margin)
                if removed == margin:
                    lines[i] = lines[i][j+1:]
                    break
                elif removed &gt; margin:
                    lines[i] = ' '*(removed-margin) + lines[i][j+1:]
                    break
            else:
                if removed:
                    lines[i] = lines[i][removed:]
    return lines

</t>
<t tx="ekr.20080121105837.1755">def dedent(text, tabsize=8, skip_first_line=False):
    """dedent(text, tabsize=8, skip_first_line=False) -&gt; dedented text

        "text" is the text to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    textwrap.dedent(s), but don't expand tabs to spaces
    """
    lines = text.splitlines(1)
    _dedentlines(lines, tabsize=tabsize, skip_first_line=skip_first_line)
    return ''.join(lines)


</t>
<t tx="ekr.20080121105837.1756"># Recipe: indent (0.2.1) in C:\trentm\tm\recipes\cookbook
def indent(s, width=4, skip_first_line=False):
    """indent(s, [width=4]) -&gt; 's' indented by 'width' spaces

    The optional "skip_first_line" argument is a boolean (default False)
    indicating if the first line should NOT be indented.
    """
    lines = s.splitlines(1)
    indentstr = ' '*width
    if skip_first_line:
        return indentstr.join(lines)
    else:
        return indentstr + indentstr.join(lines)


</t>
<t tx="ekr.20080121105837.1757"># Decorators useful for timing and profiling specific functions.
#
# timeit usage:
#   Decorate the desired function and you'll get a print for how long
#   each call to the function took.
#
# hotspotit usage:
#   1. decorate the desired function
#   2. run your code
#   3. run:
#       python .../codeintel/support/show_stats.py .../&lt;funcname&gt;.prof
#
def timeit(func):
    clock = (sys.platform == "win32" and time.clock or time.time)
    def wrapper(*args, **kw):
        start_time = clock()
        try:
            return func(*args, **kw)
        finally:
            total_time = clock() - start_time
            print "%s took %.3fs" % (func.func_name, total_time)
    return wrapper

</t>
<t tx="ekr.20080121105837.1758">def hotshotit(func):
    def wrapper(*args, **kw):
        import hotshot
        global hotshotProfilers
        prof_name = func.func_name+".prof"
        profiler = hotshotProfilers.get(prof_name)
        if profiler is None:
            profiler = hotshot.Profile(prof_name)
            hotshotProfilers[prof_name] = profiler
        return profiler.runcall(func, *args, **kw)
    return wrapper


</t>
<t tx="ekr.20080121105837.1759"># Utility functions to perform sorting the same way as scintilla does it
# for the code-completion list.
def OrdPunctLast(value):
    result = []
    value = value.upper()
    for ch in value:
        i = ord(ch)
        if i &gt;= 0x21 and i &lt;= 0x2F:  # ch &gt;= '!' &amp;&amp; ch &lt;= '/'
            result.append(chr(i - ord("!") + ord('[')))    # ch - '!' + '['
        elif i &gt;= 0x3A and i &lt;= 0x40:  # ch &gt;= ':' &amp;&amp; ch &lt;= '@'
            result.append(chr(i - ord(":") + ord('[')))    # ch - ':' + '['
        else:
            result.append(ch)
    return "".join(result)

</t>
<t tx="ekr.20080121105837.1760">def CompareNPunctLast(value1, value2):
    # value 1 is smaller, return negative
    # value 1 is equal, return 0
    # value 1 is larger, return positive
    return cmp(OrdPunctLast(value1), OrdPunctLast(value2))


</t>
<t tx="ekr.20080121105837.1761"># Utility function to make a lookup dictionary
def make_short_name_dict(names, length=3):
    outdict = {}
    for name in names:
        if len(name) &gt;= length:
            shortname = name[:length]
            l = outdict.get(shortname)
            if not l:
                outdict[shortname] = [name]
            else:
                l.append(name)
        #pprint(outdict)
    for values in outdict.values():
        values.sort(CompareNPunctLast)
    return outdict

</t>
<t tx="ekr.20080121105837.1762">#----  cachedmethod from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/325205

def cachedmethod(function):
    return types.MethodType(Memoize(function), None)

</t>
<t tx="ekr.20080121105837.1763">class Memoize:
    @others
</t>
<t tx="ekr.20080121105837.1764">def __init__(self,function):
    self._cache = {}
    self._callable = function
        
</t>
<t tx="ekr.20080121105837.1765">def __call__(self, *args, **kwds):
    cache = self._cache
    key = self._getKey(*args,**kwds)
    try: return cache[key]
    except KeyError:
        cachedValue = cache[key] = self._callable(*args,**kwds)
        return cachedValue

</t>
<t tx="ekr.20080121105837.1766">def _getKey(self,*args,**kwds):
    return kwds and (args, set(kwds)) or args    


</t>
<t tx="ekr.20080121105837.1767">#!python
# ***** BEGIN LICENSE BLOCK *****

"""Get and manage Code Intelligence data about source code of many languages.

The Code Intelligence system is one for generating and managing code
structure information on given source code. See the spec for more details:
    http://specs.tl.activestate.com/kd/kd-0100.html

General Usage
-------------

    from codeintel2.manager import Manager
    mgr = Manager()
    # Alternatively use Database upgrade methods directly for finer control.
    mgr.upgrade()
    mgr.initialize()
    try:
        # Get a Buffer object from a scimoz/path/content.
        buf = mgr.buf_from_*(...)
        
        # Use the buffer's API to do codeintel-y stuff. For example:
        # - See if you are at a trigger point.
        trg = buf.trg_from_pos(...)

        # - Get completions at that trigger. See also
        #   Buffer.async_eval_at_trg(), Buffer.calltips_from_trg().
        cplns = buf.cplns_from_trg(trg, ...)

        # ...
    finally:
        mgr.finalize() # make sure this gets run or you could get hangs
"""

@language python
@tabwidth -4

</t>
<t tx="ekr.20080121105837.1768"></t>
<t tx="ekr.20080121105837.1769">#!python

&lt;&lt; database.py docstring &gt;&gt;
&lt;&lt; imports &gt;&gt;

#---- globals
log = logging.getLogger("codeintel.db")
#log.setLevel(logging.DEBUG)

@language python
@tabwidth -4

#---- Database zone and lib implementations
class Database(object):
    """Manages the persistence data store for codeintel. This is a
    singleton instance, available from 'Manager().db'.

    The main data stored here is citree data for code blobs (i.e.
    importable modules). However, this intends to be usable for other
    types of data (e.g. things that might be useful for codeintel on
    non-programming languages like HTML, XML (e.g. schema info) and CSS).

    Dev Notes:
    - We'll start with just custom methods for different types of things
      and only "go generic" if it seems helpful.
    """
    &lt;&lt; version stuff &gt;&gt;
    VERSION = "2.0.16"
    LEN_PREFIX = 3 # Length of prefix in 'toplevelprefix_index' indeces.
    # Possible return values from .upgrade_info().
    (UPGRADE_NOT_NECESSARY,UPGRADE_NOT_POSSIBLE,UPGRADE_NECESSARY) = range(3)

    @others</t>
<t tx="ekr.20080121105837.1770">@nocolor

"""The new database for codeintel2.

# Usage

There is a single Database instance on the codeintel Manager (mgr.db).
All entry points to the database are via this instance.

There are two common modes of interaction:

1. Getting info for a particular buffer. E.g., for a code browser or for
   information on a current file. Here all interaction can be done via a
   few methods on the main Database class.

    Database.get_buf_data(buf)
    Database.get_buf_scan_time(buf)
    Database.update_buf_data(buf, ...)
    Database.remove_buf_data(buf)

2. Working with a blob (a.k.a. module) given a list of libs.
   Typically this is done during completion evaluation (i.e. detemining
   what completions to show for "foo."). Here a particular environment
   will have a list of "libs", all of them from the main Database
   instance, via, e.g.:
   
    Database.get_stdlib(...)
    Database.get_catalog_lib(...)
    Database.get_lang_lib(...)
    etc.

   A "lib" instance has the following standard interface:

    .has_blob(blobname)
        Returns True iff a so-named blob is provided by this lib.

    .get_blob(blobname)
        Returns the so-named blob (the importable section of a CIX
        element tree) provided by this lib, or None if it isn't.

    .get_blob_imports(prefix)
        Returns a set of blobnames to complete the given import prefix.
        This is generally used for completion on import statements, e.g.
            import &lt;|&gt;      # lib.get_blob_imports(prefix=())
            import foo.&lt;|&gt;  # lib.get_blob_imports(prefix=('foo',))
        Note that prefix has to be a tuple (rather than a list) because
        the method is automatically cached.
        
        Items in the returned set a 2-tuples, (&lt;import-name&gt;,
        &lt;is-dir-import&gt;), where &lt;is-dir-import&gt; is a boolean indicating
        if this is a prefix for a multidir import. For example, in
        Perl's stdlib there is an "HTTP::Request" module, but no "HTTP"
        module. One of returned items would be:
            ("HTTP", True)
        The set can have both (e.g. Perl's LWP.pm and LWP/UserAgent.pm):
            ("LWP", False)   # for "use LWP;"
            ("LWP", True)     # prefix for "use LWP::UserAgent;"

    .hits_from_lpath(lpath, ctlr=None, curr_buf=None)
        Returns all "hits" for the given lookup path in all blobs in
        this lib.  This is to support "import-everything" semantics
        necessary for langs like JavaScript (no explicit local import
        statements) and PHP (with auto-loading anything can happen). It
        is possible that other langs may not support this.

    .toplevel_cplns(prefix=None, ilk=None, ctlr=None):
        Find all toplevel names starting with the given prefix in all
        blobs in this lib and return a list of completions:
            (&lt;ilk&gt;, &lt;name&gt;)
        where &lt;ilk&gt; is, e.g., "class" or "function" or "variable", etc.
        'ilk' can be specified to restrict the results to names of that
        ilk. If prefix is None then *all* toplevel names are returned.
    
   where "blob" is the generic internal name used for "the token with
   which you import", e.g.:
  
        LANGUAGE    IMPORT STATEMENT        BLOBNAME
        --------    ----------------        --------
        Python      import foo              foo
        Perl        use Foo;                Foo
        PHP         include("foo.php");     foo.php


# Database structure

The database is divided into *zones*, primarily along
common-implementation lines. E.g. dir under "db" is a zone.


&lt;base-dir&gt;/                 # E.g. ~/.komodo/4.0/host-$HOSTNAME/codeintel
    README.txt
    VERSION
    db/
        # Any dir at this level is an independent database for a
        # single DB "zone".

        # API Catalogs zone -- codeintel API data loaded from .cix files
        # in one of the db_catalog_dirs.
        catalogs/
            res_index   # cix-path -&gt; (res_id, last-updated, name, 
                        #              {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames})
            blob_index              # {lang -&gt; blobname -&gt; (dbfile, res_id)}
            toplevelname_index      # {lang -&gt; ilk -&gt; toplevelname -&gt; res_id -&gt; blobnames}
            toplevelprefix_index    # {lang -&gt; ilk -&gt; prefix -&gt; res_id -&gt; toplevelnames}
            &lt;safe-lang&gt;/
                &lt;dbfiles&gt;

        # Codeintel includes .cix files for a number of language stdlibs
        # (all in "codeintel2/stdlibs/&lt;lang&gt;[-&lt;ver&gt;].cix"). These are
        # loaded here (as needed). 
        stdlibs/
            res_index                   # cix-path -&gt; last-updated
            vers_and_names_from_lang    # lang -&gt; ordered list of (ver, name)
            &lt;stdlib-name&gt;/
                blob_index              # {blobname -&gt; dbfile}
                toplevelname_index      # {ilk -&gt; toplevelname -&gt; blobnames}
                toplevelprefix_index    # {ilk -&gt; prefix -&gt; toplevelnames}
                &lt;dbfiles&gt;

        # Language-specific zones (data for all scanned resources that
        # don't belong to a project).  Sub-separation is done by source
        # dir to not have too many dbfiles in a directory and to match
        # the fact the import lookup is generally by dir.
        # Note: the 'toplevelname_index' is to support
        # "import-everything" semantics (i.e. lib.hits_from_lpath()).
        &lt;safe-lang-name&gt;/
            lang
            &lt;dir-hash&gt;/                 # md5 of dir path
                path
                res_index               # basename -&gt; scan_time, scan_error,
                                        #             {blobname -&gt; ilk -&gt; toplevelnames}
                blob_index              # {blobname -&gt; dbfile}
                toplevelname_index      # {ilk -&gt; toplevelname -&gt; blobnames}
                &lt;dbfiles&gt;
            ...

        # Multi-lang zones (e.g. RHTML has Ruby and JavaScript) differ a
        # little bit but are mostly the same as single-lang zones.
        &lt;safe-multi-lang-name&gt;/
            lang
            &lt;dir-hash&gt;/                 # md5 of dir path
                path
                res_index               # basename
                                        #   -&gt; scan_time, scan_error,
                                        #      {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
                blob_index              # {lang -&gt; blobname -&gt; dbfile}
                toplevelname_index      # {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
                &lt;dbfiles&gt;

        # Project-support
        # (OBSOLETE, not used)
        projs/
            &lt;proj-path-hash&gt;/
                path                # project file path
                dirs_from_basename  # index of basenames in project
                update_time         #XXX time 'dirs_from_basename' last updated

                TODO: Eventually could have a project catalog made up
                      from '.cix' files in the project tree.


# Actions

Optimizing the following actions on the database determines the db
structure.

1. Add resource. [done by database updating: various places]
2. Remove resource. [done by database updating: various places]
3. Update resource. [done by database updating: various places]
4. Has blob (for a given lang). [done by import handling during
   completion eval]
5. Load blob. [done by import handling during completion eval]
6. Where is given top-level name defined.
7. What are the top-level names matching the given prefix and ilk.


# Logging

There are some logging rules for this module to support the test suite.
- All writes to the filesystem should have a log message that begins
  with "fs-write: ".
- All reads from the filesystem should have a log message that begins
  with "fs-read: ". (TODO)

Note: Currently only doing this for LangZone stuff. This will be easier
if/when add fs interaction is moved to one place (on the Database
class).


# TODO

- bullet proof all db interaction for fs failure, corruption, etc.
  (see notes in test2/test_db.py)
- add search_index for object browser functionality
- add torture tests for this
- investigate (1) removing 'lang' redundancy in DB where possible (shouldn't
  be necessary for single-lang libraries), (2) using lang-id's instead of
  the language name to improve perf.


# Database.clean() and .check() TODO

- dbfiles for paths viewed as another language will persist in the DB
  (although I think the index entries will have been removed). 
  These should be cleaned out.
- check for collisions in catalog: same lang, same blobname provided by
  two CIX files
"""
</t>
<t tx="ekr.20080121105837.1771">import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import cPickle as pickle
from cPickle import UnpicklingError
import threading
import time
import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.util import rmdir
from codeintel2.database.stdlib import StdLibsZone
from codeintel2.database.catalog import CatalogsZone
from codeintel2.database.langlib import LangZone
from codeintel2.database.multilanglib import MultiLangZone
from codeintel2.database.projlib import ProjectZone
</t>
<t tx="ekr.20080121105837.1772">
# Database version.
# VERSION is the version of this Database code. The property
# "version" is the version of the database on disk. The patch-level
# version number should be used for small upgrades to the database.
#
# db change log:
# - 2.0.16: (PHP constants) Adding "ilk='constant'" attribute to
#   PHP variables that are marked as constants.
# - 2.0.15: (PHP/JS import-everything semantics.) Add
#   "toplevelprefix_index" to stdlibs and catalogs zones. Currently
#   not adding this index for (multi)lang zones (see comment in
#   LangTopLevelNameIndex.toplevel_cplns()).
# - 2.0.14: (PHP/JS import-everything semantics.) Update
#   "toplevelname_index" for multilang, stdlibs and catalogs zones.
# - 2.0.13: (PHP/JS import-everything semantics.) Update
#   "toplevelname_index" for lang zone.
# - 2.0.12: Only generate "toplevelname_index" for some langs. Use
#   ".blob" extension for blobs in StdLibsZone. Use "blob_index" in
#   StdLibsZone (as with other zones). Support "toplevelname_index"
#   in StdLibsZone.
# - 2.0.11: Update (Multi)LangZone's with "toplevelname_index" to
#   support "import everything" semantics.
# - 2.0.10: Manually adding a "src" attribute to blobs in
#   (Multi)LangZone's. Needed for "Goto Definition" in determining
#   file location.
# - 2.0.9: 'blob_index' renamings in (Multi)LangZone's in prep for
#   `lib.hits_from_lpath()' implementations.
# - 2.0.8: Add catalog 'name' to CatalogsZone res_index. Needed for
#   proper filtering on selection in CatalogsZone.update().
# - 2.0.7: refactor to CatalogsZone and db/catalogs/... (i.e., plural)
# - 2.0.6: Catalog zone updates to support catalog selection.
# - 2.0.5: Fix to &lt;bhash&gt;.lpaths determination for JS. Only affected
#   catalog zone.
# - 2.0.4: Updates to catalog-zone indeces for "top-level names"
#   caching (to support fast .hits_from_lpath()).
# - 2.0.3: Add ".blob" to dbfile filenames in preparation for
#   persisted cache keys (which will be stored as &lt;bhash&gt;.&lt;key&gt;
#   next to the &lt;bhash&gt;.blob).
# - 2.0.2: added scan_error to res_index in LangZone and MultiLangZone,
#   add "lang" file to lang zones for reverse safe_lang -&gt; lang lookup
# - 2.0.1: s/VERSION.txt/VERSION/, made PHP a MultiLangZone
</t>
<t tx="ekr.20080121105837.1773">def __init__(self, mgr, base_dir=None, catalog_dirs=None,
             event_reporter=None,
             import_everything_langs=None):
    """
        "base_dir" (optional) specifies the base directory for
            the codeintel database. If not given it will default to
            '~/.codeintel'.
        "catalog_dirs" (optional) is a list of catalog dirs in
            addition to the std one to use for the CatalogsZone. All
            *.cix files in a catalog dir are made available.
        "event_reporter" (optional) is a callback that will be called
                event_reporter(&lt;event-desc-string&gt;)
            before "significant" long processing events in the DB. This
            may be useful to forward to a status bar in a GUI.
        "import_everything_langs" (optional) is a set of lang names
            for which the `lib.hits_from_lpath()' API should be
            supported. This method is typically used to support
            "import-everything" cpln eval semantics.  Supporting it
            requires the 'toplevelname_index' indeces which adds
            significant space and perf burdens. If not specified,
            only JavaScript and PHP are included in the set.
    """
    self.mgr = mgr
    self._lock = threading.RLock() # XXX Perhaps use per-zone locks?

    self._catalogs_zone = None
    self._stdlibs_zone = None
    self._lang_zone_from_lang = {}
    self._proj_zone_from_proj_path = weakref.WeakValueDictionary()

    if base_dir is None:
        self.base_dir = expanduser(join("~", ".codeintel"))
    elif not isabs(base_dir):
        self.base_dir = abspath(base_dir)
    else:
        self.base_dir = base_dir
    
    self.catalog_dirs = catalog_dirs
    self.event_reporter = event_reporter

    if import_everything_langs is None:
        self.import_everything_langs = set(["JavaScript", "PHP"])
    else:
        self.import_everything_langs = import_everything_langs
    assert isinstance(self.import_everything_langs, set)

    self.corruptions = [] # list of noted errors during db operation

</t>
<t tx="ekr.20080121105837.1774">def __del__(self):
    if self._catalogs_zone:
        self._catalogs_zone = None
    self.mgr = None

</t>
<t tx="ekr.20080121105837.1775"></t>
<t tx="ekr.20080121105837.1776">def acquire_lock(self):
    self._lock.acquire()
</t>
<t tx="ekr.20080121105837.1777">def release_lock(self):
    self._lock.release()

</t>
<t tx="ekr.20080121105837.1778">@property
def version(self):
    """Return the version of the db on disk (or None if cannot determine).
    """
    path = join(self.base_dir, "VERSION")
    try:
        fin = open(path, 'r')
    except EnvironmentError, ex:
        return None
    try:
        return fin.read().strip()
    finally:
        fin.close()

</t>
<t tx="ekr.20080121105837.1779">def upgrade_info(self):
    """Returns information indicating if a db upgrade is necessary
    and possible.
    
    Returns one of the following:
        (UPGRADE_NOT_NECESSARY, None)
        (UPGRADE_NOT_POSSIBLE, "&lt;reason&gt;")
        (UPGRADE_NECESSARY, None)
    """
    if self.version == self.VERSION:
        return (Database.UPGRADE_NOT_NECESSARY, None)

    # Presuming that we *have* an upgrade path from the current version.
    return (Database.UPGRADE_NECESSARY, None)

</t>
<t tx="ekr.20080121105837.1780">def create(self):
    log.info("create db in `%s'", self.base_dir)
    self.acquire_lock()
    try:
        log.debug("fs-write: create db skeleton in '%s'", self.base_dir)
        os.makedirs(self.base_dir)
        open(join(self.base_dir, "README.txt"), 'w').write(dedent("""
            This is a database for the Code Intelligence system (a
            subsystem of Komodo). Do NOT modify anything in here unless
            you know what you are doing.

            See http://www.activestate.com/Products/Komodo/ for details.
        """))
        open(join(self.base_dir, "VERSION"), 'w').write(self.VERSION)
        os.mkdir(join(self.base_dir, "db"))
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.1781">def reset(self, backup=True):
    """Move the given database out of the way to make way for a new one.

        "backup" (optional, default True) is a boolean indicating if
            the original database should be backed up. If so, the backup
            is $base_dir+".err".
    """
    self.acquire_lock()
    try:
        if exists(self.base_dir):
            #TODO: make this more bullet proof
            if backup:
                err_base_dir = self.base_dir + ".err"
                log.info("backing up db to '%s'", err_base_dir)
                if os.path.exists(err_base_dir):
                    rmdir(err_base_dir)
                    for i in range(10): # Try to avoid OSError from slow-deleting NTFS
                        if not os.path.exists(err_base_dir): break
                        time.sleep(1)
                if os.path.exists(err_base_dir): # couldn't remove it
                    log.warn("couldn't remove old '%s' (skipping backup)",
                             err_base_dir)
                    rmdir(self.base_dir)
                else:
                    os.rename(self.base_dir, err_base_dir)
            else:
                rmdir(self.base_dir)

        self.create()
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.1782">def upgrade(self):
    """Upgrade the current database.
    
    Typically this is only called if upgrade_info() returns
    UPGRADE_NECESSARY.
    """
    self.acquire_lock()
    try:
        # 'version' is the DB ver on disk, 'VERSION' is the target ver.
        curr_ver = self.version
        while curr_ver != self.VERSION:
            try:
                result_ver, upgrader, upgrader_arg \
                    = self._result_ver_and_upgrader_and_arg_from_curr_ver[curr_ver]
            except KeyError:
                raise DatabaseError("cannot upgrade from db v%s: no "
                                    "upgrader for this version"
                                    % curr_ver)
            log.info("upgrading from db v%s to db v%s ...",
                     curr_ver, result_ver)
            if upgrader_arg is not None:
                upgrader(self, curr_ver, result_ver, upgrader_arg)
            else:
                upgrader(self, curr_ver, result_ver)
            curr_ver = result_ver
    finally:
        self.release_lock()

</t>
<t tx="ekr.20080121105837.1783">def _upgrade_wipe_db(self, curr_ver, result_ver):
    """Sometimes it is justified to just wipe the DB and start over."""
    assert result_ver == self.VERSION
    if exists(self.base_dir):
        log.debug("fs-write: wipe db")
        rmdir(self.base_dir)
    self.create()

</t>
<t tx="ekr.20080121105837.1784">def _upgrade_wipe_db_catalogs(self, curr_ver, result_ver):
    catalog_dir = join(self.base_dir, "db", "catalogs")
    if exists(catalog_dir):
        log.debug("fs-write: wipe db/catalogs")
        rmdir(catalog_dir)
    open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

</t>
<t tx="ekr.20080121105837.1785">def _upgrade_wipe_db_langzones(self, curr_ver, result_ver):
    for lang in self._gen_langs_in_db():
        safe_lang = safe_lang_from_lang(lang)
        langzone_dir = join(self.base_dir, "db", safe_lang)
        if exists(langzone_dir):
            log.debug("fs-write: wipe db/%s", safe_lang)
            rmdir(langzone_dir)
    open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

</t>
<t tx="ekr.20080121105837.1786">def _upgrade_wipe_db_langs(self, curr_ver, result_ver, langs):
    for lang in langs:
        safe_lang = safe_lang_from_lang(lang)
        # stdlibs zone
        self.get_stdlibs_zone().remove_lang(lang)

        # API catalogs zone
        #TODO: CatalogsZone needs a .remove_lang(). Until then we just
        #      remove the whole thing.

        # (multi)langzone
        langzone_dir = join(self.base_dir, "db", safe_lang)
        if exists(langzone_dir):
            log.debug("fs-write: wipe db/%s", safe_lang)
            rmdir(langzone_dir)

    catalog_dir = join(self.base_dir, "db", "catalogs")
    if exists(catalog_dir):
        log.debug("fs-write: wipe db/catalogs")
        rmdir(catalog_dir)

    open(join(self.base_dir, "VERSION"), 'w').write(result_ver)

</t>
<t tx="ekr.20080121105837.1787">_result_ver_and_upgrader_and_arg_from_curr_ver = {
    None: (VERSION, _upgrade_wipe_db, None),
    "2.0.1": (VERSION, _upgrade_wipe_db, None),
    "2.0.2": (VERSION, _upgrade_wipe_db, None),
    "2.0.3": (VERSION, _upgrade_wipe_db, None),
    "2.0.4": (VERSION, _upgrade_wipe_db, None),
    "2.0.5": (VERSION, _upgrade_wipe_db, None),
    "2.0.6": (VERSION, _upgrade_wipe_db, None),
    "2.0.7": (VERSION, _upgrade_wipe_db, None),
    "2.0.8": (VERSION, _upgrade_wipe_db, None),
    "2.0.9": (VERSION, _upgrade_wipe_db, None),
    "2.0.10": (VERSION, _upgrade_wipe_db, None),
    "2.0.11": (VERSION, _upgrade_wipe_db, None),
    "2.0.12": (VERSION, _upgrade_wipe_db, None),
    "2.0.13": (VERSION, _upgrade_wipe_db, None),
    # Techically only needed to wipe 'stdlibs' and 'catalogs' for
    # PHP and JavaScript, but this is easier.
    "2.0.14": (VERSION, _upgrade_wipe_db, None),
    "2.0.15": (VERSION, _upgrade_wipe_db_langs, ["PHP"]),
}

def report_event(self, desc):
    """Report a "significant" event in database processing.

    Various parts of the database can call this with a string
    description before performing some significant event. If
    this database was created with an event-reporter callback
    then it will be passed on.

    Guidelines:
    - report an event before doing a *long* action (e.g. importing a
      stdlib CIX file)
    """
    log.info("event: %s", desc)
    if self.event_reporter:
        try:
            self.event_reporter(desc)
        except Exception, ex:
            log.exception("error calling event reporter: %s", ex)

</t>
<t tx="ekr.20080121105837.1788">def save(self):
    # Dev Notes:
    # - This is being called by the Manager.finalize().
    # - Don't need to call .save() for StdLibsZone because it saves
    #   immediately when updating (lazily on first use).
    # - XXX The plan is that a bookkeeper thread should also
    #   periodically call this.
    if self._catalogs_zone:
        self._catalogs_zone.save()
    for lang_zone in self._lang_zone_from_lang.values():
        lang_zone.save()

</t>
<t tx="ekr.20080121105837.1789">def cull_mem(self):
    #XXX Not yet being called. The plan is that a bookkeeper thread
    #    should periodically call this.
    if self._catalogs_zone:
        self._catalogs_zone.cull_mem()
    for lang_zone in self._lang_zone_from_lang.values():
        lang_zone.cull_mem()

</t>
<t tx="ekr.20080121105837.1790">_non_lang_db_dirs = ["catalogs", "stdlibs", "projs"]
def _gen_langs_in_db(self):
    for d in os.listdir(join(self.base_dir, "db")):
        if d in self._non_lang_db_dirs:
            continue
        lang_path = join(self.base_dir, "db", d, "lang")
        if not exists(lang_path):
            log.warn("unexpected lang-zone db dir without 'lang' file: "
                     "`%s' (skipping)" % dirname(lang_path))
            continue
        fin = open(lang_path, 'r')
        try:
            lang = fin.read().strip()
        finally:
            fin.close()
        yield lang

</t>
<t tx="ekr.20080121105837.1791">def check(self):
    """Return a list of internal consistency errors (if any) for the
    database.
    """
    errors = []

    for corruption in self.corruptions:
        errors.append("database corruption during '%s': %s (resolution: %s)"
                      % corruption)

    if self.version != self.VERSION:
        errors.append("VERSION mismatch: current DB version, '%s', is "
                      "not the latest, '%s'"
                      % (self.version, self.VERSION))

    errors += self._check_catalogszone()

    #TODO: check stdlibs zone

    for lang in self._gen_langs_in_db():
        if not self.mgr.is_citadel_lang(lang):
            continue
        lang_zone = self._get_lang_zone(lang)
        if not exists(lang_zone.base_dir):
            continue
        if isinstance(lang_zone, MultiLangZone):
            errors += self._check_multilangzone(lang_zone)
        else:
            errors += self._check_langzone(lang_zone)

    projs_dir = join(self.base_dir, "db", "projs")
    if exists(projs_dir):
        for dir in [join(projs_dir, d) for d in os.listdir(projs_dir)]:
            if not isdir(dir):
                continue
            errors += self._check_proj_dir(dir)

    return errors

</t>
<t tx="ekr.20080121105837.1792">def _check_catalogszone(self):
    log.debug("check catalogs zone...")
    #TODO: check toplevelname_index
    errors = []
    catalogs_zone = self.get_catalogs_zone()
    cix_path_from_res_id = {}
    for cix_path, res_data in catalogs_zone.res_index.items():
        res_id, last_updated, name, toplevelnames_from_blobname_from_lang \
            = res_data
        if res_id in cix_path_from_res_id:
            errors.append("catalogs zone: res_id %s used for both "
                          "'%s' and '%s'", cix_path_from_res_id[res_id],
                          cix_path)
        cix_path_from_res_id[res_id] = cix_path
    return errors

</t>
<t tx="ekr.20080121105837.1793">def _check_proj_dir(self, proj_dir):
    log.debug("check '%s' proj zone...", basename(proj_dir))
    errors = []
    path_path = join(proj_dir, "path")
    if not exists(path_path):
        errors.append("proj zone: '%s/path' datafile does not exist"
                      % basename(proj_dir))
    return errors

</t>
<t tx="ekr.20080121105837.1794">def _check_langzone(self, lang_zone):
    # Each blobname in the 'res_index' should have an entry and
    # dbfile in 'blob_index'.
    log.debug("check '%s' lang zone...", lang_zone.lang)
    errors = []

    for d in os.listdir(lang_zone.base_dir):
        if not isdir(join(lang_zone.base_dir, d)):
            continue

        path_path = join(lang_zone.base_dir, d, "path")
        if not exists(path_path):
            errors.append("%s lang zone: 'path' datafile does not "
                          "exist in '%s' dbdir" % (lang_zone.lang, d))
            path = d
        else:
            path = codecs.open(path_path, encoding="utf-8").read()
        res_index = lang_zone.load_index(path, "res_index", {})
        blob_index = lang_zone.load_index(path, "blob_index", {})
        #TODO
        #toplevelname_index = lang_zone.load_index(
        #        path, "toplevelname_index", {})

        all_blobnames = {}
        for filename, (scan_time, scan_error, res_data) \
                in res_index.items():
            # res_data: {blobname -&gt; ilk -&gt; toplevelnames}
            for blobname in res_data:
                if blobname in all_blobnames:
                    errors.append("%s lang zone: blob '%s' provided "
                                  "by more than one file in '%s' dir"
                                  % (lang_zone.lang, blobname, path))
                    continue
                all_blobnames[blobname] = True
                try:
                    dbfile = blob_index[blobname]
                except KeyError:
                    errors.append(
                        "%s lang zone: blob '%s' provided by '%s' is "
                        "not in '%s/blob_index' index" 
                        % (lang_zone.lang, blobname,
                           join(path, filename), d))
                    continue
                if not exists(join(lang_zone.base_dir, d, dbfile+".blob")):
                    errors.append(
                        "%s lang zone: dbfile for blob '%s' provided "
                        "by '%s' does not exist (%s)"
                        % (lang_zone.lang, blobname,
                           join(path, filename),
                           join(d, dbfile)))
                # Note: Could check that the dbfile actually
                # includes a valid tree providing the named
                # blob. That would make .check() very slow for
                # large db's though.

    return errors

</t>
<t tx="ekr.20080121105837.1795">def _check_multilangzone(self, lang_zone):
    # Each blobname in the 'res_index' should have an entry and
    # dbfile in 'blob_index'.
    log.debug("check '%s' multilang zone...", lang_zone.lang)
    errors = []

    for d in os.listdir(lang_zone.base_dir):
        if not isdir(join(lang_zone.base_dir, d)):
            continue

        path_path = join(lang_zone.base_dir, d, "path")
        if not exists(path_path):
            errors.append("%s lang zone: 'path' datafile does not "
                          "exist in '%s' dbdir" % (lang_zone.lang, d))
            path = d
        else:
            path = codecs.open(path_path, encoding="utf-8").read()
        res_index = lang_zone.load_index(path, "res_index", {})
        blob_index = lang_zone.load_index(path, "blob_index", {})
        #toplevelname_index = lang_zone.load_index(
        #        path, "toplevelname_index", {})

        all_langs_and_blobnames = {}
        for filename, (scan_time, scan_error, res_data) \
                in res_index.items():
            # res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
            for lang, blobname in (
                 (lang, tfifb.keys()[0]) # only one blob per lang in a resource
                 for lang, tfifb in res_data.items()
                ):
                if (lang, blobname) in all_langs_and_blobnames:
                    errors.append("%s lang zone: %s blob '%s' provided "
                                  "by more than one file in '%s' dir"
                                  % (lang_zone.lang, lang, blobname, path))
                    continue
                all_langs_and_blobnames[(lang, blobname)] = True
                try:
                    dbfile = blob_index[lang][blobname]
                except KeyError:
                    errors.append(
                        "%s lang zone: %s blob '%s' provided by '%s' is "
                        "not in '%s/blob_index'" 
                        % (lang_zone.lang, lang, blobname,
                           join(path, filename), d))
                    continue
                if not exists(join(lang_zone.base_dir, d, dbfile+".blob")):
                    errors.append(
                        "%s lang zone: dbfile for %s blob '%s' provided "
                        "by '%s' does not exist (%s)"
                        % (lang_zone.lang, lang, blobname,
                           join(path, filename), join(d, dbfile)))
                # Note: Could check that the dbfile actually
                # includes a valid tree providing the named
                # blob. That would make .check() very slow for
                # large db's though.

    return errors

</t>
<t tx="ekr.20080121105837.1796">def corruption(self, action, desc, resolution):
    """Note a corruption in the database during operation.

        "action" is a string describing during what db action was
            being done when the corruption was discovered. Typically
            this is the method name.
        "desc" is a description of the corruption.
        "resolution" is a description of what was done to resolve or
            work-around the problem. Common resolutions:
                'ignore'    work around the prob and continue on
                'recover'
                'remove buf data'

    This is called by internal database handlers.
    """
    log.warn("database corruption during '%s': %s (resolution: %s)",
             action, desc, resolution)
    self.corruptions.append( (action, desc, resolution) )

</t>
<t tx="ekr.20080121105837.1797">def get_catalogs_zone(self):
    if self._catalogs_zone is None:
        self._catalogs_zone = CatalogsZone(self.mgr, self.catalog_dirs)
    return self._catalogs_zone

</t>
<t tx="ekr.20080121105837.1798">def get_catalog_lib(self, lang, selections=None,
                    attempt_load_if_necessary=False):
    """Get a lang-specific handler for the catalog of loaded CIX files.
    
        "lang" is the language.
        "selections" (optional) is a set of catalog names (or full
            path to the CIX files) to use.  Essentially it is a
            filter.  If not specified, all available catalogs for
            this language are used. Otherwise only the selected
            catalogs are used. A catalog "name" is the
            (case-normalized) basename of the .cix file.
        "attempt_load_if_necessary" (optional, default False) is a
            boolean indicating if an attempt should be made to load
            available catalogs for missing selections.
    """
    return self.get_catalogs_zone().get_lib(lang, selections,
                                            attempt_load_if_necessary)

</t>
<t tx="ekr.20080121105837.1799">def get_stdlibs_zone(self):
    if self._stdlibs_zone is None:
        self._stdlibs_zone = StdLibsZone(self)
    return self._stdlibs_zone

</t>
<t tx="ekr.20080121105837.1800">def get_stdlib(self, lang, ver=None):
    """Get a stdlib zone for the given language and version.

    On first get of a stdlib for a particular language, all
    available stdlibs for that lang are updated, if necessary.
    """
    return self.get_stdlibs_zone().get_lib(lang, ver)

</t>
<t tx="ekr.20080121105837.1801">def _get_lang_zone(self, lang):
    if lang not in self._lang_zone_from_lang:
        if self.mgr.is_multilang(lang):
            self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang)
        else:
            self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang)
    return self._lang_zone_from_lang[lang]

</t>
<t tx="ekr.20080121105837.1802">def get_lang_lib(self, lang, name, dirs, sublang=None):
    """Get a language-specific zone handler for the given
    directories.

        "lang" is the language name, e.g. "Python".
        "name" is a user-friendly name for this particular lang-lib,
            e.g. "envlib" for set of dirs in PYTHONPATH or "sitelib"
            for the dirs in the Perl sitelib. This name is just used
            for logging and debugging.
        "dirs" is the ordered set of directories in this lib.
        "sublang" is used for multi-lang libs to indicate
            sub-language for which lookups will be done. For
            example, to get a PHP lang lib for which .has_blob()
            will search for PHP content (rather than JavaScript)
            sublang must be 'PHP'.  (For single-lang libs
            this should be None.)
    """
    assert isinstance(dirs, (tuple, list))
    lang_zone = self._get_lang_zone(lang)
    if isinstance(lang_zone, MultiLangZone):
        return lang_zone.get_lib(name, dirs, sublang)
    else:
        return lang_zone.get_lib(name, dirs)

</t>
<t tx="ekr.20080121105837.1803">def get_proj_zone(self, proj):
    """Get a project zone handler for the given project.

        "proj" is an object representing the project. It should have
            the following interface:
                proj.path       path to project file
            TODO: determine needed interface
    """
    proj_path = proj.path
    proj_zone = self._proj_zone_from_proj_path.get(proj_path)
    if proj_zone is None:
        proj_zone = ProjectZone(self.mgr, self, proj)
        self._proj_zone_from_proj_path[proj_path] = proj_zone
    return proj_zone

</t>
<t tx="ekr.20080121105837.1804">def get_proj_lib(self, proj, lang):
    return self.get_proj_zone(proj).get_lib(lang)

</t>
<t tx="ekr.20080121105837.1805">def load_blob(self, dbsubpath):
    """Load the blob and all persisted blob cache keys from disk."""
    log.debug("fs-read: load blob `%s'", dbsubpath[len(self.base_dir)+1:])
    blob = ET.parse(dbsubpath+".blob").getroot()
    blob_files = glob(dbsubpath+".*")
    for blob_cache_file in blob_files:
        ext = splitext(blob_cache_file)[1]
        if ext == ".blob": continue # this is the blob ET itself
        cache_key = ext[1:]
        try:
            blob.cache[cache_key] = self.load_pickle(blob_cache_file)
        except (UnpicklingError, ImportError), ex:
            log.warn("error unpickling `%s' (skipping): %s",
                     blob_cache_file, ex)
    return blob

</t>
<t tx="ekr.20080121105837.1806">def load_pickle(self, path, default=None):
    """Load the given pickle path.

    Note that attempting to unpickle a non-pickle file can raise
    cPickle.UnpicklingError or ImportError. For example:
        &gt;&gt;&gt; import cPickle as pickle
        &gt;&gt;&gt; pickle.load(open("foo.txt", 'rb'))
        Traceback (most recent call last):
          File "&lt;stdin&gt;", line 1, in ?
        ImportError: No module named odeintel: INFO: eval 'raven' at raven.py#29
    """
    if exists(path):
        log.debug("fs-read: load pickle `%s'", path[len(self.base_dir)+1:])
        fin = open(path, 'rb')
        try:
            return pickle.load(fin)
        finally:
            fin.close()
    elif default is not None:
        return default
    else:
        raise OSError("`%s' does not exist" % path)

</t>
<t tx="ekr.20080121105837.1807">def save_pickle(self, path, obj):
    if not exists(dirname(path)):
        log.debug("fs-write: mkdir '%s'",
                  dirname(path)[len(self.base_dir)+1:])
        try:
            os.makedirs(dirname(path))
        except OSError, ex:
            log.warn("error creating `%s': %s", dirname(path), ex)
    log.debug("fs-write: '%s'", path[len(self.base_dir)+1:])
    fout = open(path, 'wb')
    try:
        pickle.dump(obj, fout, 2)
    finally:
        fout.close()


</t>
<t tx="ekr.20080121105837.1808"></t>
<t tx="ekr.20080121105837.1809">#---- Convenience methods for getting database hash keys.
# MD5 hexdigests are used to generate keys into the db (typically
# file paths).

#TODO:PERF: evaluate perf improvement with caching of this
def bhash_from_blob_info(self, res_path, lang, blobname):
    """Return a unique name for a blob dbfile.
    
    This is used as the filename for the dbfile for this blob.
    """
    s = ':'.join([res_path, lang, blobname])
    return md5.new(s).hexdigest()

</t>
<t tx="ekr.20080121105837.1810">#TODO:PERF: evaluate perf improvement with caching of this
def dhash_from_dir(self, dir):
    """Return a hash path to use internally in the db for the given dir."""
    return md5.new(dir).hexdigest()


</t>
<t tx="ekr.20080121105837.1811">#---- The following are convenience methods for working with a
#     particular LangZone and a buffer.

def get_buf_scan_time(self, buf):
    """Return the mtime for the given buffer in the database or
    return None.
    """
    return self._get_lang_zone(buf.lang).get_buf_scan_time(buf)

</t>
<t tx="ekr.20080121105837.1812">def get_buf_data(self, buf):
    """Return the tree for the given buffer in the database or
    raise NotFoundInDatabase.
    """
    return self._get_lang_zone(buf.lang).get_buf_data(buf)

</t>
<t tx="ekr.20080121105837.1813">def remove_buf_data(self, buf):
    """Remove data for this buffer from the database.

    If this resource isn't in the database, then this is a no-op.
    """
    self._get_lang_zone(buf.lang).remove_buf_data(buf)

</t>
<t tx="ekr.20080121105837.1814">def update_buf_data(self, buf, force=False):
    """Add or update data for this buffer into the database."""
    self._get_lang_zone(buf.lang).update_buf_data(buf, force=force)

</t>
<t tx="ekr.20080121105837.1815"></t>
<t tx="ekr.20080121105837.1816"></t>
<t tx="ekr.20080121105837.1817">#!/usr/bin/env python2.5
# *****LICENSE BLOCK *****

"""codeintel -- a tool for developing with Komodo's Code Intelligence system"""

__revision__ = "$Id$"
__version_info__ = (2, 0, 0)
__version__ = '.'.join(map(str, __version_info__))

@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;

#---- global data
log = logging.getLogger("codeintel")


@others

if __name__ == "__main__":
    main(sys.argv)</t>
<t tx="ekr.20080121105837.1818">import os
from os.path import (join, exists, isdir, isfile, abspath, normcase,
                     splitext, dirname, expanduser, normpath, isabs,
                     basename)
import sys
import getopt
import time
import re
from pprint import pprint
from glob import glob
import traceback
import logging
from optparse import OptionParser

sys.path.insert(0, join(dirname(dirname(abspath(__file__))), "pylib"))
import cmdln
from cmdln import option
import koextlib

def _setup_xpcom_env():
    ko_info = koextlib.KomodoInfo()
    os.environ["PATH"] += ";" + ko_info.moz_bin_dir
    sys.path += ko_info.py_lib_dirs
    try:
        from xpcom import components
    except ImportError:
        pass
    else:
        # Ensure have a dir svc provider providing XREExtDL.
        koTestSvc = components.classes["@activestate.com/koTestService;1"] \
            .getService(components.interfaces.koITestService)
        koTestSvc.init()
        
_setup_xpcom_env()

import ciElementTree as ET
from codeintel2.common import CodeIntelError
from codeintel2.manager import Manager
from codeintel2.citadel import CitadelBuffer
from codeintel2.util import guess_lang_from_path
from codeintel2.tree import pretty_tree_from_tree, check_tree

</t>
<t tx="ekr.20080121105837.1819">#---- main public stuff

class Shell(cmdln.Cmdln):
    """${name} -- a tool for developing with Komodo's codeintel system

    Usage:
        ${name} SUBCOMMAND [ARGS...]
        ${name} help SUBCOMMAND       # help on a specific command

    ${option_list}
    This tool provides some commands for working with Komodo's
    Code Intelligence system.

    ${command_list}
    ${help_list}
    """
    name = 'codeintel'
    version = __version__
    helpindent = '  '

    @others
</t>
<t tx="ekr.20080121105837.1820">def get_optparser(self):
    parser = cmdln.Cmdln.get_optparser(self)
    parser.add_option("-v", "--verbose", dest="log_level",
                      action="store_const", const=logging.DEBUG,
                      help="more verbose output")
    parser.add_option("-q", "--quiet", dest="log_level",
                      action="store_const", const=logging.WARNING,
                      help="quieter output")
    parser.set_defaults(log_level=logging.INFO)
    return parser

</t>
<t tx="ekr.20080121105837.1821">def postoptparse(self):
    global log
    log.setLevel(self.options.log_level)

</t>
<t tx="ekr.20080121105837.1822">@cmdln.option("-l", "--lang", dest="lang",
              help="the language of the given path content")
@cmdln.option("-p", "--pretty-print", action="store_true",
              help="pretty-print the CIX output")
def do_scan(self, subcmd, opts, *path_patterns):
    """Scan and print the CIX for the given path(s).

    ${cmd_usage}
    ${cmd_option_list}
    """
    extra_lang_module_dirs = []
    if koextlib.is_ext_dir() and exists("pylib"):
        sys.path.append(abspath("pylib"))
        extra_lang_module_dirs = [sys.path[-1]]
        
    mgr = Manager(extra_lang_module_dirs=extra_lang_module_dirs)
    mgr.upgrade()
    mgr.initialize()
    try:
        tree = None
        for path in _paths_from_path_patterns(path_patterns):
            try:
                lang = opts.lang or guess_lang_from_path(path)
            except CodeIntelError:
                log.info("skip `%s': couldn't determine language "
                         "(use --lang option)", path)
                continue
            buf = mgr.buf_from_path(path, lang=opts.lang)
            if not isinstance(buf, CitadelBuffer):
                raise CodeIntelError("`%s' (%s) is not a language that "
                                     "uses CIX" % (path, buf.lang))
            buf.scan()  # force a fresh scan
            tree = buf.tree
            for severity, msg in check_tree(tree):
                dump = {"warning": log.warn,
                        "error": log.error}[severity]
                dump(msg)
            if opts.pretty_print:
                tree = pretty_tree_from_tree(tree)
            ET.dump(tree)
    finally:
        mgr.finalize()

</t>
<t tx="ekr.20080121105837.1823">@cmdln.option("-o", "--output",
              help="path to which to write HTML output (instead of "
                   "PATH.html, use '-' for stdout)")
@cmdln.option("-b", "--browse", action="store_true",
              help="open output file in browser")
@cmdln.option("-e", "--do-eval", action="store_true",
              help="do (and show) completion evaluation")
@cmdln.option("-t", "--do-trg", action="store_true",
              help="do (and show) trigger handling (also implies -e)")
@cmdln.option("-l", "--lang",
              help="specify the language of the given path (if not "
                   "given it will be guessed)")
def do_html(self, subcmd, opts, path):
    """Convert the given path to styled HTML.

    ${cmd_usage}
    ${cmd_option_list}
    
    The generated HTML provides a good tool for seeing how Komodo's
    lexer lexes the given content. This is the same tokenization that
    you get from "buf.accessor.*" methods -- which you can use for
    writing the CILE, trigger handling, and completion evaluation
    for this language.
    
    Use the "-t" and "-e" option to also exercise the current
    trigger handling and completion evaluation (i.e. determining
    the appropriate completions and calltips at a given trigger
    point).
    """
    extra_lang_module_dirs = []
    if koextlib.is_ext_dir() and exists("pylib"):
        sys.path.append(abspath("pylib"))
        extra_lang_module_dirs = [sys.path[-1]]
        
    mgr = Manager(extra_lang_module_dirs=extra_lang_module_dirs)
    try:
        if opts.browse:
            htmls = []
        buf = mgr.buf_from_path(path, lang=opts.lang)
        html = buf.to_html(True, True, title=path,
                           do_trg=opts.do_trg,
                           do_eval=opts.do_eval)
    finally:
        mgr.finalize()
    
    if opts.output == '-':
        output_path = None
        output_file = sys.stdout
    else:
        if opts.output:
            output_path = opts.output
        else:
            output_path = path+".html"
        if exists(output_path):
            os.remove(output_path)
        output_file = open(output_path, 'w')
    if output_file:
        output_file.write(html)
    if output_path:
        output_file.close()

    if opts.browse:
        if not output_path:
            raise CodeIntelError("cannot open in browser if stdout "
                                 "used for output")
        import webbrowser
        url = _url_from_local_path(output_path)
        webbrowser.open_new(url)  


</t>
<t tx="ekr.20080121105837.1824">#---- internal support functions

</t>
<t tx="ekr.20080121105837.1825"># From komodo/utils/rst2html/rst2html.py.
def _url_from_local_path(local_path):
    # HACKy: This isn't super-robust.
    from os.path import abspath, normpath
    url = normpath(abspath(local_path))
    if sys.platform == "win32":
        url = "file:///" + url.replace('\\', '/')
    else:
        url = "file://" + url
    return url

</t>
<t tx="ekr.20080121105837.1826"># Recipe: paths_from_path_patterns (0.3.7)
def _should_include_path(path, includes, excludes):
    """Return True iff the given path should be included."""
    from os.path import basename
    from fnmatch import fnmatch

    base = basename(path)
    if includes:
        for include in includes:
            if fnmatch(base, include):
                try:
                    log.debug("include `%s' (matches `%s')", path, include)
                except (NameError, AttributeError):
                    pass
                break
        else:
            try:
                log.debug("exclude `%s' (matches no includes)", path)
            except (NameError, AttributeError):
                pass
            return False
    for exclude in excludes:
        if fnmatch(base, exclude):
            try:
                log.debug("exclude `%s' (matches `%s')", path, exclude)
            except (NameError, AttributeError):
                pass
            return False
    return True

</t>
<t tx="ekr.20080121105837.1827">_NOT_SPECIFIED = ("NOT", "SPECIFIED")
def _paths_from_path_patterns(path_patterns, files=True, dirs="never",
                              recursive=True, includes=[], excludes=[],
                              on_error=_NOT_SPECIFIED):
    """_paths_from_path_patterns([&lt;path-patterns&gt;, ...]) -&gt; file paths

    Generate a list of paths (files and/or dirs) represented by the given path
    patterns.

        "path_patterns" is a list of paths optionally using the '*', '?' and
            '[seq]' glob patterns.
        "files" is boolean (default True) indicating if file paths
            should be yielded
        "dirs" is string indicating under what conditions dirs are
            yielded. It must be one of:
              never             (default) never yield dirs
              always            yield all dirs matching given patterns
              if-not-recursive  only yield dirs for invocations when
                                recursive=False
            See use cases below for more details.
        "recursive" is boolean (default True) indicating if paths should
            be recursively yielded under given dirs.
        "includes" is a list of file patterns to include in recursive
            searches.
        "excludes" is a list of file and dir patterns to exclude.
            (Note: This is slightly different than GNU grep's --exclude
            option which only excludes *files*.  I.e. you cannot exclude
            a ".svn" dir.)
        "on_error" is an error callback called when a given path pattern
            matches nothing:
                on_error(PATH_PATTERN)
            If not specified, the default is look for a "log" global and
            call:
                log.error("`%s': No such file or directory")
            Specify None to do nothing.

    Typically this is useful for a command-line tool that takes a list
    of paths as arguments. (For Unix-heads: the shell on Windows does
    NOT expand glob chars, that is left to the app.)

    Use case #1: like `grep -r`
      {files=True, dirs='never', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield nothing
        script PATH*    # yield all files matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files (not dirs) recursively under DIR
        script -r PATH* # yield files matching PATH* and files recursively
                        # under dirs matching PATH*; if none, call
                        # on_error(PATH*) callback

    Use case #2: like `file -r` (if it had a recursive option)
      {files=True, dirs='if-not-recursive', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield DIR, else call on_error(DIR)
        script PATH*    # yield all files and dirs matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files (not dirs) recursively under DIR
        script -r PATH* # yield files matching PATH* and files recursively
                        # under dirs matching PATH*; if none, call
                        # on_error(PATH*) callback

    Use case #3: kind of like `find .`
      {files=True, dirs='always', recursive=(if '-r' in opts)}
        script FILE     # yield FILE, else call on_error(FILE)
        script DIR      # yield DIR, else call on_error(DIR)
        script PATH*    # yield all files and dirs matching PATH*; if none,
                        # call on_error(PATH*) callback
        script -r DIR   # yield files and dirs recursively under DIR
                        # (including DIR)
        script -r PATH* # yield files and dirs matching PATH* and recursively
                        # under dirs; if none, call on_error(PATH*)
                        # callback
    """
    from os.path import basename, exists, isdir, join
    from glob import glob

    assert not isinstance(path_patterns, basestring), \
        "'path_patterns' must be a sequence, not a string: %r" % path_patterns
    GLOB_CHARS = '*?['

    for path_pattern in path_patterns:
        # Determine the set of paths matching this path_pattern.
        for glob_char in GLOB_CHARS:
            if glob_char in path_pattern:
                paths = glob(path_pattern)
                break
        else:
            paths = exists(path_pattern) and [path_pattern] or []
        if not paths:
            if on_error is None:
                pass
            elif on_error is _NOT_SPECIFIED:
                try:
                    log.error("`%s': No such file or directory", path_pattern)
                except (NameError, AttributeError):
                    pass
            else:
                on_error(path_pattern)

        for path in paths:
            if isdir(path):
                # 'includes' SHOULD affect whether a dir is yielded.
                if (dirs == "always"
                    or (dirs == "if-not-recursive" and not recursive)
                   ) and _should_include_path(path, includes, excludes):
                    yield path

                # However, if recursive, 'includes' should NOT affect
                # whether a dir is recursed into. Otherwise you could
                # not:
                #   script -r --include="*.py" DIR
                if recursive and _should_include_path(path, [], excludes):
                    for dirpath, dirnames, filenames in os.walk(path):
                        dir_indeces_to_remove = []
                        for i, dirname in enumerate(dirnames):
                            d = join(dirpath, dirname)
                            if dirs == "always" \
                               and _should_include_path(d, includes, excludes):
                                yield d
                            if not _should_include_path(d, [], excludes):
                                dir_indeces_to_remove.append(i)
                        for i in reversed(dir_indeces_to_remove):
                            del dirnames[i]
                        if files:
                            for filename in sorted(filenames):
                                f = join(dirpath, filename)
                                if _should_include_path(f, includes, excludes):
                                    yield f

            elif files and _should_include_path(path, includes, excludes):
                yield path


</t>
<t tx="ekr.20080121105837.1828"># Recipe: pretty_logging (0.1+)
class _PerLevelFormatter(logging.Formatter):
    """Allow multiple format string -- depending on the log level.
    
    A "fmtFromLevel" optional arg is added to the constructor. It can be
    a dictionary mapping a log record level to a format string. The
    usual "fmt" argument acts as the default.
    """
    @others
</t>
<t tx="ekr.20080121105837.1829">def __init__(self, fmt=None, datefmt=None, fmtFromLevel=None):
    logging.Formatter.__init__(self, fmt, datefmt)
    if fmtFromLevel is None:
        self.fmtFromLevel = {}
    else:
        self.fmtFromLevel = fmtFromLevel
</t>
<t tx="ekr.20080121105837.1830">def format(self, record):
    record.levelname = record.levelname.lower()
    if record.levelno in self.fmtFromLevel:
        #XXX This is a non-threadsafe HACK. Really the base Formatter
        #    class should provide a hook accessor for the _fmt
        #    attribute. *Could* add a lock guard here (overkill?).
        _saved_fmt = self._fmt
        self._fmt = self.fmtFromLevel[record.levelno]
        try:
            return logging.Formatter.format(self, record)
        finally:
            self._fmt = _saved_fmt
    else:
        return logging.Formatter.format(self, record)

</t>
<t tx="ekr.20080121105837.1831">def _setup_logging():
    hdlr = logging.StreamHandler()
    defaultFmt = "%(name)s: %(levelname)s: %(message)s"
    infoFmt = "%(message)s"
    fmtFromLevel={logging.INFO: "%(name)s: %(message)s"}
    fmtr = _PerLevelFormatter(defaultFmt, fmtFromLevel=fmtFromLevel)
    hdlr.setFormatter(fmtr)
    logging.root.addHandler(hdlr)



</t>
<t tx="ekr.20080121105837.1832">#---- mainline</t>
<t tx="ekr.20080121105837.1833">def _do_main(argv):
    shell = Shell()
    return shell.main(argv)

</t>
<t tx="ekr.20080121105837.1834">def main(argv=sys.argv):
    _setup_logging()
    try:
        retval = _do_main(argv)
    except KeyboardInterrupt:
        sys.exit(1)
    except SystemExit:
        raise
    except:
        skip_it = False
        exc_info = sys.exc_info()
        if hasattr(exc_info[0], "__name__"):
            exc_class, exc, tb = exc_info
            if isinstance(exc, IOError) and exc.args[0] == 32:
                # Skip 'IOError: [Errno 32] Broken pipe'.
                skip_it = True
            if not skip_it:
                #tb_path, tb_lineno, tb_func = traceback.extract_tb(tb)[-1][:3]
                #log.error("%s (%s:%s in %s)", exc_info[1], tb_path,
                #          tb_lineno, tb_func)
                log.error(exc_info[1])
        else:  # string exception
            log.error(exc_info[0])
        if not skip_it:
            if log.isEnabledFor(logging.DEBUG):
                print
                traceback.print_exception(*exc_info)
            sys.exit(1)
    else:
        sys.exit(retval)

</t>
<t tx="ekr.20080121105837.1835">#!/usr/bin/env python
# ***** LICENSE BLOCK *****

r"""A command-line interface for managing UDL (User-Defined Language)
files for Komodo.
"""

@language python
@tabwidth -4
@others

#---- mainline

if __name__ == "__main__":
    _setup_logging() # defined in recipe:pretty_logging
    try:
        shell = Shell()
        retval = shell.main(sys.argv)
    except KeyboardInterrupt:
        sys.exit(1)
    except:
        exc_info = sys.exc_info()
        if hasattr(exc_info[0], "__name__"):
            log.error("%s: %s", exc_info[0].__name__, exc_info[1])
        else:  # string exception
            log.error(exc_info[0])
        if log.isEnabledFor(logging.DEBUG):
            import traceback
            print
            traceback.print_exception(*exc_info)
        sys.exit(1)
    else:
        sys.exit(retval)</t>
<t tx="ekr.20080121105837.1836">import os
from os.path import basename, dirname, join, exists, abspath, splitext
import sys
import re
import logging
from glob import glob
from pprint import pprint
import webbrowser

</t>
<t tx="ekr.20080121105837.1837">def _set_lib_path():
    if exists(join(dirname(__file__), "ludditelib")):  # dev layout
        pass
    else: # install layout (in Komodo SDK)
        sys.path.insert(0, join(dirname(dirname(abspath(__file__))), "pylib"))

_set_lib_path()

from ludditelib import cmdln
from ludditelib import parser, gen, constants, commands
from ludditelib.common import LudditeError, __version__, \
                              guid_pat, norm_guid, generate_guid


log = logging.getLogger("luddite")
</t>
<t tx="ekr.20080121105837.1838">#---- command line interface

class Shell(cmdln.Cmdln):
    """
    luddite: build and package Komodo language extensions

    usage:
        ${name} SUBCOMMAND [ARGS...]
        ${name} help SUBCOMMAND

    Language syntax-highlighting in Komodo requires a lexer. For most of
    Komodo's core supported languages these lexers are written in C++.
    However, as of Komodo 4, you can define custom lexers for languages that
    Komodo doesn't support out of the box. This system is called UDL -- for
    User-Defined Languages.
    
    Luddite is a tool for building and packaging a Komodo language
    extension. The typical process is:
    
    1. Use the 'koext' tool (also part of the Komodo SDK) to start a Komodo
       extension source tree and create stub files for a new Komodo language.
       
            koext startext fuzzy_language
            cd fuzzy_language/
            koext startlang fuzzy
    
    2. Author the 'udl/LANG-mainlex.udl' file defining syntax highlighting
       rules for your language and the 'components/koFuzzy_UDL_Language.py'
       language service as appropriate.
       
       The 'luddite lex' and 'luddite lexhtml' commands can help you debug
       your .udl code.

    3. Build the extension. 'koext' knows how to compile your UDL code into
       the '.lexres' files that Komodo uses at runtime.
    
            koext build

    4. Upload and announce you new extension on Komodo's add-ons site:
    
            http://community.activestate.com/addons

    For more information on writing .udl files see Komodo's UDL
    documentation.

    ${option_list}
    ${command_list}
    ${help_list}
    """
    name = "luddite"
    version = __version__
    helpindent = ' '*2

    @others
</t>
<t tx="ekr.20080121105837.1839">def get_optparser(self):
    parser = cmdln.Cmdln.get_optparser(self)
    parser.add_option("-v", "--verbose", dest="log_level",
                      action="store_const", const=logging.DEBUG,
                      help="more verbose output")
    parser.add_option("-q", "--quiet", dest="log_level",
                      action="store_const", const=logging.WARNING,
                      help="quieter output")
    parser.set_defaults(log_level=logging.INFO)
    return parser

</t>
<t tx="ekr.20080121105837.1840">def postoptparse(self):
    global log
    log.setLevel(self.options.log_level)

</t>
<t tx="ekr.20080121105837.1841">@cmdln.option("-d", "--output-dir",
              help="specify the output dir for the .lexres file (by "
                   "default the same dir as the input .udl path")
@cmdln.option("-I", dest="include_dirs", action="append",
              help="extra dirs to search for include'd UDL files")
def do_just_compile(self, subcmd, opts, udl_path):
    """${cmd_name}: compile a .udl file into a .lexres file
    
    ${cmd_usage}
    ${cmd_option_list}
    Note: This is a replacement for the deprecated `luddite compile'. In
    a subsequent release this will get the name `luddite compile'.
    """
    return commands.compile(
        udl_path, output_dir=opts.output_dir,
        include_path=opts.include_dirs, log=log)

</t>
<t tx="ekr.20080121105837.1842">@cmdln.option("--ext",
              help="specify a default file extension for this language")
@cmdln.option("-g", "--guid", 
              help="specify an XPCOM component GUID to use, or a path "
                   "to GUIDs text file")
@cmdln.option("-G", dest="new_guid", action="store_true",
              help="create a new XPCOM component GUID for this build")
@cmdln.option("--skel", action="store_true",
              help="also build skeleton Language Service and template files")
@cmdln.option("-f", "--force", action="store_true",
              help="allow build outputs to overwrite existing files")
@cmdln.alias("compile")
def do_deprecated_compile(self, subcmd, opts, udl_path):
    """${cmd_name}: compile a .udl file into lang resources
    
    Note: This has been deprecated in favour of `luddite just_compile'
    and the more generic functionality of the 'koext' tool.
    
    ${cmd_usage}
    ${cmd_option_list}
    If you specify '--skel' to build a skeleton Language Service
    then you must also specify one of the -G or -g|--guid options.
    The Language Service is a Python file that controls language
    support in Komodo. It requires a unique GUID (for the XPCOM
    component's class id).

    If you are just building the skeleton language service for every
    build (you can get away with this for minimal language support)
    the using a GUIDs text file to ensure the same GUID is used for
    your component from build to build is recommended. This file
    must be of the form (one entry per line):
        &lt;lang&gt; &lt;guid&gt;
    """
    log.warn("the 'skel' generation facilities of 'luddite compile' "
             "have been deprecated in favour of (a) the simpler "
             "'luddite just_compile' and (b) the more generic support "
             "of the 'koext' tool")
    guid = guid_from_lang = None
    if not opts.skel:
        pass
    elif opts.new_guid and opts.guid:
        raise LudditeError("cannot specify both -G and -g|--guid "
                           "options at the same time")
    elif opts.new_guid:
        guid = None
    elif opts.guid:
        if guid_pat.match(opts.guid):
            guid = norm_guid(opts.guid)
        else:
            if not exists(opts.guid):
                raise LudditeError("`%s' is not a GUID and does not "
                                   "exist" % opts.guid)
            guid_from_lang = {} #dict((lang, g) for lang, g in)
            for line in file(opts.guid):
                if line.startswith("#"): continue
                if not line.strip(): continue
                lang, g = line.strip().split(None, 1)
                guid_from_lang[lang] = norm_guid(g)
    else:
        raise LudditeError("must specify one of -G or -g|--guid")
    return commands.deprecated_compile(
        udl_path, skel=opts.skel, guid=guid, 
        guid_from_lang=guid_from_lang, ext=opts.ext,
        force=opts.force, log=log)

</t>
<t tx="ekr.20080121105837.1843">def _do_parse(self, subcmd, opts, *udl_paths):
    """${cmd_name}: parse the given .udl file (for debugging)
    
    ${cmd_usage}
    ${cmd_option_list}
    """
    for udl_path in udl_paths:
        tree = commands.parse(udl_path, log=log)
        pprint(tree)

</t>
<t tx="ekr.20080121105837.1844">@cmdln.option("-f", "--force", action="store_true",
              help="allow build outputs to overwrite existing files")
@cmdln.option("--id", action="store",
              help="the internal identifier for this extension (a short string)")
@cmdln.option("--name", action="store",
              help="the extension name")
@cmdln.option("--description", action="store",
              help="a short description of the extension")
@cmdln.option("-c", "--creator", action="store",
              help="the name of the creator/maintainer of this extension")
@cmdln.option("-V", "--version", action="store",
              help="the extension version")
@cmdln.alias("package")
def do_deprecated_package(self, subcmd, opts, lang):
    """${cmd_name}: package Komodo lang resources into an extension

    Note: This has been deprecated in favour of `luddite just_compile'
    and the more generic functionality of the 'koext' tool.

    ${cmd_usage}
    ${cmd_option_list}
    You must first have run '${name} compile ...' to build the Komodo
    resources for this language.

    Typical usage should specify the "creator" and "version". The other
    values have reasonable defaults. For example:
    
        ${name} package -c "Santa Claus" --version "2.0.1" Toy
        ${name} package -c "Larry Wall" --version "0.8.0" Perl

    (However, Komodo already has a Perl lexer so creating your own
    UDL-based one for Perl is just for the masochists.)
    """
    return commands.deprecated_package(
        lang, version=opts.version,
        creator=opts.creator, name=opts.name,
        description=opts.description, id=opts.id,
        force=opts.force, log=log)

</t>
<t tx="ekr.20080121105837.1845">def do_lex(self, subcmd, opts, lang, path):
    """${cmd_name}: lex the given file (for debugging)

    ${cmd_usage}
    ${cmd_option_list}
    Lex the given path with the UDL-based lexer for the given language,
    printing a summary to stdout. This is for debugging a .udl file
    during development.
    """
    from ludditelib.debug import lex
    content = open(path, 'r').read()
    lex(content, lang)

</t>
<t tx="ekr.20080121105837.1846">@cmdln.option("-o", "--output",
              help="path to which to write HTML output (instead of "
                   "PATH.html, use '-' for stdout)")
@cmdln.option("-b", "--browse", action="store_true",
              help="open output file in browser")
def do_lexhtml(self, subcmd, opts, lang, path):
    """${cmd_name}: lex the given file to styled HTML (for debugging)

    ${cmd_usage}
    ${cmd_option_list}
    """
    from ludditelib.debug import lex_to_html
    content = open(path, 'r').read()
    html = lex_to_html(content, lang)

    if opts.output == '-':
        output_path = None
        output_file = sys.stdout
    else:
        if opts.output:
            output_path = opts.output
        else:
            output_path = path+".html"
        if exists(output_path):
            os.remove(output_path)
        output_file = open(output_path, 'w')
    if output_file:
        output_file.write(html)
    if output_path:
        output_file.close()

    if opts.browse:
        if not output_path:
            raise LudditeError("cannot open in browser if stdout used "
                               "for output")
        import webbrowser
        url = _url_from_local_path(output_path)
        webbrowser.open_new(url)            



</t>
<t tx="ekr.20080121105837.1847">#---- internal support stuff

# Recipe: pretty_logging (0.1) in C:\trentm\tm\recipes\cookbook
class _PerLevelFormatter(logging.Formatter):
    """Allow multiple format string -- depending on the log level.
    
    A "fmtFromLevel" optional arg is added to the constructor. It can be
    a dictionary mapping a log record level to a format string. The
    usual "fmt" argument acts as the default.
    """
    @others
</t>
<t tx="ekr.20080121105837.1848">def __init__(self, fmt=None, datefmt=None, fmtFromLevel=None):
    logging.Formatter.__init__(self, fmt, datefmt)
    if fmtFromLevel is None:
        self.fmtFromLevel = {}
    else:
        self.fmtFromLevel = fmtFromLevel
</t>
<t tx="ekr.20080121105837.1849">def format(self, record):
    record.levelname = record.levelname.lower()
    if record.levelno in self.fmtFromLevel:
        #XXX This is a non-threadsafe HACK. Really the base Formatter
        #    class should provide a hook accessor for the _fmt
        #    attribute. *Could* add a lock guard here (overkill?).
        _saved_fmt = self._fmt
        self._fmt = self.fmtFromLevel[record.levelno]
        try:
            return logging.Formatter.format(self, record)
        finally:
            self._fmt = _saved_fmt
    else:
        return logging.Formatter.format(self, record)

</t>
<t tx="ekr.20080121105837.1850">def _setup_logging():
    hdlr = logging.StreamHandler()
    defaultFmt = "%(name)s: %(levelname)s: %(message)s"
    infoFmt = "%(name)s: %(message)s"
    fmtr = _PerLevelFormatter(fmt=defaultFmt,
                              fmtFromLevel={logging.INFO: infoFmt})
    hdlr.setFormatter(fmtr)
    logging.root.addHandler(hdlr)
    log.setLevel(logging.INFO)
    #log.setLevel(logging.DEBUG)


</t>
<t tx="ekr.20080121105837.1851">def _url_from_local_path(local_path):
    # HACKy: This isn't super-robust.
    from os.path import abspath, normpath
    url = normpath(abspath(local_path))
    if sys.platform == "win32":
        url = "file:///" + url.replace('\\', '/')
    else:
        url = "file://" + url
    return url



</t>
<t tx="ekr.20080121105837.1852"></t>
<t tx="ekr.20080121105837.1853">#!/usr/bin/env python

"""${lang} support for codeintel.

This file will be imported by the codeintel system on startup and the
register() function called to register this language with the system. All
Code Intelligence for this language is controlled through this module.
"""

import os
import sys
import logging

from codeintel2.common import *
from codeintel2.citadel import CitadelBuffer
from codeintel2.langintel import LangIntel

try:
    from xpcom.server import UnwrapObject
    _xpcom_ = True
except ImportError:
    _xpcom_ = False


#---- globals

lang = "${lang}"
log = logging.getLogger("codeintel.${safe_lang_lower}")
#log.setLevel(logging.DEBUG)


#---- Lexer class

# Dev Notes:
# Komodo's editing component is based on scintilla (scintilla.org). This
# project provides C++-based lexers for a number of languages -- these
# lexers are used for syntax coloring and folding in Komodo. Komodo also
# has a UDL system for writing UDL-based lexers that is simpler than
# writing C++-based lexers and has support for multi-language files.
#
# The codeintel system has a Lexer class that is a wrapper around these
# lexers. You must define a Lexer class for lang ${lang}. If Komodo's
# scintilla lexer for ${lang} is UDL-based, then this is simply:
#
#   from codeintel2.udl import UDLLexer
#   class ${safe_lang}Lexer(UDLLexer):
#       lang = lang
#
# Otherwise (the lexer for ${lang} is one of Komodo's existing C++ lexers
# then this is something like the following. See lang_python.py or
# lang_perl.py in your Komodo installation for an example. "SilverCity"
# is the name of a package that provides Python module APIs for Scintilla
# lexers.
#
#   import SilverCity
#   from SilverCity.Lexer import Lexer
#   from SilverCity import ScintillaConstants
#   class ${safe_lang}Lexer(Lexer):
#       lang = lang
#       def __init__(self):
#           self._properties = SilverCity.PropertySet()
#           self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_${safe_lang_upper})
#           self._keyword_lists = [
#               # Dev Notes: What goes here depends on the C++ lexer
#               # implementation.
#           ]


#---- LangIntel class

# Dev Notes:
# All language should define a LangIntel class. (In some rare cases it
# isn't needed but there is little reason not to have the empty subclass.)
#
# One instance of the LangIntel class will be created for each codeintel
# language. Code browser functionality and some buffer functionality
# often defers to the LangIntel singleton.
#
# This is especially important for multi-lang files. For example, an
# HTML buffer uses the JavaScriptLangIntel and the CSSLangIntel for
# handling codeintel functionality in &lt;script&gt; and &lt;style&gt; tags.
#
# See other lang_*.py files in your Komodo installation for examples of
# usage.
class ${safe_lang}LangIntel(LangIntel):
    lang = lang


#---- Buffer class

# Dev Notes:
# Every language must define a Buffer class. An instance of this class
# is created for every file of this language opened in Komodo. Most of
# that APIs for scanning, looking for autocomplete/calltip trigger points
# and determining the appropriate completions and calltips are called on
# this class.
#
# Currently a full explanation of these API is beyond the scope of this
# stub. Resources for more info are:
# - the base class definitions (Buffer, CitadelBuffer, UDLBuffer) for
#   descriptions of the APIs
# - lang_*.py files in your Komodo installation as examples
# - the upcoming "Anatomy of a Komodo Extension" tutorial
# - the Komodo community forums:
#   http://community.activestate.com/products/Komodo
# - the Komodo discussion lists:
#   http://listserv.activestate.com/mailman/listinfo/komodo-discuss
#   http://listserv.activestate.com/mailman/listinfo/komodo-beta
#
class ${safe_lang}Buffer(CitadelBuffer):
    # Dev Note: What to sub-class from?
    # - If this is a UDL-based language: codeintel2.udl.UDLBuffer
    # - Else if this is a programming language (it has functions,
    #   variables, classes, etc.): codeintel2.citadel.CitadelBuffer
    # - Otherwise: codeintel2.buffer.Buffer
    lang = lang

    cb_show_if_empty = True

    # Dev Note: many details elided.


#---- CILE Driver class

# Dev Notes:
# A CILE (Code Intelligence Language Engine) is the code that scans
# ${lang} content and returns a description of the code in that file.
# See "cile_${safe_lang_lower}.py" for more details.
#
# The CILE Driver is a class that calls this CILE. If ${lang} is
# multi-lang (i.e. can contain sections of different language content,
# e.g. HTML can contain markup, JavaScript and CSS), then you will need
# to also implement "scan_multilang()".
class ${safe_lang}CILEDriver(CILEDriver):
    lang = lang

    def scan_purelang(self, buf):
        import cile_${safe_lang_lower}
        return cile_${safe_lang_lower}.scan_buf(buf)


#---- registration
def register(mgr):
    """Register language support with the Manager."""
    mgr.set_lang_info(
        lang,
        silvercity_lexer=${safe_lang}Lexer(),
        buf_class=${safe_lang}Buffer,
        langintel_class=${safe_lang}LangIntel,
        import_handler_class=None,
        cile_driver_class=${safe_lang}CILEDriver,
        # Dev Note: set to false if this language does not support
        # autocomplete/calltips.
        is_cpln_lang=True)

</t>
<t tx="ekr.20080121105837.1854">@language html

&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;!-- ***** LICENSE BLOCK ***** --&gt;

&lt;!-- $Id$

# Basic structure of a CIX 2.0 file.

    &lt;codeintel version="2.0" xmlns="urn:activestate:cix:2.0"&gt;
        &lt;file lang="Perl" path=".../Foo.pm"&gt;
            &lt;scope ilk="blob" lang="Perl" name="Foo" src=".../Foo.pm"&gt;
                ...classes, functions, variables, imports...
            &lt;/scope&gt;
        &lt;/file&gt;
    &lt;/codeintel&gt;

    # a multi-lang file
    &lt;codeintel version="2.0" xmlns="urn:activestate:cix:2.0"&gt;   
        &lt;file lang="RHTML" path=".../blah.rhtml"&gt;
            &lt;scope ilk="blob" lang="JavaScript" name="blah.rhtml" src=".../blah.rhtml"&gt;
                ...JavaScript classes, functions, variables...
            &lt;/scope&gt;
            &lt;scope ilk="blob" lang="Ruby" name="blah.rhtml" src=".../blah.rhtml"&gt;
                ...Ruby classes, functions, variables, imports...
            &lt;/scope&gt;
        &lt;/file&gt;
    &lt;/codeintel&gt;


# Notes on this schema

"line" and "lineend" attributes are 1-based. As well, they are only optional to
allow for CIX describing binary modules (where a line number does not make
sense). They are strongly recommended for text files.

CITDL stands for CodeIntel Type Determination Language. It is an expression
that is evaluated to figure out what type a variable is. Examples:

    list       # the list symbol (possibly Python's built-in list object)
    foo()      # the result of calling function foo
    foo.bar    # member 'bar' of symbol 'foo'

I have no idea if the "value" attribute on &lt;attribute&gt; is legal Relax NG, but
tough, the authors of the RelaxNG spec strove for obtusness. You know what I
mean.

Why 'ilk' for scope type? Ilk is a synonym for "type", but "type" is
overloaded. It is short (good for space savings), it is weird (people won't
think this is related to type inferencing info) and it is rare (good for
finding uses in the codeintel sources).

"ilk" dev note: Developers should be aware that ilk is used by multiple
element types and that it is not enough to simply check the ilk type to
work out the type of element, you should be checking both the tag name
and then the ilk type to determine element type.

Why 'blob' for modules/packages/importable-things? See
&lt;http://p4.activestate.com/p4db/changeView.cgi?CH=269772&gt; for a reasons why.


# Common attributes

These are the shared common attributes that are used in any of the elements
below.

    __exported__, __exportable__
        To support Perl's special @EXPORT and @EXPORT_OK Exporter
        variables, respectively. A Perl symbol tag should have
        the appropriate attribute if it is a member of one of
        these lists.
    __hidden__
        Indicates that this symbol is not externally accessible for
        the purposes of completion. This can be required for binary
        modules. For example Python's pyexpat module has a
        ParserCreate() factory function which returns a
        pyexpat.xmlparser class instance. However, the 'xmlparser'
        class is not otherwise accessible on the pyexpat module.
    __local__
        Indicates that this element is local to the current scope, i.e.
        not visible externally. This was initially added to support
        Perl's package variables declared with "my". This has started
        to extend to other languages such as JavaScript, which uses
        this attribute for variables declared with "var" and "const".
    __fabricated__
        Indicates that this element (and its contents) does not necessarily
        represent the actual code in the underlying document.  For example,
        Rails migration classes contain an "uninteresting" class, which
        often contain methods that define parts of an ActiveRecord::Base
        class.  Fabricated items are intended to be usable in code-completion
        lists, but need not show up in code browser windows.
    private, protected
        Indicates that this item is private or protected.
        Note: Current completion processing does not use these
        attributes. Komodo's code browser does, however, adding
        a small black lock icon to the element.
    deprecated
        Indicates that this item should not be used anymore.
    constant
        Indicates that this item can/should not be modified.
        Note: PHP is defining constants by setting the ilk="constant" attribute
        on the variable element instead. This is because PHP needs to
        distinguish between the two, as PHP constants trigger differently to PHP
        variables. Setting the ilk="constant" attribute will affect the results
        of database API calls that depend upon an "ilk" attribute, like
        "toplevel_cplns()".


# TODO

- Change "module" on &lt;import&gt; be to blob (to conform to the s/module/blob/
  changes elsewhere.

--&gt;

&lt;grammar xmlns="http://relaxng.org/ns/structure/1.0"
         ns="urn:activestate:cix:2.0"&gt;
    &lt;start&gt;
        &lt;ref name="CodeIntel"/&gt;
    &lt;/start&gt;

    &lt;define name="CodeIntel"&gt;
        &lt;element name="codeintel"&gt;
            &lt;attribute name="version"/&gt;
            &lt;optional&gt;
                &lt;!-- An optional name and description of what this CIX content
                     describes. This is only suggested for API catalogs and
                     perhaps stdlib CIX files (i.e. normal scanners should not
                     bother. "name" should be just one work, e.g. "MochiKit",
                     and "description" should be short (one line). --&gt;
                &lt;attribute name="name" /&gt;
                &lt;attribute name="description" /&gt;
            &lt;/optional&gt;
            &lt;oneOrMore&gt; &lt;!-- Note: should be able to make this exactly one. --&gt;
                &lt;ref name="File"/&gt;
            &lt;/oneOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="File"&gt;
        &lt;element name="file"&gt;
            &lt;attribute name="lang"/&gt; &lt;!-- language of the file content --&gt;
            &lt;!-- path of the scanned file, must use '/' as dir separator --&gt;
            &lt;attribute name="path"/&gt;
            &lt;choice&gt;
                &lt;!-- a successful scan --&gt;
                &lt;group&gt;
                    &lt;!-- Last modified time of the file or time of the scan (in
                         seconds since the "epoch"). --&gt;
                    &lt;attribute name="mtime"/&gt;
                    &lt;!-- Only multi-lang files can have more than one module. --&gt;
                    &lt;zeroOrMore&gt;
                        &lt;ref name="Blob"/&gt;
                    &lt;/zeroOrMore&gt;
                &lt;/group&gt;
                &lt;!-- a failed scan 
                     Note: This may be dropped in favour of an error return
                     from the CILE scan methods. --&gt;
                &lt;attribute name="error"/&gt; &lt;!-- description of scan failure --&gt;
            &lt;/choice&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;!-- Represents the content for one language in a file. E.g., a Python
         module, the JS code in an HTML file. --&gt;
    &lt;define name="Blob"&gt;
        &lt;element name="scope"&gt;
            &lt;attribute name="ilk" value="blob"/&gt;
            &lt;!-- The name of the module. The file extension should be left on
                 if the file extension is used for importing by that language's
                 import statement. --&gt;
            &lt;attribute name="lang"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt;
                &lt;!-- Special module attributes:
                    __script__
                        The existence of this attribute means this is a fake
                        module for a script file that isn't actually
                        importable.  For example, Tcl files that do not define
                        packages should be marked with this attribute.
                    __version__=&lt;version&gt;
                        This can be used to define the version of a
                        module/package. It should only be used for languages
                        where a module version is relevant for import semantic,
                        e.g. Tcl.
                    Also see common attributes at the top of the file.
                --&gt;
                &lt;attribute name="attributes"/&gt;
            &lt;/optional&gt;
            &lt;optional&gt;
                &lt;!-- *Short* doc (i.e. appropriate for Komodo's Code Browser's
                     description area) for the blob, if any. --&gt;
                &lt;attribute name="doc" /&gt; 
            &lt;/optional&gt;
            &lt;optional&gt;
                &lt;!-- Path of the scanned file (same as 'path' attr on File
                     element). Must use '/' as dir separator (even on Windows).

                     Was added to easily get the file path from a blob, used
                     for "Goto Definition" functionality. --&gt;
                &lt;attribute name="src" /&gt; 
            &lt;/optional&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Import"/&gt;
                    &lt;ref name="Class"/&gt;
                    &lt;ref name="Namespace"/&gt;
                    &lt;ref name="Interface"/&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Import"&gt;
        &lt;element name="import"&gt;
            &lt;!-- The module being imported, or from which a symbol(s) is
                 being imported. 
                
                 With Ruby's 'include'-statement you import a symbol (a Ruby
                 'module') from an unspecified blob (a.k.a. a module).
                 --&gt;
            &lt;optional&gt; &lt;attribute name="module"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;!-- Symbol being imported from the module, if any.
                 This should be left blank if just the module name is
                 "imported", as with "use Foo();" in Perl and "import foo"
                 in Python.

                 If a single code statement imports multiple symbols, then
                 multiple &lt;import&gt; CIX tags should be generated. E.g.:
                    use Alphagetti qw(a b);         # Perl
                    from Alphagetti import a, b     # Python
                 should result in something like:
                    &lt;import module="Alphagetti" symbol="a"/&gt;
                    &lt;import module="Alphagetti" symbol="b"/&gt;

                 There are two special symbol values:
                 - symbol="*"
                    Indicates that all normally exported symbols are
                    imported. E.g. "from foo import *" in Python, "use Foo;"
                    in Perl.
                 - symbol="**"
                    Indicates that all exportable symbols are imported. This
                    is essentially a hack for Perl to somewhat support
                    %EXPORT_TAGS usage. AutoComplete evaluation will treat
                    "**" as an import of all @EXPORT and @EXPORT_OK symbols.
              --&gt;
            &lt;optional&gt; &lt;attribute name="symbol"/&gt; &lt;/optional&gt;
            &lt;!-- Alias for the imported symbol or module, if any.
                 Python, for example, allows this:
                    import pcre as re
                    from cgi import escape as htmlescape --&gt;
            &lt;optional&gt; &lt;attribute name="alias"/&gt; &lt;/optional&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Class"&gt;
        &lt;element name="scope"&gt;
            &lt;attribute name="ilk" value="class"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="lineend"/&gt; &lt;/optional&gt;
            &lt;!-- Special attributes:
                None. See common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="signature"/&gt; &lt;/optional&gt;
            &lt;!-- Space-separate list of base classes. The given strings are
                 actually the CITDL expr used to resolve the base class. --&gt;
            &lt;optional&gt; &lt;attribute name="classrefs"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="interfacerefs"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="mixinrefs"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc" /&gt; &lt;/optional&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Import"/&gt;
                    &lt;ref name="Class"/&gt;
                    &lt;ref name="Namespace"/&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Namespace"&gt;
        &lt;element name="scope"&gt;
            &lt;attribute name="ilk" value="namespace"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="lineend"/&gt; &lt;/optional&gt;
            &lt;!-- Special attributes:
                None. See common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="signature"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="interfacerefs"/&gt; &lt;/optional&gt;
            &lt;!-- XXX Can a Ruby module include mixins? --&gt;
            &lt;optional&gt; &lt;attribute name="mixinrefs"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc" /&gt; &lt;/optional&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Import"/&gt;
                    &lt;ref name="Namespace"/&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Interface"&gt;
        &lt;element name="scope"&gt;
            &lt;attribute name="ilk" value="interface"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="lineend"/&gt; &lt;/optional&gt;
            &lt;!-- Special attributes:
                None. See common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="signature"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="interfacerefs"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc"/&gt; &lt;/optional&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Function"&gt;
        &lt;element name="scope"&gt;
            &lt;attribute name="ilk" value="function"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="lineend"/&gt; &lt;/optional&gt;
            &lt;!-- Special function attributes:
                __ctor__
                    Used to indicate that this is a constructor for its
                    containing class.
                __classmethod__
                    Used to differentiate between class and instance methods. I
                    think most OO-capable languages have this distinct (at
                    least Python and Ruby do). Initially probably only Ruby
                    will use this.
                __instancemethod__
                    Used to indicate the method can only be called off an
                    instance.  Functions that have neither the __classmethod__
                    or __instancemethod__ attribute are assumed to be either
                    callable in either context, or not enough info is available.
                Also, see common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="signature"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc"/&gt; &lt;/optional&gt;
            &lt;!-- CITDL expression for the return type. --&gt;
            &lt;optional&gt; &lt;attribute name="returns"/&gt; &lt;/optional&gt;
            &lt;zeroOrMore&gt;
                &lt;ref name="Argument"/&gt;
            &lt;/zeroOrMore&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Import"/&gt;
                    &lt;ref name="Class"/&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;define name="Variable"&gt;
        &lt;element name="variable"&gt;
            &lt;attribute name="name"/&gt;
            &lt;optional&gt; &lt;attribute name="line"/&gt; &lt;/optional&gt;
            &lt;!-- A special ilk="constant" has been added to better support
                 variable constants (initially just for PHP), as the optional
                 attributes field (see below) can contain multiple values
                 making it more difficult to process than just a singular field.
            --&gt;
            &lt;optional&gt; &lt;attribute name="ilk"/&gt; &lt;/optional&gt;
            &lt;!-- Special variable attributes:
                __instancevar__
                    This can be used to differentiate between class instance
                    variables and static class variables. Some language, e.g.
                    Python, allow you to add attributes to class instance
                    objects on the fly.
                __const__
                    Indicates that this is a constant (if the particular
                    language distinguishes that at all, e.g. Ruby).
                Also, see common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc"/&gt; &lt;/optional&gt;
            &lt;!-- CITDL expression type inference for this variable.
                 E.g., if a Python variable "foo" is a list this will be
                 "list". --&gt;
            &lt;optional&gt; &lt;attribute name="citdl"/&gt; &lt;/optional&gt;
            &lt;!-- A variable can have behave as a namespace in JavaScript. --&gt;
            &lt;zeroOrMore&gt;
                &lt;choice&gt;
                    &lt;ref name="Class"/&gt;
                    &lt;ref name="Function"/&gt;
                    &lt;ref name="Variable"/&gt;
                &lt;/choice&gt;
            &lt;/zeroOrMore&gt;
        &lt;/element&gt;
    &lt;/define&gt;

    &lt;!-- A function argument. Otherwise, very similar to Variable. 
         XXX PHP CILE is putting "default" attributes on arguments which,
             technically is not in the spec. If they prove useful though, go
             crazy.
      --&gt;
    &lt;define name="Argument"&gt;
        &lt;element name="variable"&gt;
            &lt;attribute name="ilk" value="argument"/&gt;
            &lt;attribute name="name"/&gt;
            &lt;!-- XXX Consider adding a __block__ or __ruby_block__
                 attribute at some point for Ruby block params.
                Also, see common attributes at the top of the file.
            --&gt;
            &lt;optional&gt; &lt;attribute name="attributes"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="citdl"/&gt; &lt;/optional&gt;
            &lt;optional&gt; &lt;attribute name="doc"/&gt; &lt;/optional&gt;
        &lt;/element&gt;
    &lt;/define&gt;
&lt;/grammar&gt;

</t>
<t tx="ekr.20080121105837.1855">@ These contain .cix files describing various libraries.

Examples:
    
javascript.cix
python-2.4.cix
python-2.5.cix</t>
<t tx="ekr.20080121105857"></t>
<t tx="ekr.20080121121728.1">#!python


"""The API catalogs-zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

@language python
@tabwidth -4

&lt;&lt; imports &gt;&gt;

#---- globals
log = logging.getLogger("codeintel.db")


@others
</t>
<t tx="ekr.20080121121728.3">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.4">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.5">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.6">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.7">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.8">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121121728.9">#!python
# ***** LICENSE BLOCK *****

"""the codeintel database (start by reading database/database.py)"""

@language python
@tabwidth -4

</t>
<t tx="ekr.20080121121842">import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile, normpath,
                     normcase)
import cPickle as pickle
import threading
import time
import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner, hotshotit
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.util import filter_blobnames_for_prefix
from codeintel2.database.resource import AreaResource
</t>
<t tx="ekr.20080121121842.1">#log.setLevel(logging.DEBUG)



#---- Database zone and lib implementations

class CatalogsZone(object):
    """Singleton zone managing the db/catalogs/... area.

    TODO: Locking: .cull_mem() and .save() will be called periodically
          on indexer thread. Anything they access needs to be guarded.
    """
    _res_index = None
    _blob_index = None
    _toplevelname_index = None
    _toplevelprefix_index = None
    
    _have_updated_at_least_once = False

    @others
</t>
<t tx="ekr.20080121121842.2">def __init__(self, mgr, catalog_dirs=None):
    self.mgr = mgr
    self.db = mgr.db

    if catalog_dirs is None:
        catalog_dirs = []
    assert isinstance(catalog_dirs, list)
    std_catalog_dir = join(dirname(dirname(abspath(__file__))), "catalogs")
    if std_catalog_dir not in catalog_dirs:
        catalog_dirs.append(std_catalog_dir)
    self.catalog_dirs = catalog_dirs

    self.base_dir = join(self.db.base_dir, "db", "catalogs")

    self._lib_cache = {} # (lang, selection_res_ids) -&gt; CatalogLib

    self._lock = threading.RLock()
    self._blob_and_atime_from_blobname_from_lang_cache = {}
    self._dbsubpaths_and_lpaths_to_save = []

</t>
<t tx="ekr.20080121121842.3">def __repr__(self):
    return "&lt;catalog zone&gt;"

</t>
<t tx="ekr.20080121121842.4">def _selection_from_selector(self, selections):
    """Given a sequence of catalog selection strings (each is a
    catalog name or full path to a catalog .cix file) return a dict
    mapping:

        &lt;normalized-selector&gt; -&gt; &lt;selection-string&gt;

    If "selections" is None, this returns None.
    """
    if selections is None:
        return None
    selection_from_selector = {}
    for selection in selections:
        if isabs(selection):
            selector = normpath(normcase(selection))
        else:
            selector = selection.lower()
        selection_from_selector[selector] = selection
    return selection_from_selector

</t>
<t tx="ekr.20080121121842.5">_res_ids_from_selector_cache = None
def _res_ids_from_selections(self, selections):
    """Returns a tuple of the database resource ids for the given
    selections and a list of selections that didn't match any loaded
    resources.
    """
    if self._res_ids_from_selector_cache is None:
        cache = self._res_ids_from_selector_cache = {}
        for cix_area_path, res_data in self.res_index.items():
            cix_path = AreaResource(cix_area_path).path
            res_id = res_data[0]
            cache[normpath(normcase(cix_path))] = [res_id]
            name = splitext(basename(cix_path))[0].lower()
            if name not in cache:
                cache[name] = []
            cache[name].append(res_id)
        log.debug("_res_ids_from_selector_cache: %r", cache)

    res_ids = []
    missing_selections = []
    for selector, selection \
        in self._selection_from_selector(selections).items():
        try:
            res_ids += self._res_ids_from_selector_cache[selector]
        except KeyError, ex:
            missing_selections.append(selection)
    log.debug("_res_ids_from_selections: res_ids=%r", res_ids)
    return tuple(res_ids), missing_selections

</t>
<t tx="ekr.20080121121842.6">def get_lib(self, lang, selections=None, attempt_load_if_necessary=False):
    """Return a CatalogLib for the given lang and selections.

        ...
        "attempt_load_if_necessary" (optional, default False) is a
            boolean indicating if an attempt should be made to load
            available catalogs for missing selections.
    """
    assert not isinstance(selections, basestring),\
        "catalog lib 'selections' must be None or a sequence, not %r: %r"\
        % (type(selections), selections)
    if not self._have_updated_at_least_once:
        self.update(selections)

    if selections is not None:
        selection_res_ids, missing_selections \
            = self._res_ids_from_selections(selections)
        if missing_selections and attempt_load_if_necessary:
            self.update(missing_selections)
            selection_res_ids, missing_selections \
                = self._res_ids_from_selections(selections)
        if missing_selections:
            log.warn("the following catalog selections didn't match "
                     "any loaded API catalog: '%s'",
                     "', '".join(missing_selections))
    else:
        selection_res_ids = None
    key = (lang, selection_res_ids)
    if key not in self._lib_cache:
        self._lib_cache[key] = CatalogLib(self, lang,
                                          selections, selection_res_ids)
    return self._lib_cache[key]

</t>
<t tx="ekr.20080121121842.7">@property
def res_index(self):
    """Load and return the resource index (res_index)."""
    if self._res_index is None:
        idxpath = join(self.base_dir, "res_index")
        self._res_index = self.db.load_pickle(idxpath, {})
    return self._res_index

</t>
<t tx="ekr.20080121121842.8">@property
def blob_index(self):
    """Load and return the blob index (blob_index)."""
    if self._blob_index is None:
        idxpath = join(self.base_dir, "blob_index")
        self._blob_index = self.db.load_pickle(idxpath, {})
    return self._blob_index

</t>
<t tx="ekr.20080121121842.9">@property
def toplevelname_index(self):
    """Load and return the top-level name index (toplevelname_index)."""
    if self._toplevelname_index is None:
        idxpath = join(self.base_dir, "toplevelname_index")
        self._toplevelname_index = self.db.load_pickle(idxpath, {})
    return self._toplevelname_index

</t>
<t tx="ekr.20080121121842.10">@property
def toplevelprefix_index(self):
    """Load and return the top-level prefix index (toplevelprefix_index)."""
    if self._toplevelprefix_index is None:
        idxpath = join(self.base_dir, "toplevelprefix_index")
        self._toplevelprefix_index = self.db.load_pickle(idxpath, {})
    return self._toplevelprefix_index

</t>
<t tx="ekr.20080121121842.11">def save(self):
    self._lock.acquire()
    try:
        for dbsubpath, lpaths in self._dbsubpaths_and_lpaths_to_save:
            self.db.save_pickle(join(self.base_dir, dbsubpath), lpaths)
        self._dbsubpaths_and_lpaths_to_save = []
    finally:
        self._lock.release()

</t>
<t tx="ekr.20080121121842.12">def cull_mem(self):
    """Drop blobs from cache that have not been accessed in over 5
    minutes.

    To attempt to keep memory consumption under control we want to
    ensure we don't keep everything cached from the db in memory
    until process completion.
    """
    #TOTEST: Does Python/Komodo actually release this memory or
    #        are we kidding ourselves?
    self._lock.acquire()
    try:
        N = 10
        if len(self._blob_and_atime_from_blobname_from_lang_cache) &lt; N:
            # Too few blobs in memory to bother culling.
            return

        log.info("catalog: culling memory")
        now = time.time()
        for lang, blob_and_atime_from_blobname \
            in self._blob_and_atime_from_blobname_from_lang_cache.items():
            for blobname, (blob, atime) in blob_and_atime_from_blobname.items():
                if now - atime &gt; 300.0: # &gt;5 minutes since last access
                    del blob_and_atime_from_blobname[blobname]
    finally:
        self._lock.release()

</t>
<t tx="ekr.20080121121842.13">def avail_catalogs(self, selections=None):
    """Generate a list of available catalogs.

        "selections" (optional) is a list of string of the same form
            as to `.get_lib()'. It is used to determine the boolean
            value of &lt;selected&gt; in the yielded tuples.

    Generated dicts as follows:
        {"name": &lt;catalog-name&gt;,    # 'name' attr of &lt;codeintel&gt; tag
                                    #   or file basename
         "lang": &lt;lang&gt;,            # 'lang' attribute of first &lt;file&gt; tag
         "description": &lt;desc&gt;,     # 'description' attr of &lt;codeintel&gt;
         "cix_path": &lt;cix-path&gt;,
         "selected": &lt;selected&gt;,
         "selection": &lt;selection&gt;,
        }
    where &lt;selected&gt; is boolean indicating if this catalog is
    selected according to "selections" and &lt;selection&gt; is the string
    in "selections" that resulted in this.
    """
    selection_from_selector = self._selection_from_selector(selections)
    for cix_path in (cix_path for d in self.catalog_dirs if exists(d)
                     for cix_path in glob(join(d, "*.cix"))):
        name = lang = description = None
        try:
            for event, elem in ET.iterparse(cix_path, events=("start",)):
                if elem.tag == "codeintel":
                    name = elem.get("name")
                    description = elem.get("description")
                elif elem.tag == "file":
                    lang = elem.get("lang")
                    break
        except ET.XMLParserError, ex:
            log.warn("%s: error reading catalog, skipping it (%s)",
                     cix_path, ex)
            continue
        if lang is None:
            log.warn("%s: no 'lang' attribute on catalog &lt;file&gt; tag, "
                     "skipping it", cix_path)
            continue
        if name is None:
            name = splitext(basename(cix_path))[0]
        norm_name = name.lower()
        norm_cix_path = normpath(normcase(cix_path))
        if selection_from_selector is None:
            selected = True
            selection = None
        else:
            selection = (selection_from_selector.get(norm_name)
                         or selection_from_selector.get(norm_cix_path))
            selected = selection is not None
        yield {"name": name,
               "lang": lang,
               "description": description,
               "cix_path": cix_path,
               "selected": selected,
               "selection": selection}

</t>
<t tx="ekr.20080121121842.14">def update(self, selections=None, progress_cb=None):
    """Update the catalog as necessary.
    
        "selections" (optional) is a list of string of the same form
            as to `.get_lib()' -- used here to filter the catalogs
            that we consider for updating.
        "progress_cb" (optional) is a callable that is called as
            follows to show the progress of the update:
                progress_cb(&lt;desc&gt;, &lt;value&gt;)
            where &lt;desc&gt; is a short string describing the current step
            and &lt;value&gt; is an integer between 0 and 100 indicating the
            level of completeness.
    """
    self._have_updated_at_least_once = True

    # Figure out what updates need to be done...
    if progress_cb:
        try:    progress_cb("Determining necessary catalog updates...", 5)
        except: log.exception("error in progress_cb (ignoring)")
    res_name_from_res_path = dict(  # this is our checklist
        (p, v[2]) for p,v in self.res_index.items())
    todos = []
    log.info("updating %s: %d catalog dir(s)", self,
             len(self.catalog_dirs))
    for catalog_info in self.avail_catalogs(selections):
        cix_path = catalog_info["cix_path"]
        res = AreaResource(cix_path)
        # check that the update-time is the mtime (i.e. up-to-date)
        try:
            res_id, last_updated, name, res_data \
                = self.res_index[res.area_path]
        except KeyError:
            # add this new CIX file
            todos.append(("add", res, catalog_info["name"]))
        else:
            mtime = os.stat(cix_path).st_mtime
            if last_updated != mtime: # epsilon? '&gt;=' instead of '!='?
                # update with newer version
                todos.append(("update", res, catalog_info["name"]))
            #else:
            #    log.debug("not updating '%s' catalog: mtime is unchanged",
            #              catalog_info["name"])
            del res_name_from_res_path[res.area_path] # tick it off

    for res_area_path, res_name in res_name_from_res_path.items():
        # remove this obsolete CIX file
        try:
            todos.append( ("remove", AreaResource(res_area_path), res_name) )
        except ValueError, ex:
            # Skip resources in unknown areas. This is primarily to
            # allow debugging/testing (when the set of registered
            # path_areas may not include the set when running in
            # Komodo.)
            pass

    # Filter todos on selections, if any.
    if selections is not None:
        selection_from_selector = self._selection_from_selector(selections)
        before = todos[:]
        todos = [todo for todo in todos
            if todo[2].lower() in selection_from_selector
            or normpath(normcase(todo[1].path)) in selection_from_selector
        ]

    # ... and then do them.
    if not todos:
        return
    for i, (action, res, name) in enumerate(todos):
        log.debug("%s `%s' catalog (%s)", action, name, res)
        try:
            if action == "add":
                desc = "Adding '%s' API catalog" % basename(res.subpath)
                self.db.report_event(desc)
                if progress_cb:
                    try:    progress_cb(desc, (5 + 95/len(todos)*i))
                    except: log.exception("error in progress_cb (ignoring)")
                self._add_res(res)
            elif action == "remove":
                desc = "Removing '%s' API catalog" % basename(res.subpath)
                self.db.report_event(desc)
                if progress_cb:
                    try:    progress_cb(desc, (5 + 95/len(todos)*i))
                    except: log.exception("error in progress_cb (ignoring)")
                self._remove_res(res)
            elif action == "update":
                desc = "Updating '%s' API catalog" % basename(res.subpath)
                self.db.report_event(desc)
                if progress_cb:
                    try:    progress_cb(desc, (5 + 95/len(todos)*i))
                    except: log.exception("error in progress_cb (ignoring)")
                #XXX Bad for filesystem. Change this to do it
                #    more intelligently if possible.
                self._remove_res(res)
                self._add_res(res)
        except DatabaseError, ex:
            log.warn("%s (skipping)" % ex)

    if progress_cb:
        try:    progress_cb("Saving catalog indeces...", 95)
        except: log.exception("error in progress_cb (ignoring)")
    self._res_ids_from_selector_cache = None # invalidate this cache
    if self._res_index is not None:
        self.db.save_pickle(
            join(self.base_dir, "res_index"),
            self._res_index)
    if self._blob_index is not None:
        self.db.save_pickle(
            join(self.base_dir, "blob_index"),
            self._blob_index)
    if self._toplevelname_index is not None:
        self.db.save_pickle(
            join(self.base_dir, "toplevelname_index"),
            self._toplevelname_index)
    if self._toplevelprefix_index is not None:
        self.db.save_pickle(
            join(self.base_dir, "toplevelprefix_index"),
            self._toplevelprefix_index)

</t>
<t tx="ekr.20080121121842.15">_existing_res_ids_cache = None
_new_res_id_counter = 0
def _new_res_id(self):
    if self._existing_res_ids_cache is None:
        self._existing_res_ids_cache \
            = dict((d[0], True) for d in self.res_index.values())
    while True:
        if self._new_res_id_counter not in self._existing_res_ids_cache:
            new_res_id = self._new_res_id_counter
            self._new_res_id_counter += 1
            self._existing_res_ids_cache[new_res_id] = True
            return new_res_id
        self._new_res_id_counter += 1

</t>
<t tx="ekr.20080121121842.16">def _remove_res(self, res):
    LEN_PREFIX = self.db.LEN_PREFIX
    res_id, last_updated, name, res_data = self.res_index[res.area_path]
    # res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
    for lang, tfifb in res_data.items():
        dbfile_and_res_id_from_blobname = self.blob_index[lang]
        for blobname, toplevelnames_from_ilk in tfifb.items():
            # Update 'blob_index' for $lang.
            dbfile, res_id = dbfile_and_res_id_from_blobname[blobname]
            del dbfile_and_res_id_from_blobname[blobname]

            # Remove ".blob" file (and associated caches).
            pattern = join(self.base_dir, safe_lang_from_lang(lang),
                           dbfile+".*")
            try:
                for path in glob(pattern):
                    log.debug("fs-write: remove catalog %s blob file '%s'",
                              lang, basename(path))
                    os.remove(path)
            except EnvironmentError, ex:
                #XXX If get lots of these, then try harder. Perhaps
                #    creating a zombies area, or creating a list of
                #    them: self.db.add_zombie(dbpath).
                #XXX THis isn't a correct analysis: the dbfile may just
                #    not have been there.
                log.warn("could not remove dbfile '%s' (%s '%s'): "
                         "leaving zombie", dbpath, lang, blobname)

            # Update 'toplevel*_index' for $lang.
            # toplevelname_index:   {lang -&gt; ilk -&gt; toplevelname -&gt; res_id -&gt; blobnames}
            # toplevelprefix_index: {lang -&gt; ilk -&gt; prefix -&gt; res_id -&gt; toplevelnames}
            for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                try:
                    bfrft = self.toplevelname_index[lang][ilk]
                    for toplevelname in toplevelnames:
                        del bfrft[toplevelname][res_id]
                        if not bfrft[toplevelname]:
                            del bfrft[toplevelname]
                except KeyError, ex:
                    self.db.corruption("CatalogsZone._remove_res",
                        "error removing top-level names of ilk '%s' for "
                            "'%s' resource from toplevelname_index: %s"
                            % (ilk, basename(res.path), ex),
                        "ignore")

                try:
                    tfrfp = self.toplevelprefix_index[lang][ilk]
                    for toplevelname in toplevelnames:
                        prefix = toplevelname[:LEN_PREFIX]
                        del tfrfp[prefix][res_id]
                        if not tfrfp[prefix]:
                            del tfrfp[prefix]
                except KeyError, ex:
                    self.db.corruption("CatalogsZone._remove_res",
                        "error removing top-level name of ilk '%s' for "
                            "'%s' resource from toplevelprefix_index: %s"
                            % (ilk, basename(res.path), ex),
                        "ignore")

    del self.res_index[res.area_path]

</t>
<t tx="ekr.20080121121842.17">def _add_res(self, res):
    cix_path = res.path
    try:
        tree = tree_from_cix_path(cix_path)
    except ET.XMLParserError, ex:
        log.warn("could not load `%s' into catalog (skipping): %s",
                 cix_path, ex)
        return

    LEN_PREFIX = self.db.LEN_PREFIX
    res_id = self._new_res_id()
    res_data = {}   # {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
    name = tree.get("name") or splitext(basename(cix_path))[0]
    for blob in tree.findall("file/scope"):
        lang, blobname = blob.get("lang"), blob.get("name")
        if not lang:
            raise DatabaseError("add `%s': no 'lang' attr on %r"
                                % (res, blob))

        # Create 'res_data'.
        tfifb = res_data.setdefault(lang, {})
        toplevelnames_from_ilk = tfifb.setdefault(blobname, {})
        if lang in self.db.import_everything_langs:
            for toplevelname, elem in blob.names.iteritems():
                ilk = elem.get("ilk") or elem.tag
                if ilk not in toplevelnames_from_ilk:
                    toplevelnames_from_ilk[ilk] = set([toplevelname])
                else:
                    toplevelnames_from_ilk[ilk].add(toplevelname)

        # Update 'toplevel*_index'.
        # toplevelname_index:   {lang -&gt; ilk -&gt; toplevelname -&gt; res_id -&gt; blobnames}
        # toplevelprefix_index: {lang -&gt; ilk -&gt; prefix -&gt; res_id -&gt; toplevelnames}
        bfrftfi = self.toplevelname_index.setdefault(lang, {})
        tfrfpfi = self.toplevelprefix_index.setdefault(lang, {})
        for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
            bfrft = bfrftfi.setdefault(ilk, {})
            tfrfp = tfrfpfi.setdefault(ilk, {})
            for toplevelname in toplevelnames:
                bfr = bfrft.setdefault(toplevelname, {})
                if res_id not in bfr:
                    bfr[res_id] = set([blobname])
                else:
                    bfr[res_id].add(blobname)
                prefix = toplevelname[:LEN_PREFIX]
                tfr = tfrfp.setdefault(prefix, {})
                if res_id not in tfr:
                    tfr[res_id] = set([toplevelname])
                else:
                    tfr[res_id].add(toplevelname)

        # Update 'blob_index'.
        dbfile_and_res_id_from_blobname \
            = self.blob_index.setdefault(lang, {})
        assert blobname not in dbfile_and_res_id_from_blobname, \
               ("codeintel: %s %r blob in `%s' collides "
                "with existing %s %r blob in catalog: "
                "XXX haven't decided how to deal with that yet"
                % (lang, blobname, cix_path, lang, blobname))
        dbfile = self.db.bhash_from_blob_info(cix_path, lang, blobname)
        dbfile_and_res_id_from_blobname[blobname] = (dbfile, res_id)

        # Write out '.blob' file.
        dbdir = join(self.base_dir, safe_lang_from_lang(lang))
        if not exists(dbdir):
            log.debug("fs-write: mkdir '%s'", dbdir)
            os.makedirs(dbdir)
        log.debug("fs-write: catalog %s blob '%s'", lang, dbfile)
        ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))

    # Update 'res_index'.
    last_updated = os.stat(cix_path).st_mtime
    self.res_index[res.area_path] \
        = (res_id, last_updated, name, res_data)

</t>
<t tx="ekr.20080121121842.18">def res_id_from_lang_and_blobname(self, lang, blobname):
    try:
        dbfile, res_id = self.blob_index[lang][blobname]
    except KeyError:
        return None
    else:
        return res_id

</t>
<t tx="ekr.20080121121842.19">def get_blob(self, lang, blobname, look_in_cache_only=False):
    try:
        dbfile, res_id = self.blob_index[lang][blobname]
    except KeyError:
        return None

    # If index path is in the cache: return it, update its atime.
    now = time.time()
    blob_and_atime_from_blobname \
        = self._blob_and_atime_from_blobname_from_lang_cache.setdefault(lang, {})
    if blobname in blob_and_atime_from_blobname:
        log.debug("cache-read: load %s blob `%s'", lang, blobname)
        blob, atime = blob_and_atime_from_blobname[blobname]
        blob_and_atime_from_blobname[blobname] = (blob, now)
        return blob

    # Need to load and cache it.
    if look_in_cache_only:
        return None
    dbsubpath = join(self.base_dir, safe_lang_from_lang(lang), dbfile)
    blob = self.db.load_blob(dbsubpath)
    blob_and_atime_from_blobname[blobname] = (blob, now)
    return blob

</t>
<t tx="ekr.20080121121842.20">def lpaths_from_lang_and_blobname(self, lang, blobname):
    """Get lpaths for the named blob.

    We get it from the blob's "lpaths" cache key (calculating that
    if necessary).
    """
    blob = self.get_blob(lang, blobname, look_in_cache_only=True)
    if blob is not None: 
        if "lpaths" in blob.cache:
            return blob.cache["lpaths"]
    else:
        blob = self.get_blob(lang, blobname)
        if blob is None:
            raise NotFoundInDatabase("%s '%s' blob not found in catalogs"
                                     % (lang, blobname))
        if "lpaths" in blob.cache:
            return blob.cache["lpaths"]

    # Need to calculate lpaths from 'blob'.
    log.debug("calc symbol info for %s '%s' catalog blob", lang, blobname)
    langintel = self.mgr.langintel_from_lang(lang)
    lpaths = langintel.lpaths_from_blob(blob)

    # Update cache and queue this up to be saved to disk (by .save()).
    blob.cache["lpaths"] = lpaths
    dbfile, res_id = self.blob_index[lang][blobname]
    self._lock.acquire()
    try:
        self._dbsubpaths_and_lpaths_to_save.append(
            (join(safe_lang_from_lang(lang), dbfile+".lpaths"), lpaths)
        )
    finally:
        self._lock.release()

    return lpaths


</t>
<t tx="ekr.20080121121842.21">class CatalogLib(object):
    """A light lang-specific and selection-filtered view on the whole
    CatalogsZone.
    """
    name = "cataloglib"

    @others
</t>
<t tx="ekr.20080121121842.22">def __init__(self, catalogs_zone, lang,
             selections=None, selection_res_ids=None):
    self.catalogs_zone = catalogs_zone
    self.lang = lang
    self.selections = selections
    if selection_res_ids is None:
        self.selection_res_id_set = None
    else:
        self.selection_res_id_set = set(selection_res_ids)
    self._import_handler = None
    self._blob_imports_from_prefix_cache = {}
    
</t>
<t tx="ekr.20080121121842.23">_repr_cache = None
def __repr__(self):
    if self._repr_cache is None:
        # Include the base names of the selected resources in the name.
        if self.selection_res_id_set is None:
            selection_names = ['(all)']
        else:
            selection_names = []
            for s in self.selections:
                if isabs(s):
                    selection_names.append(splitext(basename(s))[0])
                else:
                    selection_names.append(s)
        self._repr_cache = "&lt;%s cataloglib: %s&gt;"\
                           % (self.lang, ', '.join(selection_names))
    return self._repr_cache

</t>
<t tx="ekr.20080121121842.24">@property
def import_handler(self):
    if self._import_handler is None:
        self._import_handler \
            = self.catalogs_zone.mgr.citadel.import_handler_from_lang(self.lang)
    return self._import_handler

</t>
<t tx="ekr.20080121121842.25">def has_blob(self, blobname):
    res_id = self.catalogs_zone.res_id_from_lang_and_blobname(self.lang,
                                                              blobname)
    if res_id is None:
        return False
    if self.selection_res_id_set is None:
        return True
    return res_id in self.selection_res_id_set

</t>
<t tx="ekr.20080121121842.26">def get_blob(self, blobname):
    if not self.has_blob(blobname): # knows how to filter on selections
        return None
    return self.catalogs_zone.get_blob(self.lang, blobname)

</t>
<t tx="ekr.20080121121842.27">def get_blob_imports(self, prefix):
    """Return the set of imports under the given prefix.

        "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
            for "import xml.sax." in Python. Or ("XML", "Parser") for
            "use XML::Parser::" in Perl.

    See description in database.py docstring for details.
    """
    # This code works fine if prefix is the empty tuple.
    if prefix not in self._blob_imports_from_prefix_cache:
        try:
            dbfile_and_res_id_from_blobname \
                = self.catalogs_zone.blob_index[self.lang]
        except KeyError:
            return set()
        
        if self.selection_res_id_set is None:
            matches = filter_blobnames_for_prefix(
                dbfile_and_res_id_from_blobname,
                prefix,
                self.import_handler.sep)
        else:
            matches = filter_blobnames_for_prefix(
                (bn
                 for bn, (f, res_id) in dbfile_and_res_id_from_blobname.items()
                 if res_id in self.selection_res_id_set),
                prefix,
                self.import_handler.sep)
        self._blob_imports_from_prefix_cache[prefix] = matches
    return self._blob_imports_from_prefix_cache[prefix]

</t>
<t tx="ekr.20080121121842.28">def _blobnames_from_toplevelname(self, toplevelname, ilk=None):
    """Yield all blobnames in the currently selected catalogs
    with the given toplevelname.
    
    If "ilk" is given then only symbols of that ilk will be considered.
    """
    # toplevelname_index: {lang -&gt; ilk -&gt; toplevelname -&gt; res_id -&gt; blobnames}
    if self.lang in self.catalogs_zone.toplevelname_index:
        for i, potential_bfrft \
            in self.catalogs_zone.toplevelname_index[self.lang].iteritems():
            if ilk is not None and i != ilk:
                continue
            if toplevelname not in potential_bfrft:
                continue
            potential_bfr = potential_bfrft[toplevelname]
            if self.selection_res_id_set is None:
                for blobnames in potential_bfr.itervalues():
                    for blobname in blobnames:
                        yield blobname
            else:
                for res_id, blobnames in potential_bfr.iteritems():
                    if res_id not in self.selection_res_id_set:
                        continue
                    for blobname in blobnames:
                        yield blobname

</t>
<t tx="ekr.20080121121842.29">def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
    assert isinstance(lpath, tuple)  # common mistake to pass in a string
    
    hits = []
    for blobname in self._blobnames_from_toplevelname(lpath[0]):
        lpaths = self.catalogs_zone.lpaths_from_lang_and_blobname(
                    self.lang, blobname)
        if lpath not in lpaths: continue
        blob = self.catalogs_zone.get_blob(self.lang, blobname)
        #TODO: Convert lpath's in tree-evalrs to tuples instead of lists.
        elem = _elem_from_scoperef( (blob, list(lpath)) )
        hits.append( (elem, (blob, list(lpath[:-1]))) )

    return hits

</t>
<t tx="ekr.20080121121842.30">def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk in all selected blobs in this lib.
    
        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).

    Note: the list is not sorted, because often some special sorting
    is required for the different completion evaluators that might use
    this API.
    """
    cplns = []
    if prefix is None:
        # Use 'toplevelname_index':
        #   {lang -&gt; ilk -&gt; toplevelname -&gt; res_id -&gt; blobnames}
        toplevelname_index = self.catalogs_zone.toplevelname_index
        if self.lang in toplevelname_index:
            if ilk is not None:
                try:
                    bfrft = toplevelname_index[self.lang][ilk]
                except KeyError:
                    pass
                else:
                    if self.selection_res_id_set is None:
                        cplns += [(ilk, t) for t in bfrft]
                    else:
                        cplns += [(ilk, t) for t, bfr in bfrft.iteritems()
                                  if self.selection_res_id_set.intersection(bfr)]
            elif self.selection_res_id_set is None:
                for i, bfrft in toplevelname_index[self.lang].iteritems():
                    cplns += [(i, t) for t in bfrft]
            else: # ilk=None, have a selection set
                for i, bfrft in toplevelname_index[self.lang].iteritems():
                    cplns += [(i, t) for t, bfr in bfrft.iteritems()
                              if self.selection_res_id_set.intersection(bfr)]
    else:
        # Use 'toplevelprefix_index':
        #   {lang -&gt; ilk -&gt; prefix -&gt; res_id -&gt; toplevelnames}
        toplevelprefix_index = self.catalogs_zone.toplevelprefix_index
        if self.lang in toplevelprefix_index:
            if ilk is not None:
                try:
                    tfr = toplevelprefix_index[self.lang][ilk][prefix]
                except KeyError:
                    pass
                else:
                    if self.selection_res_id_set is None:
                        cplns += [(ilk, t)
                                  for toplevelnames in tfr.itervalues()
                                  for t in toplevelnames]
                    else:
                        cplns += [(ilk, t)
                                  for r in self.selection_res_id_set.intersection(tfr)
                                  for t in tfr[r]]
            elif self.selection_res_id_set is None:
                for i, tfrfp in toplevelprefix_index[self.lang].iteritems():
                    if prefix not in tfrfp:
                        continue
                    cplns += [(i, t)
                              for toplevelnames in tfrfp[prefix].itervalues()
                              for t in toplevelnames]
            else: # ilk=None, have a selection set
                for i, tfrfp in toplevelprefix_index[self.lang].iteritems():
                    if prefix not in tfrfp:
                        continue
                    tfr = tfrfp[prefix]
                    cplns += [(i, t)
                              for r in self.selection_res_id_set.intersection(tfr)
                              for t in tfr[r]]
    return cplns



</t>
<t tx="ekr.20080121121842.31">#---- internal support routines

def _elem_from_scoperef(scoperef):
    """A scoperef is (&lt;blob&gt;, &lt;lpath&gt;). Return the actual elem in
    the &lt;blob&gt; ciElementTree being referred to.
    """
    elem = scoperef[0]
    for lname in scoperef[1]:
        elem = elem.names[lname]
    return elem


</t>
<t tx="ekr.20080121121842.32">#!python
# ***** LICENSE BLOCK *****

"""The langzone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import threading
import time
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy

import ciElementTree as ET
from codeintel2.common import *
from codeintel2 import util



#---- globals

log = logging.getLogger("codeintel.db")
</t>
<t tx="ekr.20080121121842.33">#log.setLevel(logging.DEBUG)



#---- Database zone and lib implementations

class LangDirsLib(object):
    """A zone providing a view into an ordered list of dirs in a
    db/$lang/... area of the db.

    These are dished out via Database.get_lang_lib(), which indirectly
    then is dished out by the LangZone.get_lib(). Mostly this is just a
    view on the LangZone singleton for this particular language.

    Dev Notes:
    - The goal is to provide quick has_blob() and get_blob() -- i.e.
      some caching is involved (if 'foo' referred to
      'some/path/to/foo.py' a minute ago then it still does). As well,
      scanning/loading is done automatically as necessary. For example,
      if a request for Perl blob 'Bar' is made but there is no 'Bar' in
      the database yet, this code looks for a 'Bar.pm' on the file
      system and will scan it, load it and return the blob for it.
    """
    @others
</t>
<t tx="ekr.20080121121842.34">def __init__(self, lang_zone, lock, lang, name, dirs):
    self.lang_zone = lang_zone
    self._lock = lock
    self.mgr = lang_zone.mgr
    self.lang = lang
    self.name = name
    self.dirs = dirs
    self.import_handler \
        = self.mgr.citadel.import_handler_from_lang(self.lang)

    self._blob_imports_from_prefix_cache = {}
    self._have_ensured_scanned_from_dir_cache = {}
    self._importables_from_dir_cache = {}

    # We keep a "weak" merged cache of blobname lookup for all dirs
    # in this zone -- where "weak" means that we verify a hit by
    # checking the current real blob_index for that dir (which may
    # have changed). This caching slows down lookup for single-dir
    # LangDirsZones, but should scale better for LangDirsZones with
    # many dirs. (TODO-PERF: test this assertion.)
    self._dir_and_blobbase_from_blobname = {}

</t>
<t tx="ekr.20080121121842.35">def __repr__(self):
    return "&lt;%s %s&gt;" % (self.lang, self.name)

</t>
<t tx="ekr.20080121121842.36">def _acquire_lock(self):
    self._lock.acquire()
</t>
<t tx="ekr.20080121121842.37">def _release_lock(self):
    self._lock.release()

</t>
<t tx="ekr.20080121121842.38">def has_blob(self, blobname, ctlr=None):
    dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
    return dbsubpath is not None

</t>
<t tx="ekr.20080121121842.39">def has_blob_in_db(self, blobname, ctlr=None):
    """Return true if the blobname is in the database.

    Typically this method is only used for debugging and .has_blob()
    is what you want.
    """
    dbsubpath = self._dbsubpath_from_blobname(
        blobname, ctlr=ctlr, only_look_in_db=True)
    return dbsubpath is not None

</t>
<t tx="ekr.20080121121842.40">def get_blob(self, blobname, ctlr=None):
    self._acquire_lock()
    try:
        dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
        if dbsubpath is not None:
            return self.lang_zone.load_blob(dbsubpath)
        else:
            return None
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.41">def get_blob_imports(self, prefix):
    """Return the set of imports under the given prefix.

        "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
            for "import xml.sax." in Python. Or ("XML", "Parser") for
            "use XML::Parser::" in Perl.

    See description in database.py docstring for details.
    """
    self._acquire_lock()
    try:
        if prefix not in self._blob_imports_from_prefix_cache:
            if prefix:
                for dir in self.dirs:
                    importables = self._importables_from_dir(dir)
                    if prefix[0] in importables:
                        sub_importables = self._importables_from_dir(
                            join(dir, *prefix))
                        imports = set(
                            (name, is_dir_import)
                            for name, (_, _, is_dir_import)
                            in sub_importables.items()
                        )
                        break
                else:
                    imports = set()
            else:
                imports = set()
                for dir in self.dirs:
                    importables = self._importables_from_dir(dir)
                    imports.update(
                        (name, is_dir_import)
                        for name, (_, _, is_dir_import)
                        in importables.items()
                    )
            self._blob_imports_from_prefix_cache[prefix] = imports
        return self._blob_imports_from_prefix_cache[prefix]
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.42">def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
    """Return all hits of the given lookup path.
    
    I.e. a symbol table lookup across all files in the dirs of this
    lib.

        "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
            or ['dojo', 'animation'].
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).
        "curr_buf" (optional), if specified, is the current buf for
            which this query is being made. Hits from it should be
            skipped (i.e. don't bother searching it).

    A "hit" is (&lt;CIX node&gt;, &lt;scope-ref&gt;).  Each one represent a
    scope-tag or variable-tag hit in all of the blobs for the
    execution set buffers.

    Returns the empty list if no hits.
    """
    assert isinstance(lpath, tuple)  # common mistake to pass in a string

    if curr_buf:
        curr_blobname = curr_buf.blob_from_lang.get(self.lang, {}).get("name")
        curr_buf_dir = dirname(curr_buf.path)
    
    # Naive implementation (no caching)
    hits = []
    for dir in self.dirs:
        if ctlr and ctlr.is_aborted():
            log.debug("ctlr aborted")
            break

        # Need to have (at least once) scanned all importables.
        # Responsibility for ensuring the scan data is *up-to-date*
        # is elsewhere.
        self.ensure_dir_scanned(dir, ctlr=ctlr)

        toplevelname_index = self.lang_zone.load_index(
                dir, "toplevelname_index", {})
        for blobname in toplevelname_index.get_blobnames(lpath[0], ()):
            if curr_buf and curr_buf_dir == dir and blobname == curr_blobname:
                continue
            blob = self.get_blob(blobname, ctlr=ctlr)
            try:
                elem = blob
                for p in lpath:
                    #LIMITATION: *Imported* names at each scope are
                    # not being included here. This is fine while we
                    # just care about JavaScript.
                    elem = elem.names[p]
            except KeyError:
                continue
            hits.append( (elem, (blob, list(lpath[:-1]))) )

    return hits

</t>
<t tx="ekr.20080121121842.43">def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk in all blobs in this lib.
    
        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).

    Note: the list is not sorted, because often some special sorting
    is required for the different completion evaluators that might use
    this API.
    """
    cplns = []
    # Naive implementation (no caching)
    for dir in self.dirs:
        if ctlr and ctlr.is_aborted():
            log.debug("ctlr aborted")
            break

        self.ensure_dir_scanned(dir, ctlr=ctlr)

        try:
            toplevelname_index = self.lang_zone.load_index(
                    dir, "toplevelname_index")
        except EnvironmentError:
            # No toplevelname_index for this dir likely indicates that
            # there weren't any files of the current lang in this dir.
            continue
        cplns += toplevelname_index.toplevel_cplns(prefix=prefix, ilk=ilk)
    return cplns

</t>
<t tx="ekr.20080121121842.44">def ensure_dir_scanned(self, dir, ctlr=None):
    """Ensure that all importables in this dir have been scanned
    into the db at least once.

    Note: This is identical to MultiLangDirsLib.ensure_dir_scanned().
    Would be good to share.
    """
    if dir not in self._have_ensured_scanned_from_dir_cache:
        event_reported = False
        res_index = self.lang_zone.load_index(dir, "res_index", {})
        importables = self._importables_from_dir(dir)
        for base in (i[0] for i in importables.values()
                     if i[0] is not None):
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                return
            if base not in res_index:
                if not event_reported:
                    self.lang_zone.db.report_event(
                        "scanning %s files in '%s'" % (self.lang, dir))
                    event_reported = True
                buf = self.mgr.buf_from_path(join(dir, base),
                                             lang=self.lang)
                if ctlr is not None:
                    ctlr.info("load %r", buf)
                buf.load()
        self._have_ensured_scanned_from_dir_cache[dir] = True

</t>
<t tx="ekr.20080121121842.45">def _importables_from_dir(self, dir):
    if dir not in self._importables_from_dir_cache:
        self._importables_from_dir_cache[dir] \
            = self.import_handler.find_importables_in_dir(dir)
    return self._importables_from_dir_cache[dir]

</t>
<t tx="ekr.20080121121842.46">def _dbsubpath_from_blobname(self, blobname, ctlr=None, 
                             only_look_in_db=False):
    """Return the subpath to the dbfile for the given blobname,
    or None if not found.

    Remember that this is complicated by possible multi-level
    imports. E.g. "import foo.bar" or "import foo" where 'foo'
    refers to 'foo/__init__.py'.
    """
    assert blobname is not None, "'blobname' cannot be None"
    lang_zone = self.lang_zone

    self._acquire_lock()
    try:
        # Use our weak cache to try to return quickly.
        if blobname in self._dir_and_blobbase_from_blobname:
            blobdir, blobbase \
                = self._dir_and_blobbase_from_blobname[blobname]

            # Check it. The actual info for that dir may have changed.
            dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir)
            if blobbase in dbfile_from_blobname:
                log.debug("have blob '%s' in '%s'? yes (in weak cache)",
                          blobname, blobdir)
                return join(lang_zone.dhash_from_dir(blobdir),
                            dbfile_from_blobname[blobbase])
            # Drop from weak cache.
            del self._dir_and_blobbase_from_blobname[blobname]

        # Brute force: look in each dir.
        blobparts = blobname.split(self.import_handler.sep)
        blobbase = blobparts[-1]
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("aborting search for blob '%s' on %s: "
                          "ctlr aborted", blobname, self)
                return None

            # Is the blob in 'blobdir' (i.e. a non-multi-level import
            # that has been scanned already).
            blobdir = join(dir, *blobparts[:-1])
            dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
            if blobbase in dbfile_from_blobname:
                self._dir_and_blobbase_from_blobname[blobname] \
                    = (blobdir, blobbase)
                log.debug("have blob '%s' in '%s'? yes (in dir index)", 
                          blobname, blobdir)
                return join(lang_zone.dhash_from_dir(blobdir),
                            dbfile_from_blobname[blobbase])

            importables = self._importables_from_dir(blobdir)
            # 'importables' look like, for Python:
            #   {'foo':  ('foo.py',          None,       False),
            #    'pkg':  ('pkg/__init__.py', '__init__', False)}
            # for Perl:
            #   {'LWP':  ('LWP.pm',          None,       True),
            #    'File': (None,              None,       True)}
            #    |        |                  |           `-- is-dir-import
            #    |        |                  `-- subdir-blobbase
            #    |        `-- blobfile
            #    `-- blobbase

            if blobbase not in importables:
                continue

            blobfile, subdir_blobbase, is_dir_import = importables[blobbase]
            if blobfile is None:
                # There isn't an actual importable file here -- just
                # a dir prefix to a multidir import.
                log.debug("have blob '%s' in %s? no", blobname, self)
                return None
            elif os.sep in blobfile:
                # This is an import from a subdir. We need to get a new dbf.
                blobdir = join(blobdir, dirname(blobfile))
                blobfile = basename(blobfile)
                blobbase = subdir_blobbase
                dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (in dir index)", 
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

            # The file isn't loaded.
            if not only_look_in_db:
                log.debug("%s importables in '%s':\n    %s", self.lang,
                          blobdir, importables)
                log.debug("'%s' likely provided by '%s' in '%s': "
                          "attempting load", blobname, blobfile, blobdir)
                buf = self.mgr.buf_from_path(
                        join(blobdir, blobfile), self.lang)
                buf.load()

                dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, {})
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (after load)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

        log.debug("have blob '%s' in %s? no", blobname, self)
        return None
    finally:
        self._release_lock()


</t>
<t tx="ekr.20080121121842.47">class LangTopLevelNameIndex(object):
    """A wrapper around the plain-dictionary toplevelname_index for a
    LangZone dir to provide better performance for continual updating
    and some simpler access.

        {ilk -&gt; toplevelname -&gt; blobnames}

    # Problem

    A 'toplevelname_index' is a merge of {blobname -&gt; ilk -&gt; toplevelnames}
    data for all resources in its dir.  As those resources are
    continually re-scanned (e.g. as a file is edited in Komodo), it
    would be too expensive to update this index everytime.

    # Solution
    
    Keep a list of "recent updates" and only merge them into the main
    data when that buf hasn't been updated in "a while" and when needed
    for saving the index. Note: Buffer *removals* are not put on-deck,
    but removed immediately.

    # .get_blobnames(..., ilk=None)
    
    Originally the toplevelname_index stored {toplevelname -&gt; blobnames}.
    The per-"ilk" level was added afterwards to support occassional ilk
    filtering for PHP (and possible eventually other langs).
    
    .get_blobnames() still behaves like a {toplevelname -&gt; blobnames}
    mapping, but it provides an optional "ilk" keyword arg to limit the
    results to that ilk.

    # Notes on locking

    This class does not guard its datastructures with locking. It is up
    to the LangZone using this to guard against simultaneous access on
    separate threads.
    """
    @others
</t>
<t tx="ekr.20080121121842.48">def __init__(self, data=None, timeout=90):
    # toplevelname_index data: {ilk -&gt; toplevelname -&gt; blobnames}
    if data is None:
        self._data = {}
    else:
        self._data = data

    # Time (in seconds) to hold a change "on deck".
    # Timed-out changes are merged on .get() and .update().
    self.timeout = timeout
    self._on_deck = {
        # basename                           # the basename of the buf path
        #   -&gt; [timestamp,                   # time of the last update
        #       # The dict in res_index, a.k.a. 'res_data'
        #       {blobname -&gt; ilk -&gt; toplevelnames},
        #       # Lazily generated pivot, a.k.a. 'res_data_pivot'
        #       {ilk -&gt; toplevelname -&gt; blobnames}
        #      ]
    }

</t>
<t tx="ekr.20080121121842.49">def __repr__(self):
    num_toplevelnames = sum(len(v) for v in self._data.itervalues())
    return ("&lt;LangTopLevelNameIndex: %d top-level name(s), "
            "%d update(s) on-deck&gt;"
                % (num_toplevelnames, len(self._on_deck)))

</t>
<t tx="ekr.20080121121842.50">def merge(self):
    """Merge all on-deck changes with `self.data'."""
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if res_data_pivot is None:
            res_data_pivot = self._pivot_res_data(res_data)
        # res_data_pivot: {ilk -&gt; toplevelname -&gt; blobnames}
        # "bft" means blobnames_from_toplevelname
        for ilk, bft in res_data_pivot.iteritems():
            data_bft = self._data.setdefault(ilk, {})
            for toplevelname, blobnames in bft.iteritems():
                if toplevelname not in data_bft:
                    data_bft[toplevelname] = blobnames
                else:
                    data_bft[toplevelname].update(blobnames)
        del self._on_deck[base]

</t>
<t tx="ekr.20080121121842.51">def merge_expired(self, now):
    """Merge expired on-deck changes with `self.data'."""
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if now - timestamp &lt; self.timeout:
            continue

        if res_data_pivot is None:
            res_data_pivot = self._pivot_res_data(res_data)
        # res_data_pivot: {ilk -&gt; toplevelname -&gt; blobnames}
        # "bft" means blobnames_from_toplevelname
        for ilk, bft in res_data_pivot.iteritems():
            data_bft = self._data.setdefault(ilk, {})
            for toplevelname, blobnames in bft.iteritems():
                if toplevelname not in data_bft:
                    data_bft[toplevelname] = blobnames
                else:
                    data_bft[toplevelname].update(blobnames)
        del self._on_deck[base]

</t>
<t tx="ekr.20080121121842.52">@property
def data(self):
    self.merge()
    return self._data

</t>
<t tx="ekr.20080121121842.53">def update(self, base, old_res_data, new_res_data):
    now = time.time()
    self.remove(base, old_res_data)
    self._on_deck[base] = [now, new_res_data, None]
    self.merge_expired(now)

</t>
<t tx="ekr.20080121121842.54">def remove(self, base, old_res_data):
    if base in self._on_deck:
        del self._on_deck[base]
    else:
        # Remove old refs from current data.
        # old_res_data:   {blobname -&gt; ilk -&gt; toplevelnames}
        # self._data: {ilk -&gt; toplevelname -&gt; blobnames}
        for blobname, toplevelnames_from_ilk in old_res_data.iteritems():
            for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                for toplevelname in toplevelnames:
                    try:
                        self._data[ilk][toplevelname].remove(blobname)
                    except KeyError:
                        pass # ignore this for now, might indicate corruption
                    else:
                        if not self._data[ilk][toplevelname]:
                            del self._data[ilk][toplevelname]
                if not self._data.get(ilk):
                    del self._data[ilk]

</t>
<t tx="ekr.20080121121842.55">def _pivot_res_data(self, res_data):
    # res_data:       {blobname -&gt; ilk -&gt; toplevelnames}
    # res_data_pivot: {ilk -&gt; toplevelname -&gt; blobnames}
    res_data_pivot = {}
    for blobname, toplevelnames_from_ilk in res_data.iteritems():
        for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
            pivot_bft = res_data_pivot.setdefault(ilk, {})
            for toplevelname in toplevelnames:
                if toplevelname not in pivot_bft:
                    pivot_bft[toplevelname] = set([blobname])
                else:
                    pivot_bft[toplevelname].add(blobname)
    return res_data_pivot

</t>
<t tx="ekr.20080121121842.56">def toplevel_cplns(self, prefix=None, ilk=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk.

        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).
    """
    self.merge_expired(time.time())

    # Need to check merged and on-deck items:
    cplns = []

    # ...on-deck items
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if res_data_pivot is None:
            res_data_pivot = self._on_deck[base][2] \
                = self._pivot_res_data(res_data)
        # res_data_pivot: {ilk -&gt; toplevelname -&gt; blobnames}
        if ilk is None:
            for i, bft in res_data_pivot.iteritems():
                cplns += [(i, toplevelname) for toplevelname in bft]
        elif ilk in res_data_pivot:
            cplns += [(ilk, toplevelname)
                      for toplevelname in res_data_pivot[ilk]]

    # ...merged data
    # self._data: {ilk -&gt; toplevelname -&gt; blobnames}
    if ilk is None:
        for i, bft in self._data.iteritems():
            cplns += [(i, toplevelname) for toplevelname in bft]
    elif ilk in self._data:
        cplns += [(ilk, toplevelname)
                  for toplevelname in self._data[ilk]]

    # Naive implementation: Instead of maintaining a separate
    # 'toplevelprefix_index' (as we do for StdLibsZone and CatalogsZone)
    # for now we'll just gather all results and filter on the prefix
    # here. Only if this proves to be a perf issue will we add the
    # complexity of another index:
    #   {ilk -&gt; prefix -&gt; toplevelnames}
    if prefix is not None:
        cplns = [(i, t) for i, t in cplns if t.startswith(prefix)]

    return cplns

</t>
<t tx="ekr.20080121121842.57">def get_blobnames(self, toplevelname, default=None, ilk=None):
    """Return the blobnames defining the given toplevelname.

    If "ilk" is given then only symbols of that ilk will be considered.
    If not match is found the "default" is returned.
    """
    self.merge_expired(time.time())

    blobnames = set()
    # First check on-deck items.
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if res_data_pivot is None:
            res_data_pivot = self._on_deck[base][2] \
                = self._pivot_res_data(res_data)
        # res_data_pivot: {ilk -&gt; toplevelname -&gt; blobnames}
        if ilk is None:
            for bft in res_data_pivot.itervalues():
                if toplevelname in bft:
                    blobnames.update(bft[toplevelname])
        elif ilk in res_data_pivot:
            if toplevelname in res_data_pivot[ilk]:
                blobnames.update(res_data_pivot[ilk][toplevelname])

    #TODO: Put lookup in merged data ahead of lookup in on-deck -- so
    #      we don't do on-deck work if not necessary.
    # Then, fallback to already merged data.
    # self._data: {ilk -&gt; toplevelname -&gt; blobnames}
    if ilk is None:
        for bft in self._data.itervalues():
            if toplevelname in bft:
                blobnames.update(bft[toplevelname])
    elif ilk in self._data:
        if toplevelname in self._data[ilk]:
            blobnames.update(self._data[ilk][toplevelname])

    if blobnames:
        return blobnames
    return default


</t>
<t tx="ekr.20080121121842.58">class LangZone(object):
    """Singleton zone managing a particular db/$lang/... area.

    # caching and memory control

    We cache all retrieved indices and blobs and maintain their latest
    access time. To try to manage memory consumption, we rely on a
    bookkeeper thread (the indexer) to periodically call .cull_mem() --
    which unloads cache items that have not been accessed in a while.

    (TODO:
    - Get the indexer to actually call .cull_mem() and .save()
      periodically.
    - Test that .cull_mem() actually results in the process releasing
      memory.)

    # robustness (TODO)

    Work should be done to improve robustness.
    - Collect filesystem interactions in one place.
    - Rationalize OSError handling.
    - Consider a journal system, if necessary/feasible. My hope is to
      get away without one and rely on graceful recovery. The db does
      not store critical info so can allow some loss of data (it can all
      be regenerated).
    """
    toplevelname_index_class = LangTopLevelNameIndex

    @others
</t>
<t tx="ekr.20080121121842.59">def __init__(self, mgr, lang):
    self.mgr = mgr
    self.db = mgr.db
    self.lang = lang
    self.base_dir = join(self.db.base_dir, "db",
                         util.safe_lang_from_lang(lang))
    self._check_lang(lang)

    self._lock = threading.RLock()

    self._dhash_from_dir_cache = {}
    self._dirslib_cache = {}
    self._ordered_dirslib_cache_keys = [] # most recent first

    # We cache the set of recent indeces and blobs in memory.
    #   {db-subpath: [index-object, &lt;atime&gt;]),
    #    ...}
    # For example:
    #   {'7bce640bc48751b128af5c8bf5df8412/res_index':
    #       [&lt;res-index&gt;, 1158289000]),
    #    ...}
    self._index_and_atime_from_dbsubpath = {}
    #TODO-PERF: Use set() object for this? Compare perf.
    self._is_index_dirty_from_dbsubpath = {} # set of dirty indeces
    ##TODO: blob caching and *use* this
    #self._blob_and_atime_from_dbsubpath = {}

    #XXX Need a 'dirty-set' for blobs? No, because currently
    #    .update_buf_data() saves blob changes to disk immediately. Not
    #    sure that is best for perf. Definitely not ideal for the
    #    "editset".

</t>
<t tx="ekr.20080121121842.60">def __repr__(self):
    return "&lt;%s lang db&gt;" % self.lang

</t>
<t tx="ekr.20080121121842.61">def __del__(self):
    self._dirslib_cache = {} # drop refs
    #XXX Drop index and blob caches as well.

</t>
<t tx="ekr.20080121121842.62">def _acquire_lock(self):
    self._lock.acquire()
</t>
<t tx="ekr.20080121121842.63">def _release_lock(self):
    self._lock.release()

</t>
<t tx="ekr.20080121121842.64">def _check_lang(self, lang):
    """Ensure that the given lang matches case exactly with the lang
    in the db. If this invariant is broken, then weird things with
    caching can result.
    """
    if exists(self.base_dir):
        lang_path = join(self.base_dir, "lang")
        try:
            fin = open(lang_path, 'r')
        except EnvironmentError, ex:
            self.db.corruption("LangZone._check_lang",
                "could not open `%s': %s" % (lang_path, ex),
                "recover")
            fin = open(lang_path, 'w')
            try:
                fin.write(lang)
            finally:
                fin.close()
        else:
            try:
                lang_on_disk = fin.read().strip()
            finally:
                fin.close()
            assert lang_on_disk == lang

</t>
<t tx="ekr.20080121121842.65">#TODO: If Database.dhash_from_dir() grows caching, then this
#      shouldn't bother.
def dhash_from_dir(self, dir):
    if dir not in self._dhash_from_dir_cache:
        self._dhash_from_dir_cache[dir] = self.db.dhash_from_dir(dir)
    return self._dhash_from_dir_cache[dir]

</t>
<t tx="ekr.20080121121842.66">def dfb_from_dir(self, dir, default=None):
    """Get the {blobname -&gt; dbfile} mapping index for the given dir.
    
    'dfb' stands for 'dbfile_from_blobname'.
    This must be called with the lock held.
    """
    return self.load_index(dir, "blob_index", default)

</t>
<t tx="ekr.20080121121842.67">def get_buf_scan_time(self, buf):
    #TODO Canonicalize path (or assert that it is canonicalized)
    self._acquire_lock()
    try:
        dir, base = split(buf.path)
        res_index = self.load_index(dir, "res_index", {})
        if base not in res_index:
            return None
        return res_index[base][0]
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.68">def get_buf_data(self, buf):
    #TODO Canonicalize path (or assert that it is canonicalized)
    #     Should have a Resource object that we pass around that
    #     handles all of this.
    self._acquire_lock()
    try:
        dir, base = split(buf.path)
        res_index = self.load_index(dir, "res_index", {})
        if base not in res_index:
            raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                     % (buf.lang, buf.path))
        scan_time, scan_error, res_data = res_index[base]

        blob_from_lang = {}
        if res_data:
            try:
                dbfile_from_blobname = self.dfb_from_dir(dir)
            except EnvironmentError, ex:
                # DB corruption will be noted in remove_buf_data()
                self.remove_buf_data(buf)
                raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                         % (buf.lang, buf.path))
            dhash = self.dhash_from_dir(dir)
            for blobname in res_data:
                dbsubpath = join(dhash, dbfile_from_blobname[blobname])
                try:
                    blob = self.load_blob(dbsubpath)
                except ET.XMLParserError, ex:
                    #XXX Or should we clean out index and raise NotFoundInDatabase?
                    self.db.corruption("LangZone.get_buf_data",
                        "could not parse dbfile for '%s' blob: %s"\
                            % (blobname, ex),
                        "ignore")
                    continue
                except EnvironmentError, ex:
                    self.db.corruption("LangZone.get_buf_data",
                        "could not read dbfile for '%s' blob: %s"\
                            % (blobname, ex),
                        "ignore")
                    continue
                lang = blob.get("lang")
                assert lang is not None
                blob_from_lang[lang] = blob

        return scan_time, scan_error, blob_from_lang
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.69">def remove_buf_data(self, buf):
    """Remove the given resource from the database."""
    #TODO Canonicalize path (or assert that it is canonicalized)
    #     Should have a Resource object that we pass around that
    #     handles all of this.
    self._acquire_lock()
    try:
        dir, base = split(buf.path)

        res_index = self.load_index(dir, "res_index", {})
        try:
            scan_time, scan_error, res_data = res_index[base]
        except KeyError:
            # This resource isn't loaded in the db. Nothing to remove.
            return

        try:
            blob_index = self.load_index(dir, "blob_index")
        except EnvironmentError, ex:
            self.db.corruption("LangZone.remove_buf_data",
                "could not read blob_index for '%s' dir: %s" % (dir, ex),
                "recover")
            blob_index = {}

        is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
        if is_hits_from_lpath_lang:
            try:
                toplevelname_index = self.load_index(dir, "toplevelname_index")
            except EnvironmentError, ex:
                self.db.corruption("LangZone.remove_buf_data",
                    "could not read toplevelname_index for '%s' dir: %s"
                        % (dir, ex),
                    "recover")
                toplevelname_index = self.toplevelname_index_class()

        dhash = self.dhash_from_dir(dir)
        del res_index[base]
        for blobname in res_data:
            try:
                dbfile = blob_index[blobname]
            except KeyError:
                blob_index_path = join(dhash, "blob_index")
                self.db.corruption("LangZone.remove_buf_data",
                    "'%s' blob not in '%s'" \
                        % (blobname, blob_index_path),
                    "ignore")
                continue
            del blob_index[blobname]
            for path in glob(join(self.base_dir, dhash, dbfile+".*")):
                log.debug("fs-write: remove %s blob file '%s/%s'",
                          self.lang, dhash, basename(path))
                os.remove(path)
        if is_hits_from_lpath_lang:
            toplevelname_index.remove(base, res_data)

        self.changed_index(dir, "res_index")
        self.changed_index(dir, "blob_index")
        if is_hits_from_lpath_lang:
            self.changed_index(dir, "toplevelname_index")
    finally:
        self._release_lock()
    #TODO Database.clean() should remove dirs that have no
    #     blob_index entries.    

</t>
<t tx="ekr.20080121121842.70">def update_buf_data(self, buf, force=False):
    """Update this LangZone with the buffer data.

        "buf" is the CitadelBuffer instance with the relevant info
            (path, tree, scan_time).
        "force" (default False) is a boolean indicating if the
            buffer data should be updated even if buf.scan_time is
            &lt;= that in the database.
    """
    self._acquire_lock()
    try:
        #TODO: Canonicalize path (or assert that it is canonicalized)
        dir, base = split(buf.path)

        # Get the current data, if any.
        res_index = self.load_index(dir, "res_index", {})
        res_index_has_changed = False
        blob_index = self.load_index(dir, "blob_index", {})
        blob_index_has_changed = False
        is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
        if is_hits_from_lpath_lang:
            #TODO: Not sure {} for a default is correct here.
            toplevelname_index = self.load_index(dir, "toplevelname_index", {})
            toplevelname_index_has_changed = False
        try:
            (old_scan_time, old_scan_error, old_res_data) = res_index[base]
        except KeyError:    # adding a new entry
            (old_scan_time, old_scan_error, old_res_data) = None, None, {}
        else:               # updating an existing entry
            if not force and buf.scan_time is not None \
               and buf.scan_time &lt;= old_scan_time:
                log.debug("skipping db update for '%s': %s &lt; %s and "
                          "no force option",
                          base, buf.scan_time, old_scan_time)
                return

        log.debug("update from %s buf '%s'", buf.lang, buf.path)

        # Parse the tree and get the list of blobnames.
        # res_data: {blobname -&gt; ilk -&gt; toplevelnames}
        new_res_data = {}
        new_blobnames_and_blobs = []
        for lang, blob in buf.blob_from_lang.items():
            assert lang == blob.get("lang") == self.lang
            blobname = blob.get("name")
            for toplevelname, elem in blob.names.iteritems():
                toplevelnames_from_ilk \
                    = new_res_data.setdefault(blobname, {})
                ilk = elem.get("ilk") or elem.tag
                if ilk not in toplevelnames_from_ilk:
                    toplevelnames_from_ilk[ilk] = set([toplevelname])
                else:
                    toplevelnames_from_ilk[ilk].add(toplevelname)
            new_blobnames_and_blobs.append((blobname, blob))

        # Determine necessary changes to res_index.
        new_scan_time = buf.scan_time
        new_scan_error = buf.scan_error
        if new_scan_error:
            if (new_scan_time != old_scan_time
                or new_scan_error != old_scan_error):
                res_index[base] = (new_scan_time, new_scan_error,
                                   old_res_data)
                res_index_has_changed = True

        else:
            # Only consider new blobs if there wasn't a scan error.
            # I.e., we want to preserve the last good scan info.

            if (new_scan_time != old_scan_time
                or new_scan_error != old_scan_error
                or new_res_data != old_res_data):
                res_index[base] = (new_scan_time, new_scan_error,
                                   new_res_data)
                res_index_has_changed = True

            if is_hits_from_lpath_lang:
                if new_res_data != old_res_data:
                    toplevelname_index.update(base,
                        old_res_data, new_res_data)
                    toplevelname_index_has_changed = True

            # Determine necessary changes to blob_index and the
            # dbfiles and then make them.
            dbfile_changes = []
            for blobname, blob in new_blobnames_and_blobs:
                if blobname in old_res_data:
                    dbfile_changes.append(("update", blobname, blob))
                else:
                    dbfile_changes.append(("add", blobname, blob))
            for blobname in old_res_data:
                if blobname not in new_res_data:
                    dbfile_changes.append(("remove", blobname, None))

            dhash = self.dhash_from_dir(dir)
            for action, blobname, blob in dbfile_changes:
                if action == "add":
                    dbfile = self.db.bhash_from_blob_info(
                                buf.path, self.lang, blobname)
                    blob_index[blobname] = dbfile
                    blob_index_has_changed = True
                    dbdir = join(self.base_dir, dhash)
                    if not exists(dbdir):
                        self._mk_dbdir(dbdir, dir)
                    #XXX What to do on write failure?
                    log.debug("fs-write: %s blob '%s/%s'",
                              self.lang, dhash, dbfile)
                    if blob.get("src") is None:
                        blob.set("src", buf.path)   # for defns_from_pos() support
                    ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
                elif action == "remove":
                    dbfile = blob_index[blobname]
                    del blob_index[blobname]
                    blob_index_has_changed = True
                    #XXX What to do on removal failure?
                    log.debug("fs-write: remove %s blob '%s/%s'",
                              self.lang, dhash, dbfile)
                    os.remove(join(self.base_dir, dhash, dbfile+".blob"))
                elif action == "update":
                    # Try to only change the dbfile on disk if it is
                    # different.
                    s = StringIO()
                    if blob.get("src") is None:
                        blob.set("src", buf.path)   # for defns_from_pos() support
                    ET.ElementTree(blob).write(s)
                    new_dbfile_content = s.getvalue()
                    dbfile = blob_index[blobname]
                    dbpath = join(self.base_dir, dhash, dbfile+".blob")
                    # PERF: Might be nice to cache the new dbfile
                    #       content for the next time this resource is
                    #       updated. For files under edit this will be
                    #       common. I.e. just for the "editset".
                    try:
                        fin = open(dbpath, 'r')
                    except OSError, ex:
                        # Technically if the dbfile doesn't exist, this
                        # is a sign of database corruption. No matter
                        # though (for this blob anyway), we are about to
                        # replace it.
                        old_dbfile_content = None
                    else:
                        try:
                            old_dbfile_content = fin.read()
                        finally:
                            fin.close()
                    if new_dbfile_content != old_dbfile_content:
                        if not exists(dirname(dbpath)):
                            self._mk_dbdir(dirname(dbpath), dir)
                        #XXX What to do if fail to write out file?
                        log.debug("fs-write: %s blob '%s/%s'",
                                  self.lang, dhash, dbfile)
                        fout = open(dbpath, 'w')
                        try:
                            fout.write(new_dbfile_content)
                        finally:
                            fout.close()

        if res_index_has_changed:
            self.changed_index(dir, "res_index")
        if blob_index_has_changed:
            self.changed_index(dir, "blob_index")
        if is_hits_from_lpath_lang and toplevelname_index_has_changed:
            self.changed_index(dir, "toplevelname_index")
    finally:
        self._release_lock()
    #TODO Database.clean() should remove dirs that have no
    #     blob_index entries.    

</t>
<t tx="ekr.20080121121842.71">def _mk_zone_skel(self):
    log.debug("fs-write: mkdir '%s'", self.base_dir)
    os.makedirs(self.base_dir)
    log.debug("fs-write: create 'lang'")
    fout = codecs.open(join(self.base_dir, "lang"), 'wb', 'utf-8')
    try:
        fout.write(self.lang)
    finally:
        fout.close()

</t>
<t tx="ekr.20080121121842.72">def _mk_dbdir(self, dbdir, dir):
    if not exists(self.base_dir):
        self._mk_zone_skel()
    log.debug("fs-write: mkdir '%s'", dbdir[len(self.base_dir)+1:])
    os.mkdir(dbdir)
    log.debug("fs-write: '%s/path'", dbdir[len(self.base_dir)+1:])
    fout = codecs.open(join(dbdir, "path"), 'wb', 'utf-8')
    try:
        fout.write(dir)
    finally:
        fout.close()

</t>
<t tx="ekr.20080121121842.73">def load_blob(self, dbsubpath):
    """This must be called with the lock held."""
    log.debug("TODO: LangZone.load_blob: add blob caching!")
    log.debug("fs-read: load %s blob '%s'", self.lang, dbsubpath)
    dbpath = join(self.base_dir, dbsubpath+".blob")
    return ET.parse(dbpath).getroot()

</t>
<t tx="ekr.20080121121842.74">def load_index(self, dir, index_name, default=None):
    """Get the indicated index.

        "dir" is the dir path this index represents.
        "index_name" is the name of the index.
        "default" (default None) indicate the value to return for
            the index if the index doesn't exist. If not set (or
            None) then an OSError is raised if the index doesn't exist.

    The index is loaded from a pickle on disk, if necessary, put
    into the cache system, and returned.
    
    This must be called with the lock held.
    """
    self._acquire_lock()
    try:
        dbsubpath = join(self.db.dhash_from_dir(dir), index_name)

        # If index path is in the cache: return it, update its atime.
        now = time.time()
        if dbsubpath in self._index_and_atime_from_dbsubpath:
            log.debug("cache-read: load %s index '%s'", self.lang, dbsubpath)
            self._index_and_atime_from_dbsubpath[dbsubpath][1] = now
            return self._index_and_atime_from_dbsubpath[dbsubpath][0]

        # Otherwise, load it.
        log.debug("fs-read: load %s index '%s'", self.lang, dbsubpath)
        dbpath = join(self.base_dir, dbsubpath)
        index = self.db.load_pickle(dbpath, default)
        if index_name == "toplevelname_index":
            index = self.toplevelname_index_class(index)
        self._index_and_atime_from_dbsubpath[dbsubpath] = [index, now]
        return index
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.75">def changed_index(self, dir, index_name):
    """Note that we've changed this index (so it can be saved as
    appropriate).
    """
    self._acquire_lock()
    try:
        now = time.time()
        dbsubpath = join(self.db.dhash_from_dir(dir), index_name)
        self._index_and_atime_from_dbsubpath[dbsubpath][1] = now
        self._is_index_dirty_from_dbsubpath[dbsubpath] = True
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.76">def save_index(self, dbsubpath, index):
    if isinstance(index, self.toplevelname_index_class):
        index = index.data
    self.db.save_pickle(join(self.base_dir, dbsubpath), index)

</t>
<t tx="ekr.20080121121842.77">def save(self):
    self._acquire_lock()
    try:
        for dbsubpath in self._is_index_dirty_from_dbsubpath:
            self.save_index(dbsubpath,
                self._index_and_atime_from_dbsubpath[dbsubpath][0])
        self._is_index_dirty_from_dbsubpath = {}
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.78">def cull_mem(self):
    """Drop indeces and tree from cache that have not been
    accessed in over 5 minutes.

    To attempt to keep memory consumption under control we want to
    ensure we don't keep everything cached from the db in memory
    until process completion. The plan is to have a thread
    periodically cull memory.
    """
    #TODO: Database.cull_mem(). Add it. Get indexer to call it.
    #TOTEST: Does Python/Komodo actually release this memory or
    #        are we kidding ourselves?
    self._acquire_lock()
    try:
        N = 30
        if len(self._index_and_atime_from_dbsubpath) &lt; N:
            # Too few indeces in memory to bother culling.
            return

        print "XXX culling memory..."
        now = time.time()
        for dbsubpath, (index, atime) \
                in self._index_and_atime_from_dbsubpath.items():
            if now - atime &gt; 300.0: # &gt;5 minutes since last access
                if dbsubpath in self._is_index_dirty_from_dbsubpath:
                    self.save_index(dbsubpath, index)
                    del self._is_index_dirty_from_dbsubpath[dbsubpath]
                del self._index_and_atime_from_dbsubpath[dbsubpath]
    finally:
        self._release_lock()

    #XXX Database.clean(): Go through each $lang/dir/res_index and
    #    clean out files in the index but that don't actually exist
    #    anymore.
    #XXX Database.clean(): drop memory for indeces that are quite
    #    old (say haven't been accessed in 20 minutes).
    #XXX Database.check(): Shouldn't have too many cached indeces in
    #    memory. How old is the oldest one? Estimate memory size
    #    used by all loaded indeces?

</t>
<t tx="ekr.20080121121842.79">def get_lib(self, name, dirs):
    """
    Dev Notes:
    We make a lib for a particular sequence of dirs a singleton because:
    1. The sequence of dirs for a language's import path tends to
       not change, so the same object will tend to get used.
    2. This allows caching of filesystem lookups to be done naturally
       on the LangDirsLib instance.

    To ensure that this cache doesn't grow unboundedly we only allow
    there to be N cached LangDirsLib's. A good value for N is when
    there are relatively few cache misses. Ideally we'd want to
    count the number of cache misses (i.e. LangDirsLib instance
    creations) for a number of "typical" uses of codeintel -- i.e. a
    long running Komodo profile. Failing that we'll just use N=10.
    """
    assert isinstance(dirs, (tuple, list))
    canon_dirs = tuple(abspath(normpath(expanduser(d))) for d in dirs)
    if canon_dirs in self._dirslib_cache:
        return self._dirslib_cache[canon_dirs]

    langdirslib = LangDirsLib(self, self._lock, self.lang, name,
                              canon_dirs)
    
    N = 10
    while len(self._ordered_dirslib_cache_keys) &gt;= N:
        cache_key = self._ordered_dirslib_cache_keys.pop()
        del self._dirslib_cache[cache_key]
    self._dirslib_cache[canon_dirs] = langdirslib
    self._ordered_dirslib_cache_keys.insert(0, canon_dirs)

    return langdirslib

</t>
<t tx="ekr.20080121121842.80">#!python
# ***** LICENSE BLOCK *****

"""The multilang-zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import copy

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.database.langlib import LangZone
from codeintel2 import util



#---- globals

log = logging.getLogger("codeintel.db")
</t>
<t tx="ekr.20080121121842.81">#log.setLevel(logging.DEBUG)



#---- Database zone and lib implementations

class MultiLangTopLevelNameIndex(object):
    """A wrapper around the plain-dictionary toplevelname_index for a
    MultiLangZone dir to provide better performance for continual updating
    and some simpler access.

        {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}

    # Problem

    A 'toplevelname_index' is a merge of
        {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
    data for all resources in its dir.  As those resources are
    continually re-scanned (e.g. as a file is edited in Komodo), it
    would be too expensive to update this index everytime.

    # Solution

    Keep a list of "recent updates" and only merge them into the main
    data when that buf hasn't been updated in "a while" and when needed
    for saving the index. Note: Buffer *removals* are not put on-deck,
    but removed immediately.

    # .get_blobnames(lang, ..., ilk=None)
    
    Originally the toplevelname_index stored
        {lang -&gt; toplevelname -&gt; blobnames}
    The per-"ilk" level was added afterwards to support occassional ilk
    filtering for PHP (and possible eventually other langs).
    
    .get_blobnames() still behaves like a {lang -&gt; toplevelname -&gt; blobnames}
    mapping, but it provides an optional "ilk" keyword arg to limit the
    results to that ilk.

    # Notes on locking

    This class does not guard its datastructures with locking. It is up
    to the MultiLangZone using this to guard against simultaneous access
    on separate threads.
    """
    @others
</t>
<t tx="ekr.20080121121842.82">def __init__(self, data=None, timeout=90):
    # toplevelname_index data: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
    if data is None:
        self._data = {}
    else:
        self._data = data

    # Time (in seconds) to hold a change "on deck".
    # Timed-out changes are merged on .get() and .update().
    self.timeout = timeout
    self._on_deck = {
        # basename                           # the basename of the buf path
        #   -&gt; [timestamp,                   # time of the last update
        #       # The dict in res_index, a.k.a. 'res_data'
        #       {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames},
        #       # Lazily generated pivot, a.k.a. 'res_data_pivot'
        #       {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        #      ]
    }

</t>
<t tx="ekr.20080121121842.83">def __repr__(self):
    return "&lt;MultiLangTopLevelNameIndex: %d update(s) on-deck&gt;"\
           % len(self._on_deck)

</t>
<t tx="ekr.20080121121842.84">def merge(self):
    """Merge all on-deck changes with `self.data'."""
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if res_data_pivot is None:
            res_data_pivot = self._pivot_res_data(res_data)
        # res_data_pivot: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        # "bftfi" means blobnames_from_toplevelname_from_ilk
        for lang, bftfi in res_data_pivot.iteritems():
            data_bftfi = self._data.setdefault(lang, {})
            for ilk, bft in bftfi.iteritems():
                data_bft = data_bftfi.setdefault(ilk, {})
                for toplevelname, blobnames in bft.iteritems():
                    if toplevelname not in data_bft:
                        data_bft[toplevelname] = blobnames
                    else:
                        data_bft[toplevelname].update(blobnames)
        del self._on_deck[base]

</t>
<t tx="ekr.20080121121842.85">def merge_expired(self, now):
    """Merge expired on-deck changes with `self.data'."""
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if now - timestamp &lt; self.timeout:
            continue

        if res_data_pivot is None:
            res_data_pivot = self._pivot_res_data(res_data)
        # res_data_pivot: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        # "bftfi" means blobnames_from_toplevelname_from_ilk
        for lang, bftfi in res_data_pivot.iteritems():
            data_bftfi = self._data.setdefault(lang, {})
            for ilk, bft in bftfi.iteritems():
                data_bft = data_bftfi.setdefault(ilk, {})
                for toplevelname, blobnames in bft.iteritems():
                    if toplevelname not in data_bft:
                        data_bft[toplevelname] = blobnames
                    else:
                        data_bft[toplevelname].update(blobnames)
        del self._on_deck[base]

</t>
<t tx="ekr.20080121121842.86">@property
def data(self):
    self.merge()
    return self._data

</t>
<t tx="ekr.20080121121842.87">def update(self, base, old_res_data, new_res_data):
    now = time.time()
    self.remove(base, old_res_data)
    self._on_deck[base] = [now, new_res_data, None]
    self.merge_expired(now)

</t>
<t tx="ekr.20080121121842.88">def remove(self, base, old_res_data):
    if base in self._on_deck:
        del self._on_deck[base]
    else:
        # Remove old refs from current data.
        # old_res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
        # self._data:   {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        for lang, tfifb in old_res_data.iteritems():
            if lang not in self._data:
                continue
            data_bftfi = self._data[lang]
            for blobname, tfi in tfifb.iteritems():
                for ilk, toplevelnames in tfi.iteritems():
                    for toplevelname in toplevelnames:
                        try:
                            data_bftfi[ilk][toplevelname].remove(blobname)
                        except KeyError:
                            pass # ignore this for now, might indicate corruption
                        else:
                            if not data_bftfi[ilk][toplevelname]:
                                del data_bftfi[ilk][toplevelname]
                    if not data_bftfi.get(ilk):
                        del data_bftfi[ilk]
            if not self._data[lang]:
                del self._data[lang]

</t>
<t tx="ekr.20080121121842.89">def _pivot_res_data(self, res_data):
    # res_data:       {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
    # res_data_pivot: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
    res_data_pivot = dict(
        (lang, {}) for lang in res_data
    )
    for lang, tfifb in res_data.iteritems():
        for blobname, toplevelnames_from_ilk in tfifb.iteritems():
            for ilk, toplevelnames in toplevelnames_from_ilk.iteritems():
                pivot_bft = res_data_pivot[lang].setdefault(ilk, {})
                for toplevelname in toplevelnames:
                    if toplevelname not in pivot_bft:
                        pivot_bft[toplevelname] = set([blobname])
                    else:
                        pivot_bft[toplevelname].add(blobname)
    return res_data_pivot

</t>
<t tx="ekr.20080121121842.90">def toplevel_cplns(self, lang, prefix=None, ilk=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk.

        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).
    """
    self.merge_expired(time.time())

    # Need to check merged and on-deck items:
    cplns = []

    # ...on-deck items
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if lang not in res_data:
            continue
        if res_data_pivot is None:
            res_data_pivot = self._on_deck[base][2] \
                = self._pivot_res_data(res_data)
        # res_data_pivot: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        bftfi = res_data_pivot[lang]
        if ilk is None:
            for i, bft in bftfi.iteritems():
                cplns += [(i, toplevelname) for toplevelname in bft]
        elif ilk in bftfi:
            cplns += [(ilk, toplevelname) for toplevelname in bftfi[ilk]]

    # ...merged data
    # self._data: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
    if lang in self._data:
        bftfi = self._data[lang]
        if ilk is None:
            for i, bft in bftfi.iteritems():
                cplns += [(i, toplevelname) for toplevelname in bft]
        elif ilk in bftfi:
            cplns += [(ilk, toplevelname) for toplevelname in bftfi[ilk]]


    # Naive implementation: Instead of maintaining a separate
    # 'toplevelprefix_index' (as we do for StdLibsZone and CatalogsZone)
    # for now we'll just gather all results and filter on the prefix
    # here. Only if this proves to be a perf issue will we add the
    # complexity of another index:
    #   {lang -&gt; ilk -&gt; prefix -&gt; toplevelnames}
    if prefix is not None:
        cplns = [(i, t) for i, t in cplns if t.startswith(prefix)]

    return cplns


</t>
<t tx="ekr.20080121121842.91">#TODO: Change this API to just have the empty list as a default.
#      No point in the 'default' arg.
def get_blobnames(self, lang, toplevelname, default=None, ilk=None):
    """Return the blobnames of the given lang defining the given
    toplevelname.

    If "ilk" is given then only symbols of that ilk will be considered.
    If not match is found the "default" is returned.
    """
    self.merge_expired(time.time())

    blobnames = set()
    # First check on-deck items.
    for base, (timestamp, res_data,
               res_data_pivot) in self._on_deck.items():
        if lang not in res_data:
            continue
        if res_data_pivot is None:
            res_data_pivot = self._on_deck[base][2] \
                = self._pivot_res_data(res_data)
        # res_data_pivot: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
        bftfi = res_data_pivot[lang]
        if ilk is None:
            for bft in bftfi.itervalues():
                if toplevelname in bft:
                    blobnames.update(bft[toplevelname])
        elif ilk in bftfi:
            if toplevelname in bftfi[ilk]:
                blobnames.update(bftfi[ilk][toplevelname])

    #TODO: Put lookup in merged data ahead of lookup in on-deck -- so
    #      we don't do on-deck work if not necessary.
    # Then, fallback to already merged data.
    # self._data: {lang -&gt; ilk -&gt; toplevelname -&gt; blobnames}
    if lang in self._data:
        bftfi = self._data[lang]
        if ilk is None:
            for bft in bftfi.itervalues():
                if toplevelname in bft:
                    blobnames.update(bft[toplevelname])
        elif ilk in bftfi:
            if toplevelname in bftfi[ilk]:
                blobnames.update(bftfi[ilk][toplevelname])

    if blobnames:
        return blobnames
    return default


</t>
<t tx="ekr.20080121121842.92">class MultiLangZone(LangZone):
    toplevelname_index_class = MultiLangTopLevelNameIndex

    @others
</t>
<t tx="ekr.20080121121842.93">def get_lib(self, name, dirs, sublang):
    assert isinstance(dirs, (tuple, list))
    assert sublang is not None, "must specify '%s' sublang" % self.lang

    canon_dirs = tuple(abspath(normpath(expanduser(d))) for d in dirs)
    key = (canon_dirs, sublang)
    if key in self._dirslib_cache:
        return self._dirslib_cache[key]

    langdirslib = MultiLangDirsLib(self, self._lock, self.lang,
                                    name, canon_dirs, sublang)
    
    N = 10
    while len(self._ordered_dirslib_cache_keys) &gt;= N:
        cache_key = self._ordered_dirslib_cache_keys.pop()
        del self._dirslib_cache[cache_key]
    self._dirslib_cache[key] = langdirslib
    self._ordered_dirslib_cache_keys.insert(0, key)

    return langdirslib

</t>
<t tx="ekr.20080121121842.94">def dfb_from_dir(self, dir, sublang, default=None):
    """Get the {blobname -&gt; dbfile} mapping index for the given dir
    and lang.
    
    'dfb' stands for 'dbfile_from_blobname'.
    This must be called with the lock held.
    """
    blob_index = self.load_index(dir, "blob_index", default=default)
    try:
        return blob_index[sublang]
    except KeyError, ex:
        if default is not None:
            return default
        raise

</t>
<t tx="ekr.20080121121842.95">def get_buf_data(self, buf):
    #TODO Canonicalize path (or assert that it is canonicalized)
    #     Should have a Resource object that we pass around that
    #     handles all of this.
    self._acquire_lock()
    try:
        dir, base = split(buf.path)
        res_index = self.load_index(dir, "res_index", {})
        if base not in res_index:
            raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                     % (buf.lang, buf.path))
        scan_time, scan_error, res_data = res_index[base]

        try:
            blob_index = self.load_index(dir, "blob_index")
        except EnvironmentError, ex:
            self.db.corruption("MultiLangZone.get_buf_data",
                "could not find 'blob_index' index: %s" % ex,
                "recover")
            raise NotFoundInDatabase("%s buffer '%s' not found in database"
                                     % (buf.lang, buf.path))

        dhash = self.dhash_from_dir(dir)
        blob_from_lang = {}
        # res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
        for lang, blobname in (
             (lang, tfifb.keys()[0]) # only one blob per lang in a resource
             for lang, tfifb in res_data.items()
            ):
            dbsubpath = join(dhash, blob_index[lang][blobname])
            try:
                blob = self.load_blob(dbsubpath)
            except ET.XMLParserError, ex:
                #XXX Or should we clean out index and raise NotFoundInDatabase?
                self.db.corruption("MultiLangZone.get_buf_data",
                    "could not parse dbfile for '%s' blob: %s"\
                        % (blobname, ex),
                    "ignore")
                continue
            except EnvironmentError, ex:
                self.db.corruption("MultiLangZone.get_buf_data",
                    "could not read dbfile for '%s' blob: %s"\
                        % (blobname, ex),
                    "ignore")
                continue
            assert blob.get("lang") == lang
            blob_from_lang[lang] = blob

        return scan_time, scan_error, blob_from_lang
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.96">def remove_buf_data(self, buf):
    """Remove the given resource from the database."""
    #TODO Canonicalize path (or assert that it is canonicalized)
    #     Should have a Resource object that we pass around that
    #     handles all of this.
    self._acquire_lock()
    try:
        dir, base = split(buf.path)

        res_index = self.load_index(dir, "res_index", {})
        try:
            scan_time, scan_error, res_data = res_index[base]
        except KeyError:
            # This resource isn't loaded in the db. Nothing to remove.
            return

        try:
            blob_index = self.load_index(dir, "blob_index")
        except EnvironmentError, ex:
            self.db.corruption("MultiLangZone.remove_buf_data",
                "could not read blob_index for '%s' dir: %s" % (dir, ex),
                "recover")
            blob_index = {}

        is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
        if is_hits_from_lpath_lang:
            try:
                toplevelname_index = self.load_index(dir, "toplevelname_index")
            except EnvironmentError, ex:
                self.db.corruption("MultiLangZone.remove_buf_data",
                    "could not read toplevelname_index for '%s' dir: %s"
                        % (dir, ex),
                    "recover")
                toplevelname_index = self.toplevelname_index_class()

        dhash = self.dhash_from_dir(dir)
        del res_index[base]
        # res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
        for lang, blobname in (
             (lang, tfifb.keys()[0]) # only one blob per lang in a resource
             for lang, tfifb in res_data.items()
            ):
            try:
                dbfile = blob_index[lang][blobname]
            except KeyError:
                blob_index_path = join(dhash, "blob_index")
                self.db.corruption("MultiLangZone.remove_buf_data",
                    "%s '%s' blob not in '%s'" \
                        % (lang, blobname, blob_index_path),
                    "ignore")
                continue
            del blob_index[lang][blobname]
            for path in glob(join(self.base_dir, dhash, dbfile+".*")):
                log.debug("fs-write: remove %s|%s blob file '%s/%s'",
                          self.lang, lang, dhash, basename(path))
                os.remove(path)
        if is_hits_from_lpath_lang:
            toplevelname_index.remove(base, res_data)

        self.changed_index(dir, "res_index")
        self.changed_index(dir, "blob_index")
        if is_hits_from_lpath_lang:
            self.changed_index(dir, "toplevelname_index")
    finally:
        self._release_lock()
    #XXX Database.clean() should remove dirs that have no
    #    dbfile_from_blobname entries.

</t>
<t tx="ekr.20080121121842.97">def update_buf_data(self, buf, force=False):
    """Update this MultiLangZone with the buffer data.

        "buf" is the CitadelBuffer instance with the relevant info
            (path, tree, scan_time).
        "force" (default False) is a boolean indicating if the
            buffer data should be updated even if buf.scan_time is
            &lt;= that in the database.
    """
    self._acquire_lock()
    try:
        #TODO: Canonicalize path (or assert that it is canonicalized)
        dir, base = split(buf.path)

        # Get the current data, if any.
        res_index = self.load_index(dir, "res_index", {})
        res_index_has_changed = False
        blob_index = self.load_index(dir, "blob_index", {})
        blob_index_has_changed = False
        is_hits_from_lpath_lang = self.lang in self.db.import_everything_langs
        if is_hits_from_lpath_lang:
            #TODO: Not sure {} for a default is correct here.
            toplevelname_index = self.load_index(dir, "toplevelname_index", {})
            toplevelname_index_has_changed = False
        try:
            (old_scan_time, old_scan_error, old_res_data) = res_index[base]
        except KeyError:    # adding a new entry
            (old_scan_time, old_scan_error, old_res_data) = None, None, {}
        else:               # updating an existing entry
            if not force and buf.scan_time is not None \
               and buf.scan_time &lt;= old_scan_time:
                log.debug("skipping db update for '%s': %s &lt; %s and "
                          "no force option",
                          base, buf.scan_time, old_scan_time)
                return

        log.debug("update from %s buf '%s'", buf.lang, buf.path)

        # Parse the tree and get the list of blobnames.
        # res_data: {lang -&gt; blobname -&gt; ilk -&gt; toplevelnames}
        new_res_data = {}
        new_blob_from_lang_and_blobname = {}
        for lang, blob in buf.blob_from_lang.items():
            blobname = blob.get("name")
            new_blob_from_lang_and_blobname[(lang, blobname)] = blob
            tfifb = new_res_data.setdefault(lang, {})
            toplevelnames_from_ilk = tfifb.setdefault(blobname, {})
            for toplevelname, elem in blob.names.iteritems():
                ilk = elem.get("ilk") or elem.tag
                if ilk not in toplevelnames_from_ilk:
                    toplevelnames_from_ilk[ilk] = set([toplevelname])
                else:
                    toplevelnames_from_ilk[ilk].add(toplevelname)

        # Determine necessary changes to res_index.
        new_scan_time = buf.scan_time
        new_scan_error = buf.scan_error
        if new_scan_error:
            if (new_scan_time != old_scan_time
                or new_scan_error != old_scan_error):
                res_index[base] = (new_scan_time, new_scan_error,
                                   old_res_data)
                res_index_has_changed = True

        else:
            # Only consider new blobs if there wasn't a scan error.
            # I.e., we want to preserve the last good scan info.

            if (new_scan_time != old_scan_time
                or new_scan_error != old_scan_error
                or new_res_data != old_res_data):
                res_index[base] = (new_scan_time, new_scan_error,
                                   new_res_data)
                res_index_has_changed = True

            if is_hits_from_lpath_lang:
                if new_res_data != old_res_data:
                    toplevelname_index.update(base,
                        old_res_data, new_res_data)
                    toplevelname_index_has_changed = True

            # Determine necessary changes to dbfile_from_blobname index
            # and the dbfiles and then make them.
            dbfile_changes = []
            for (lang, blobname), blob \
                    in new_blob_from_lang_and_blobname.items():
                try:
                    old_res_data[lang][blobname]
                except KeyError:
                    dbfile_changes.append(("add", lang, blobname, blob))
                else:
                    dbfile_changes.append(("update", lang, blobname, blob))

            for lang, old_tfifb in old_res_data.items():
                for blobname in old_tfifb:
                    try:
                        new_res_data[lang][blobname]
                    except KeyError:
                        dbfile_changes.append(("remove", lang, blobname, None))

            dhash = self.dhash_from_dir(dir)
            for action, lang, blobname, blob in dbfile_changes:
                if action == "add":
                    dbfile = self.db.bhash_from_blob_info(
                                buf.path, lang, blobname)
                    blob_index.setdefault(lang, {})[blobname] = dbfile
                    blob_index_has_changed = True
                    dbdir = join(self.base_dir, dhash)
                    if not exists(dbdir):
                        self._mk_dbdir(dbdir, dir)
                    #XXX What to do on write failure?
                    log.debug("fs-write: %s|%s blob '%s/%s'",
                              self.lang, lang, dhash, dbfile)
                    if blob.get("src") is None:
                        blob.set("src", buf.path)   # for defns_from_pos() support
                    ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
                elif action == "remove":
                    dbfile = blob_index[lang][blobname]
                    del blob_index[lang][blobname]
                    blob_index_has_changed = True
                    #XXX What to do on removal failure?
                    log.debug("fs-write: remove %s|%s blob '%s/%s'",
                              self.lang, lang, dhash, dbfile)
                    try:
                        os.remove(join(self.base_dir, dhash, dbfile+".blob"))
                    except EnvironmentError, ex:
                        self.db.corruption("MultiLangZone.update_buf_data",
                            "could not remove dbfile for '%s' blob: %s"\
                                % (blobname, ex),
                            "ignore")
                elif action == "update":
                    # Try to only change the dbfile on disk if it is
                    # different.
                    s = StringIO()
                    if blob.get("src") is None:
                        blob.set("src", buf.path)   # for defns_from_pos() support
                    ET.ElementTree(blob).write(s)
                    new_dbfile_content = s.getvalue()
                    dbfile = blob_index[lang][blobname]
                    dbpath = join(self.base_dir, dhash, dbfile+".blob")
                    # PERF: Might be nice to cache the new dbfile
                    #       content for the next time this resource is
                    #       updated. For files under edit this will be
                    #       common. I.e. just for the "editset".
                    try:
                        fin = open(dbpath, 'r')
                    except OSError, ex:
                        # Technically if the dbfile doesn't exist, this
                        # is a sign of database corruption. No matter
                        # though (for this blob anyway), we are about to
                        # replace it.
                        old_dbfile_content = None
                    else:
                        try:
                            old_dbfile_content = fin.read()
                        finally:
                            fin.close()
                    if new_dbfile_content != old_dbfile_content:
                        if not exists(dirname(dbpath)):
                            self._mk_dbdir(dirname(dbpath), dir)
                        #XXX What to do if fail to write out file?
                        log.debug("fs-write: %s|%s blob '%s/%s'",
                                  self.lang, lang, dhash, dbfile)
                        fout = open(dbpath, 'w')
                        try:
                            fout.write(new_dbfile_content)
                        finally:
                            fout.close()

        if res_index_has_changed:
            self.changed_index(dir, "res_index")
        if blob_index_has_changed:
            self.changed_index(dir, "blob_index")
        if is_hits_from_lpath_lang and toplevelname_index_has_changed:
            self.changed_index(dir, "toplevelname_index")
    finally:
        self._release_lock()
    #TODO: Database.clean() should remove dirs that have no
    #      blob_index entries.    



</t>
<t tx="ekr.20080121121842.98">class MultiLangDirsLib(object):
    """A zone providing a view into an ordered list of dirs in a
    db/$multilang/... area of the db.

    These are dished out via Database.get_lang_lib(), which indirectly
    then is dished out by the MultiLangZone.get_lib(). Mostly this is
    just a view on the MultiLangZone singleton for this particular
    language.
    """
    @others
</t>
<t tx="ekr.20080121121842.99">def __init__(self, lang_zone, lock, lang, name, dirs, sublang):
    self.lang_zone = lang_zone
    self._lock = lock
    self.mgr = lang_zone.mgr
    self.lang = lang
    self.name = name
    self.dirs = dirs
    self.sublang = sublang
    self.import_handler \
        = self.mgr.citadel.import_handler_from_lang(sublang)
    self._have_ensured_scanned_from_dir_cache = {}

    # We keep a "weak" merged cache of blobname lookup for all dirs
    # in this zone -- where "weak" means that we verify a hit by
    # checking the current real dbfile_from_blobname index for that
    # dir (which may have changed). This caching slows down lookup
    # for single-dir LangDirsZones, but should scale better for
    # LangDirsZones with many dirs. (TODO-PERF: test this assertion.)
    self._dir_and_blobbase_from_blobname = {}
    self._importables_from_dir_cache = {}

</t>
<t tx="ekr.20080121121842.100">def __repr__(self):
    return "&lt;%s %s&gt;" % (self.lang, self.name)

</t>
<t tx="ekr.20080121121842.101">def _acquire_lock(self):
    self._lock.acquire()
</t>
<t tx="ekr.20080121121842.102">def _release_lock(self):
    self._lock.release()

</t>
<t tx="ekr.20080121121842.103">def has_blob(self, blobname, ctlr=None):
    dbsubpath = self._dbsubpath_from_blobname(blobname, ctlr=ctlr)
    return dbsubpath is not None

</t>
<t tx="ekr.20080121121842.104">def has_blob_in_db(self, blobname, ctlr=None):
    """Return true if the blobname is in the database.

    Typically this method is only used for debugging and .has_blob()
    is what you want.
    """
    dbsubpath = self._dbsubpath_from_blobname(
        blobname, ctlr=ctlr, only_look_in_db=True)
    return dbsubpath is not None

</t>
<t tx="ekr.20080121121842.105">def get_blob(self, blobname, ctlr=None):
    self._acquire_lock()
    try:
        dbsubpath = self._dbsubpath_from_blobname(
            blobname, ctlr=ctlr)
        if dbsubpath is not None:
            return self.lang_zone.load_blob(dbsubpath)
        else:
            return None
    finally:
        self._release_lock()

</t>
<t tx="ekr.20080121121842.106">def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
    """Return all hits of the given lookup path.
    
    I.e. a symbol table lookup across all files in the dirs of this
    lib.

        "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
            or ['dojo', 'animation'].
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).
        "curr_buf" (optional), if specified, is the current buf for
            which this query is being made. Hits from it should be
            skipped (i.e. don't bother searching it).

    A "hit" is (&lt;CIX node&gt;, &lt;scope-ref&gt;).  Each one represent a
    scope-tag or variable-tag hit in all of the blobs for the
    execution set buffers.

    Returns the empty list if no hits.
    """
    assert isinstance(lpath, tuple)  # common mistake to pass in a string

    if curr_buf:
        curr_blobname = curr_buf.blob_from_lang.get(self.lang, {}).get("name")
        curr_buf_dir = dirname(curr_buf.path)
    
    # Naive implementation (no caching)
    hits = []
    for dir in self.dirs:
        if ctlr and ctlr.is_aborted():
            log.debug("ctlr aborted")
            break
        
        # Need to have (at least once) scanned all importables.
        # Responsibility for ensuring the scan data is *up-to-date*
        # is elsewhere.
        self.ensure_dir_scanned(dir, ctlr=ctlr)

        toplevelname_index = self.lang_zone.load_index(
                dir, "toplevelname_index", {})
        for blobname in toplevelname_index.get_blobnames(
                            self.lang, lpath[0], ()):
            if curr_buf and curr_buf_dir == dir and blobname == curr_blobname:
                continue
            blob = self.get_blob(blobname, ctlr=ctlr)
            try:
                elem = blob
                for p in lpath:
                    #LIMITATION: *Imported* names at each scope are
                    # not being included here. This *should* be okay for
                    # PHP because imports only add symbols to the
                    # top-level. Worse case: the user has to add another
                    # dir to his "extra-dirs" pref.
                    elem = elem.names[p]
            except KeyError:
                continue
            hits.append( (elem, (blob, list(lpath[:-1]))) )

    return hits

</t>
<t tx="ekr.20080121121842.107">def toplevel_cplns(self, prefix=None, ilk=None, ctlr=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk in all blobs in this lib.
    
        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).

    Note: the list is not sorted, because often some special sorting
    is required for the different completion evaluators that might use
    this API.
    """
    cplns = []
    # Naive implementation (no caching)
    for dir in self.dirs:
        if ctlr and ctlr.is_aborted():
            log.debug("ctlr aborted")
            break

        self.ensure_dir_scanned(dir, ctlr=ctlr)

        try:
            toplevelname_index = self.lang_zone.load_index(
                dir, "toplevelname_index")
        except EnvironmentError:
            # No toplevelname_index for this dir likely indicates that
            # there weren't any files of the current lang in this dir.
            continue
        cplns += toplevelname_index.toplevel_cplns(
            self.lang, prefix=prefix, ilk=ilk)
    return cplns

</t>
<t tx="ekr.20080121121842.108">def ensure_dir_scanned(self, dir, ctlr=None):
    """Ensure that all importables in this dir have been scanned
    into the db at least once.

    Note: This is identical to MultiLangDirsLib.ensure_dir_scanned().
    Would be good to share.
    """
    #TODO: should "self.lang" in this function be "self.sublang"?
    if dir not in self._have_ensured_scanned_from_dir_cache:
        event_reported = False
        res_index = self.lang_zone.load_index(dir, "res_index", {})
        importables = self._importables_from_dir(dir)
        for base in (i[0] for i in importables.values()
                     if i[0] is not None):
            if ctlr and ctlr.is_aborted():
                log.debug("ctlr aborted")
                return
            if base not in res_index:
                if not event_reported:
                    self.lang_zone.db.report_event(
                        "scanning %s files in '%s'" % (self.lang, dir))
                    event_reported = True
                buf = self.mgr.buf_from_path(join(dir, base),
                                             lang=self.lang)
                if ctlr is not None:
                    ctlr.info("load %r", buf)
                buf.load()
        self._have_ensured_scanned_from_dir_cache[dir] = True

</t>
<t tx="ekr.20080121121842.109">def _importables_from_dir(self, dir):
    if dir not in self._importables_from_dir_cache:
        self._importables_from_dir_cache[dir] \
            = self.import_handler.find_importables_in_dir(dir)
    return self._importables_from_dir_cache[dir]

</t>
<t tx="ekr.20080121121842.110">def _dbsubpath_from_blobname(self, blobname, ctlr=None, 
                             only_look_in_db=False):
    """Return the subpath to the dbfile for the given blobname,
    or None if not found.

    Remember that this is complicated by possible multi-level
    imports. E.g. "include('foo/bar.php')".
    """
    lang_zone = self.lang_zone

    self._acquire_lock()
    try:
        # Use our weak cache to try to return quickly.
        if blobname in self._dir_and_blobbase_from_blobname:
            blobdir, blobbase = self._dir_and_blobbase_from_blobname[blobname]

            # Check it. The actual info for that dir may have changed.
            dbfile_from_blobname = lang_zone.dfb_from_dir(blobdir, self.sublang)
            if blobbase in dbfile_from_blobname:
                log.debug("have blob '%s' in '%s'? yes (in weak cache)",
                          blobname, blobdir)
                return join(lang_zone.dhash_from_dir(blobdir),
                            dbfile_from_blobname[blobbase])
            del self._dir_and_blobbase_from_blobname[blobname] # drop from weak cache

        # Brute force: look in each dir.
        assert self.import_handler.sep is not None, \
            "%r.sep is None, this must be set" % self.import_handler
        blobparts = blobname.split(self.import_handler.sep)
        blobbase = blobparts[-1]
        for dir in self.dirs:
            if ctlr and ctlr.is_aborted():
                log.debug("aborting search for blob '%s' on %s: ctlr aborted",
                          blobname, self)
                return None

            # Is the blob in 'blobdir' (i.e. a non-multi-level import
            # that has been scanned already).
            blobdir = join(dir, *blobparts[:-1])
            dbfile_from_blobname = lang_zone.dfb_from_dir(
                                        blobdir, self.sublang, {})
            if blobbase in dbfile_from_blobname:
                self._dir_and_blobbase_from_blobname[blobname] \
                    = (blobdir, blobbase)
                log.debug("have blob '%s' in '%s'? yes (in dir index)", 
                          blobname, blobdir)
                return join(lang_zone.dhash_from_dir(blobdir),
                            dbfile_from_blobname[blobbase])

            importables = self._importables_from_dir(blobdir)
            # 'importables' look like, for PHP:
            #   {'foo.php': ('foo.php', None, False),
            #    'foo.inc': ('foo.inc', None, False),
            #    'somedir': (None,      None, True)}

            if blobbase not in importables:
                continue

            blobfile, subdir_blobbase, is_dir_import = importables[blobbase]
            if blobfile is None:
                # There isn't an actual importable file here -- just
                # a dir prefix to a multidir import.
                log.debug("have blob '%s' in %s? no", blobname, self)
                return None
            elif os.sep in blobfile:
                # This is an import from a subdir. We need to get a new dbf.
                blobdir = join(blobdir, dirname(blobfile))
                blobfile = basename(blobfile)
                blobbase = subdir_blobbase
                dbfile_from_blobname = lang_zone.dfb_from_dir(
                                            blobdir, self.sublang, {})
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (in dir index)", 
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

            # The file isn't loaded.
            if not only_look_in_db:
                log.debug("%s importables in '%s':\n    %s", self.sublang,
                          blobdir, importables)
                log.debug("'%s' likely provided by '%s' in '%s': "
                          "attempting load", blobname, blobfile, blobdir)
                buf = self.mgr.buf_from_path(
                        join(blobdir, blobfile), self.lang)
                buf.load()

                dbfile_from_blobname = lang_zone.dfb_from_dir(
                                            blobdir, self.sublang, {})
                if blobbase in dbfile_from_blobname:
                    self._dir_and_blobbase_from_blobname[blobname] \
                        = (blobdir, blobbase)
                    log.debug("have blob '%s' in '%s'? yes (after load)",
                              blobname, blobdir)
                    return join(lang_zone.dhash_from_dir(blobdir),
                                dbfile_from_blobname[blobbase])

        log.debug("have blob '%s' in %s? no", blobname, self)
        return None
    finally:
        self._release_lock()


</t>
<t tx="ekr.20080121121842.111">#!python
# ***** LICENSE BLOCK *****

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import threading
import md5
from pprint import pprint, pformat
import logging
import codecs
import weakref

from codeintel2.common import *



#---- globals

log = logging.getLogger("codeintel.db")



</t>
<t tx="ekr.20080121121842.112">#---- Database zone and lib implementations

class ProjectZone(object):
    """Manage a 'db/projs/&lt;proj-hash&gt;/...' area of the database.

    A project zone works with a project object(*) to provide quick
    mapping of a (lang, blobname) to a file in the project, if any.

    # Dealing with updating

    Knowing when a file has been removed from a project is fairly easy:
    we hit it in the cache, then do a quick stat (or query on the
    project) to ensure it it still there.

    Knowing when a file has been added to a project is harder. Fully
    hooking into Komodo's file system-level dir watching and various
    in-Komodo update notifications is hard (doesn't translate well to
    simply requiring an API on the project object) and isn't perfect
    anyway. Ideally .dirs_from_basename() is all handled by the project
    object and we don't have to worry about it. However, Komodo Projects
    aren't currently setup to do this well, so codeintel is taking the
    burden of caching.

    The planned solution is to attempt a reasonable job of creating the
    dirs_from_basename cache and then providing a manual interface
    (perhaps right-click on Project -&gt; "Refresh Status") to update.

    (*) The project object is required to have the following API:
        TODO: spec the API.
    """
    @others
</t>
<t tx="ekr.20080121121842.113">def __init__(self, mgr, db, proj):
    self.mgr = mgr
    self.db = db
    self.proj = proj

    self.name = basename(proj.path)
    self.base_dir = join(self.db.base_dir, "db", "projs", 
                         md5.new(proj.path).hexdigest())
    self._proj_lib_from_lang = weakref.WeakValueDictionary()
    self._idx_lock = threading.RLock()
    self._dirs_from_basename = None
    self._is_idx_dirty = False

</t>
<t tx="ekr.20080121121842.114">def __repr__(self):
    return "&lt;proj '%s' zone&gt;" % self.name

</t>
<t tx="ekr.20080121121842.115">def __del__(self):
    try:
        self.save()
    except:
        log.exception("error saving %s" % self)

</t>
<t tx="ekr.20080121121842.116">def get_dirs_from_basename(self):
    self._idx_lock.acquire()
    try:
        if self._dirs_from_basename is None:
            log.debug("fs-read: load %s 'dirs_from_basename' index", self)
            self._dirs_from_basename = self.db.load_pickle(
                join(self.base_dir, "dirs_from_basename"), {})
        return self._dirs_from_basename
    finally:
        self._idx_lock.release()
</t>
<t tx="ekr.20080121121842.117">def set_dirs_from_basename(self, value):
    self._idx_lock.acquire()
    try:
        old_value = self.dirs_from_basename
        self._dirs_from_basename = value
        if old_value != value:
            #PERF: can this be smarter? Would have to be on
            #      .update() for that.
            self._is_idx_dirty = True
    finally:
        self._idx_lock.release()
</t>
<t tx="ekr.20080121121842.118">dirs_from_basename = property(get_dirs_from_basename,
    set_dirs_from_basename, None, "index of basenames in project")

def _mk_dbdir(self):
    log.debug("fs-write: mkdir '%s'", self.base_dir)
    os.makedirs(self.base_dir)
    log.debug("fs-write: '%s/path'", self.base_dir)
    fout = codecs.open(join(self.base_dir, "path"), 'wb', 'utf-8')
    try:
        fout.write(self.proj.path)
    finally:
        fout.close()

</t>
<t tx="ekr.20080121121842.119">def save(self):
    self._idx_lock.acquire()
    try:
        if self._is_idx_dirty:
            if not exists(self.base_dir):
                self._mk_dbdir()
            self.db.save_pickle(join(self.base_dir, "dirs_from_basename"),
                self._dirs_from_basename)
            self._is_idx_dirty = False
    finally:
        self._idx_lock.release()

</t>
<t tx="ekr.20080121121842.120">def update(self, nice=False):
    """Update the index for the list of files in the project.

        "nice" (default False) is a boolean indicating if this
            update process should attempt to keep the CPU load low.
    """
    if nice:
        XXX
    #XXX Update this to handle includes, excludes,
    #    static-project-entries. I.e. move this logic to the
    #    project where it can handle this stuff.
    dirs_from_basename = {}
    for dirpath, dirnames, filenames in os.walk(self.proj.base_dir):
        for filename in filenames:
            dirs_from_basename.setdefault(filename, []).append(dirpath)
    self.dirs_from_basename = dirs_from_basename

</t>
<t tx="ekr.20080121121842.121">def _likely_filename_from_lang_and_blobname(self, lang, blobname):
    #XXX Need to canonicalize filename.
    #XXX Shouldn't be hardcoding this stuff here. Defer out to the
    #    lang_*.py modules.
    #XXX Do we have to worry about multi-level imports here? E.g.,
    #       Python:  os.path
    #       Perl:    LWP::UserAgent
    #       Ruby:    yaml/context
    #       PHP:     blah/blam.php
    if lang == "Python":
        return blobname+".py"
    else:
        XXX

</t>
<t tx="ekr.20080121121842.122">def has_blob(self, lang, blobname):
    lang_lib = self._lang_lib_for_blob(lang, blobname)
    if lang_lib is None:
        return False
    return lang_lib.has_blob(blobname)

</t>
<t tx="ekr.20080121121842.123">def get_blob(self, lang, blobname):
    lang_lib = self._lang_lib_for_blob(lang, blobname)
    if lang_lib is None:
        return None
    return lang_lib.get_blob(blobname)

</t>
<t tx="ekr.20080121121842.124">def _lang_lib_for_blob(self, lang, blobname):
    filename = self._likely_filename_from_lang_and_blobname(lang, blobname)
    try:
        dirs = self.dirs_from_basename[filename]
    except KeyError:
        return None
    else:
        #XXX This may be a perf issue because of a possibly large
        #    number of created LangDirsLib's -- which was unexpected
        #    when the LangDirsLibs caching was designed on LangZone.
        #    The cache size may need to be increased or some other
        #    scheme considered.
        return self.db.get_lang_lib(lang, "proj '%s' lib" % self.name,
                                    dirs,
                                    sublang=lang) # for PHP

</t>
<t tx="ekr.20080121121842.125">def get_lib(self, lang):
    proj_lib = self._proj_lib_from_lang.get(lang)
    if proj_lib is None:
        proj_lib = ProjectLib(self, lang)
        self._proj_lib_from_lang[lang] = proj_lib
    return proj_lib

</t>
<t tx="ekr.20080121121842.126">class ProjectLib(object):
    @others
</t>
<t tx="ekr.20080121121842.127"># Light lang-specific wrapper around a ProjectZone (akin to
# CatalogLig).
def __init__(self, proj_zone, lang):
    self.proj_zone = proj_zone
    self.lang = lang
</t>
<t tx="ekr.20080121121842.128">def __repr__(self):
    return "&lt;proj '%s' %s lib&gt;" % (self.proj_zone.name, self.lang)
</t>
<t tx="ekr.20080121121842.129">def has_blob(self, blobname):
    return self.proj_zone.has_blob(self.lang, blobname)
</t>
<t tx="ekr.20080121121842.130">def get_blob(self, blobname):
    return self.proj_zone.get_blob(self.lang, blobname)
</t>
<t tx="ekr.20080121121842.131">#!python
# ***** LICENSE BLOCK *****


#TODO: docstring

import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import cPickle as pickle
import threading
import time
import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner
from codeintel2.tree import tree_from_cix_path



#---- globals

log = logging.getLogger("codeintel.db")
</t>
<t tx="ekr.20080121121842.132">#log.setLevel(logging.DEBUG)


#---- Resource classes
# For abstraction and canonicalization of paths.

class Resource(object):
    """A reference to a resource for the database.

    Typically this is just a path to a file on the local disk. However
    the intention is to also support remote file urls (TODO) and unsaved
    files (TODO).

    This class also provides canonicalization on comparison of resource
    paths.
    """
    @others
</t>
<t tx="ekr.20080121121842.133">
def __init__(self, path):
    self.path = path

</t>
<t tx="ekr.20080121121842.134">@property
def canon_path(self):
    # normalize os.altsep to os.sep? or even consider normalizing to
    # all '/'. This gets more complicated if have URL resources for
    # remote files: subclassing.
    XXX


</t>
<t tx="ekr.20080121121842.135">class AreaResource(Resource):
    """A resource that is at a relative path under some area.

    For example, at 'template/Perl.pl' under 'the Komodo user data
    dir' or at 'catalog/baz.cix' under 'the codeintel2 package dir'.

    TODO: change ctor sig to AreaResource([area, ] path). More logical
    to have input be in same order as .area_path.
    """
    # The known path areas. We only have use for the one right now.
    _path_areas = {
        "ci-pkg-dir": dirname(dirname(abspath(__file__))),
    }
    _ordered_area_items = [(d,a) for a,d in _path_areas.items()]
    _ordered_area_items.sort(key=lambda i: len(i[0]), reverse=True)

    @others
</t>
<t tx="ekr.20080121121842.136">@classmethod
def area_and_subpath_from_path(cls, path):
    #XXX Need to worry about canonicalization!
    for area_dir, area in cls._ordered_area_items:
        if (path.startswith(area_dir)
            # Ensure we are matching at a dir boundary. This implies
            # a limitation that there *is* a subpath. I'm fine with
            # that.
            and path[len(area_dir)] in (os.sep, os.altsep)):
            return area, path[len(area_dir)+1:]
    return None, path

</t>
<t tx="ekr.20080121121842.137">def __init__(self, path, area=None):
    """Create an area-relative resource.

        "path" is either the full path to the resource, or a
            relative path under the given area name. "area" must be
            specified for the latter.
        "area" (optional) can be given to specify under which area
            this resource resides. If not given, the best-fit of the
            known path areas will be used.
    """
    if area is not None:
        if area not in self._path_areas:
            raise ValueError("unknown path area: `%s'" % area)
        self.area = area
        if isabs(path):
            area_base = self._path_areas[area]
            if not path.startswith(area_base):
                raise ValueError("cannot create AreaResource: `%s' is "
                                 "not under `%s' area (%s)" 
                                 % (path, area, area_base))
            self.subpath = path[len(area_base)+1:]
        else:
            self.subpath = path
    elif isinstance(path, tuple): # as per AreaResource.area_path
        self.area, self.subpath = path 
    else:
        self.area, self.subpath = self.area_and_subpath_from_path(path)

</t>
<t tx="ekr.20080121121842.138">def __str__(self):
    if self.area:
        return "[%s]%s%s" % (self.area, os.sep, self.subpath)
    else:
        return self.subpath

</t>
<t tx="ekr.20080121121842.139">def __repr__(self):
    return "AreaResource(%r, %r)" % (self.path, self.area)

</t>
<t tx="ekr.20080121121842.140">@property
def area_path(self):
    return (self.area, self.subpath)

</t>
<t tx="ekr.20080121121842.141">@property
def path(self):
    if self.area is None:
        return self.subpath
    else:
        return join(self._path_areas[self.area], self.subpath)


</t>
<t tx="ekr.20080121121842.142">#!python
# ***** LICENSE BLOCK *****

"""The stdlib zone of the codeintel database.
See the database/database.py module docstring for an overview.
"""


import sys
import os
from os.path import (join, dirname, exists, expanduser, splitext, basename,
                     split, abspath, isabs, isdir, isfile)
import cPickle as pickle
import threading
import time
import md5
import bisect
import fnmatch
from glob import glob
from pprint import pprint, pformat
import logging
from cStringIO import StringIO
import codecs
import copy
import weakref
import Queue

import ciElementTree as ET
from codeintel2.common import *
from codeintel2.buffer import Buffer
from codeintel2.util import dedent, safe_lang_from_lang, banner
from codeintel2.tree import tree_from_cix_path
from codeintel2.database.resource import AreaResource
from codeintel2.database.util import (rmdir, filter_blobnames_for_prefix)



#---- globals

log = logging.getLogger("codeintel.db")
</t>
<t tx="ekr.20080121121842.143">#log.setLevel(logging.DEBUG)



#---- Database zone and lib implementations

class StdLib(object):
    """Singleton lib managing a particular db/stdlibs/&lt;stdlib-name&gt;
    area of the db.

    These are dished out via Database.get_stdlib(), which indirectly
    then is dished out by the StdLibsZone.get_lib().

    Because (1) any updating of the stdlib db area for this language has
    already been done (by StdLibsZone.get_lib()) and (2) this is a
    singleton: we shouldn't have to worry about locking.
    """
    _blob_index = None
    _toplevelname_index = None
    _toplevelprefix_index = None

    @others
</t>
<t tx="ekr.20080121121842.144">def __init__(self, db, base_dir, lang, name):
    self.db = db
    self.lang = lang
    self.name = name
    self.base_dir = base_dir
    self._import_handler = None
    self._blob_imports_from_prefix_cache = {}

</t>
<t tx="ekr.20080121121842.145">def __repr__(self):
    return "&lt;%s stdlib&gt;" % self.name

</t>
<t tx="ekr.20080121121842.146">@property
def import_handler(self):
    if self._import_handler is None:
        self._import_handler \
            = self.db.mgr.citadel.import_handler_from_lang(self.lang)
    return self._import_handler

</t>
<t tx="ekr.20080121121842.147">@property
def blob_index(self):
    if self._blob_index is None:
        idxpath = join(self.base_dir, "blob_index")
        self._blob_index = self.db.load_pickle(idxpath)
    return self._blob_index

</t>
<t tx="ekr.20080121121842.148">@property
def toplevelname_index(self):
    if self._toplevelname_index is None:
        idxpath = join(self.base_dir, "toplevelname_index")
        self._toplevelname_index = self.db.load_pickle(idxpath)
    return self._toplevelname_index

</t>
<t tx="ekr.20080121121842.149">@property
def toplevelprefix_index(self):
    if self._toplevelprefix_index is None:
        idxpath = join(self.base_dir, "toplevelprefix_index")
        self._toplevelprefix_index = self.db.load_pickle(idxpath)
    return self._toplevelprefix_index

</t>
<t tx="ekr.20080121121842.150">def has_blob(self, blobname):
    return blobname in self.blob_index

</t>
<t tx="ekr.20080121121842.151">def get_blob(self, blobname):
    try:
        dbfile = self.blob_index[blobname]
    except KeyError:
        return None
    return self.db.load_blob(join(self.base_dir, dbfile))

</t>
<t tx="ekr.20080121121842.152">def get_blob_imports(self, prefix):
    """Return the set of imports under the given prefix.

        "prefix" is a tuple of import name parts. E.g. ("xml", "sax")
            for "import xml.sax." in Python. Or ("XML", "Parser") for
            "use XML::Parser::" in Perl.

    See description in database.py docstring for details.
    """
    if prefix not in self._blob_imports_from_prefix_cache:
        matches = filter_blobnames_for_prefix(self.blob_index,
                    prefix, self.import_handler.sep)
        self._blob_imports_from_prefix_cache[prefix] = matches
    return self._blob_imports_from_prefix_cache[prefix]

</t>
<t tx="ekr.20080121121842.153">def hits_from_lpath(self, lpath, ctlr=None, curr_buf=None):
    """Return all hits of the given lookup path.
    
    I.e. a symbol table lookup across all files in the dirs of this
    lib.

        "lpath" is a lookup name list, e.g. ['Casper', 'Logging']
            or ['dojo', 'animation'].
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).
        "curr_buf" (optional) is not relevant for StdLib. Used for
            other *Lib classes.

    A "hit" is (&lt;CIX node&gt;, &lt;scope-ref&gt;).  Each one represent a
    scope-tag or variable-tag hit in all of the blobs for the
    execution set buffers.

    Returns the empty list if no hits.
    """
    assert isinstance(lpath, tuple)  # common mistake to pass in a string
    hits = []
    # toplevelname_index: {ilk -&gt; toplevelname -&gt; blobnames}
    for blobnames_from_toplevelname in self.toplevelname_index.itervalues():
        for blobname in blobnames_from_toplevelname.get(lpath[0], ()):
            blob = self.get_blob(blobname)
            try:
                elem = blob
                for p in lpath:
                    #LIMITATION: *Imported* names at each scope are
                    # not being included here. This is fine while we
                    # just care about JavaScript.
                    elem = elem.names[p]
            except KeyError:
                continue
            hits.append( (elem, (blob, list(lpath[:-1]))) )
    return hits

</t>
<t tx="ekr.20080121121842.154">def toplevel_cplns(self, prefix=None, ilk=None):
    """Return completion info for all top-level names matching the
    given prefix and ilk in all blobs in this lib.
    
        "prefix" is a 3-character prefix with which to filter top-level
            names. If None (or not specified), results are not filtered
            based on the prefix.
        "ilk" is a symbol type (e.g. "class", "variable", "function")
            with which to filter results. If None (or not specified),
            results of any ilk are returned.
        "ctlr" (optional) is an EvalController instance. If
            specified it should be used in the normal way (logging,
            checking .is_aborted()).

    Returns a list of 2-tuples: (&lt;ilk&gt;, &lt;name&gt;).

    Note: the list is not sorted, because often some special sorting
    is required for the different completion evaluators that might use
    this API.
    """
    cplns = []
    if prefix is None:
        # Use 'toplevelname_index': {ilk -&gt; toplevelname -&gt; blobnames}
        for i, bft in self.toplevelname_index.iteritems():
            if ilk is not None and i != ilk:
                continue
            cplns += [(i, toplevelname) for toplevelname in bft]
    else:
        # Use 'toplevelprefix_index':
        #   {ilk -&gt; prefix -&gt; toplevelnames}
        if ilk is not None:
            try:
                toplevelnames = self.toplevelprefix_index[ilk][prefix]
            except KeyError:
                pass
            else:
                cplns += [(ilk, t) for t in toplevelnames]
        else:
            for i, tfp in self.toplevelprefix_index.iteritems():
                if prefix not in tfp:
                    continue
                cplns += [(i, t) for t in tfp[prefix]]

    return cplns
    


</t>
<t tx="ekr.20080121121842.155">class StdLibsZone(object):
    """Singleton zone managing the db/stdlibs/... area.

    Because this is a singleton we shouldn't have to worry about locking
    to prevent corruption.
    """
    _res_index = None                   # cix-path -&gt; last-updated
    _vers_and_names_from_lang = None    # lang -&gt; ordered list of (ver, name)

    @others
</t>
<t tx="ekr.20080121121842.156">def __init__(self, db):
    self.db = db
    self.stdlibs_dir = join(dirname(dirname(__file__)), "stdlibs")
    self.base_dir = join(self.db.base_dir, "db", "stdlibs")
    self._stdlib_from_stdlib_name = {} # cache of StdLib singletons
    self._have_updated_stdlib_from_lang = {}

</t>
<t tx="ekr.20080121121842.157">def __del__(self):
    for stdlib in self._stdlib_from_stdlib_name.keys():
        del self._stdlib_from_stdlib_name[stdlib] # drop reference

</t>
<t tx="ekr.20080121121842.158">@property
def vers_and_names_from_lang(self):
    "lang -&gt; ordered list of (ver, name)"
    if self._vers_and_names_from_lang is None:
        idxpath = join(self.base_dir, "vers_and_names_from_lang")
        self._vers_and_names_from_lang \
            = self.db.load_pickle(idxpath, {})
    return self._vers_and_names_from_lang

</t>
<t tx="ekr.20080121121842.159">@property
def res_index(self):
    "cix-path -&gt; last-updated"
    if self._res_index is None:
        idxpath = join(self.base_dir, "res_index")
        self._res_index = self.db.load_pickle(idxpath, {})
    return self._res_index

</t>
<t tx="ekr.20080121121842.160">def save(self):
    if self._res_index is not None:
        self.db.save_pickle(join(self.base_dir, "res_index"),
                            self._res_index)
    if self._vers_and_names_from_lang is not None:
        self.db.save_pickle(
            join(self.base_dir, "vers_and_names_from_lang"),
            self._vers_and_names_from_lang)

</t>
<t tx="ekr.20080121121842.161">def get_lib(self, lang, ver_str=None):
    """Return a view into the stdlibs zone for a particular language
    and version's stdlib.

        "lang" is the language, e.g. "Perl", for which to get a
            stdlib.
        "ver_str" (optional) is a specific version of the language,
            e.g. "5.8".

    On first get of a stdlib for a particular language, all
    available stdlibs for that lang are updated, if necessary.

    Returns None if there is not stdlib for this language.
    """
    if lang not in self._have_updated_stdlib_from_lang:
        self.update_lang(lang)
        self._have_updated_stdlib_from_lang[lang] = True

    vers_and_names = self.vers_and_names_from_lang.get(lang)
    if not vers_and_names:
        return None
    if ver_str is None:
        # Default to the latest version.
        ver = vers_and_names[-1][0]
    else:
        ver = _ver_from_ver_str(ver_str)

    # Here is something like what we have for PHP:
    #    vers_and_names = [
    #        (None, "php"),
    #        ((4,0), "php-4.0"),
    #        ((4,1), "php-4.1"),
    #        ((4,2), "php-4.2"),
    #        ((4,3), "php-4.3"),
    #        ((5,0), "php-5.0"),
    #        ((5,1), "php-5.1"),
    #    ]
    # We want to (quickly) pick the best fit stdlib for the given
    # PHP version:
    #   PHP (ver=None): php
    #   PHP 3.0:        php
    #   PHP 4.0:        php-4.0 (exact match)
    #   PHP 4.0.2:      php-4.0 (higher sub-version)
    #   PHP 4.4:        php-4.3
    #   PHP 6.0:        php-5.1
    key = (ver, "zzz") # 'zzz' &gt; any stdlib name (e.g., 'zzz' &gt; 'php-4.2')
    idx = max(0, bisect.bisect_right(vers_and_names, key)-1)
    log.debug("best stdlib fit for %s ver=%s in %s is %s",
              lang, ver, vers_and_names, vers_and_names[idx])
    
    stdlib_name = vers_and_names[idx][1]
    if stdlib_name not in self._stdlib_from_stdlib_name:
        self._stdlib_from_stdlib_name[stdlib_name] = StdLib(
            self.db, join(self.base_dir, stdlib_name), lang, stdlib_name)
    return self._stdlib_from_stdlib_name[stdlib_name]

</t>
<t tx="ekr.20080121121842.162">def _get_preload_zip(self):
    return join(self.stdlibs_dir, "stdlibs.zip")

</t>
<t tx="ekr.20080121121842.163">def can_preload(self):
    """Return True iff can preload."""
    if exists(self.base_dir):
        log.info("can't preload stdlibs: `%s' exists", self.base_dir)
        return False
    try:
        import process
        import which
    except ImportError, ex:
        log.info("can't preload stdlibs: %s", ex)
        return False
    try:
        which.which("unzip")
    except which.WhichError, ex:
        log.info("can't preload stdlibs: %s", ex)
        return False
    preload_zip = self._get_preload_zip()
    if not exists(preload_zip):
        log.info("can't preload stdlibs: `%s' does not exist", preload_zip)
        return False
    return True

</t>
<t tx="ekr.20080121121842.164">def preload(self, progress_cb=None):
    """Pre-load the stdlibs zone, if able.

        "progress_cb" (optional) is a callable that is called as
            follows to show the progress of the update:
                progress_cb(&lt;desc&gt;, &lt;value&gt;)
            where &lt;desc&gt; is a short string describing the current step
            and &lt;value&gt; is an integer between 0 and 100 indicating the
            level of completeness.

    Use `.can_preload()' to determine if able to pre-load.
    """
    import which
    import process

    log.debug("preloading stdlibs zone")
    if progress_cb:
        try:    progress_cb("Preloading stdlibs...", None)
        except: log.exception("error in progress_cb (ignoring)")
    preload_zip = self._get_preload_zip()
    unzip_exe = which.which("unzip")
    cmd = '"%s" -q -d "%s" "%s"'\
          % (unzip_exe, dirname(self.base_dir), preload_zip)
    p = process.ProcessOpen(cmd)
    retval = p.wait()
    if retval:
        raise OSError("error running '%s'" % cmd)

</t>
<t tx="ekr.20080121121842.165">#TODO: Add ver_str option (as per get_lib above) and only update
#      the relevant stdlib.
def remove_lang(self, lang):
    """Remove the given language from the stdlib zone."""
    log.debug("update '%s' stdlibs", lang)

    # Figure out what updates need to be done...
    cix_glob = join(self.stdlibs_dir, safe_lang_from_lang(lang)+"*.cix")
    todo = []
    for area, subpath in self.res_index:
        res = AreaResource(subpath, area)
        if fnmatch.fnmatch(res.path, cix_glob):
            todo.append(("remove", AreaResource(subpath, area)))

    # ... and then do them.
    self._handle_res_todos(lang, todo)
    self.save()
    
</t>
<t tx="ekr.20080121121842.166">#TODO: Add ver_str option (as per get_lib above) and only update
#      the relevant stdlib.
def update_lang(self, lang, progress_cb=None):
    """Import stdlib data for this lang, if necessary.
    
        "lang" is the language to update.
        "progress_cb" (optional) is a callable that is called as
            follows to show the progress of the update:
                progress_cb(&lt;desc&gt;, &lt;value&gt;)
            where &lt;desc&gt; is a short string describing the current step
            and &lt;value&gt; is an integer between 0 and 100 indicating the
            level of completeness.
    """
    log.debug("update '%s' stdlibs", lang)
    # Figure out what updates need to be done...
    if progress_cb:
        try:    progress_cb("Determining necessary updates...", 5)
        except: log.exception("error in progress_cb (ignoring)")
    cix_glob = join(self.stdlibs_dir, safe_lang_from_lang(lang)+"*.cix")
    todo = []
    checklist = {}
    for area, subpath in self.res_index:
        res = AreaResource(subpath, area)
        if fnmatch.fnmatch(res.path, cix_glob):
            checklist[res.area_path] = True
    for cix_path in glob(cix_glob):
        res = AreaResource(cix_path, "ci-pkg-dir")
        try:
            last_updated = self.res_index[res.area_path]
        except KeyError:
            todo.append(("add", res))
        else:
            mtime = os.stat(cix_path).st_mtime
            if last_updated != mtime: # epsilon? '&gt;=' instead of '!='?
                todo.append(("update", res))
            del checklist[res.area_path] # tick it off
    for area, subpath in checklist:
        todo.append(("remove", AreaResource(subpath, area)))

    # ... and then do them.
    self._handle_res_todos(lang, todo, progress_cb)
    self.save()

</t>
<t tx="ekr.20080121121842.167">def _handle_res_todos(self, lang, todo, progress_cb=None):
    if not todo:
        return
    for i, (action, res) in enumerate(todo):
        cix_path = res.path
        name = splitext(basename(cix_path))[0]
        if '-' in name:
            base, ver_str = name.split('-', 1)
            ver = _ver_from_ver_str(ver_str)
        else:
            base = name
            ver = None
        assert base == safe_lang_from_lang(lang)

        log.debug("%s %s stdlib: `%s'", action, name, cix_path)
        verb = {"add": "Adding", "remove": "Removing",
                "update": "Updating"}[action]
        desc = "%s %s stdlib" % (verb, name)
        self.db.report_event(desc)
        if progress_cb:
            try:    progress_cb(desc, (5 + 95/len(todo)*i))
            except: log.exception("error in progress_cb (ignoring)")

        if action == "add":
            self._add_res(res, lang, name, ver)
        elif action == "remove":
            self._remove_res(res, lang, name, ver)
        elif action == "update":
            #XXX Bad for filesystem. Change this to do it
            #    more intelligently if possible.
            self._remove_res(res, lang, name, ver)
            self._add_res(res, lang, name, ver)
    for vers_and_names in self.vers_and_names_from_lang.values():
        vers_and_names.sort()

</t>
<t tx="ekr.20080121121842.168">def _remove_res(self, res, lang, name, ver):
    log.debug("%s stdlibs: remove %s", lang, res)
    del self.res_index[res.area_path]
    self.vers_and_names_from_lang[lang].remove((ver, name))
    dbdir = join(self.base_dir, name)
    try:
        rmdir(dbdir)
    except OSError, ex:
        try:
            os.rename(dbdir, dbdir+".zombie")
        except OSError, ex2:
            log.error("could not remove %s stdlib database dir `%s' (%s): "
                      "couldn't even rename it to `%s.zombie' (%s): "
                      "giving up", name, dbdir, ex, name, ex2)
        else:
            log.warn("could not remove %s stdlib database dir `%s' (%s): "
                     "moved it to `%s.zombie'", name, dbdir, ex)

</t>
<t tx="ekr.20080121121842.169">def _add_res(self, res, lang, name, ver):
    log.debug("%s stdlibs: add %s", lang, res)
    cix_path = res.path
    try:
        tree = tree_from_cix_path(cix_path)
    except ET.XMLParserError, ex:
        log.warn("could not load %s stdlib from `%s' (%s): skipping",
                 name, cix_path, ex)
        return

    dbdir = join(self.base_dir, name)
    if exists(dbdir):
        log.warn("`db/stdlibs/%s' already exists and should not: "
                 "removing it", name)
        try:
            rmdir(dbdir)
        except OSError, ex:
            log.error("could not remove `%s' to create %s stdlib in "
                      "database (%s): skipping", dbdir, name)
    if not exists(dbdir):
        os.makedirs(dbdir)

    # Create 'blob_index' and 'toplevel*_index' and write out
    # '.blob' file.
    LEN_PREFIX = self.db.LEN_PREFIX
    is_hits_from_lpath_lang = lang in self.db.import_everything_langs
    blob_index = {} # {blobname -&gt; dbfile}
    if is_hits_from_lpath_lang:
        toplevelname_index = {} # {ilk -&gt; toplevelname -&gt; blobnames}
        toplevelprefix_index = {} # {ilk -&gt; prefix -&gt; toplevelnames}
    for blob in tree.findall("file/scope"):
        assert lang == blob.get("lang")
        blobname = blob.get("name")
        dbfile = self.db.bhash_from_blob_info(cix_path, lang, blobname)
        blob_index[blobname] = dbfile
        ET.ElementTree(blob).write(join(dbdir, dbfile+".blob"))
        if is_hits_from_lpath_lang:
            for toplevelname, elem in blob.names.iteritems():
                ilk = elem.get("ilk") or elem.tag
                bft = toplevelname_index.setdefault(ilk, {})
                if toplevelname not in bft:
                    bft[toplevelname] = set([blobname])
                else:
                    bft[toplevelname].add(blobname)
                prefix = toplevelname[:LEN_PREFIX]
                tfp = toplevelprefix_index.setdefault(ilk, {})
                if prefix not in tfp:
                    tfp[prefix] = set([toplevelname])
                else:
                    tfp[prefix].add(toplevelname)

    self.db.save_pickle(join(dbdir, "blob_index"), blob_index)
    if is_hits_from_lpath_lang:
        self.db.save_pickle(join(dbdir, "toplevelname_index"),
                            toplevelname_index)
        self.db.save_pickle(join(dbdir, "toplevelprefix_index"),
                            toplevelprefix_index)

    mtime = os.stat(cix_path).st_mtime
    self.vers_and_names_from_lang.setdefault(lang, []) \
        .append((ver, name))
    self.res_index[res.area_path] = mtime



</t>
<t tx="ekr.20080121121842.170">#---- internal support stuff

def _ver_from_ver_str(ver_str):
    """Convert a version string to a version object as used internally
    for the "stdlibs" area of the database.
   
        &gt;&gt;&gt; _ver_from_ver_str("5.8")
        (5, 8)
        &gt;&gt;&gt; _ver_from_ver_str("1.8.2")
        (1, 8, 2)
        &gt;&gt;&gt; _ver_from_ver_str("ecma")
        'ecma'
        &gt;&gt;&gt; _ver_from_ver_str("ie")
        'ie'
    """
    ver = []
    for s in ver_str.split('.'):
        try:
            ver.append(int(s))
        except ValueError:
            ver.append(s)
    return tuple(ver)




</t>
<t tx="ekr.20080121121842.171">#!python
# ***** LICENSE BLOCK *****

import os
import sys
import md5
import logging
import shutil

log = logging.getLogger("codeintel.db")



</t>
<t tx="ekr.20080121121842.172">def filter_blobnames_for_prefix(candidates, prefix, sep):
    """Given a iterator of candidate blob names, return a set of
    2-tuples indicating each match:
    
        (&lt;sub-name&gt;, &lt;is-partial-match&gt;)

    where,
        &lt;sub-name&gt; is the import component after the prefix
        &lt;is-partial-match&gt; is a boolean indicating if suffix is
            multipart.

    For example, given:
        candidates = ["LWP",
                      "LWP::Authen::Basic", "LWP::Authen::Digest",
                      "LWP::ConnCache",
                      "LWP::Protocol",
                      "LWP::Protocol::http", "LWP::Protocol::https",
                      "LWP::UserAgent"]
        prefix = ("LWP",)
        sep = "::"
    the returned items should be:
        ("Authen",    True)
        ("ConnCache", False)
        ("Protocol",  False)
        ("Protocol",  True)
        ("UserAgent", False)
    """
    matches = set()
    if not prefix:
        for name in candidates:
            if name == "*": continue  # skip "built-in" blob
            if sep in name:
                matches.add( (name[:name.index(sep)], True) )
            else:
                matches.add( (name, False) )
    else:
        sep_len = len(sep)
        sepped_prefix = sep.join(prefix)
        for name in candidates:
            if name == "*": continue  # skip "built-in" blob
            if name.startswith(sepped_prefix + sep):
                # e.g. prefix is "xml", and we see "xml.sax" and "xml.bar.foo"
                subname = name[len(sepped_prefix)+sep_len:]
                # subname is "sax" and "bar.foo"
                if sep in subname:
                    # we want to return bar, not bar.foo
                    subname = subname[:subname.index(sep)]
                    is_partial_match = True
                else:
                    is_partial_match = False
                matches.add( (subname, is_partial_match) )
    return matches


</t>
<t tx="ekr.20080121121842.173">def rmdir(dir):
    """Remove the given dir. Raises an OSError on failure."""
    if sys.platform == "win32":
        # Apparent just running 'rd' (or else because run via
        # process.Process) on Windows == DOS box flash (bug 61348).
        log.debug("fs-write: rmdir `%s'", dir)
        shutil.rmtree(dir, 0, _rmtree_onerror)
    else:
        run('rm -rf "%s"' % dir)

</t>
<t tx="ekr.20080121121842.174">def _rmtree_onerror(rm_func, path, exc_info):
    if exc_info[0] == OSError:
        # presuming because file is read-only
        os.chmod(path, 0777)
        rm_func(path)



</t>
<t tx="ekr.20080121121842.175">#---- internal support routines

# Recipe: run (0.5.3) in /home/trentm/tm/recipes/cookbook
_RUN_DEFAULT_LOGSTREAM = ("RUN", "DEFAULT", "LOGSTREAM")
def __run_log(logstream, msg, *args, **kwargs):
    if not logstream:
        pass
    elif logstream is _RUN_DEFAULT_LOGSTREAM:
        try:
            log
        except NameError:
            pass
        else:
            if hasattr(log, "debug"):
                log.debug(msg, *args, **kwargs)
    else:
        logstream(msg, *args, **kwargs)

</t>
<t tx="ekr.20080121121842.176">def run(cmd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command.

        "cmd" is the command to run
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    __run_log(logstream, "running '%s'", cmd)

    # Using os.system on Windows == DOS box flash (bug 61348).
    # TODO: Perhaps we should use Process for all plats? (bug 65961).
    if sys.platform == "win32":
        import process
        p = process.Process(cmd)
        retval = p.wait()
    else:
        retval = os.system(cmd)

    if hasattr(os, "WEXITSTATUS"):
        status = os.WEXITSTATUS(retval)
    else:
        status = retval
    if status:
        #TODO: add std OSError attributes or pick more approp. exception
        raise OSError("error running '%s': %r" % (cmd, status))

</t>
<t tx="ekr.20080121121842.177">def run_in_dir(cmd, cwd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command in the given working directory.

        "cmd" is the command to run
        "cwd" is the directory in which the commmand is run.
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    old_dir = os.getcwd()
    try:
        os.chdir(cwd)
        __run_log(logstream, "running '%s' in '%s'", cmd, cwd)
        run(cmd, logstream=None)
    finally:
        os.chdir(old_dir)

</t>
<t tx="ekr.20080121122039">pat = '''\
# ***** BEGIN LICENSE BLOCK *****
# Version: MPL 1.1/GPL 2.0/LGPL 2.1
# 
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
# 
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
# 
# The Original Code is Komodo code.
# 
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
# 
# Contributor(s):
#   ActiveState Software Inc
# 
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
# 
# ***** END LICENSE BLOCK *****'''

s2 = '# ***** LICENSE BLOCK *****\n'

n = len(pat)
print '=' * 20
for p in p.self_and_subtree_iter():
    s = p.bodyString()
    i = s.find(pat)
    if i != -1:
        g.es_print('found %s' % p.headString())
        s = s[:i] + s2 + s[i+n:]</t>
<t tx="ekr.20080121123437">@killcolor

&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;!-- ***** BEGIN LICENSE BLOCK *****--&gt;

&lt;codeintel description="Python Extensions for Windows" name="PyWin32" version="2.0"&gt;

  &lt;file lang="Python" mtime="0" path="pywin32.cix"&gt;
  
    &lt;scope ilk="blob" lang="Python" name="_win32sysloader"&gt;
      &lt;scope ilk="function" name="GetModuleFilename" /&gt;
      &lt;scope ilk="function" name="LoadModule" /&gt;
    &lt;/scope&gt;
    
    &lt;scope ilk="blob" lang="Python" name="netbios"&gt;
    
      &lt;scope ilk="function" line="257" lineend="258" name="ACTION_HEADER" returns="NCBStruct" signature="ACTION_HEADER()" /&gt;
      &lt;variable citdl="list" line="174" name="ACTION_HEADER_ITEMS" /&gt;
      
      &lt;scope ilk="class" line="194" lineend="234" name="NCBStruct"&gt;
        &lt;scope ilk="function" line="227" lineend="234" name="__setattr__" signature="__setattr__(attr, val)"&gt;
          &lt;variable citdl="NCBStruct" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;variable attributes="protected __instancevar__" citdl="string.join()" line="196" name="_format" /&gt;
      &lt;/scope&gt;
      
    &lt;/scope&gt;
   
    &lt;scope doc="Helper classes for SSPI authentication via the win32security module.&amp;#xA;&amp;#xA;SSPI authentication involves a token-exchange &amp;quot;dance&amp;quot;, the exact details" ilk="blob" lang="Python" name="sspi"&gt;
    
      &lt;scope classrefs="_BaseAuth" doc="Manages the client side of an SSPI authentication handshake" ilk="class" line="96" lineend="154" name="ClientAuth"&gt;
      
        &lt;scope ilk="function" line="99" lineend="118" name="__init__"
          signature="ClientAuth(pkg_name, client_name=None, auth_info=None, targetspn=None, scflags=None, datarep=sspicon.SECURITY_NETWORK_DREP)"&gt;
          &lt;variable citdl="int" ilk="argument" name="scflags" /&gt;
          &lt;variable ilk="argument" name="client_name" /&gt;
        &lt;/scope&gt;
        
        &lt;variable attributes="__instancevar__" citdl="bool" line="153" name="authenticated" /&gt;
        &lt;variable attributes="__instancevar__" citdl="win32security.QuerySecurityPackageInfo()" line="112" name="pkg_info" /&gt;
      &lt;/scope&gt;
      
      &lt;scope classrefs="_BaseAuth" doc="Manages the server side of an SSPI authentication handshake" ilk="class" line="156" lineend="211" name="ServerAuth"&gt;
      
        &lt;scope doc="# Perform *one* step of the server authentication process." ilk="function" line="182" lineend="211" name="authorize" returns="tuple" signature="authorize(sec_buffer_in)"&gt;
          &lt;variable citdl="self.ctxt" line="196" name="ctxtin" /&gt;
        &lt;/scope&gt;
        
        &lt;variable attributes="__instancevar__" citdl="bool" line="210" name="authenticated" /&gt;
      &lt;/scope&gt;
      
      &lt;scope classrefs="Exception" ilk="class" line="18" name="error" /&gt;
      
      &lt;import module="sspicon" /&gt;
      &lt;import module="win32security" /&gt;
      
      &lt;variable attributes="__hidden__" citdl="ServerAuth" line="216" name="sspiserver" /&gt;

      &lt;scope attributes="protected __hidden__" classrefs="object" ilk="class" line="26" lineend="94" name="_BaseAuth"&gt;
        &lt;scope attributes="__ctor__" ilk="function" line="27" lineend="28" name="__init__" signature="_BaseAuth()"&gt;
          &lt;variable citdl="_BaseAuth" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
      &lt;/scope&gt;
      &lt;variable attributes="__hidden__" citdl="sspiclient.sign()" line="226" name="sig" /&gt;
      &lt;variable attributes="__hidden__" citdl="bool" line="24" name="True" /&gt;
    &lt;/scope&gt;
    
    &lt;scope doc="# Generated by h2py from c:\microsoft sdk\include\sspi.h" ilk="blob" lang="Python" name="sspicon"&gt;
      &lt;variable citdl="int" line="113" name="ASC_REQ_ALLOCATE_MEMORY" /&gt;
     [snip]
      &lt;variable citdl="int" line="211" name="SEC_WINNT_AUTH_IDENTITY_VERSION" /&gt;
      &lt;variable citdl="long" line="306" name="WARNING_IPSEC_MM_POLICY_PRUNED" /&gt;
      &lt;variable citdl="long" line="307" name="WARNING_IPSEC_QM_POLICY_PRUNED" /&gt;
    &lt;/scope&gt;
    
    &lt;scope ilk="blob" lang="Python" name="win2kras"&gt;
      &lt;scope ilk="function" name="GetEapUserIdentity" /&gt;
      &lt;variable citdl="int" name="RASEAPF_Logon" /&gt;
      &lt;variable citdl="int" name="RASEAPF_NonInteractive" /&gt;
      &lt;variable citdl="int" name="RASEAPF_Preview" /&gt;
    &lt;/scope&gt;
    
    &lt;scope ilk="blob" lang="Python" name="win32clipboard"&gt;
      &lt;variable citdl="int" name="CF_BITMAP" /&gt;
      &lt;variable citdl="int" name="CF_DIB" /&gt;
     [snip]
      &lt;scope ilk="function" name="SetClipboardViewer" /&gt;
      &lt;scope classrefs="Exception" ilk="class" name="error" /&gt;
    &lt;/scope&gt;
    
    &lt;scope doc="# Initialization for the win32com package&amp;#xA;#" ilk="blob" lang="Python" name="win32com"&gt;
      &lt;scope ilk="function" name="SetupEnvironment" signature="SetupEnvironment()" /&gt;
      &lt;scope doc="# A Helper for developers." ilk="function" name="__PackageSupportBuildPath__" signature="__PackageSupportBuildPath__(package_path)" /&gt;
      &lt;variable citdl="NoneType" name="__build_path__" /&gt;
      &lt;variable citdl="str" name="__gen_path__" /&gt;
      &lt;import module="gen_py" /&gt;
      &lt;import module="win32com" /&gt;
    &lt;/scope&gt;
    
    &lt;scope doc="# This module exists to create the &amp;quot;best&amp;quot; dispatch object for a given&amp;#xA;# object.  If &amp;quot;makepy&amp;quot; support for a given object is detected, it is&amp;#xA;# used, otherwise a dynamic dispatch object." ilk="blob" lang="Python" name="win32com.client"&gt;
    
      &lt;scope classrefs="CDispatch" doc="The dynamic class used as a last resort.&amp;#xA;The purpose of this overriding of dynamic.CDispatch is to perpetuate the policy&amp;#xA;of using the makepy generated wrapper Python class instead of dynamic.CDispatch" ilk="class" name="CDispatch"&gt;
      
        &lt;scope ilk="function" name="_wrap_dispatch_" /&gt;
      &lt;/scope&gt;
      
      &lt;import module="CLSIDToClass" /&gt;
      
      &lt;scope doc="&amp;apos;Cast&amp;apos; a COM object to another interface" ilk="function" name="CastTo" signature="CastTo(ob, target)" /&gt;
      
      &lt;scope ilk="class" name="CoClassBaseClass"&gt;
        &lt;scope ilk="function" name="__setattr__" /&gt;
        &lt;scope ilk="function" name="__getattr__" /&gt;
        &lt;scope ilk="function" name="__repr__" /&gt;
        &lt;scope ilk="function" name="__init__" /&gt;
      &lt;/scope&gt;
      
      &lt;scope doc="A container for generated COM constants." ilk="class" name="Constants"&gt;
        &lt;scope ilk="function" name="__init__" /&gt;
        &lt;scope ilk="function" name="__getattr__" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Creates a Dispatch based COM object." ilk="function" name="Dispatch" signature="Dispatch(dispatch, userName=None, resultCLSID=None, typeinfo=None, UnicodeToString=False, clsctx=21)" /&gt;
      &lt;scope doc="############################################&amp;#xA;# The base of all makepy generated classes&amp;#xA;############################################" ilk="class" name="DispatchBaseClass"&gt;
        &lt;scope ilk="function" name="_get_good_object_" /&gt;
        &lt;scope ilk="function" name="__setattr__" /&gt;
        &lt;scope ilk="function" name="__getattr__" /&gt;
        &lt;scope doc="# Delegate comparison to the oleobjs, as they know how to do&amp;#xA;identity." ilk="function" name="__cmp__" /&gt;
        &lt;scope doc="# Provide a prettier name than the CLSID" ilk="function" name="__repr__" /&gt;
        &lt;scope ilk="function" name="_get_good_single_object_" /&gt;
        &lt;scope ilk="function" name="_ApplyTypes_" /&gt;
        &lt;scope ilk="function" name="__init__" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Creates a Dispatch based COM object on a specific machine." ilk="function" name="DispatchEx" signature="DispatchEx(clsid, machine=None, userName=None, resultCLSID=None, typeinfo=None, UnicodeToString=False, clsctx=None)" /&gt;
      &lt;scope doc="Create a COM object that can fire events to a user defined&amp;#xA;class." ilk="function" name="DispatchWithEvents" signature="DispatchWithEvents(clsid, user_event_class)" /&gt;
      &lt;scope doc="# An instance of this &amp;quot;proxy&amp;quot; is created to break the COM circular references&amp;#xA;# that exist (ie, when we connect to the COM events, COM keeps a reference&amp;#xA;# to the object.  Thus, the Event connection must be manually broken before" ilk="class" name="EventsProxy"&gt;
        &lt;scope ilk="function" name="__del__" /&gt;
        &lt;scope ilk="function" name="__setattr__" /&gt;
        &lt;scope ilk="function" name="__getattr__" /&gt;
        &lt;scope ilk="function" name="__init__" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Python friendly version of GetObject&amp;apos;s ProgID/CLSID&amp;#xA;functionality." ilk="function" name="GetActiveObject" signature="GetActiveObject(Class, clsctx=23)" /&gt;
      &lt;scope doc="Mimic VB&amp;apos;s GetObject() function." ilk="function" name="GetObject" signature="GetObject(Pathname=None, Class=None, clsctx=None)" /&gt;
      &lt;scope doc="Python friendly version of GetObject&amp;apos;s moniker&amp;#xA;functionality." ilk="function" name="Moniker" signature="Moniker(Pathname, clsctx=23)" /&gt;
      &lt;variable citdl="bool" name="NeedUnicodeConversions" /&gt;
      &lt;scope doc="Creates a new record object, given the name of the record,&amp;#xA;and an object from the same type library." ilk="function" name="Record" signature="Record(name, object)" /&gt;
      &lt;scope classrefs="object" doc="tuple() -&amp;gt; an empty tuple&amp;#xA;tuple(sequence) -&amp;gt; tuple initialized from sequence&amp;apos;s items&amp;#xA;" ilk="class" name="TupleType"&gt;
        &lt;scope doc="x.__ne__(y) &amp;lt;==&amp;gt; x!=y" ilk="function" name="__ne__" signature="x.__ne__(y) &amp;lt;==&amp;gt; x!=y" /&gt;
        &lt;scope doc="Use of negative indices is not supported." ilk="function" name="__getslice__" signature="x.__getslice__(i, j) &amp;lt;==&amp;gt; x[i:j]" /&gt;
        [snip]
        &lt;scope doc="x.__mul__(n) &amp;lt;==&amp;gt; x*n" ilk="function" name="__mul__" signature="x.__mul__(n) &amp;lt;==&amp;gt; x*n" /&gt;
      &lt;/scope&gt;
      &lt;scope classrefs="basestring" doc="unicode(string [, encoding[, errors]]) -&amp;gt; object&amp;#xA;&amp;#xA;Create a new Unicode object from the given encoded string." ilk="class" name="UnicodeType"&gt;
        &lt;scope doc="Return a copy of S converted to uppercase." ilk="function" name="upper" signature="S.upper() -&amp;gt; unicode" /&gt;
        [snip]        &lt;scope doc="Like S.find() but raise ValueError when the substring is not&amp;#xA;found." ilk="function" name="index" signature="S.index(sub [,start [,end]]) -&amp;gt; int" /&gt;
        &lt;scope ilk="function" name="__getnewargs__" /&gt;
        &lt;scope doc="Return True if all characters in S are alphanumeric and&amp;#xA;there is at least one character in S, False otherwise." ilk="function" name="isalnum" signature="S.isalnum() -&amp;gt; bool" /&gt;
        &lt;scope doc="x.__contains__(y) &amp;lt;==&amp;gt; y in x" ilk="function" name="__contains__" signature="x.__contains__(y) &amp;lt;==&amp;gt; y in x" /&gt;
        &lt;scope doc="Like S.rfind() but raise ValueError when the substring is&amp;#xA;not found." ilk="function" name="rindex" signature="S.rindex(sub [,start [,end]]) -&amp;gt; int" /&gt;
        &lt;scope doc="Return a list of the words in S, using sep as the delimiter&amp;#xA;string, starting at the end of the string and working to the&amp;#xA;front." ilk="function" name="rsplit" signature="S.rsplit([sep [,maxsplit]]) -&amp;gt; list of strings" /&gt;
        &lt;scope doc="Return the lowest index in S where substring sub is found,&amp;#xA;such that sub is contained within s[start,end]." ilk="function" name="find" signature="S.find(sub [,start [,end]]) -&amp;gt; int" /&gt;
        &lt;scope doc="Decodes S using the codec registered for encoding." ilk="function" name="decode" signature="S.decode([encoding[,errors]]) -&amp;gt; string or unicode" /&gt;
       [snip]
        &lt;scope doc="x.__ge__(y) &amp;lt;==&amp;gt; x&amp;gt;=y" ilk="function" name="__ge__" signature="x.__ge__(y) &amp;lt;==&amp;gt; x&amp;gt;=y" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Similar to DispatchWithEvents - except that the returned&amp;#xA;object is *not* also usable as the original Dispatch object&amp;#xA;- that is the returned object is not dispatchable." ilk="function" name="WithEvents" signature="WithEvents(disp, user_event_class)" /&gt;
      &lt;import module="__builtin__" /&gt;
      &lt;import module="build" /&gt;
      &lt;variable citdl="Constants" name="constants" /&gt;
      &lt;scope doc="A container for generated COM constants." ilk="class" name="Constants"&gt;
        &lt;scope ilk="function" name="__init__" /&gt;
        &lt;scope ilk="function" name="__getattr__" /&gt;
      &lt;/scope&gt;
      &lt;import module="dynamic" /&gt;
      &lt;import module="gencache" /&gt;
      &lt;scope doc="Determine the default outgoing interface for a class, given&amp;#xA;either a clsid or progid." ilk="function" name="getevents" signature="getevents(clsid)" /&gt;
      &lt;import module="pythoncom" /&gt;
      &lt;import module="pywintypes" /&gt;
      &lt;import module="sys" /&gt;
    &lt;/scope&gt;
    &lt;scope doc="Contains knowledge to build a COM object definition.&amp;#xA;&amp;#xA;This module is used by both the @dynamic@ and @makepy@ modules to build" ilk="blob" lang="Python" name="win32com.client.build"&gt;
      &lt;scope doc="Builds a Python declaration for a method." ilk="function" line="568" lineend="620" name="BuildCallList" returns="MakeDefaultArgRepr()" signature="BuildCallList(fdesc, names, defNamedOptArg, defNamedNotOptArg, defUnnamedArg, defOutArg, is_comment=False)"&gt;
        &lt;variable citdl="False" ilk="argument" name="is_comment" /&gt;
        &lt;variable line="572" name="numOptArgs" /&gt;
        &lt;variable citdl="str" line="573" name="strval" /&gt;
        &lt;variable citdl="int" line="582" name="namedArg" /&gt;
        &lt;variable ilk="argument" name="defNamedOptArg" /&gt;
        &lt;variable ilk="argument" name="defNamedNotOptArg" /&gt;
        &lt;variable citdl="len()" line="575" name="firstOptArg" /&gt;
        &lt;variable citdl="MakeDefaultArgRepr()" line="588" name="defArgVal" /&gt;
        &lt;variable ilk="argument" name="defOutArg" /&gt;
        &lt;variable citdl="len()" line="571" name="numArgs" /&gt;
        &lt;variable ilk="argument" name="fdesc" /&gt;
        &lt;variable ilk="argument" name="names" /&gt;
        &lt;variable ilk="argument" name="defUnnamedArg" /&gt;
        &lt;variable citdl="MakePublicAttributeName()" line="581" name="argName" /&gt;
        &lt;variable line="586" name="thisdesc" /&gt;
      &lt;/scope&gt;
      &lt;scope classrefs="OleItem" ilk="class" line="100" lineend="389" name="DispatchItem"&gt;
        &lt;scope doc="Return tuple counting in/outs/OPTS." ilk="function" line="277" lineend="292" name="CountInOutOptArgs" returns="tuple" signature="CountInOutOptArgs(argTuple)"&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable citdl="int" line="279" name="ins" /&gt;
          &lt;variable line="281" name="inOut" /&gt;
          &lt;variable ilk="argument" name="argTuple" /&gt;
          &lt;variable citdl="int" line="289" name="opts" /&gt;
          &lt;variable citdl="int" line="284" name="out" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="301" lineend="368" name="MakeDispatchFuncMethod" returns="list" signature="MakeDispatchFuncMethod(entry, name, bMakeClass=1)"&gt;
          &lt;variable citdl="str" line="307" name="linePrefix" /&gt;
          &lt;variable citdl="entry.GetResultCLSID()" line="325" name="resclsid" /&gt;
          &lt;variable ilk="argument" name="name" /&gt;
          &lt;variable citdl="int" ilk="argument" name="bMakeClass" /&gt;
          &lt;variable citdl="str" line="308" name="defNamedOptArg" /&gt;
          &lt;variable citdl="entry.doc" line="303" name="doc" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable citdl="str" line="309" name="defNamedNotOptArg" /&gt;
          &lt;variable citdl="map()" line="337" name="param_flags" /&gt;
          &lt;variable citdl="list" line="305" name="ret" /&gt;
          &lt;variable citdl="filter()" line="338" name="bad_params" /&gt;
          &lt;variable citdl="str" line="316" name="defOutArg" /&gt;
          &lt;variable citdl="str" line="318" name="s" /&gt;
          &lt;variable citdl="entry.desc" line="302" name="fdesc" /&gt;
          &lt;variable citdl="entry.names" line="304" name="names" /&gt;
          &lt;variable citdl="tuple()" line="332" name="argsDesc" /&gt;
          &lt;variable citdl="str" line="310" name="defUnnamedArg" /&gt;
          &lt;variable ilk="argument" name="entry" /&gt;
          &lt;variable line="341" name="rd" /&gt;
          &lt;variable line="317" name="id" /&gt;
          &lt;variable citdl="list" line="331" name="retDesc" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="149" lineend="224" name="_AddFunc_" returns="tuple" signature="_AddFunc_(typeinfo, fdesc, bForUser)"&gt;
          &lt;variable citdl="dict" line="190" name="map" /&gt;
          &lt;variable ilk="argument" name="typeinfo" /&gt;
          [snip]
          &lt;variable citdl="fdesc.memid" line="150" name="id" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="132" lineend="147" name="_propMapGetCheck_" signature="_propMapGetCheck_(key, item)"&gt;
          &lt;variable ilk="argument" name="item" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable citdl="int" line="137" name="deleteExisting" /&gt;
          &lt;variable ilk="argument" name="key" /&gt;
          &lt;variable citdl="str" line="136" name="newKey" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="254" lineend="275" name="Build" signature="Build(typeinfo, attr, bForUser=1)"&gt;
          &lt;variable citdl="typeinfo.GetVarDesc()" line="260" name="fdesc" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable ilk="argument" name="typeinfo" /&gt;
          &lt;variable ilk="argument" name="attr" /&gt;
          &lt;variable citdl="int" ilk="argument" name="bForUser" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="294" lineend="299" name="MakeFuncMethod" returns="self.MakeVarArgsFuncMethod()" signature="MakeFuncMethod(entry, name, bMakeClass=1)"&gt;
          &lt;variable ilk="argument" name="entry" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable ilk="argument" name="name" /&gt;
          &lt;variable citdl="int" ilk="argument" name="bMakeClass" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="226" lineend="252" name="_AddVar_" returns="tuple" signature="_AddVar_(typeinfo, fdesc, bForUser)"&gt;
          &lt;variable citdl="dict" line="244" name="map" /&gt;
          &lt;variable ilk="argument" name="typeinfo" /&gt;
          &lt;variable citdl="typeinfo.GetDocumentation()" line="237" name="doc" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable ilk="argument" name="fdesc" /&gt;
          &lt;variable citdl="typeinfo.GetNames()" line="232" name="names" /&gt;
          &lt;variable ilk="argument" name="bForUser" /&gt;
          &lt;variable citdl="int" line="246" name="hidden" /&gt;
          &lt;variable citdl="fdesc.memid" line="231" name="id" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="115" lineend="130" name="_propMapPutCheck_" signature="_propMapPutCheck_(key, item)"&gt;
          &lt;variable ilk="argument" name="item" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable citdl="int" line="120" name="deleteExisting" /&gt;
          &lt;variable ilk="argument" name="key" /&gt;
          &lt;variable citdl="str" line="119" name="newKey" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="370" lineend="389" name="MakeVarArgsFuncMethod" returns="list" signature="MakeVarArgsFuncMethod(entry, name, bMakeClass=1)"&gt;
          &lt;variable citdl="str" line="377" name="linePrefix" /&gt;
          &lt;variable citdl="str" line="375" name="argPrefix" /&gt;
          &lt;variable ilk="argument" name="name" /&gt;
          &lt;variable citdl="int" ilk="argument" name="bMakeClass" /&gt;
          &lt;variable citdl="entry.doc" line="373" name="doc" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable citdl="str" line="386" name="s" /&gt;
          &lt;variable citdl="list" line="374" name="ret" /&gt;
          &lt;variable citdl="pythoncom.DISPATCH_METHOD" line="383" name="invoketype" /&gt;
          &lt;variable citdl="entry.desc" line="371" name="fdesc" /&gt;
          &lt;variable citdl="entry.names" line="372" name="names" /&gt;
          &lt;variable ilk="argument" name="entry" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="103" lineend="113" name="__init__" signature="DispatchItem(typeinfo=None, attr=None, doc=None, bForUser=1)"&gt;
          &lt;variable ilk="argument" name="doc" /&gt;
          &lt;variable citdl="DispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable ilk="argument" name="typeinfo" /&gt;
          &lt;variable ilk="argument" name="attr" /&gt;
          &lt;variable citdl="int" ilk="argument" name="bForUser" /&gt;
        &lt;/scope&gt;
        &lt;variable attributes="__instancevar__" citdl="str" line="109" name="defaultDispatchName" /&gt;
        &lt;variable attributes="__instancevar__" citdl="dict" line="107" name="propMapPut" /&gt;
        &lt;variable attributes="__instancevar__" citdl="dict" line="108" name="mapFuncs" /&gt;
        &lt;variable citdl="str" line="101" name="typename" /&gt;
        &lt;variable attributes="__instancevar__" line="255" name="clsid" /&gt;
        &lt;variable attributes="__instancevar__" citdl="bool" line="256" name="bIsDispatch" /&gt;
        &lt;variable attributes="__instancevar__" citdl="dict" line="105" name="propMap" /&gt;
        &lt;variable attributes="__instancevar__" citdl="int" line="110" name="hidden" /&gt;
        &lt;variable attributes="__instancevar__" citdl="dict" line="106" name="propMapGet" /&gt;
      &lt;/scope&gt;
      &lt;variable citdl="str" line="36" name="DropIndirection" /&gt;
      &lt;scope classrefs="DispatchItem" doc="# A Lazy dispatch item - builds an item on request using info from&amp;#xA;# an ITypeComp.  The dynamic module makes the called to build each item,&amp;#xA;# and also holds the references to the typeinfo and typecomp." ilk="class" line="412" lineend="416" name="LazyDispatchItem"&gt;
        &lt;scope ilk="function" line="414" lineend="416" name="__init__" signature="LazyDispatchItem(attr, doc)"&gt;
          &lt;variable ilk="argument" name="doc" /&gt;
          &lt;variable citdl="LazyDispatchItem" ilk="argument" name="self" /&gt;
          &lt;variable ilk="argument" name="attr" /&gt;
        &lt;/scope&gt;
        &lt;variable citdl="str" line="413" name="typename" /&gt;
        &lt;variable attributes="__instancevar__" line="415" name="clsid" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="# Given a default value passed by a type library, return a&amp;#xA;string with # an appropriate repr() for the type." ilk="function" line="549" lineend="566" name="MakeDefaultArgRepr" returns="repr()" signature="MakeDefaultArgRepr(defArgVal)"&gt;
        &lt;variable citdl="val.hour" line="562" name="hour" /&gt;
        &lt;variable line="558" name="val" /&gt;
        &lt;variable citdl="val.msec" line="562" name="msec" /&gt;
        &lt;variable ilk="argument" name="defArgVal" /&gt;
        &lt;variable citdl="val.month" line="562" name="month" /&gt;
        &lt;variable citdl="val.second" line="562" name="second" /&gt;
        &lt;variable citdl="val.minute" line="562" name="minute" /&gt;
        &lt;variable citdl="val.year" line="562" name="year" /&gt;
        &lt;variable citdl="val.day" line="562" name="day" /&gt;
        &lt;variable citdl="pythoncom.PARAMFLAG_FIN" line="551" name="inOut" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="# Given a &amp;quot;public name&amp;quot; (eg, the name of a class, function,&amp;#xA;etc) # make sure it is a legal (and reasonable!) Python&amp;#xA;name." ilk="function" line="518" lineend="542" name="MakePublicAttributeName" returns="filter()" signature="MakePublicAttributeName(className, is_global=False)"&gt;
        &lt;variable citdl="str" ilk="argument" name="className" /&gt;
        &lt;variable citdl="False" ilk="argument" name="is_global" /&gt;
        &lt;variable citdl="className.capitalize()" line="537" name="ret" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Simple holder for named attibutes - items in a map." ilk="class" line="54" lineend="83" name="MapEntry"&gt;
        &lt;scope ilk="function" line="70" lineend="73" name="GetResultCLSID" returns="pythoncom.IID_NULL" signature="GetResultCLSID()"&gt;
          &lt;variable citdl="MapEntry" ilk="argument" name="self" /&gt;
          &lt;variable citdl="pythoncom.IID_NULL" line="71" name="rc" /&gt;
        &lt;/scope&gt;
        &lt;scope doc="# Return a string, suitable for output - either &amp;quot;&amp;apos;{...}&amp;apos;&amp;quot; or&amp;#xA;&amp;quot;None&amp;quot;" ilk="function" line="75" lineend="78" name="GetResultCLSIDStr" returns="str" signature="GetResultCLSIDStr()"&gt;
          &lt;variable citdl="MapEntry" ilk="argument" name="self" /&gt;
          &lt;variable citdl="GetResultCLSID()" line="76" name="rc" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="56" lineend="69" name="__init__" signature="MapEntry(desc_or_id, names=None, doc=None, resultCLSID=pythoncom.IID_NULL, resultDoc=None, hidden=0)"&gt;
          &lt;variable ilk="argument" name="resultDoc" /&gt;
          &lt;variable ilk="argument" name="doc" /&gt;
          &lt;variable citdl="MapEntry" ilk="argument" name="self" /&gt;
          &lt;variable citdl="pythoncom.IID_NULL" ilk="argument" name="resultCLSID" /&gt;
          &lt;variable ilk="argument" name="names" /&gt;
          &lt;variable citdl="int" ilk="argument" name="hidden" /&gt;
          &lt;variable ilk="argument" name="desc_or_id" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="80" lineend="83" name="GetResultName" signature="GetResultName()"&gt;
          &lt;variable citdl="MapEntry" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;variable attributes="__instancevar__" line="65" name="doc" /&gt;
        &lt;variable attributes="__instancevar__" line="59" name="desc" /&gt;
      &lt;/scope&gt;
      &lt;variable citdl="bool" name="NeedUnicodeConversions" /&gt;
      &lt;variable citdl="dict" line="50" name="NoTranslateMap" /&gt;
      &lt;variable citdl="list" line="38" name="NoTranslateTypes" /&gt;
      &lt;scope classrefs="Exception" ilk="class" line="35" lineend="35" name="NotSupportedException" /&gt;
      
      &lt;scope ilk="class" line="85" lineend="98" name="OleItem"&gt;
        &lt;scope ilk="function" line="88" lineend="98" name="__init__" signature="OleItem(doc=None)"&gt;
          &lt;variable ilk="argument" name="doc" /&gt;
          &lt;variable citdl="OleItem" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;variable attributes="__instancevar__" citdl="int" line="95" name="bIsDispatch" /&gt;
        &lt;variable attributes="__instancevar__" citdl="MakePublicAttributeName()" line="91" name="python_name" /&gt;
      &lt;/scope&gt;
      
      &lt;scope classrefs="object" ilk="class" name="TimeType"&gt;
        &lt;scope doc="x.__int__() &amp;lt;==&amp;gt; int(x)" ilk="function" name="__int__" signature="x.__int__() &amp;lt;==&amp;gt; int(x)" /&gt;
        &lt;scope doc="x.__ror__(y) &amp;lt;==&amp;gt; y|x" ilk="function" name="__ror__" signature="x.__ror__(y) &amp;lt;==&amp;gt; y|x" /&gt;
        &lt;scope doc="x.__pow__(y[, z]) &amp;lt;==&amp;gt; pow(x, y[, z])" ilk="function" name="__pow__" signature="x.__pow__(y[, z]) &amp;lt;==&amp;gt; pow(x, y[, z])" /&gt;
      &lt;/scope&gt;
      
      
      &lt;scope classrefs="DispatchItem" doc="# Note - &amp;quot;DispatchItem&amp;quot; poorly named - need a new intermediate class." ilk="class" line="392" lineend="407" name="VTableItem"&gt;
        &lt;variable attributes="__instancevar__" citdl="list" line="405" name="vtableFuncs" /&gt;
      &lt;/scope&gt;
      
      &lt;scope ilk="function" line="509" lineend="514" name="demunge_leading_underscores" returns="list" signature="demunge_leading_underscores(className)"&gt;
        &lt;variable ilk="argument" name="className" /&gt;
        &lt;variable citdl="int" line="510" name="i" /&gt;
      &lt;/scope&gt;
      
      &lt;variable citdl="str" line="34" name="error" /&gt;
      &lt;scope doc="x.__contains__(y) &amp;lt;==&amp;gt; y in x." ilk="function" name="iskeyword" signature="x.__contains__(y) &amp;lt;==&amp;gt; y in x." /&gt;
      
      &lt;import module="pythoncom" /&gt;
      &lt;import module="string" /&gt;
      &lt;import module="sys" /&gt;
      &lt;variable citdl="dict" line="418" name="typeSubstMap" /&gt;
      &lt;import module="types" /&gt;
      &lt;variable citdl="int" name="v" /&gt;
      &lt;variable citdl="str" line="507" name="valid_identifier_chars" /&gt;
      &lt;import module="winerror" /&gt;
      
      &lt;scope attributes="protected __hidden__" ilk="function" line="30" lineend="32" name="_safeQuotedString" returns="str" signature="_safeQuotedString(s)"&gt;
        &lt;variable citdl="list" ilk="argument" name="s" /&gt;
      &lt;/scope&gt;
      
      &lt;scope attributes="protected __hidden__" doc="Builds list of args to the underlying Invoke method." ilk="function" line="488" lineend="505" name="_BuildArgList" returns="string.join()" signature="_BuildArgList(fdesc, names)"&gt;
        &lt;variable ilk="argument" name="fdesc" /&gt;
        &lt;variable citdl="map()" ilk="argument" name="names" /&gt;
        &lt;variable citdl="max()" line="491" name="numArgs" /&gt;
        &lt;variable citdl="names.index()" line="494" name="i" /&gt;
        &lt;variable citdl="int" line="497" name="name_num" /&gt;
      &lt;/scope&gt;

    &lt;/scope&gt;
    
    &lt;scope doc="Manages a dictionary of CLSID strings to Python classes.&amp;#xA;&amp;#xA;Primary use of this module is to allow modules generated by" ilk="blob" lang="Python" name="win32com.client.CLSIDToClass"&gt;
      &lt;scope doc="Given a CLSID, return the globally associated class." ilk="function" line="45" lineend="50" name="GetClass" signature="GetClass(clsid)"&gt;
        &lt;variable ilk="argument" name="clsid" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Determines if the CLSID has an associated class." ilk="function" line="52" lineend="57" name="HasClass" returns="mapCLSIDToClass.has_key()" signature="HasClass(clsid)"&gt;
        &lt;variable ilk="argument" name="clsid" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Register a class that wraps a CLSID" ilk="function" line="21" lineend="29" name="RegisterCLSID" signature="RegisterCLSID(clsid, pythonClass)"&gt;
        &lt;variable ilk="argument" name="pythonClass" /&gt;
        &lt;variable ilk="argument" name="clsid" /&gt;
      &lt;/scope&gt;
      &lt;scope doc="Register a dictionary of CLSID&amp;apos;s and classes." ilk="function" line="31" lineend="43" name="RegisterCLSIDsFromDict" signature="RegisterCLSIDsFromDict(dict)"&gt;
        &lt;variable ilk="argument" name="dict" /&gt;
      &lt;/scope&gt;
      &lt;variable citdl="dict" line="19" name="mapCLSIDToClass" /&gt;
    &lt;/scope&gt;
    &lt;scope doc="A utility for browsing COM objects.&amp;#xA;&amp;#xA;Usage:" ilk="blob" lang="Python" name="win32com.client.combrowse"&gt;
      &lt;scope classrefs="HLICOM" ilk="class" line="46" lineend="60" name="HLICLSID"&gt;
        &lt;scope ilk="function" line="57" lineend="58" name="CalculateIsExpandable" returns="int" signature="CalculateIsExpandable()"&gt;
          &lt;variable citdl="HLICLSID" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="59" lineend="60" name="GetSubList" returns="list" signature="GetSubList()"&gt;
          &lt;variable citdl="HLICLSID" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="47" lineend="56" name="__init__" signature="HLICLSID(myobject, name=None)"&gt;
          &lt;variable citdl="HLICLSID" ilk="argument" name="self" /&gt;
          &lt;variable citdl="pythoncom.MakeIID()" ilk="argument" name="myobject" /&gt;
          &lt;variable citdl="pythoncom.ProgIDFromCLSID()" ilk="argument" name="name" /&gt;
        &lt;/scope&gt;
      &lt;/scope&gt;
      
      &lt;scope classrefs="HLIPythonObject" ilk="class" line="40" lineend="44" name="HLICOM"&gt;
        &lt;scope ilk="function" line="43" lineend="44" name="CalculateIsExpandable" returns="int" signature="CalculateIsExpandable()"&gt;
          &lt;variable citdl="HLICOM" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
        &lt;scope ilk="function" line="41" lineend="42" name="GetText" returns="self.name" signature="GetText()"&gt;
          &lt;variable citdl="HLICOM" ilk="argument" name="self" /&gt;
        &lt;/scope&gt;
      &lt;/scope&gt;
      
      &lt;scope classrefs="HLICOM" doc="An actual Registered Category" ilk="class" line="109" lineend="124" name="HLICategory"&gt;
      
        &lt;scope ilk="function" line="115" lineend="124" name="GetSubList" returns="list" signature="GetSubList()"&gt;
          &lt;variable citdl="HLICategory" ilk="argument" name="self" /&gt;
          &lt;variable citdl="pythoncom.CoCreateInstance()" line="118" name="catinf" /&gt;
          &lt;variable citdl="list" line="119" name="ret" /&gt;
        &lt;/scope&gt;
        
        &lt;scope ilk="function" line="111" lineend="114" name="GetText" returns="str" signature="GetText()"&gt;
          &lt;variable citdl="HLICategory" ilk="argument" name="self" /&gt;
          &lt;variable citdl="str" line="112" name="desc" /&gt;
        &lt;/scope&gt;
      &lt;/scope&gt;
      
  &lt;/file&gt;
&lt;/codeintel&gt;
</t>
<t tx="ekr.20080121131522"></t>
<t tx="ekr.20080121131751"></t>
<t tx="ekr.20080121133057"></t>
<t tx="ekr.20080121133057.1">
r"""Handling for citadel parts of CodeIntel.

The origin of the name "citadel":

In early dev of codeintel naming for various things generally began with "CI"
for CodeIntel. The (simple) syntax for defining type guesses (the things that
are evaluated against the CIDB) was (and is) called CITDL (CodeIntel Type
Definition Language) -- pronounced "citadel", in an attempt to be mnemonic.

In dev for Komodo 4, the codeintel system is being generalized to support
languages that don't fit in the CIDB/CITDL-framework so "citadel" is the
umbrella term for CIDB/CITDL-based stuff in the codeintel system. """</t>
<t tx="ekr.20080121133057.2">"""Virtual base class for language Buffers whose completion evaluation
is based on CIDB/CITDL/CIX.

CitadelBuffers have the following additional API:
    .defns_from_pos(..) Returns a list of citdl expressions for position.
    .scan(...)          Force a scan of the buffer.
    .scan_time          Time of the last scan (or None if not in the db)
    .scan_error         A string describing why the last scan failed
                        (or None if it didn't fail or there hasn't
                        been a scan)
    .blob_from_lang     Mapping of language to blob (a.k.a. the
                        module Element). This will synchronously
                        scan if there is not scan data already
                        available.

    .tree/.cix          CIX Element tree and serialized CIX of this
                        buffer's scan data.

    .scoperef_from_pos()
    .scoperef_from_blob_and_line()
                        Routines for getting the current scope in
                        the blob scan data. Used for completion eval
                        and code browsing.

    # Two convenience routines for working with the db.
    .load()             Load data about this buffer into the db.
    .unload()           Remove data about this buffer from the db.

"""</t>
<t tx="ekr.20080121134628"></t>
<t tx="ekr.20080121134650">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134650.1">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134847">#!/usr/bin/env python
# Copyright (c) 2002-2007 ActiveState Software Inc.
# License: MIT (see LICENSE.txt for license details)
# Author:  Trent Mick
# Home:    http://trentm.com/projects/cmdln/

"""An improvement on Python's standard cmd.py module.

As with cmd.py, this module provides "a simple framework for writing
line-oriented command intepreters."  This module provides a 'RawCmdln'
class that fixes some design flaws in cmd.Cmd, making it more scalable
and nicer to use for good 'cvs'- or 'svn'-style command line interfaces
or simple shells.  And it provides a 'Cmdln' class that add
optparse-based option processing. Basically you use it like this:

    import cmdln

    class MySVN(cmdln.Cmdln):
        name = "svn"

        @cmdln.alias('stat', 'st')
        @cmdln.option('-v', '--verbose', action='store_true'
                      help='print verbose information')
        def do_status(self, subcmd, opts, *paths):
            print "handle 'svn status' command"

        #...

    if __name__ == "__main__":
        shell = MySVN()
        retval = shell.main()
        sys.exit(retval)

See the README.txt or &lt;http://trentm.com/projects/cmdln/&gt; for more
details.
"""

__revision__ = "$Id$"
__version_info__ = (1, 0, 1)
__version__ = '.'.join(map(str, __version_info__))

import os
import re
import cmd
import optparse
from pprint import pprint




#---- globals

LOOP_ALWAYS, LOOP_NEVER, LOOP_IF_EMPTY = range(3)

# An unspecified optional argument when None is a meaningful value.
_NOT_SPECIFIED = ("Not", "Specified")

# Pattern to match a TypeError message from a call that
# failed because of incorrect number of arguments (see
# Python/getargs.c).
_INCORRECT_NUM_ARGS_RE = re.compile(
    r"(takes [\w ]+ )(\d+)( arguments? \()(\d+)( given\))")



</t>
<t tx="ekr.20080121134847.1">#---- exceptions

class CmdlnError(Exception):
    """A cmdln.py usage error."""
    @others
</t>
<t tx="ekr.20080121134847.2">def __init__(self, msg):
    self.msg = msg
</t>
<t tx="ekr.20080121134847.3">def __str__(self):
    return self.msg

</t>
<t tx="ekr.20080121134847.4">class CmdlnUserError(Exception):
    """An error by a user of a cmdln-based tool/shell."""
    pass



</t>
<t tx="ekr.20080121134847.5">#---- public methods and classes

def alias(*aliases):
    """Decorator to add aliases for Cmdln.do_* command handlers.
    
    Example:
        class MyShell(cmdln.Cmdln):
            @cmdln.alias("!", "sh")
            def do_shell(self, argv):
                #...implement 'shell' command
    """
    def decorate(f):
        if not hasattr(f, "aliases"):
            f.aliases = []
        f.aliases += aliases
        return f
    return decorate


</t>
<t tx="ekr.20080121134847.6">class RawCmdln(cmd.Cmd):
    """An improved (on cmd.Cmd) framework for building multi-subcommand
    scripts (think "svn" &amp; "cvs") and simple shells (think "pdb" and
    "gdb").

    A simple example:

        import cmdln

        class MySVN(cmdln.RawCmdln):
            name = "svn"

            @cmdln.aliases('stat', 'st')
            def do_status(self, argv):
                print "handle 'svn status' command"

        if __name__ == "__main__":
            shell = MySVN()
            retval = shell.main()
            sys.exit(retval)

    See &lt;http://trentm.com/projects/cmdln&gt; for more information.
    """
    name = None      # if unset, defaults basename(sys.argv[0])
    prompt = None    # if unset, defaults to self.name+"&gt; "
    version = None   # if set, default top-level options include --version

    # Default messages for some 'help' command error cases.
    # They are interpolated with one arg: the command.
    nohelp = "no help on '%s'"
    unknowncmd = "unknown command: '%s'"

    helpindent = '' # string with which to indent help output

    @others
</t>
<t tx="ekr.20080121134847.7">def __init__(self, completekey='tab', 
             stdin=None, stdout=None, stderr=None):
    """Cmdln(completekey='tab', stdin=None, stdout=None, stderr=None)

    The optional argument 'completekey' is the readline name of a
    completion key; it defaults to the Tab key. If completekey is
    not None and the readline module is available, command completion
    is done automatically.
    
    The optional arguments 'stdin', 'stdout' and 'stderr' specify
    alternate input, output and error output file objects; if not
    specified, sys.* are used.
    
    If 'stdout' but not 'stderr' is specified, stdout is used for
    error output. This is to provide least surprise for users used
    to only the 'stdin' and 'stdout' options with cmd.Cmd.
    """
    import sys
    if self.name is None:
        self.name = os.path.basename(sys.argv[0])
    if self.prompt is None:
        self.prompt = self.name+"&gt; "
    self._name_str = self._str(self.name)
    self._prompt_str = self._str(self.prompt)
    if stdin is not None:
        self.stdin = stdin
    else:
        self.stdin = sys.stdin
    if stdout is not None:
        self.stdout = stdout
    else:
        self.stdout = sys.stdout
    if stderr is not None:
        self.stderr = stderr
    elif stdout is not None:
        self.stderr = stdout
    else:
        self.stderr = sys.stderr
    self.cmdqueue = []
    self.completekey = completekey
    self.cmdlooping = False

</t>
<t tx="ekr.20080121134847.8">def get_optparser(self):
    """Hook for subclasses to set the option parser for the
    top-level command/shell.

    This option parser is used retrieved and used by `.main()' to
    handle top-level options.

    The default implements a single '-h|--help' option. Sub-classes
    can return None to have no options at the top-level. Typically
    an instance of CmdlnOptionParser should be returned.
    """
    version = (self.version is not None 
                and "%s %s" % (self._name_str, self.version)
                or None)
    return CmdlnOptionParser(self, version=version)

</t>
<t tx="ekr.20080121134847.9">def postoptparse(self):
    """Hook method executed just after `.main()' parses top-level
    options.

    When called `self.options' holds the results of the option parse.
    """
    pass

</t>
<t tx="ekr.20080121134847.10">def main(self, argv=None, loop=LOOP_NEVER):
    """A possible mainline handler for a script, like so:

        import cmdln
        class MyCmd(cmdln.Cmdln):
            name = "mycmd"
            ...
        
        if __name__ == "__main__":
            MyCmd().main()

    By default this will use sys.argv to issue a single command to
    'MyCmd', then exit. The 'loop' argument can be use to control
    interactive shell behaviour.
    
    Arguments:
        "argv" (optional, default sys.argv) is the command to run.
            It must be a sequence, where the first element is the
            command name and subsequent elements the args for that
            command.
        "loop" (optional, default LOOP_NEVER) is a constant
            indicating if a command loop should be started (i.e. an
            interactive shell). Valid values (constants on this module):
                LOOP_ALWAYS     start loop and run "argv", if any
                LOOP_NEVER      run "argv" (or .emptyline()) and exit
                LOOP_IF_EMPTY   run "argv", if given, and exit;
                                otherwise, start loop
    """
    if argv is None:
        import sys
        argv = sys.argv
    else:
        argv = argv[:] # don't modify caller's list

    self.optparser = self.get_optparser()
    if self.optparser: # i.e. optparser=None means don't process for opts
        try:
            self.options, args = self.optparser.parse_args(argv[1:])
        except CmdlnUserError, ex:
            msg = "%s: %s\nTry '%s help' for info.\n"\
                  % (self.name, ex, self.name)
            self.stderr.write(self._str(msg))
            self.stderr.flush()
            return 1
        except StopOptionProcessing, ex:
            return 0
    else:
        self.options, args = None, argv[1:]
    self.postoptparse()

    if loop == LOOP_ALWAYS:
        if args:
            self.cmdqueue.append(args)
        return self.cmdloop()
    elif loop == LOOP_NEVER:
        if args:
            return self.cmd(args)
        else:
            return self.emptyline()
    elif loop == LOOP_IF_EMPTY:
        if args:
            return self.cmd(args)
        else:
            return self.cmdloop()

</t>
<t tx="ekr.20080121134847.11">def cmd(self, argv):
    """Run one command and exit.
    
        "argv" is the arglist for the command to run. argv[0] is the
            command to run. If argv is an empty list then the
            'emptyline' handler is run.

    Returns the return value from the command handler.
    """
    assert (isinstance(argv, (list, tuple)), 
            "'argv' is not a sequence: %r" % argv)
    retval = None
    try:
        argv = self.precmd(argv)
        retval = self.onecmd(argv)
        self.postcmd(argv)
    except:
        if not self.cmdexc(argv):
            raise
        retval = 1
    return retval

</t>
<t tx="ekr.20080121134847.12">def _str(self, s):
    """Safely convert the given str/unicode to a string for printing."""
    try:
        return str(s)
    except UnicodeError:
        #XXX What is the proper encoding to use here? 'utf-8' seems
        #    to work better than "getdefaultencoding" (usually
        #    'ascii'), on OS X at least.
        #import sys
        #return s.encode(sys.getdefaultencoding(), "replace")
        return s.encode("utf-8", "replace")

</t>
<t tx="ekr.20080121134847.13">def cmdloop(self, intro=None):
    """Repeatedly issue a prompt, accept input, parse into an argv, and
    dispatch (via .precmd(), .onecmd() and .postcmd()), passing them
    the argv. In other words, start a shell.
    
        "intro" (optional) is a introductory message to print when
            starting the command loop. This overrides the class
            "intro" attribute, if any.
    """
    self.cmdlooping = True
    self.preloop()
    if intro is None:
        intro = self.intro
    if intro:
        intro_str = self._str(intro)
        self.stdout.write(intro_str+'\n')
    self.stop = False
    retval = None
    while not self.stop:
        if self.cmdqueue:
            argv = self.cmdqueue.pop(0)
            assert (isinstance(argv, (list, tuple)), 
                    "item on 'cmdqueue' is not a sequence: %r" % argv)
        else:
            if self.use_rawinput:
                try:
                    line = raw_input(self._prompt_str)
                except EOFError:
                    line = 'EOF'
            else:
                self.stdout.write(self._prompt_str)
                self.stdout.flush()
                line = self.stdin.readline()
                if not len(line):
                    line = 'EOF'
                else:
                    line = line[:-1] # chop '\n'
            argv = line2argv(line)
        try:
            argv = self.precmd(argv)
            retval = self.onecmd(argv)
            self.postcmd(argv)
        except:
            if not self.cmdexc(argv):
                raise
            retval = 1
        self.lastretval = retval
    self.postloop()
    self.cmdlooping = False
    return retval

</t>
<t tx="ekr.20080121134847.14">def precmd(self, argv):
    """Hook method executed just before the command argv is
    interpreted, but after the input prompt is generated and issued.

        "argv" is the cmd to run.
        
    Returns an argv to run (i.e. this method can modify the command
    to run).
    """
    return argv

</t>
<t tx="ekr.20080121134847.15">def postcmd(self, argv):
    """Hook method executed just after a command dispatch is finished.
    
        "argv" is the command that was run.
    """
    pass

</t>
<t tx="ekr.20080121134847.16">def cmdexc(self, argv):
    """Called if an exception is raised in any of precmd(), onecmd(),
    or postcmd(). If True is returned, the exception is deemed to have
    been dealt with. Otherwise, the exception is re-raised.

    The default implementation handles CmdlnUserError's, which
    typically correspond to user error in calling commands (as
    opposed to programmer error in the design of the script using
    cmdln.py).
    """
    import sys
    type, exc, traceback = sys.exc_info()
    if isinstance(exc, CmdlnUserError):
        msg = "%s %s: %s\nTry '%s help %s' for info.\n"\
              % (self.name, argv[0], exc, self.name, argv[0])
        self.stderr.write(self._str(msg))
        self.stderr.flush()
        return True

</t>
<t tx="ekr.20080121134847.17">def onecmd(self, argv):
    if not argv:
        return self.emptyline()
    self.lastcmd = argv
    cmdname = self._get_canonical_cmd_name(argv[0])
    if cmdname:
        handler = self._get_cmd_handler(cmdname)
        if handler:
            return self._dispatch_cmd(handler, argv)
    return self.default(argv)

</t>
<t tx="ekr.20080121134847.18">def _dispatch_cmd(self, handler, argv):
    return handler(argv)

</t>
<t tx="ekr.20080121134847.19">def default(self, argv):
    """Hook called to handle a command for which there is no handler.

        "argv" is the command and arguments to run.
    
    The default implementation writes and error message to stderr
    and returns an error exit status.

    Returns a numeric command exit status.
    """
    errmsg = self._str(self.unknowncmd % (argv[0],))
    if self.cmdlooping:
        self.stderr.write(errmsg+"\n")
    else:
        self.stderr.write("%s: %s\nTry '%s help' for info.\n"
                          % (self._name_str, errmsg, self._name_str))
    self.stderr.flush()
    return 1

</t>
<t tx="ekr.20080121134847.20">def parseline(self, line):
    # This is used by Cmd.complete (readline completer function) to
    # massage the current line buffer before completion processing.
    # We override to drop special '!' handling.
    line = line.strip()
    if not line:
        return None, None, line
    elif line[0] == '?':
        line = 'help ' + line[1:]
    i, n = 0, len(line)
    while i &lt; n and line[i] in self.identchars: i = i+1
    cmd, arg = line[:i], line[i:].strip()
    return cmd, arg, line

</t>
<t tx="ekr.20080121134847.21">def helpdefault(self, cmd, known):
    """Hook called to handle help on a command for which there is no
    help handler.

        "cmd" is the command name on which help was requested.
        "known" is a boolean indicating if this command is known
            (i.e. if there is a handler for it).
    
    Returns a return code.
    """
    if known:
        msg = self._str(self.nohelp % (cmd,))
        if self.cmdlooping:
            self.stderr.write(msg + '\n')
        else:
            self.stderr.write("%s: %s\n" % (self.name, msg))
    else:
        msg = self.unknowncmd % (cmd,)
        if self.cmdlooping:
            self.stderr.write(msg + '\n')
        else:
            self.stderr.write("%s: %s\n"
                              "Try '%s help' for info.\n"
                              % (self.name, msg, self.name))
    self.stderr.flush()
    return 1

</t>
<t tx="ekr.20080121134847.22">def do_help(self, argv):
    """${cmd_name}: give detailed help on a specific sub-command

    Usage:
        ${name} help [COMMAND]
    """
    if len(argv) &gt; 1: # asking for help on a particular command
        doc = None
        cmdname = self._get_canonical_cmd_name(argv[1]) or argv[1]
        if not cmdname:
            return self.helpdefault(argv[1], False)
        else:
            helpfunc = getattr(self, "help_"+cmdname, None)
            if helpfunc:
                doc = helpfunc()
            else:
                handler = self._get_cmd_handler(cmdname)
                if handler:
                    doc = handler.__doc__
                if doc is None:
                    return self.helpdefault(argv[1], handler != None)
    else: # bare "help" command
        doc = self.__class__.__doc__  # try class docstring
        if doc is None:
            # Try to provide some reasonable useful default help.
            if self.cmdlooping: prefix = ""
            else:               prefix = self.name+' '
            doc = """Usage:
                %sCOMMAND [ARGS...]
                %shelp [COMMAND]

            ${option_list}
            ${command_list}
            ${help_list}
            """ % (prefix, prefix)
        cmdname = None

    if doc: # *do* have help content, massage and print that
        doc = self._help_reindent(doc)
        doc = self._help_preprocess(doc, cmdname)
        doc = doc.rstrip() + '\n' # trim down trailing space
        self.stdout.write(self._str(doc))
        self.stdout.flush()
</t>
<t tx="ekr.20080121134847.23">do_help.aliases = ["?"]

def _help_reindent(self, help, indent=None):
    """Hook to re-indent help strings before writing to stdout.

        "help" is the help content to re-indent
        "indent" is a string with which to indent each line of the
            help content after normalizing. If unspecified or None
            then the default is use: the 'self.helpindent' class
            attribute. By default this is the empty string, i.e.
            no indentation.

    By default, all common leading whitespace is removed and then
    the lot is indented by 'self.helpindent'. When calculating the
    common leading whitespace the first line is ignored -- hence
    help content for Conan can be written as follows and have the
    expected indentation:

        def do_crush(self, ...):
            '''${cmd_name}: crush your enemies, see them driven before you...

            c.f. Conan the Barbarian'''
    """
    if indent is None:
        indent = self.helpindent
    lines = help.splitlines(0)
    _dedentlines(lines, skip_first_line=True)
    lines = [(indent+line).rstrip() for line in lines]
    return '\n'.join(lines)

</t>
<t tx="ekr.20080121134847.24">def _help_preprocess(self, help, cmdname):
    """Hook to preprocess a help string before writing to stdout.

        "help" is the help string to process.
        "cmdname" is the canonical sub-command name for which help
            is being given, or None if the help is not specific to a
            command.

    By default the following template variables are interpolated in
    help content. (Note: these are similar to Python 2.4's
    string.Template interpolation but not quite.)

    ${name}
        The tool's/shell's name, i.e. 'self.name'.
    ${option_list}
        A formatted table of options for this shell/tool.
    ${command_list}
        A formatted table of available sub-commands.
    ${help_list}
        A formatted table of additional help topics (i.e. 'help_*'
        methods with no matching 'do_*' method).
    ${cmd_name}
        The name (and aliases) for this sub-command formatted as:
        "NAME (ALIAS1, ALIAS2, ...)".
    ${cmd_usage}
        A formatted usage block inferred from the command function
        signature.
    ${cmd_option_list}
        A formatted table of options for this sub-command. (This is
        only available for commands using the optparse integration,
        i.e.  using @cmdln.option decorators or manually setting the
        'optparser' attribute on the 'do_*' method.)

    Returns the processed help. 
    """
    preprocessors = {
        "${name}":            self._help_preprocess_name,
        "${option_list}":     self._help_preprocess_option_list,
        "${command_list}":    self._help_preprocess_command_list,
        "${help_list}":       self._help_preprocess_help_list,
        "${cmd_name}":        self._help_preprocess_cmd_name,
        "${cmd_usage}":       self._help_preprocess_cmd_usage,
        "${cmd_option_list}": self._help_preprocess_cmd_option_list,
    }

    for marker, preprocessor in preprocessors.items():
        if marker in help:
            help = preprocessor(help, cmdname)
    return help

</t>
<t tx="ekr.20080121134847.25">def _help_preprocess_name(self, help, cmdname=None):
    return help.replace("${name}", self.name)

</t>
<t tx="ekr.20080121134847.26">def _help_preprocess_option_list(self, help, cmdname=None):
    marker = "${option_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    if self.optparser:
        # Setup formatting options and format.
        # - Indentation of 4 is better than optparse default of 2.
        #   C.f. Damian Conway's discussion of this in Perl Best
        #   Practices.
        self.optparser.formatter.indent_increment = 4
        self.optparser.formatter.current_indent = indent_width
        block = self.optparser.format_option_help() + '\n'
    else:
        block = ""
        
    help = help.replace(indent+marker+suffix, block, 1)
    return help


</t>
<t tx="ekr.20080121134847.27">def _help_preprocess_command_list(self, help, cmdname=None):
    marker = "${command_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Find any aliases for commands.
    token2canonical = self._get_canonical_map()
    aliases = {}
    for token, cmdname in token2canonical.items():
        if token == cmdname: continue
        aliases.setdefault(cmdname, []).append(token)

    # Get the list of (non-hidden) commands and their
    # documentation, if any.
    cmdnames = {} # use a dict to strip duplicates
    for attr in self.get_names():
        if attr.startswith("do_"):
            cmdnames[attr[3:]] = True
    cmdnames = cmdnames.keys()
    cmdnames.sort()
    linedata = []
    for cmdname in cmdnames:
        if aliases.get(cmdname):
            a = aliases[cmdname]
            a.sort()
            cmdstr = "%s (%s)" % (cmdname, ", ".join(a))
        else:
            cmdstr = cmdname
        doc = None
        try:
            helpfunc = getattr(self, 'help_'+cmdname)
        except AttributeError:
            handler = self._get_cmd_handler(cmdname)
            if handler:
                doc = handler.__doc__
        else:
            doc = helpfunc()
            
        # Strip "${cmd_name}: " from the start of a command's doc. Best
        # practice dictates that command help strings begin with this, but
        # it isn't at all wanted for the command list.
        to_strip = "${cmd_name}:"
        if doc and doc.startswith(to_strip):
            #log.debug("stripping %r from start of %s's help string",
            #          to_strip, cmdname)
            doc = doc[len(to_strip):].lstrip()
        linedata.append( (cmdstr, doc) )

    if linedata:
        subindent = indent + ' '*4
        lines = _format_linedata(linedata, subindent, indent_width+4)
        block = indent + "Commands:\n" \
                + '\n'.join(lines) + "\n\n"
        help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121134847.28">def _gen_names_and_attrs(self):
    # Inheritance says we have to look in class and
    # base classes; order is not important.
    names = []
    classes = [self.__class__]
    while classes:
        aclass = classes.pop(0)
        if aclass.__bases__:
            classes = classes + list(aclass.__bases__)
        for name in dir(aclass):
            yield (name, getattr(aclass, name))

</t>
<t tx="ekr.20080121134847.29">def _help_preprocess_help_list(self, help, cmdname=None):
    marker = "${help_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Determine the additional help topics, if any.
    helpnames = {}
    token2cmdname = self._get_canonical_map()
    for attrname, attr in self._gen_names_and_attrs():
        if not attrname.startswith("help_"): continue
        helpname = attrname[5:]
        if helpname not in token2cmdname:
            helpnames[helpname] = attr

    if helpnames:
        linedata = [(n, a.__doc__ or "") for n, a in helpnames.items()]
        linedata.sort()

        subindent = indent + ' '*4
        lines = _format_linedata(linedata, subindent, indent_width+4)
        block = (indent
                + "Additional help topics (run `%s help TOPIC'):\n" % self.name
                + '\n'.join(lines)
                + "\n\n")
    else:
        block = ''
    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121134847.30">def _help_preprocess_cmd_name(self, help, cmdname=None):
    marker = "${cmd_name}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    s = cmdname
    if hasattr(handler, "aliases"):
        s += " (%s)" % (", ".join(handler.aliases))
    help = help.replace(marker, s)
    return help

</t>
<t tx="ekr.20080121134847.31">#TODO: this only makes sense as part of the Cmdln class.
#      Add hooks to add help preprocessing template vars and put
#      this one on that class.
def _help_preprocess_cmd_usage(self, help, cmdname=None):
    marker = "${cmd_usage}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Extract the introspection bits we need.
    func = handler.im_func
    if func.func_defaults:
        func_defaults = list(func.func_defaults)
    else:
        func_defaults = []
    co_argcount = func.func_code.co_argcount
    co_varnames = func.func_code.co_varnames
    co_flags = func.func_code.co_flags
    CO_FLAGS_ARGS = 4
    CO_FLAGS_KWARGS = 8

    # Adjust argcount for possible *args and **kwargs arguments.
    argcount = co_argcount
    if co_flags &amp; CO_FLAGS_ARGS:   argcount += 1
    if co_flags &amp; CO_FLAGS_KWARGS: argcount += 1

    # Determine the usage string.
    usage = "%s %s" % (self.name, cmdname)
    if argcount &lt;= 2:   # handler ::= do_FOO(self, argv)
        usage += " [ARGS...]"
    elif argcount &gt;= 3: # handler ::= do_FOO(self, subcmd, opts, ...)
        argnames = list(co_varnames[3:argcount])
        tail = ""
        if co_flags &amp; CO_FLAGS_KWARGS:
            name = argnames.pop(-1)
            import warnings
            # There is no generally accepted mechanism for passing
            # keyword arguments from the command line. Could
            # *perhaps* consider: arg=value arg2=value2 ...
            warnings.warn("argument '**%s' on '%s.%s' command "
                          "handler will never get values" 
                          % (name, self.__class__.__name__,
                             func.func_name))
        if co_flags &amp; CO_FLAGS_ARGS:
            name = argnames.pop(-1)
            tail = "[%s...]" % name.upper()
        while func_defaults:
            func_defaults.pop(-1)
            name = argnames.pop(-1)
            tail = "[%s%s%s]" % (name.upper(), (tail and ' ' or ''), tail)
        while argnames:
            name = argnames.pop(-1)
            tail = "%s %s" % (name.upper(), tail)
        usage += ' ' + tail

    block_lines = [
        self.helpindent + "Usage:",
        self.helpindent + ' '*4 + usage
    ]
    block = '\n'.join(block_lines) + '\n\n'

    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121134847.32">#TODO: this only makes sense as part of the Cmdln class.
#      Add hooks to add help preprocessing template vars and put
#      this one on that class.
def _help_preprocess_cmd_option_list(self, help, cmdname=None):
    marker = "${cmd_option_list}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)
    if hasattr(handler, "optparser"):
        # Setup formatting options and format.
        # - Indentation of 4 is better than optparse default of 2.
        #   C.f. Damian Conway's discussion of this in Perl Best
        #   Practices.
        handler.optparser.formatter.indent_increment = 4
        handler.optparser.formatter.current_indent = indent_width
        block = handler.optparser.format_option_help() + '\n'
    else:
        block = ""

    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121134847.33">def _get_canonical_cmd_name(self, token):
    map = self._get_canonical_map()
    return map.get(token, None)

</t>
<t tx="ekr.20080121134847.34">def _get_canonical_map(self):
    """Return a mapping of available command names and aliases to
    their canonical command name.
    """
    cacheattr = "_token2canonical"
    if not hasattr(self, cacheattr):
        # Get the list of commands and their aliases, if any.
        token2canonical = {}
        cmd2funcname = {} # use a dict to strip duplicates
        for attr in self.get_names():
            if attr.startswith("do_"):    cmdname = attr[3:]
            elif attr.startswith("_do_"): cmdname = attr[4:]
            else:
                continue
            cmd2funcname[cmdname] = attr
            token2canonical[cmdname] = cmdname
        for cmdname, funcname in cmd2funcname.items(): # add aliases
            func = getattr(self, funcname)
            aliases = getattr(func, "aliases", [])
            for alias in aliases:
                if alias in cmd2funcname:
                    import warnings
                    warnings.warn("'%s' alias for '%s' command conflicts "
                                  "with '%s' handler"
                                  % (alias, cmdname, cmd2funcname[alias]))
                    continue
                token2canonical[alias] = cmdname
        setattr(self, cacheattr, token2canonical)
    return getattr(self, cacheattr)

</t>
<t tx="ekr.20080121134847.35">def _get_cmd_handler(self, cmdname):
    handler = None
    try:
        handler = getattr(self, 'do_' + cmdname)
    except AttributeError:
        try:
            # Private command handlers begin with "_do_".
            handler = getattr(self, '_do_' + cmdname)
        except AttributeError:
            pass
    return handler

</t>
<t tx="ekr.20080121134847.36">def _do_EOF(self, argv):
    # Default EOF handler
    # Note: an actual EOF is redirected to this command.
    #TODO: separate name for this. Currently it is available from
    #      command-line. Is that okay?
    self.stdout.write('\n')
    self.stdout.flush()
    self.stop = True

</t>
<t tx="ekr.20080121134847.37">def emptyline(self):
    # Different from cmd.Cmd: don't repeat the last command for an
    # emptyline.
    if self.cmdlooping:
        pass
    else:
        return self.do_help(["help"])


</t>
<t tx="ekr.20080121134847.38">#---- optparse.py extension to fix (IMO) some deficiencies
#
# See the class _OptionParserEx docstring for details.
#

class StopOptionProcessing(Exception):
    """Indicate that option *and argument* processing should stop
    cleanly. This is not an error condition. It is similar in spirit to
    StopIteration. This is raised by _OptionParserEx's default "help"
    and "version" option actions and can be raised by custom option
    callbacks too.
    
    Hence the typical CmdlnOptionParser (a subclass of _OptionParserEx)
    usage is:

        parser = CmdlnOptionParser(mycmd)
        parser.add_option("-f", "--force", dest="force")
        ...
        try:
            opts, args = parser.parse_args()
        except StopOptionProcessing:
            # normal termination, "--help" was probably given
            sys.exit(0)
    """

</t>
<t tx="ekr.20080121134847.39">class _OptionParserEx(optparse.OptionParser):
    """An optparse.OptionParser that uses exceptions instead of sys.exit.

    This class is an extension of optparse.OptionParser that differs
    as follows:
    - Correct (IMO) the default OptionParser error handling to never
      sys.exit(). Instead OptParseError exceptions are passed through.
    - Add the StopOptionProcessing exception (a la StopIteration) to
      indicate normal termination of option processing.
      See StopOptionProcessing's docstring for details.

    I'd also like to see the following in the core optparse.py, perhaps
    as a RawOptionParser which would serve as a base class for the more
    generally used OptionParser (that works as current):
    - Remove the implicit addition of the -h|--help and --version
      options. They can get in the way (e.g. if want '-?' and '-V' for
      these as well) and it is not hard to do:
        optparser.add_option("-h", "--help", action="help")
        optparser.add_option("--version", action="version")
      These are good practices, just not valid defaults if they can
      get in the way.
    """
    @others
</t>
<t tx="ekr.20080121134847.40">def error(self, msg):
    raise optparse.OptParseError(msg)

</t>
<t tx="ekr.20080121134847.41">def exit(self, status=0, msg=None):
    if status == 0:
        raise StopOptionProcessing(msg)
    else:
        #TODO: don't lose status info here
        raise optparse.OptParseError(msg)



</t>
<t tx="ekr.20080121134847.42">#---- optparse.py-based option processing support

class CmdlnOptionParser(_OptionParserEx):
    """An optparse.OptionParser class more appropriate for top-level
    Cmdln options. For parsing of sub-command options, see
    SubCmdOptionParser.

    Changes:
    - disable_interspersed_args() by default, because a Cmdln instance
      has sub-commands which may themselves have options.
    - Redirect print_help() to the Cmdln.do_help() which is better
      equiped to handle the "help" action.
    - error() will raise a CmdlnUserError: OptionParse.error() is meant
      to be called for user errors. Raising a well-known error here can
      make error handling clearer.
    - Also see the changes in _OptionParserEx.
    """
    @others
</t>
<t tx="ekr.20080121134847.43">def __init__(self, cmdln, **kwargs):
    self.cmdln = cmdln
    kwargs["prog"] = self.cmdln.name
    _OptionParserEx.__init__(self, **kwargs)
    self.disable_interspersed_args()

</t>
<t tx="ekr.20080121134847.44">def print_help(self, file=None):
    self.cmdln.onecmd(["help"])

</t>
<t tx="ekr.20080121134847.45">def error(self, msg):
    raise CmdlnUserError(msg)


</t>
<t tx="ekr.20080121134847.46">class SubCmdOptionParser(_OptionParserEx):
    @others
</t>
<t tx="ekr.20080121134847.47">def set_cmdln_info(self, cmdln, subcmd):
    """Called by Cmdln to pass relevant info about itself needed
    for print_help().
    """
    self.cmdln = cmdln
    self.subcmd = subcmd

</t>
<t tx="ekr.20080121134847.48">def print_help(self, file=None):
    self.cmdln.onecmd(["help", self.subcmd])

</t>
<t tx="ekr.20080121134847.49">def error(self, msg):
    raise CmdlnUserError(msg)


</t>
<t tx="ekr.20080121134847.50">def option(*args, **kwargs):
    """Decorator to add an option to the optparser argument of a Cmdln
    subcommand.
    
    Example:
        class MyShell(cmdln.Cmdln):
            @cmdln.option("-f", "--force", help="force removal")
            def do_remove(self, subcmd, opts, *args):
                #...
    """
    #XXX Is there a possible optimization for many options to not have a
    #    large stack depth here?
    def decorate(f):
        if not hasattr(f, "optparser"):
            f.optparser = SubCmdOptionParser()
        f.optparser.add_option(*args, **kwargs)
        return f
    return decorate


</t>
<t tx="ekr.20080121134847.51">class Cmdln(RawCmdln):
    """An improved (on cmd.Cmd) framework for building multi-subcommand
    scripts (think "svn" &amp; "cvs") and simple shells (think "pdb" and
    "gdb").

    A simple example:

        import cmdln

        class MySVN(cmdln.Cmdln):
            name = "svn"

            @cmdln.aliases('stat', 'st')
            @cmdln.option('-v', '--verbose', action='store_true'
                          help='print verbose information')
            def do_status(self, subcmd, opts, *paths):
                print "handle 'svn status' command"

            #...

        if __name__ == "__main__":
            shell = MySVN()
            retval = shell.main()
            sys.exit(retval)

    'Cmdln' extends 'RawCmdln' by providing optparse option processing
    integration.  See this class' _dispatch_cmd() docstring and
    &lt;http://trentm.com/projects/cmdln&gt; for more information.
    """
    @others
</t>
<t tx="ekr.20080121134847.52">def _dispatch_cmd(self, handler, argv):
    """Introspect sub-command handler signature to determine how to
    dispatch the command. The raw handler provided by the base
    'RawCmdln' class is still supported:

        def do_foo(self, argv):
            # 'argv' is the vector of command line args, argv[0] is
            # the command name itself (i.e. "foo" or an alias)
            pass

    In addition, if the handler has more than 2 arguments option
    processing is automatically done (using optparse):

        @cmdln.option('-v', '--verbose', action='store_true')
        def do_bar(self, subcmd, opts, *args):
            # subcmd = &lt;"bar" or an alias&gt;
            # opts = &lt;an optparse.Values instance&gt;
            if opts.verbose:
                print "lots of debugging output..."
            # args = &lt;tuple of arguments&gt;
            for arg in args:
                bar(arg)

    TODO: explain that "*args" can be other signatures as well.

    The `cmdln.option` decorator corresponds to an `add_option()`
    method call on an `optparse.OptionParser` instance.

    You can declare a specific number of arguments:

        @cmdln.option('-v', '--verbose', action='store_true')
        def do_bar2(self, subcmd, opts, bar_one, bar_two):
            #...

    and an appropriate error message will be raised/printed if the
    command is called with a different number of args.
    """
    co_argcount = handler.im_func.func_code.co_argcount
    if co_argcount == 2:   # handler ::= do_foo(self, argv)
        return handler(argv)
    elif co_argcount &gt;= 3: # handler ::= do_foo(self, subcmd, opts, ...)
        try:
            optparser = handler.optparser
        except AttributeError:
            optparser = handler.im_func.optparser = SubCmdOptionParser()
        assert isinstance(optparser, SubCmdOptionParser)
        optparser.set_cmdln_info(self, argv[0])
        try:
            opts, args = optparser.parse_args(argv[1:])
        except StopOptionProcessing:
            #TODO: this doesn't really fly for a replacement of
            #      optparse.py behaviour, does it?
            return 0 # Normal command termination

        try:
            return handler(argv[0], opts, *args)
        except TypeError, ex:
            # Some TypeError's are user errors:
            #   do_foo() takes at least 4 arguments (3 given)
            #   do_foo() takes at most 5 arguments (6 given)
            #   do_foo() takes exactly 5 arguments (6 given)
            # Raise CmdlnUserError for these with a suitably
            # massaged error message.
            import sys
            tb = sys.exc_info()[2] # the traceback object
            if tb.tb_next is not None:
                # If the traceback is more than one level deep, then the
                # TypeError do *not* happen on the "handler(...)" call
                # above. In that we don't want to handle it specially
                # here: it would falsely mask deeper code errors.
                raise
            msg = ex.args[0]
            match = _INCORRECT_NUM_ARGS_RE.search(msg)
            if match:
                msg = list(match.groups())
                msg[1] = int(msg[1]) - 3
                if msg[1] == 1:
                    msg[2] = msg[2].replace("arguments", "argument")
                msg[3] = int(msg[3]) - 3
                msg = ''.join(map(str, msg))
                raise CmdlnUserError(msg)
            else:
                raise
    else:
        raise CmdlnError("incorrect argcount for %s(): takes %d, must "
                         "take 2 for 'argv' signature or 3+ for 'opts' "
                         "signature" % (handler.__name__, co_argcount))
    


</t>
<t tx="ekr.20080121134847.53">#---- internal support functions

def _format_linedata(linedata, indent, indent_width):
    """Format specific linedata into a pleasant layout.
    
        "linedata" is a list of 2-tuples of the form:
            (&lt;item-display-string&gt;, &lt;item-docstring&gt;)
        "indent" is a string to use for one level of indentation
        "indent_width" is a number of columns by which the
            formatted data will be indented when printed.

    The &lt;item-display-string&gt; column is held to 15 columns.
    """
    lines = []
    WIDTH = 78 - indent_width
    SPACING = 2
    NAME_WIDTH_LOWER_BOUND = 13
    NAME_WIDTH_UPPER_BOUND = 16
    NAME_WIDTH = max([len(s) for s,d in linedata])
    if NAME_WIDTH &lt; NAME_WIDTH_LOWER_BOUND:
        NAME_WIDTH = NAME_WIDTH_LOWER_BOUND
    else:
        NAME_WIDTH = NAME_WIDTH_UPPER_BOUND

    DOC_WIDTH = WIDTH - NAME_WIDTH - SPACING
    for namestr, doc in linedata:
        line = indent + namestr
        if len(namestr) &lt;= NAME_WIDTH:
            line += ' ' * (NAME_WIDTH + SPACING - len(namestr))
        else:
            lines.append(line)
            line = indent + ' ' * (NAME_WIDTH + SPACING)
        line += _summarize_doc(doc, DOC_WIDTH)
        lines.append(line.rstrip())
    return lines

</t>
<t tx="ekr.20080121134847.54">def _summarize_doc(doc, length=60):
    r"""Parse out a short one line summary from the given doclines.
    
        "doc" is the doc string to summarize.
        "length" is the max length for the summary

    &gt;&gt;&gt; _summarize_doc("this function does this")
    'this function does this'
    &gt;&gt;&gt; _summarize_doc("this function does this", 10)
    'this fu...'
    &gt;&gt;&gt; _summarize_doc("this function does this\nand that")
    'this function does this and that'
    &gt;&gt;&gt; _summarize_doc("this function does this\n\nand that")
    'this function does this'
    """
    import re
    if doc is None:
        return ""
    assert length &gt; 3, "length &lt;= 3 is absurdly short for a doc summary"
    doclines = doc.strip().splitlines(0)
    if not doclines:
        return ""

    summlines = []
    for i, line in enumerate(doclines):
        stripped = line.strip()
        if not stripped:
            break
        summlines.append(stripped)
        if len(''.join(summlines)) &gt;= length:
            break

    summary = ' '.join(summlines)
    if len(summary) &gt; length:
        summary = summary[:length-3] + "..." 
    return summary


</t>
<t tx="ekr.20080121134847.55">def line2argv(line):
    r"""Parse the given line into an argument vector.
    
        "line" is the line of input to parse.

    This may get niggly when dealing with quoting and escaping. The
    current state of this parsing may not be completely thorough/correct
    in this respect.
    
    &gt;&gt;&gt; from cmdln import line2argv
    &gt;&gt;&gt; line2argv("foo")
    ['foo']
    &gt;&gt;&gt; line2argv("foo bar")
    ['foo', 'bar']
    &gt;&gt;&gt; line2argv("foo bar ")
    ['foo', 'bar']
    &gt;&gt;&gt; line2argv(" foo bar")
    ['foo', 'bar']

    Quote handling:
    
    &gt;&gt;&gt; line2argv("'foo bar'")
    ['foo bar']
    &gt;&gt;&gt; line2argv('"foo bar"')
    ['foo bar']
    &gt;&gt;&gt; line2argv(r'"foo\"bar"')
    ['foo"bar']
    &gt;&gt;&gt; line2argv("'foo bar' spam")
    ['foo bar', 'spam']
    &gt;&gt;&gt; line2argv("'foo 'bar spam")
    ['foo bar', 'spam']
    &gt;&gt;&gt; line2argv("'foo")
    Traceback (most recent call last):
        ...
    ValueError: command line is not terminated: unfinished single-quoted segment
    &gt;&gt;&gt; line2argv('"foo')
    Traceback (most recent call last):
        ...
    ValueError: command line is not terminated: unfinished double-quoted segment
    &gt;&gt;&gt; line2argv('some\tsimple\ttests')
    ['some', 'simple', 'tests']
    &gt;&gt;&gt; line2argv('a "more complex" test')
    ['a', 'more complex', 'test']
    &gt;&gt;&gt; line2argv('a more="complex test of " quotes')
    ['a', 'more=complex test of ', 'quotes']
    &gt;&gt;&gt; line2argv('a more" complex test of " quotes')
    ['a', 'more complex test of ', 'quotes']
    &gt;&gt;&gt; line2argv('an "embedded \\"quote\\""')
    ['an', 'embedded "quote"']
    """
    import string
    line = line.strip()
    argv = []
    state = "default"
    arg = None  # the current argument being parsed
    i = -1
    while 1:
        i += 1
        if i &gt;= len(line): break
        ch = line[i]

        if ch == "\\": # escaped char always added to arg, regardless of state
            if arg is None: arg = ""
            i += 1
            arg += line[i]
            continue

        if state == "single-quoted":
            if ch == "'":
                state = "default"
            else:
                arg += ch
        elif state == "double-quoted":
            if ch == '"':
                state = "default"
            else:
                arg += ch
        elif state == "default":
            if ch == '"':
                if arg is None: arg = ""
                state = "double-quoted"
            elif ch == "'":
                if arg is None: arg = ""
                state = "single-quoted"
            elif ch in string.whitespace:
                if arg is not None:
                    argv.append(arg)
                arg = None
            else:
                if arg is None: arg = ""
                arg += ch
    if arg is not None:
        argv.append(arg)
    if state != "default":
        raise ValueError("command line is not terminated: unfinished %s "
                         "segment" % state)
    return argv


</t>
<t tx="ekr.20080121134847.56">def argv2line(argv):
    r"""Put together the given argument vector into a command line.
    
        "argv" is the argument vector to process.
    
    &gt;&gt;&gt; from cmdln import argv2line
    &gt;&gt;&gt; argv2line(['foo'])
    'foo'
    &gt;&gt;&gt; argv2line(['foo', 'bar'])
    'foo bar'
    &gt;&gt;&gt; argv2line(['foo', 'bar baz'])
    'foo "bar baz"'
    &gt;&gt;&gt; argv2line(['foo"bar'])
    'foo"bar'
    &gt;&gt;&gt; print argv2line(['foo" bar'])
    'foo" bar'
    &gt;&gt;&gt; print argv2line(["foo' bar"])
    "foo' bar"
    &gt;&gt;&gt; argv2line(["foo'bar"])
    "foo'bar"
    """
    escapedArgs = []
    for arg in argv:
        if ' ' in arg and '"' not in arg:
            arg = '"'+arg+'"'
        elif ' ' in arg and "'" not in arg:
            arg = "'"+arg+"'"
        elif ' ' in arg:
            arg = arg.replace('"', r'\"')
            arg = '"'+arg+'"'
        escapedArgs.append(arg)
    return ' '.join(escapedArgs)


</t>
<t tx="ekr.20080121134847.57"># Recipe: dedent (0.1) in /Users/trentm/tm/recipes/cookbook
def _dedentlines(lines, tabsize=8, skip_first_line=False):
    """_dedentlines(lines, tabsize=8, skip_first_line=False) -&gt; dedented lines
    
        "lines" is a list of lines to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    Same as dedent() except operates on a sequence of lines. Note: the
    lines list is modified **in-place**.
    """
    DEBUG = False
    if DEBUG: 
        print "dedent: dedent(..., tabsize=%d, skip_first_line=%r)"\
              % (tabsize, skip_first_line)
    indents = []
    margin = None
    for i, line in enumerate(lines):
        if i == 0 and skip_first_line: continue
        indent = 0
        for ch in line:
            if ch == ' ':
                indent += 1
            elif ch == '\t':
                indent += tabsize - (indent % tabsize)
            elif ch in '\r\n':
                continue # skip all-whitespace lines
            else:
                break
        else:
            continue # skip all-whitespace lines
        if DEBUG: print "dedent: indent=%d: %r" % (indent, line)
        if margin is None:
            margin = indent
        else:
            margin = min(margin, indent)
    if DEBUG: print "dedent: margin=%r" % margin

    if margin is not None and margin &gt; 0:
        for i, line in enumerate(lines):
            if i == 0 and skip_first_line: continue
            removed = 0
            for j, ch in enumerate(line):
                if ch == ' ':
                    removed += 1
                elif ch == '\t':
                    removed += tabsize - (removed % tabsize)
                elif ch in '\r\n':
                    if DEBUG: print "dedent: %r: EOL -&gt; strip up to EOL" % line
                    lines[i] = lines[i][j:]
                    break
                else:
                    raise ValueError("unexpected non-whitespace char %r in "
                                     "line %r while removing %d-space margin"
                                     % (ch, line, margin))
                if DEBUG:
                    print "dedent: %r: %r -&gt; removed %d/%d"\
                          % (line, ch, removed, margin)
                if removed == margin:
                    lines[i] = lines[i][j+1:]
                    break
                elif removed &gt; margin:
                    lines[i] = ' '*(removed-margin) + lines[i][j+1:]
                    break
    return lines

</t>
<t tx="ekr.20080121134847.58">def _dedent(text, tabsize=8, skip_first_line=False):
    """_dedent(text, tabsize=8, skip_first_line=False) -&gt; dedented text

        "text" is the text to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    textwrap.dedent(s), but don't expand tabs to spaces
    """
    lines = text.splitlines(1)
    _dedentlines(lines, tabsize=tabsize, skip_first_line=skip_first_line)
    return ''.join(lines)


</t>
<t tx="ekr.20080121134847.59">def _get_indent(marker, s, tab_width=8):
    """_get_indent(marker, s, tab_width=8) -&gt;
        (&lt;indentation-of-'marker'&gt;, &lt;indentation-width&gt;)"""
    # Figure out how much the marker is indented.
    INDENT_CHARS = tuple(' \t')
    start = s.index(marker)
    i = start
    while i &gt; 0:
        if s[i-1] not in INDENT_CHARS:
            break
        i -= 1
    indent = s[i:start]
    indent_width = 0
    for ch in indent:
        if ch == ' ':
            indent_width += 1
        elif ch == '\t':
            indent_width += tab_width - (indent_width % tab_width)
    return indent, indent_width

</t>
<t tx="ekr.20080121134847.60">def _get_trailing_whitespace(marker, s):
    """Return the whitespace content trailing the given 'marker' in string 's',
    up to and including a newline.
    """
    suffix = ''
    start = s.index(marker) + len(marker)
    i = start
    while i &lt; len(s):
        if s[i] in ' \t':
            suffix += s[i]
        elif s[i] in '\r\n':
            suffix += s[i]
            if s[i] == '\r' and i+1 &lt; len(s) and s[i+1] == '\n':
                suffix += s[i+1]
            break
        else:
            break
        i += 1
    return suffix

</t>
<t tx="ekr.20080121134847.61">#!/usr/bin/env python
# ***** LICENSE BLOCK *****

"""Tools for building Komodo extensions.

Typical usage is for a Komodo extension source dir to put the Komodo SDK
bin dir on ones path and call the "koext" tool for building an extension.
"koext" is a light wrapper around this lib.

Provided that the source dir has an appropriate "install.rdf" (the main
file for describing a Komodo extension), then "build_ext" will do the rest.
The "Komodo Extension" project template provides boilerplate for this.

A Komodo extension source dir looks like this:

    install.rdf         # main extension meta-data file
                        #   (all other pieces are optional)

    # Chrome
    chrome.manifest     # necessary if have any XUL "content", "skin"
                        #   or "locale"
    content/            # XUL overlays, dialogs and JavaScript
    skin/               # CSS
    locale/             # localized chrome files (typically DTDs)

    # Other extension hooks
    components/         # XPCOM components
    templates/          # Komodo "New File" templates
    project-templates/  # Komodo "New Project" templates
    lexers/             # UDL-based ".lexres" files for custom language
                        #   syntax coloring. These are built with the
                        #   "luddite" tool. Typically source ".udl" files
                        #   are placed in a "udl" dir.
    xmlcatalogs/        # XML catalog defining namespace to schema mapping
      catalog.xml       #   for XML autocomplete, and the schemas
      ...               #   themselves (DTDs, XML Schemas, Relax NG)
    apicatalogs/        # API Catalog ".cix" files for custom autocomplete
                        #   and calltips.
    pylib/              # This dir will be added to Komodo's runtime sys.path.
                        #   As well, "lang_LANG.py" files here define codeintel
                        #   language support.

TODO: create_ext_chrome_skel
TODO: create_ext_component_skel
"""

import os
from os.path import exists, join, dirname, isdir, basename, splitext, \
                    normpath, abspath
import sys
import re
import uuid
import logging
import tempfile
from glob import glob
from pprint import pprint


</t>
<t tx="ekr.20080121134847.62">class KoExtError(Exception):
    pass



</t>
<t tx="ekr.20080121134847.63">#---- globals

_log = logging.getLogger("koextlib")
_log.setLevel(logging.INFO)

_install_rdf_template = """&lt;?xml version="1.0"?&gt;
&lt;RDF xmlns="http://www.w3.org/1999/02/22-rdf-syntax-ns#" 
     xmlns:em="http://www.mozilla.org/2004/em-rdf#"&gt;
  &lt;Description about="urn:mozilla:install-manifest"&gt;
    &lt;em:id&gt;%(id)s&lt;/em:id&gt;
    &lt;em:name&gt;%(name)s&lt;/em:name&gt;
    &lt;em:version&gt;%(version)s&lt;/em:version&gt;
    &lt;em:description&gt;%(desc)s&lt;/em:description&gt;
    &lt;em:creator&gt;%(creator)s&lt;/em:creator&gt;
    &lt;em:homepageURL&gt;%(homepage)s&lt;/em:homepageURL&gt;
    &lt;em:type&gt;2&lt;/em:type&gt; &lt;!-- type=extension --&gt; 

    &lt;em:targetApplication&gt;
            &lt;Description&gt;
                    &lt;!-- Komodo Snapdragon uuid --&gt;
                    &lt;em:id&gt;{2cb9d397-8ec9-4211-bd89-7fea34120af6}&lt;/em:id&gt;
                    &lt;em:minVersion&gt;0&lt;/em:minVersion&gt;
                    &lt;em:maxVersion&gt;1.*&lt;/em:maxVersion&gt;
            &lt;/Description&gt;
    &lt;/em:targetApplication&gt;
    &lt;em:targetApplication&gt; &lt;!-- Komodo IDE --&gt;
      &lt;Description&gt;
        &lt;em:id&gt;{36E66FA0-F259-11D9-850E-000D935D3368}&lt;/em:id&gt;
        &lt;em:minVersion&gt;4.1&lt;/em:minVersion&gt;
        &lt;em:maxVersion&gt;4.*&lt;/em:maxVersion&gt;
      &lt;/Description&gt;
    &lt;/em:targetApplication&gt;
    &lt;em:targetApplication&gt; &lt;!-- Komodo Edit --&gt;
      &lt;Description&gt;
        &lt;em:id&gt;{b1042fb5-9e9c-11db-b107-000d935d3368}&lt;/em:id&gt;
        &lt;em:minVersion&gt;4.1&lt;/em:minVersion&gt;
        &lt;em:maxVersion&gt;4.*&lt;/em:maxVersion&gt;
      &lt;/Description&gt;
    &lt;/em:targetApplication&gt;
  &lt;/Description&gt;
&lt;/RDF&gt;
"""



#---- module api

def is_ext_dir(dir=os.curdir):
    import operator
    return operator.truth(glob(join(dir, "install.*rdf*")))

</t>
<t tx="ekr.20080121134847.64"># Validation.
def validate_ext_name(name):
    if not name.strip():
        return "The name must not be empty."

</t>
<t tx="ekr.20080121134847.65">def validate_ext_id(id):
    if not id.strip():
        return "You must specify an ID."
    id_pat = re.compile("(.*?)@(.*?)")
    if not id_pat.match(id):
        return "The ID does not match to '%s' pattern." % id_pat
    if ' ' in id:
        return "The ID should not contain spaces."

</t>
<t tx="ekr.20080121134847.66">def validate_ext_version(version):
    if not version.strip():
        return "You must specify a version."
    if not re.match("^\d+\.\d+(\.\d+([a-z]\d*)?)?$", version):
        return "The version must be of the form X.Y.Z or X.Y where"

</t>
<t tx="ekr.20080121134847.67">def validate_ext_creator(creator):
    if not creator.strip():
        return "You must specify a creator."


</t>
<t tx="ekr.20080121134847.68">def create_ext_skel(base_dir, name=None, id=None, version=None, desc="",
                    creator=None, homepage="", dry_run=False, log=None):
    """Creates an empty starter Komodo extension skeleton in the given
    base directory.
    
    If not specified, this will query for all the meta-data on stdin/stdout.
    """
    if log is None: log = _log
    if exists(base_dir):
        raise KoExtError("`%s' exists (aborting creation of skeleton)"
                         % base_dir)

    # Gather info for install.rdf.
    need_to_query = (id is None or name is None or version is None
                     or creator is None)
    while need_to_query:
        print _banner("Gathering extension information")
        
        if name is None:
            name = ' '.join(s.capitalize()
                            for s in basename(base_dir).split('\t _'))
        name = _query(
            "Name of your extension, for example 'Fuzzy Wuzzy'.",
            default=name, validate=validate_ext_name,
            prompt="      name: ")
        id = _query(
            "\nString ID for this extension. This shouldn't have spaces\n"
                "and must be of the form 'PROJECTNAME@DOMAIN', for\n"
                "example '%s@mydomain.com'." % name.lower().replace(' ', '_'),
            default=id, validate=validate_ext_id,
            prompt="        id: ")
        version = _query(
            "\nVersion for this extension. Examples: 1.0, 2.1.2, 0.9.0b2.",
            default=version, validate=validate_ext_version,
            prompt="   version: ")
        desc = _query(
            "\nA brief description of this extension, for example: 'Fuzzy\n"
                "Wuzzy tools for Komodo'.",
            default=desc or "",
            prompt="      desc: ")
        creator = _query(
            "\nThe creator/author of this extension, typically your name.",
            default=creator, validate=validate_ext_creator,
            prompt="   creator: ")
        homepage = _query(
            "\nThe main URL at which to get information on this extension.",
            default=homepage or "",
            prompt="  homepage: ")

        print
        print _banner(None, '-')
        sys.stdout.write(_dedent("""
            Extension information:
                  name: %(name)s
                    id: %(id)s
               version: %(version)s
                  desc: %(desc)s
               creator: %(creator)s
              homepage: %(homepage)s
            """ % locals()).lstrip())
        answer = _query_yes_no_quit("Are these details correct?")
        if answer == "yes":
            print _banner(None)
            break
        elif answer == "no":
            print _banner(None, '-')
            continue
        elif answer == "quit":
            raise SystemExit("aborting")

    # Validate ext data.
    errors = [s for s in [validate_ext_name(name),
                          validate_ext_id(id),
                          validate_ext_version(version)] if s]
    if errors:
        raise KoExtError("invalid extension information: %s"
                         % ' '.join(errors))

    # Create install.rdf.
    if not dry_run:
        _mkdir(base_dir, log.info)
    install_rdf_path = join(base_dir, "install.rdf")
    log.info(_dedent("""
        create `%(install_rdf_path)s':
              name: %(name)s
                id: %(id)s
           version: %(version)s
              desc: %(desc)s
           creator: %(creator)s
          homepage: %(homepage)s
        """ % locals()).strip())
    if not dry_run:
        open(install_rdf_path, 'w').write(
            _install_rdf_template % locals())


</t>
<t tx="ekr.20080121134847.69">def create_udl_lang_skel(base_dir, lang, ext=None, is_html_based=False,
                         is_xml_based=False, dry_run=False, log=None):
    """Create the skeleton files for a new UDL-based Komodo language."""
    if log is None: log = _log
    if not is_ext_dir(base_dir):
        raise KoExtError("`%s' isn't an extension source dir: there is no "
                         "'install.rdf' file (run `koext startext' first)"
                         % base_dir)

    if is_html_based and is_xml_based:
        raise KoExtError("a language cannot be both HTML- and XML-based: "
                         "lang=%r, is_html_based=%r, is_xml_based=%r"
                         % (lang, is_html_based, is_xml_based))
    safe_lang = _code_safe_lang_from_lang(lang)

    # Create udl/${lang}-mainlex.udl
    mainlex_path = normpath(join(base_dir, "udl",
                                 safe_lang.lower()+"-mainlex.udl"))
    if exists(mainlex_path):
        log.warn("`%s' exists (skipping)", mainlex_path)
    else:
        if not dry_run and not exists(dirname(mainlex_path)):
            _mkdir(dirname(mainlex_path), log.debug)
        log.info("create %s (lexer definition)", mainlex_path)
        if not dry_run:
            open(mainlex_path, 'w').write(_dedent("""
                # UDL for %(lang)s
                
                language %(lang)s
                
                #...
                """ % locals()).lstrip())

    # Create components/ko${lang}_UDL_Language.py
    lang_svc_path = normpath(join(base_dir, "components",
                                  "ko%s_UDL_Language.py" % safe_lang))
    if exists(lang_svc_path):
        log.warn("`%s' exists (skipping)", lang_svc_path)
    else:
        guid = uuid.uuid4()
        if ext is None:
            default_ext_assign = ""
        else:
            if not ext.startswith('.'):
                log.warn("extension for %s, %r, does not being with a '.': "
                         "that might cause problems" % (lang, ext))
            default_ext_assign = "defaultExtension = %r" % ext
        if is_xml_based:
            base_module = "koXMLLanguageBase"
            base_class = "koXMLLanguageBase"
            lang_from_udl_family = {'M': 'XML'}
        elif is_html_based:
            base_module = "koXMLLanguageBase"
            base_class = "koHTMLLanguageBase"
            lang_from_udl_family = {'M': 'HTML'}
        else:
            base_module = "koUDLLanguageBase"
            base_class = "KoUDLLanguage"
            lang_from_udl_family = {}
    
        lang_svc = _dedent("""
            # Komodo %(lang)s language service.
            
            import logging
            from %(base_module)s import %(base_class)s
    
    
            log = logging.getLogger("ko%(safe_lang)sLanguage")
            #log.setLevel(logging.DEBUG)
    
    
            def registerLanguage(registry):
                log.debug("Registering language %(lang)s")
                registry.registerLanguage(Ko%(safe_lang)sLanguage())
    
    
            class Ko%(safe_lang)sLanguage(%(base_class)s):
                name = "%(lang)s"
                lexresLangName = "%(safe_lang)s"
                _reg_desc_ = "%%s Language" %% name
                _reg_contractid_ = "@activestate.com/koLanguage?language=%%s;1" %% name
                _reg_clsid_ = "%(guid)s"
                %(default_ext_assign)s
            
                #TODO: Update 'lang_from_udl_family' as appropriate for your
                #      lexer definition. There are four UDL language families:
                #           M (markup), i.e. HTML or XML
                #           CSL (client-side language), e.g. JavaScript
                #           SSL (server-side language), e.g. Perl, PHP, Python
                #           TPL (template language), e.g. RHTML, Django, Smarty
                #      'lang_from_udl_family' maps each UDL family code (M,
                #      CSL, ...) to the sub-langauge name in your language.
                #      Some examples:
                #        lang_from_udl_family = {   # A PHP file can contain
                #           'M': 'HTML',            #   HTML
                #           'SSL': 'PHP',           #   PHP
                #           'CSL': 'JavaScript',    #   JavaScript
                #        }
                #        lang_from_udl_family = {   # An RHTML file can contain
                #           'M': 'HTML',            #   HTML
                #           'SSL': 'Ruby',          #   Ruby
                #           'CSL': 'JavaScript',    #   JavaScript
                #           'TPL': 'RHTML',         #   RHTML template code
                #        }
                #        lang_from_udl_family = {   # A plain XML can just contain
                #           'M': 'XML',             #   XML
                #        }
                lang_from_udl_family = %(lang_from_udl_family)r
            """ % locals()).lstrip()
    
        if not dry_run and not exists(dirname(lang_svc_path)):
            _mkdir(dirname(lang_svc_path), log.debug)
        log.info("create %s (language service)", lang_svc_path)
        if not dry_run:
            open(lang_svc_path, 'w').write(lang_svc)

    # Create templates.
    if not ext:
        log.warn("no file extension given for %s: skipping generation "
                 "of 'New File' templates" % lang)
    else:
        tpl_paths = [
            normpath(join(base_dir, "templates", "All Languages", safe_lang+ext)),
            normpath(join(base_dir, "templates", "Common", safe_lang+ext)),
        ]
        for tpl_path in tpl_paths:
            if exists(tpl_path):
                log.warn("`%s' exists (skipping)", tpl_path)
                continue
            if not dry_run and not exists(dirname(tpl_path)):
                _mkdir(dirname(tpl_path), log.debug)
            log.info("create %s ('New File' template)", tpl_path)
            if not dry_run:
                open(tpl_path, 'w').write('')


</t>
<t tx="ekr.20080121134847.70">def create_codeintel_lang_skel(base_dir, lang, dry_run=False, force=False,
                               log=None):
    """Create the skeleton files for Code Intelligence support for a
    new language.
    
    "New" here means a language for which Komodo has no current Code
    Intelligence support.
    """
    if log is None: log = _log
    if not is_ext_dir(base_dir):
        raise KoExtError("`%s' isn't an extension source dir: there is no "
                         "'install.rdf' file (run `koext startext' first)"
                         % base_dir)

    ko_info = KomodoInfo()
    safe_lang = _code_safe_lang_from_lang(lang)
    log.debug("safe lang: %r", safe_lang)

    # Create codeintel/lang_${lang}.py
    lang_path = normpath(join(base_dir, "pylib",
                              "lang_%s.py" % safe_lang.lower()))
    if exists(lang_path) and not force:
        log.warn("`%s' exists (skipping, use --force to override)",
                 lang_path)
    else:
        if not dry_run and not exists(dirname(lang_path)):
            _mkdir(dirname(lang_path), log.debug)
        log.info("create %s (codeintel language master)", lang_path)
        if not dry_run:
            template_path = join(ko_info.sdk_dir, "share",
                                 "lang_LANG.py")
            import string
            template = string.Template(open(template_path).read())
            content = template.safe_substitute(
                {"lang": lang,
                 "safe_lang": safe_lang,
                 "safe_lang_lower": safe_lang.lower(),
                 "safe_lang_upper": safe_lang.upper()})
            open(lang_path, 'w').write(content)

    # Create codeintel/cile_${lang}.py
    cile_path = normpath(join(base_dir, "pylib",
                              "cile_%s.py" % safe_lang.lower()))
    if exists(cile_path) and not force:
        log.warn("`%s' exists (skipping, use --force to override)",
                 cile_path)
    else:
        if not dry_run and not exists(dirname(cile_path)):
            _mkdir(dirname(cile_path), log.debug)
        log.info("create %s (codeintel language scanner)", cile_path)
        if not dry_run:
            template_path = join(ko_info.sdk_dir, "share",
                                 "cile_LANG.py")
            import string
            template = string.Template(open(template_path).read())
            content = template.safe_substitute(
                {"lang": lang,
                 "safe_lang": safe_lang,
                 "safe_lang_lower": safe_lang.lower(),
                 "safe_lang_upper": safe_lang.upper()})
            open(cile_path, 'w').write(content)



</t>
<t tx="ekr.20080121134847.71">def build_ext(base_dir, log=None):
    """Build a Komodo extension from the sources in the given dir.
    
    This reads the "install.rdf" in this directory and the appropriate
    source files to create a Komodo .xpi extension.
    
    - Files in "chrome/..." are put into a jar file.
    - IDL and PyXPCOM components in "components/..." are handled
      appropriately.
    - etc. (see `koext help hooks' for more details)
    """
    if log is None: log = _log
    if not is_ext_dir(base_dir):
        raise KoExtError("`%s' isn't an extension source dir: there is no "
                         "'install.rdf' file (run `koext startext' first)"
                         % base_dir)

    build_dir = normpath(join(base_dir, "build"))
    if exists(build_dir):
        _rm(build_dir, log.info)
    
    ext_info = ExtensionInfo(base_dir)
    ko_info = KomodoInfo()
    xpi_manifest = ["install.rdf"]
    
    # Make the chrome jar.
    chrome_dirs = [d for d in ("content", "skin", "locale") if isdir(d)]
    if chrome_dirs:
        assert exists("chrome.manifest"), \
            "you have chrome dirs ('%s') but no 'chrome.manifest' file" \
            % "', '".join(chrome_dirs)
        jar_build_dir = join(build_dir, "jar")
        _mkdir(jar_build_dir, log.info)
        for d in chrome_dirs:
            _cp(d, join(jar_build_dir, d), log.info)
        _trim_files_in_dir(jar_build_dir, [".svn", ".hg", "CVS"], log.info)
        _run_in_dir("zip -r %s.jar *" % ext_info.codename, jar_build_dir,
                    log.info)

        xpi_manifest += [
            join(jar_build_dir, ext_info.codename+".jar"),
            "chrome.manifest",
        ]

    # Handle any PyXPCOM components and idl.
    if isdir("components"):
        components_build_dir = join(build_dir, "components")
        _mkdir(components_build_dir, log.info)
        for path in glob(join("components", "*.py")):
            _cp(path, components_build_dir, log.info)
        xpi_manifest.append(components_build_dir)
        
        idl_build_dir = join(build_dir, "idl")
        idl_paths = glob(join("components", "*.idl"))
        if idl_paths:
            _mkdir(idl_build_dir, log.info)
            for idl_path in glob(join("components", "*.idl")):
                _cp(idl_path, idl_build_dir, log.info)
                xpt_path = join(components_build_dir,
                    splitext(basename(idl_path))[0] + ".xpt")
                _xpidl(idl_path, xpt_path, ko_info, log.info)
            xpi_manifest.append(idl_build_dir)

    # Handle any UDL lexer compilation.
    lexers_dir = join(build_dir, "lexers")
    for mainlex_udl_path in glob(join("udl", "*-mainlex.udl")):
        if not exists(lexers_dir):
            _mkdir(lexers_dir, log.info)
        _luddite_compile(mainlex_udl_path, lexers_dir, ko_info)
    if exists(lexers_dir):
        xpi_manifest.append(lexers_dir)

    # Remaining hook dirs that are just included verbatim in the XPI.
    for dname in ("templates", "apicatalogs", "xmlcatalogs", "pylib",
                  "project-templates"):
        if isdir(dname):
            xpi_manifest.append(dname)

    # Handle XML catalogs (**for compatibility with Komodo &lt;=4.2.1**)
    # Komodo version &lt;=4.2.1 only looked for 'catalog.xml' files for
    # XML autocomplete in the *top-level* of extension dirs. In Komodo
    # versions &gt;=4.2.2 this has moved to 'xmlcatalogs/catalog.xml'
    # (although for a transition period Komodo looks in both areas).
    if isdir("xmlcatalogs"):
        for path in glob(join("xmlcatalogs", "*")):
            xpi_manifest.append(path)

    # Make the xpi.
    #pprint(xpi_manifest)
    xpi_build_dir = join(build_dir, "xpi")
    _mkdir(xpi_build_dir, log.info)
    for src in xpi_manifest:
        if isdir(src):
            _cp(src, join(xpi_build_dir, basename(src)), log.info)
        else:
            _cp(src, xpi_build_dir, log.info)
    _trim_files_in_dir(xpi_build_dir, [".svn", ".hg", "CVS"], log.info)
    _run_in_dir("zip -r %s *" % ext_info.pkg_name, xpi_build_dir, log.info)
    _cp(join(xpi_build_dir, ext_info.pkg_name), ext_info.pkg_name, log.info)
    print "'%s' created." % ext_info.pkg_name




</t>
<t tx="ekr.20080121134847.72">#---- internal support routines

class KomodoInfo(object):
    """Information about this Komodo build/installation.
    
    This class is meant to hide the details of whether you are working
    with a Komodo development build or just in the Komodo source tree
    or with a Komodo installation.
    """
    #TODO: Move this a new komodolib.py (or something like that).
    
    _where_am_i_cache = None
    @others
</t>
<t tx="ekr.20080121134847.73">@property
def _where_am_i(self):
    """This module is running from one of three locations:
        source      the Komodo source tree
        build       in the Komodo/Mozilla $MOZ_OBJDIR tree
        install     in a Komodo installation (in the "SDK" area)
    """
    if self._where_am_i_cache is not None:
        return self._where_am_i_cache
    
    # from: src/sdk/pylib/koextlib.py
    #   to: Blackfile.py
    up_3_dir = dirname(dirname(dirname(dirname(abspath(__file__)))))
    if exists(join(up_3_dir, "Blackfile.py")):
        self._where_am_i_cache = "source"
        return "source"

    # from: .../dist/komodo-bits/sdk/pylib/koextlib.py
    #   to: .../dist/bin
    if exists(join(up_3_dir, "bin", "is_dev_tree.txt")):
        self._where_am_i_cache = "build"
        return "build"

    if sys.platform == "darwin":
        # from: .../Contents/SharedSupport/sdk/pylib/koextlib.py
        #   to: .../Contents/MacOS/komodo
        komodo_path = join(up_3_dir, "MacOS", "komodo")
    elif sys.platform == "win32":
        # from: ...\lib\sdk\pylib\koextlib.py
        #   to: ...\komodo.exe
        komodo_path = join(up_3_dir, "komodo.exe")
    else:
        # from: .../lib/sdk/pylib/koextlib.py
        #   to: .../bin/komodo
        komodo_path = join(up_3_dir, "bin", "komodo")
    assert exists(komodo_path)
    self._where_am_i_cache = "install"
    return "install"

</t>
<t tx="ekr.20080121134847.74">@property
def in_src_tree(self):
    # DEPRECATED
    return self._where_am_i == "source"

</t>
<t tx="ekr.20080121134847.75">@property
def xpidl_path(self):
    exe_ext = (".exe" if sys.platform == "win32" else "")
    return join(self.sdk_dir, "bin", "xpidl"+exe_ext)

</t>
<t tx="ekr.20080121134847.76">@property
def sdk_dir(self):
    return dirname(dirname(abspath(__file__)))

</t>
<t tx="ekr.20080121134847.77">@property
def idl_dir(self):
    return join(self.sdk_dir, "idl")

</t>
<t tx="ekr.20080121134847.78">@property
def udl_dir(self):
    if self._where_am_i == "source":
        return join(dirname(self.sdk_dir), "udl", "udl")
    else:
        return join(self.sdk_dir, "udl")

</t>
<t tx="ekr.20080121134847.79">def _get_bkconfig_var(self, name):
    assert self._where_am_i == "source"
    ko_src_dir = dirname(dirname(dirname(dirname(__file__))))
    module = _module_from_path(join(ko_src_dir, "bkconfig.py"))
    return getattr(module, name)

</t>
<t tx="ekr.20080121134847.80">@property
def py_lib_dirs(self):
    return [join(self.moz_bin_dir, "python"),
            join(self.moz_bin_dir, "python", "komodo")]

</t>
<t tx="ekr.20080121134847.81">@property
def moz_bin_dir(self):
    if self._where_am_i == "source":
        return self._get_bkconfig_var("mozBin")
    elif self._where_am_i == "build":
        up_3_dir = dirname(dirname(dirname(dirname(abspath(__file__)))))
        if sys.platform == "darwin":
            # from: .../dist/komodo-bits/sdk/pylib/koextlib.py
            #   to: .../dist/Komodo.app/Contents/MacOS
            return join(up_3_dir, "Komodo.app", "Contents", "MacOS")
        else:
            # from: .../dist/komodo-bits/sdk/pylib/koextlib.py
            #   to: .../dist/bin
            return join(up_3_dir, "bin")
    else: # self._where_am_i == "install"
        up_2_dir = dirname(dirname(dirname(abspath(__file__))))
        if sys.platform == "darwin":
            # from: .../Contents/SharedSupport/sdk/pylib/koextlib.py
            #   to: .../Contents/MacOS
            return join(dirname(up_2_dir), "MacOS")
        else:
            # from: .../lib/sdk/pylib/koextlib.py
            #   to: .../lib/mozilla
            return join(up_2_dir, "mozilla")

</t>
<t tx="ekr.20080121134847.82">@property
def ext_dirs(self):
    """Generate all extension dirs in this Komodo installation
    *and* (TODO) for the current user.
    """
    # Extensions in the Komodo install tree.
    base_dir = join(self.moz_bin_dir, "extensions")
    try:
        for d in os.listdir(base_dir):
            yield join(base_dir, d)
    except EnvironmentError:
        pass
    
    #TODO: Extensions in the user's app data dir.


</t>
<t tx="ekr.20080121134847.83">class ExtensionInfo(object):
    """Information about this Komodo extension gathered from install.rdf."""
    @others
</t>
<t tx="ekr.20080121134847.84">def __init__(self, base_dir=os.curdir):
    self.base_dir = base_dir
    candidates = ["install.p.rdf", "install.rdf"]
    for name in candidates:
        path = normpath(join(base_dir, name))
        if exists(path):
            self._install_rdf_path = path
            break
    else:
        raise KoExtError("couldn't find any of '%s' for this project"
                         % "' or '".join(candidates))

</t>
<t tx="ekr.20080121134847.85">_install_rdf_info_cache = None
@property
def _install_rdf_info(self):
    if self._install_rdf_info_cache is None:
        info = {}
        install_rdf = open(self._install_rdf_path, 'r').read()
        id_pat = re.compile(r'&lt;em:id&gt;(.*?)&lt;/em:id&gt;')
        info["id"] = id = id_pat.search(install_rdf).group(1)
        codename_pat = re.compile("(.*?)@(.*?)")
        try:
            info["codename"] = codename_pat.search(id).group(1)
        except AttributeError:
            raise KoExtError("couldn't extract extension code name from "
                             "the id, '%s': you must use an id of the "
                             "form 'name@example.com'" % id)
        name_pat = re.compile(r'&lt;em:name&gt;(.*?)&lt;/em:name&gt;')
        info["name"] = name_pat.search(install_rdf).group(1)
        ver_pat = re.compile(r'&lt;em:version&gt;(.*?)&lt;/em:version&gt;')
        info["version"] = ver_pat.search(install_rdf).group(1)
        self._install_rdf_info_cache = info
    return self._install_rdf_info_cache

</t>
<t tx="ekr.20080121134847.86">@property
def name(self):
    return self._install_rdf_info["name"]

</t>
<t tx="ekr.20080121134847.87">@property
def version(self):
    return self._install_rdf_info["version"]

</t>
<t tx="ekr.20080121134847.88">@property
def id(self):
    return self._install_rdf_info["id"]

</t>
<t tx="ekr.20080121134847.89">@property
def codename(self):
    return self._install_rdf_info["codename"]

</t>
<t tx="ekr.20080121134847.90">@property
def pkg_name(self):
    return "%s-%s-ko.xpi" % (self.codename, self.version)


</t>
<t tx="ekr.20080121134847.91">def _code_safe_lang_from_lang(lang):
    """Return a language name safe to use in a code identifier for the
    given language name.
    
    Note that a leading number is not escaped.
    """
    safe_lang = lang.replace('+', 'P')  # e.g., nicer for C++
    return re.sub(r'[^-_.\w\d]+', '_', safe_lang)


</t>
<t tx="ekr.20080121134847.92"># Recipe: module_from_path (1.0.1)
def _module_from_path(path):
    import imp, os
    dir = os.path.dirname(path) or os.curdir
    name = os.path.splitext(os.path.basename(path))[0]
    iinfo = imp.find_module(name, [dir])
    return imp.load_module(name, *iinfo)


</t>
<t tx="ekr.20080121134847.93"># Recipe: query_yes_no_quit (1.0)
def _query_yes_no_quit(question, default="yes"):
    """Ask a yes/no/quit question via raw_input() and return their answer.
    
    "question" is a string that is presented to the user.
    "default" is the presumed answer if the user just hits &lt;Enter&gt;.
        It must be "yes" (the default), "no", "quit" or None (meaning
        an answer is required of the user).

    The "answer" return value is one of "yes", "no" or "quit".
    """
    valid = {"yes":"yes",   "y":"yes",    "ye":"yes",
             "no":"no",     "n":"no",
             "quit":"quit", "qui":"quit", "qu":"quit", "q":"quit"}
    if default == None:
        prompt = " [y/n/q] "
    elif default == "yes":
        prompt = " [Y/n/q] "
    elif default == "no":
        prompt = " [y/N/q] "
    elif default == "quit":
        prompt = " [y/n/Q] "
    else:
        raise ValueError("invalid default answer: '%s'" % default)

    while 1:
        sys.stdout.write(question + prompt)
        choice = raw_input().lower()
        if default is not None and choice == '':
            return default
        elif choice in valid.keys():
            return valid[choice]
        else:
            sys.stdout.write("Please repond with 'yes', 'no' or 'quit'.\n")


</t>
<t tx="ekr.20080121134847.94"># Recipe: query (1.0)
def _query(preamble, default=None, prompt="&gt; ", validate=None):
    """Ask the user a question using raw_input() and looking something
    like this:

        PREAMBLE
        Hit &lt;Enter&gt; to use the default, DEFAULT.
        PROMPT
        ...validate...

    Arguments:
        "preamble" is a string to display before the user is prompted
            (i.e. this is the question).
        "default" (optional) is a default value.
        "prompt" (optional) is the prompt string.
        "validate" (optional) is either a string naming a stock validator:\

                notempty        Ensure the user's answer is not empty.
                yes-or-no       Ensure the user's answer is 'yes' or 'no'.
                                ('y', 'n' and any capitalization are
                                also accepted)

            or a callback function with this signature:
                validate(answer) -&gt; errmsg
            It should return None to indicate a valid answer.

            By default no validation is done.
    """
    if isinstance(validate, (str, unicode)):
        if validate == "notempty":
            def validate_notempty(answer):
                if not answer:
                    return "You must enter some non-empty value."
            validate = validate_notempty
        elif validate == "yes-or-no":
            def validate_yes_or_no(answer):
                if answer.lower() not in ('yes', 'no', 'y', 'n', 'ye'):
                    return "Please enter 'yes' or 'no'."
            validate = validate_yes_or_no
        else:
            raise ValueError("unknown stock validator: '%s'" % validate)
    
    def indented(text, indent=' '*4):
        lines = text.splitlines(1)
        return indent + indent.join(lines)

    sys.stdout.write(preamble+'\n')
    if default:
        sys.stdout.write("Hit &lt;Enter&gt; to use the default, %r.\n" % default)
    elif default is not None:
        default_str = default and repr(default) or '&lt;empty&gt;'
        sys.stdout.write("Hit &lt;Enter&gt; to leave blank.\n")
    while True:
        if True:
            answer = raw_input(prompt)
        else:
            sys.stdout.write(prompt)
            sys.stdout.flush()
            answer = sys.stdout.readline()
        if not answer and default:
            answer = default
        if validate is not None:
            errmsg = validate(answer)
            if errmsg:
                sys.stdout.write(errmsg+'\n')
                continue
        break
    return answer


</t>
<t tx="ekr.20080121134847.95"># Recipe: banner (1.0.1)
def _banner(text, ch='=', length=78):
    """Return a banner line centering the given text.
    
        "text" is the text to show in the banner. None can be given to have
            no text.
        "ch" (optional, default '=') is the banner line character (can
            also be a short string to repeat).
        "length" (optional, default 78) is the length of banner to make.

    Examples:
        &gt;&gt;&gt; _banner("Peggy Sue")
        '================================= Peggy Sue =================================='
        &gt;&gt;&gt; _banner("Peggy Sue", ch='-', length=50)
        '------------------- Peggy Sue --------------------'
        &gt;&gt;&gt; _banner("Pretty pretty pretty pretty Peggy Sue", length=40)
        'Pretty pretty pretty pretty Peggy Sue'
    """
    if text is None:
        return ch * length
    elif len(text) + 2 + len(ch)*2 &gt; length:
        # Not enough space for even one line char (plus space) around text.
        return text
    else:
        remain = length - (len(text) + 2)
        prefix_len = remain / 2
        suffix_len = remain - prefix_len
        if len(ch) == 1:
            prefix = ch * prefix_len
            suffix = ch * suffix_len
        else:
            prefix = ch * (prefix_len/len(ch)) + ch[:prefix_len%len(ch)]
            suffix = ch * (suffix_len/len(ch)) + ch[:suffix_len%len(ch)]
        return prefix + ' ' + text + ' ' + suffix


</t>
<t tx="ekr.20080121134847.96"># Recipe: dedent (0.1.2)
def _dedentlines(lines, tabsize=8, skip_first_line=False):
    """_dedentlines(lines, tabsize=8, skip_first_line=False) -&gt; dedented lines
    
        "lines" is a list of lines to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    Same as dedent() except operates on a sequence of lines. Note: the
    lines list is modified **in-place**.
    """
    DEBUG = False
    if DEBUG: 
        print "dedent: dedent(..., tabsize=%d, skip_first_line=%r)"\
              % (tabsize, skip_first_line)
    indents = []
    margin = None
    for i, line in enumerate(lines):
        if i == 0 and skip_first_line: continue
        indent = 0
        for ch in line:
            if ch == ' ':
                indent += 1
            elif ch == '\t':
                indent += tabsize - (indent % tabsize)
            elif ch in '\r\n':
                continue # skip all-whitespace lines
            else:
                break
        else:
            continue # skip all-whitespace lines
        if DEBUG: print "dedent: indent=%d: %r" % (indent, line)
        if margin is None:
            margin = indent
        else:
            margin = min(margin, indent)
    if DEBUG: print "dedent: margin=%r" % margin

    if margin is not None and margin &gt; 0:
        for i, line in enumerate(lines):
            if i == 0 and skip_first_line: continue
            removed = 0
            for j, ch in enumerate(line):
                if ch == ' ':
                    removed += 1
                elif ch == '\t':
                    removed += tabsize - (removed % tabsize)
                elif ch in '\r\n':
                    if DEBUG: print "dedent: %r: EOL -&gt; strip up to EOL" % line
                    lines[i] = lines[i][j:]
                    break
                else:
                    raise ValueError("unexpected non-whitespace char %r in "
                                     "line %r while removing %d-space margin"
                                     % (ch, line, margin))
                if DEBUG:
                    print "dedent: %r: %r -&gt; removed %d/%d"\
                          % (line, ch, removed, margin)
                if removed == margin:
                    lines[i] = lines[i][j+1:]
                    break
                elif removed &gt; margin:
                    lines[i] = ' '*(removed-margin) + lines[i][j+1:]
                    break
            else:
                if removed:
                    lines[i] = lines[i][removed:]
    return lines

</t>
<t tx="ekr.20080121134847.97">def _dedent(text, tabsize=8, skip_first_line=False):
    """_dedent(text, tabsize=8, skip_first_line=False) -&gt; dedented text

        "text" is the text to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    textwrap.dedent(s), but don't expand tabs to spaces
    """
    lines = text.splitlines(1)
    _dedentlines(lines, tabsize=tabsize, skip_first_line=skip_first_line)
    return ''.join(lines)


</t>
<t tx="ekr.20080121134847.98">def _xpidl(idl_path, xpt_path, ko_info, logstream=None):
    assert xpt_path.endswith(".xpt")
    idl_name = splitext(basename(idl_path))[0]
    xpt_path_sans_ext = splitext(xpt_path)[0]
    cmd = '"%s" -I "%s" -I "%s" -o %s -m typelib %s' \
          % (ko_info.xpidl_path, ko_info.idl_dir, dirname(idl_path),
             xpt_path_sans_ext, idl_path)
    _run(cmd, logstream)


</t>
<t tx="ekr.20080121134847.99">def _luddite_compile(udl_path, output_dir, ko_info):
    if ko_info.in_src_tree:
        sys.path.insert(0, dirname(ko_info.udl_dir))
        try:
            from ludditelib.commands import compile
        finally:
            del sys.path[0]
    else:
        from ludditelib.commands import compile
    compile(udl_path, output_dir, [ko_info.udl_dir], log=_log)

</t>
<t tx="ekr.20080121134847.100">def _trim_files_in_dir(dir, patterns, log=None):
    if log:
        log("trim '%s' files under '%s'", "', '".join(patterns), dir)
    from fnmatch import fnmatch
    for dirpath, dirnames, filenames in os.walk(dir):
        for d in dirnames[:]:
            for pat in patterns:
                if fnmatch(d, pat):
                    _rmtree(join(dirpath, d))
                    dirnames.remove(d)
                    break
        for f in dirnames[:]:
            for pat in patterns:
                if fnmatch(f, pat):
                    os.remove(join(dirpath, f))
                    break

</t>
<t tx="ekr.20080121134847.101"># Recipe: rmtree (0.5)
def _rmtree_OnError(rmFunction, filePath, excInfo):
    if excInfo[0] == OSError:
        # presuming because file is read-only
        os.chmod(filePath, 0777)
        rmFunction(filePath)
</t>
<t tx="ekr.20080121134847.102">def _rmtree(dirname):
    import shutil
    shutil.rmtree(dirname, 0, _rmtree_OnError)

</t>
<t tx="ekr.20080121134847.103"># Recipe: run (0.5.3)
_RUN_DEFAULT_LOGSTREAM = ("RUN", "DEFAULT", "LOGSTREAM")
def __run_log(logstream, msg, *args, **kwargs):
    if not logstream:
        pass
    elif logstream is _RUN_DEFAULT_LOGSTREAM:
        try:
            log
        except NameError:
            pass
        else:
            if hasattr(log, "debug"):
                log.debug(msg, *args, **kwargs)
    else:
        logstream(msg, *args, **kwargs)

</t>
<t tx="ekr.20080121134847.104">def _run(cmd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command.

        "cmd" is the command to run
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    __run_log(logstream, "running '%s'", cmd)
    fixed_cmd = cmd
    if sys.platform == "win32" and cmd.count('"') &gt; 2:
        fixed_cmd = '"' + cmd + '"'
    retval = os.system(fixed_cmd)
    if hasattr(os, "WEXITSTATUS"):
        status = os.WEXITSTATUS(retval)
    else:
        status = retval
    if status:
        #TODO: add std OSError attributes or pick more approp. exception
        raise OSError("error running '%s': %r" % (cmd, status))

</t>
<t tx="ekr.20080121134847.105">def _run_in_dir(cmd, cwd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command in the given working directory.

        "cmd" is the command to run
        "cwd" is the directory in which the commmand is run.
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    old_dir = os.getcwd()
    try:
        os.chdir(cwd)
        __run_log(logstream, "running '%s' in '%s'", cmd, cwd)
        _run(cmd, logstream=None)
    finally:
        os.chdir(old_dir)

</t>
<t tx="ekr.20080121134847.106">def _rm(path, logstream=None):
    """My little lame cross-platform 'rm -rf'"""
    assert ' ' not in path,\
        "_rm: can't handle paths in spaces: '%s'" % path
    if sys.platform == "win32":
        path = path.replace("/", "\\")
        assert "*" not in path and "?" not in path,\
            "_rm on win32: can't yet handle wildcards: '%s'" % path
        if not exists(path):
            pass
        elif isdir(path):
            _run("rd /s/q %s" % path, logstream=logstream)
        else:
            if not os.access(path, os.W_OK):
                _run("attrib -R %s" % path, logstream=logstream)
            _run("del /q %s" % path, logstream=logstream)
    else:
        _run("rm -rf %s" % path, logstream=logstream)

</t>
<t tx="ekr.20080121134847.107">def _mv(src, dest, logstream=None):
    """My little lame cross-platform 'mv'"""
    assert ' ' not in src and ' ' not in dest,\
        "_mv: can't handle paths in spaces: src=%r, dest=%r" % (src, dest)
    if sys.platform == "win32":
        _run("move %s %s" % (src, dest), logstream=logstream)
    else:
        _run("mv %s %s" % (src, dest), logstream=logstream)

</t>
<t tx="ekr.20080121134847.108">def _cp(src, dest, logstream=None):
    """My little lame cross-platform 'cp'"""
    assert ' ' not in src and ' ' not in dest,\
        "_cp: can't handle paths in spaces: src=%r, dest=%r" % (src, dest)
    if sys.platform == "win32":
        src = src.replace("/", "\\")
        dest = dest.replace("/", "\\")
        if isdir(src):
            _run("xcopy /e/i/y/q %s %s" % (src, dest), logstream=logstream)
        else:
            _run("copy /y %s %s" % (src, dest), logstream=logstream)
    else:
        if isdir(src):
            _run("cp -R %s %s" % (src, dest), logstream=logstream)
        else:
            _run("cp %s %s" % (src, dest), logstream=logstream)

</t>
<t tx="ekr.20080121134847.109">def _mkdir(dir, logstream=None):
    """My little lame cross-platform 'mkdir -p'"""
    if exists(dir): return
    if logstream:
        logstream("mkdir %s" % dir)
    os.makedirs(dir)


</t>
<t tx="ekr.20080121134949"></t>
<t tx="ekr.20080121134949.1">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.2">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.3">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.4">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.5">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.6">@language python
@tabwidth -4
@others
@ignore # &lt;&lt;keyword_style CSS_IDENTIFIER =&gt; CSS_WORD&gt;&gt; causes problems.</t>
<t tx="ekr.20080121134949.7">@language python
@tabwidth -4
@others
@ignore</t>
<t tx="ekr.20080121134949.8">@language python
@tabwidth -4
@others
if __name__ == "__main__":
    import sys
    sys.exit(main(sys.argv))
</t>
<t tx="ekr.20080121134949.9">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.10">@language python
@tabwidth -4
@others
NAMESPACE_DNS = UUID('{6ba7b810-9dad-11d1-80b4-00c04fd430c8}')
NAMESPACE_URL = UUID('{6ba7b811-9dad-11d1-80b4-00c04fd430c8}')
NAMESPACE_OID = UUID('{6ba7b812-9dad-11d1-80b4-00c04fd430c8}')
NAMESPACE_X500 = UUID('{6ba7b814-9dad-11d1-80b4-00c04fd430c8}')
</t>
<t tx="ekr.20080121134949.11">@language python
@tabwidth -4
@others
</t>
<t tx="ekr.20080121134949.12">@language python
@tabwidth -4

# Intentionally empty. Here just to make this a Python package.
</t>
<t tx="ekr.20080121135406">#!/usr/bin/env python
# Copyright (c) 2002-2007 ActiveState Software Inc.
# License: MIT (see LICENSE.txt for license details)
# Author:  Trent Mick
# Home:    http://trentm.com/projects/cmdln/

"""An improvement on Python's standard cmd.py module.

As with cmd.py, this module provides "a simple framework for writing
line-oriented command intepreters."  This module provides a 'RawCmdln'
class that fixes some design flaws in cmd.Cmd, making it more scalable
and nicer to use for good 'cvs'- or 'svn'-style command line interfaces
or simple shells.  And it provides a 'Cmdln' class that add
optparse-based option processing. Basically you use it like this:

    import cmdln

    class MySVN(cmdln.Cmdln):
        name = "svn"

        @cmdln.alias('stat', 'st')
        @cmdln.option('-v', '--verbose', action='store_true'
                      help='print verbose information')
        def do_status(self, subcmd, opts, *paths):
            print "handle 'svn status' command"

        #...

    if __name__ == "__main__":
        shell = MySVN()
        retval = shell.main()
        sys.exit(retval)

See the README.txt or &lt;http://trentm.com/projects/cmdln/&gt; for more
details.
"""

__revision__ = "$Id$"
__version_info__ = (1, 0, 1)
__version__ = '.'.join(map(str, __version_info__))

import os
import re
import cmd
import optparse
from pprint import pprint




#---- globals

LOOP_ALWAYS, LOOP_NEVER, LOOP_IF_EMPTY = range(3)

# An unspecified optional argument when None is a meaningful value.
_NOT_SPECIFIED = ("Not", "Specified")

# Pattern to match a TypeError message from a call that
# failed because of incorrect number of arguments (see
# Python/getargs.c).
_INCORRECT_NUM_ARGS_RE = re.compile(
    r"(takes [\w ]+ )(\d+)( arguments? \()(\d+)( given\))")



</t>
<t tx="ekr.20080121135406.1">#---- exceptions

class CmdlnError(Exception):
    """A cmdln.py usage error."""
    @others
</t>
<t tx="ekr.20080121135406.2">def __init__(self, msg):
    self.msg = msg
</t>
<t tx="ekr.20080121135406.3">def __str__(self):
    return self.msg

</t>
<t tx="ekr.20080121135406.4">class CmdlnUserError(Exception):
    """An error by a user of a cmdln-based tool/shell."""
    pass



</t>
<t tx="ekr.20080121135406.5">#---- public methods and classes

def alias(*aliases):
    """Decorator to add aliases for Cmdln.do_* command handlers.
    
    Example:
        class MyShell(cmdln.Cmdln):
            @cmdln.alias("!", "sh")
            def do_shell(self, argv):
                #...implement 'shell' command
    """
    def decorate(f):
        if not hasattr(f, "aliases"):
            f.aliases = []
        f.aliases += aliases
        return f
    return decorate


</t>
<t tx="ekr.20080121135406.6">class RawCmdln(cmd.Cmd):
    """An improved (on cmd.Cmd) framework for building multi-subcommand
    scripts (think "svn" &amp; "cvs") and simple shells (think "pdb" and
    "gdb").

    A simple example:

        import cmdln

        class MySVN(cmdln.RawCmdln):
            name = "svn"

            @cmdln.aliases('stat', 'st')
            def do_status(self, argv):
                print "handle 'svn status' command"

        if __name__ == "__main__":
            shell = MySVN()
            retval = shell.main()
            sys.exit(retval)

    See &lt;http://trentm.com/projects/cmdln&gt; for more information.
    """
    name = None      # if unset, defaults basename(sys.argv[0])
    prompt = None    # if unset, defaults to self.name+"&gt; "
    version = None   # if set, default top-level options include --version

    # Default messages for some 'help' command error cases.
    # They are interpolated with one arg: the command.
    nohelp = "no help on '%s'"
    unknowncmd = "unknown command: '%s'"

    helpindent = '' # string with which to indent help output

    @others
</t>
<t tx="ekr.20080121135406.7">def __init__(self, completekey='tab', 
             stdin=None, stdout=None, stderr=None):
    """Cmdln(completekey='tab', stdin=None, stdout=None, stderr=None)

    The optional argument 'completekey' is the readline name of a
    completion key; it defaults to the Tab key. If completekey is
    not None and the readline module is available, command completion
    is done automatically.
    
    The optional arguments 'stdin', 'stdout' and 'stderr' specify
    alternate input, output and error output file objects; if not
    specified, sys.* are used.
    
    If 'stdout' but not 'stderr' is specified, stdout is used for
    error output. This is to provide least surprise for users used
    to only the 'stdin' and 'stdout' options with cmd.Cmd.
    """
    import sys
    if self.name is None:
        self.name = os.path.basename(sys.argv[0])
    if self.prompt is None:
        self.prompt = self.name+"&gt; "
    self._name_str = self._str(self.name)
    self._prompt_str = self._str(self.prompt)
    if stdin is not None:
        self.stdin = stdin
    else:
        self.stdin = sys.stdin
    if stdout is not None:
        self.stdout = stdout
    else:
        self.stdout = sys.stdout
    if stderr is not None:
        self.stderr = stderr
    elif stdout is not None:
        self.stderr = stdout
    else:
        self.stderr = sys.stderr
    self.cmdqueue = []
    self.completekey = completekey
    self.cmdlooping = False

</t>
<t tx="ekr.20080121135406.8">def get_optparser(self):
    """Hook for subclasses to set the option parser for the
    top-level command/shell.

    This option parser is used retrieved and used by `.main()' to
    handle top-level options.

    The default implements a single '-h|--help' option. Sub-classes
    can return None to have no options at the top-level. Typically
    an instance of CmdlnOptionParser should be returned.
    """
    version = (self.version is not None 
                and "%s %s" % (self._name_str, self.version)
                or None)
    return CmdlnOptionParser(self, version=version)

</t>
<t tx="ekr.20080121135406.9">def postoptparse(self):
    """Hook method executed just after `.main()' parses top-level
    options.

    When called `self.options' holds the results of the option parse.
    """
    pass

</t>
<t tx="ekr.20080121135406.10">def main(self, argv=None, loop=LOOP_NEVER):
    """A possible mainline handler for a script, like so:

        import cmdln
        class MyCmd(cmdln.Cmdln):
            name = "mycmd"
            ...
        
        if __name__ == "__main__":
            MyCmd().main()

    By default this will use sys.argv to issue a single command to
    'MyCmd', then exit. The 'loop' argument can be use to control
    interactive shell behaviour.
    
    Arguments:
        "argv" (optional, default sys.argv) is the command to run.
            It must be a sequence, where the first element is the
            command name and subsequent elements the args for that
            command.
        "loop" (optional, default LOOP_NEVER) is a constant
            indicating if a command loop should be started (i.e. an
            interactive shell). Valid values (constants on this module):
                LOOP_ALWAYS     start loop and run "argv", if any
                LOOP_NEVER      run "argv" (or .emptyline()) and exit
                LOOP_IF_EMPTY   run "argv", if given, and exit;
                                otherwise, start loop
    """
    if argv is None:
        import sys
        argv = sys.argv
    else:
        argv = argv[:] # don't modify caller's list

    self.optparser = self.get_optparser()
    if self.optparser: # i.e. optparser=None means don't process for opts
        try:
            self.options, args = self.optparser.parse_args(argv[1:])
        except CmdlnUserError, ex:
            msg = "%s: %s\nTry '%s help' for info.\n"\
                  % (self.name, ex, self.name)
            self.stderr.write(self._str(msg))
            self.stderr.flush()
            return 1
        except StopOptionProcessing, ex:
            return 0
    else:
        self.options, args = None, argv[1:]
    self.postoptparse()

    if loop == LOOP_ALWAYS:
        if args:
            self.cmdqueue.append(args)
        return self.cmdloop()
    elif loop == LOOP_NEVER:
        if args:
            return self.cmd(args)
        else:
            return self.emptyline()
    elif loop == LOOP_IF_EMPTY:
        if args:
            return self.cmd(args)
        else:
            return self.cmdloop()

</t>
<t tx="ekr.20080121135406.11">def cmd(self, argv):
    """Run one command and exit.
    
        "argv" is the arglist for the command to run. argv[0] is the
            command to run. If argv is an empty list then the
            'emptyline' handler is run.

    Returns the return value from the command handler.
    """
    assert (isinstance(argv, (list, tuple)), 
            "'argv' is not a sequence: %r" % argv)
    retval = None
    try:
        argv = self.precmd(argv)
        retval = self.onecmd(argv)
        self.postcmd(argv)
    except:
        if not self.cmdexc(argv):
            raise
        retval = 1
    return retval

</t>
<t tx="ekr.20080121135406.12">def _str(self, s):
    """Safely convert the given str/unicode to a string for printing."""
    try:
        return str(s)
    except UnicodeError:
        #XXX What is the proper encoding to use here? 'utf-8' seems
        #    to work better than "getdefaultencoding" (usually
        #    'ascii'), on OS X at least.
        #import sys
        #return s.encode(sys.getdefaultencoding(), "replace")
        return s.encode("utf-8", "replace")

</t>
<t tx="ekr.20080121135406.13">def cmdloop(self, intro=None):
    """Repeatedly issue a prompt, accept input, parse into an argv, and
    dispatch (via .precmd(), .onecmd() and .postcmd()), passing them
    the argv. In other words, start a shell.
    
        "intro" (optional) is a introductory message to print when
            starting the command loop. This overrides the class
            "intro" attribute, if any.
    """
    self.cmdlooping = True
    self.preloop()
    if intro is None:
        intro = self.intro
    if intro:
        intro_str = self._str(intro)
        self.stdout.write(intro_str+'\n')
    self.stop = False
    retval = None
    while not self.stop:
        if self.cmdqueue:
            argv = self.cmdqueue.pop(0)
            assert (isinstance(argv, (list, tuple)), 
                    "item on 'cmdqueue' is not a sequence: %r" % argv)
        else:
            if self.use_rawinput:
                try:
                    line = raw_input(self._prompt_str)
                except EOFError:
                    line = 'EOF'
            else:
                self.stdout.write(self._prompt_str)
                self.stdout.flush()
                line = self.stdin.readline()
                if not len(line):
                    line = 'EOF'
                else:
                    line = line[:-1] # chop '\n'
            argv = line2argv(line)
        try:
            argv = self.precmd(argv)
            retval = self.onecmd(argv)
            self.postcmd(argv)
        except:
            if not self.cmdexc(argv):
                raise
            retval = 1
        self.lastretval = retval
    self.postloop()
    self.cmdlooping = False
    return retval

</t>
<t tx="ekr.20080121135406.14">def precmd(self, argv):
    """Hook method executed just before the command argv is
    interpreted, but after the input prompt is generated and issued.

        "argv" is the cmd to run.
        
    Returns an argv to run (i.e. this method can modify the command
    to run).
    """
    return argv

</t>
<t tx="ekr.20080121135406.15">def postcmd(self, argv):
    """Hook method executed just after a command dispatch is finished.
    
        "argv" is the command that was run.
    """
    pass

</t>
<t tx="ekr.20080121135406.16">def cmdexc(self, argv):
    """Called if an exception is raised in any of precmd(), onecmd(),
    or postcmd(). If True is returned, the exception is deemed to have
    been dealt with. Otherwise, the exception is re-raised.

    The default implementation handles CmdlnUserError's, which
    typically correspond to user error in calling commands (as
    opposed to programmer error in the design of the script using
    cmdln.py).
    """
    import sys
    type, exc, traceback = sys.exc_info()
    if isinstance(exc, CmdlnUserError):
        msg = "%s %s: %s\nTry '%s help %s' for info.\n"\
              % (self.name, argv[0], exc, self.name, argv[0])
        self.stderr.write(self._str(msg))
        self.stderr.flush()
        return True

</t>
<t tx="ekr.20080121135406.17">def onecmd(self, argv):
    if not argv:
        return self.emptyline()
    self.lastcmd = argv
    cmdname = self._get_canonical_cmd_name(argv[0])
    if cmdname:
        handler = self._get_cmd_handler(cmdname)
        if handler:
            return self._dispatch_cmd(handler, argv)
    return self.default(argv)

</t>
<t tx="ekr.20080121135406.18">def _dispatch_cmd(self, handler, argv):
    return handler(argv)

</t>
<t tx="ekr.20080121135406.19">def default(self, argv):
    """Hook called to handle a command for which there is no handler.

        "argv" is the command and arguments to run.
    
    The default implementation writes and error message to stderr
    and returns an error exit status.

    Returns a numeric command exit status.
    """
    errmsg = self._str(self.unknowncmd % (argv[0],))
    if self.cmdlooping:
        self.stderr.write(errmsg+"\n")
    else:
        self.stderr.write("%s: %s\nTry '%s help' for info.\n"
                          % (self._name_str, errmsg, self._name_str))
    self.stderr.flush()
    return 1

</t>
<t tx="ekr.20080121135406.20">def parseline(self, line):
    # This is used by Cmd.complete (readline completer function) to
    # massage the current line buffer before completion processing.
    # We override to drop special '!' handling.
    line = line.strip()
    if not line:
        return None, None, line
    elif line[0] == '?':
        line = 'help ' + line[1:]
    i, n = 0, len(line)
    while i &lt; n and line[i] in self.identchars: i = i+1
    cmd, arg = line[:i], line[i:].strip()
    return cmd, arg, line

</t>
<t tx="ekr.20080121135406.21">def helpdefault(self, cmd, known):
    """Hook called to handle help on a command for which there is no
    help handler.

        "cmd" is the command name on which help was requested.
        "known" is a boolean indicating if this command is known
            (i.e. if there is a handler for it).
    
    Returns a return code.
    """
    if known:
        msg = self._str(self.nohelp % (cmd,))
        if self.cmdlooping:
            self.stderr.write(msg + '\n')
        else:
            self.stderr.write("%s: %s\n" % (self.name, msg))
    else:
        msg = self.unknowncmd % (cmd,)
        if self.cmdlooping:
            self.stderr.write(msg + '\n')
        else:
            self.stderr.write("%s: %s\n"
                              "Try '%s help' for info.\n"
                              % (self.name, msg, self.name))
    self.stderr.flush()
    return 1

</t>
<t tx="ekr.20080121135406.22">def do_help(self, argv):
    """${cmd_name}: give detailed help on a specific sub-command

    Usage:
        ${name} help [COMMAND]
    """
    if len(argv) &gt; 1: # asking for help on a particular command
        doc = None
        cmdname = self._get_canonical_cmd_name(argv[1]) or argv[1]
        if not cmdname:
            return self.helpdefault(argv[1], False)
        else:
            helpfunc = getattr(self, "help_"+cmdname, None)
            if helpfunc:
                doc = helpfunc()
            else:
                handler = self._get_cmd_handler(cmdname)
                if handler:
                    doc = handler.__doc__
                if doc is None:
                    return self.helpdefault(argv[1], handler != None)
    else: # bare "help" command
        doc = self.__class__.__doc__  # try class docstring
        if doc is None:
            # Try to provide some reasonable useful default help.
            if self.cmdlooping: prefix = ""
            else:               prefix = self.name+' '
            doc = """Usage:
                %sCOMMAND [ARGS...]
                %shelp [COMMAND]

            ${option_list}
            ${command_list}
            ${help_list}
            """ % (prefix, prefix)
        cmdname = None

    if doc: # *do* have help content, massage and print that
        doc = self._help_reindent(doc)
        doc = self._help_preprocess(doc, cmdname)
        doc = doc.rstrip() + '\n' # trim down trailing space
        self.stdout.write(self._str(doc))
        self.stdout.flush()
</t>
<t tx="ekr.20080121135406.23">do_help.aliases = ["?"]

def _help_reindent(self, help, indent=None):
    """Hook to re-indent help strings before writing to stdout.

        "help" is the help content to re-indent
        "indent" is a string with which to indent each line of the
            help content after normalizing. If unspecified or None
            then the default is use: the 'self.helpindent' class
            attribute. By default this is the empty string, i.e.
            no indentation.

    By default, all common leading whitespace is removed and then
    the lot is indented by 'self.helpindent'. When calculating the
    common leading whitespace the first line is ignored -- hence
    help content for Conan can be written as follows and have the
    expected indentation:

        def do_crush(self, ...):
            '''${cmd_name}: crush your enemies, see them driven before you...

            c.f. Conan the Barbarian'''
    """
    if indent is None:
        indent = self.helpindent
    lines = help.splitlines(0)
    _dedentlines(lines, skip_first_line=True)
    lines = [(indent+line).rstrip() for line in lines]
    return '\n'.join(lines)

</t>
<t tx="ekr.20080121135406.24">def _help_preprocess(self, help, cmdname):
    """Hook to preprocess a help string before writing to stdout.

        "help" is the help string to process.
        "cmdname" is the canonical sub-command name for which help
            is being given, or None if the help is not specific to a
            command.

    By default the following template variables are interpolated in
    help content. (Note: these are similar to Python 2.4's
    string.Template interpolation but not quite.)

    ${name}
        The tool's/shell's name, i.e. 'self.name'.
    ${option_list}
        A formatted table of options for this shell/tool.
    ${command_list}
        A formatted table of available sub-commands.
    ${help_list}
        A formatted table of additional help topics (i.e. 'help_*'
        methods with no matching 'do_*' method).
    ${cmd_name}
        The name (and aliases) for this sub-command formatted as:
        "NAME (ALIAS1, ALIAS2, ...)".
    ${cmd_usage}
        A formatted usage block inferred from the command function
        signature.
    ${cmd_option_list}
        A formatted table of options for this sub-command. (This is
        only available for commands using the optparse integration,
        i.e.  using @cmdln.option decorators or manually setting the
        'optparser' attribute on the 'do_*' method.)

    Returns the processed help. 
    """
    preprocessors = {
        "${name}":            self._help_preprocess_name,
        "${option_list}":     self._help_preprocess_option_list,
        "${command_list}":    self._help_preprocess_command_list,
        "${help_list}":       self._help_preprocess_help_list,
        "${cmd_name}":        self._help_preprocess_cmd_name,
        "${cmd_usage}":       self._help_preprocess_cmd_usage,
        "${cmd_option_list}": self._help_preprocess_cmd_option_list,
    }

    for marker, preprocessor in preprocessors.items():
        if marker in help:
            help = preprocessor(help, cmdname)
    return help

</t>
<t tx="ekr.20080121135406.25">def _help_preprocess_name(self, help, cmdname=None):
    return help.replace("${name}", self.name)

</t>
<t tx="ekr.20080121135406.26">def _help_preprocess_option_list(self, help, cmdname=None):
    marker = "${option_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    if self.optparser:
        # Setup formatting options and format.
        # - Indentation of 4 is better than optparse default of 2.
        #   C.f. Damian Conway's discussion of this in Perl Best
        #   Practices.
        self.optparser.formatter.indent_increment = 4
        self.optparser.formatter.current_indent = indent_width
        block = self.optparser.format_option_help() + '\n'
    else:
        block = ""
        
    help = help.replace(indent+marker+suffix, block, 1)
    return help


</t>
<t tx="ekr.20080121135406.27">def _help_preprocess_command_list(self, help, cmdname=None):
    marker = "${command_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Find any aliases for commands.
    token2canonical = self._get_canonical_map()
    aliases = {}
    for token, cmdname in token2canonical.items():
        if token == cmdname: continue
        aliases.setdefault(cmdname, []).append(token)

    # Get the list of (non-hidden) commands and their
    # documentation, if any.
    cmdnames = {} # use a dict to strip duplicates
    for attr in self.get_names():
        if attr.startswith("do_"):
            cmdnames[attr[3:]] = True
    cmdnames = cmdnames.keys()
    cmdnames.sort()
    linedata = []
    for cmdname in cmdnames:
        if aliases.get(cmdname):
            a = aliases[cmdname]
            a.sort()
            cmdstr = "%s (%s)" % (cmdname, ", ".join(a))
        else:
            cmdstr = cmdname
        doc = None
        try:
            helpfunc = getattr(self, 'help_'+cmdname)
        except AttributeError:
            handler = self._get_cmd_handler(cmdname)
            if handler:
                doc = handler.__doc__
        else:
            doc = helpfunc()
            
        # Strip "${cmd_name}: " from the start of a command's doc. Best
        # practice dictates that command help strings begin with this, but
        # it isn't at all wanted for the command list.
        to_strip = "${cmd_name}:"
        if doc and doc.startswith(to_strip):
            #log.debug("stripping %r from start of %s's help string",
            #          to_strip, cmdname)
            doc = doc[len(to_strip):].lstrip()
        linedata.append( (cmdstr, doc) )

    if linedata:
        subindent = indent + ' '*4
        lines = _format_linedata(linedata, subindent, indent_width+4)
        block = indent + "Commands:\n" \
                + '\n'.join(lines) + "\n\n"
        help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121135406.28">def _gen_names_and_attrs(self):
    # Inheritance says we have to look in class and
    # base classes; order is not important.
    names = []
    classes = [self.__class__]
    while classes:
        aclass = classes.pop(0)
        if aclass.__bases__:
            classes = classes + list(aclass.__bases__)
        for name in dir(aclass):
            yield (name, getattr(aclass, name))

</t>
<t tx="ekr.20080121135406.29">def _help_preprocess_help_list(self, help, cmdname=None):
    marker = "${help_list}"
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Determine the additional help topics, if any.
    helpnames = {}
    token2cmdname = self._get_canonical_map()
    for attrname, attr in self._gen_names_and_attrs():
        if not attrname.startswith("help_"): continue
        helpname = attrname[5:]
        if helpname not in token2cmdname:
            helpnames[helpname] = attr

    if helpnames:
        linedata = [(n, a.__doc__ or "") for n, a in helpnames.items()]
        linedata.sort()

        subindent = indent + ' '*4
        lines = _format_linedata(linedata, subindent, indent_width+4)
        block = (indent
                + "Additional help topics (run `%s help TOPIC'):\n" % self.name
                + '\n'.join(lines)
                + "\n\n")
    else:
        block = ''
    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121135406.30">def _help_preprocess_cmd_name(self, help, cmdname=None):
    marker = "${cmd_name}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    s = cmdname
    if hasattr(handler, "aliases"):
        s += " (%s)" % (", ".join(handler.aliases))
    help = help.replace(marker, s)
    return help

</t>
<t tx="ekr.20080121135406.31">#TODO: this only makes sense as part of the Cmdln class.
#      Add hooks to add help preprocessing template vars and put
#      this one on that class.
def _help_preprocess_cmd_usage(self, help, cmdname=None):
    marker = "${cmd_usage}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)

    # Extract the introspection bits we need.
    func = handler.im_func
    if func.func_defaults:
        func_defaults = list(func.func_defaults)
    else:
        func_defaults = []
    co_argcount = func.func_code.co_argcount
    co_varnames = func.func_code.co_varnames
    co_flags = func.func_code.co_flags
    CO_FLAGS_ARGS = 4
    CO_FLAGS_KWARGS = 8

    # Adjust argcount for possible *args and **kwargs arguments.
    argcount = co_argcount
    if co_flags &amp; CO_FLAGS_ARGS:   argcount += 1
    if co_flags &amp; CO_FLAGS_KWARGS: argcount += 1

    # Determine the usage string.
    usage = "%s %s" % (self.name, cmdname)
    if argcount &lt;= 2:   # handler ::= do_FOO(self, argv)
        usage += " [ARGS...]"
    elif argcount &gt;= 3: # handler ::= do_FOO(self, subcmd, opts, ...)
        argnames = list(co_varnames[3:argcount])
        tail = ""
        if co_flags &amp; CO_FLAGS_KWARGS:
            name = argnames.pop(-1)
            import warnings
            # There is no generally accepted mechanism for passing
            # keyword arguments from the command line. Could
            # *perhaps* consider: arg=value arg2=value2 ...
            warnings.warn("argument '**%s' on '%s.%s' command "
                          "handler will never get values" 
                          % (name, self.__class__.__name__,
                             func.func_name))
        if co_flags &amp; CO_FLAGS_ARGS:
            name = argnames.pop(-1)
            tail = "[%s...]" % name.upper()
        while func_defaults:
            func_defaults.pop(-1)
            name = argnames.pop(-1)
            tail = "[%s%s%s]" % (name.upper(), (tail and ' ' or ''), tail)
        while argnames:
            name = argnames.pop(-1)
            tail = "%s %s" % (name.upper(), tail)
        usage += ' ' + tail

    block_lines = [
        self.helpindent + "Usage:",
        self.helpindent + ' '*4 + usage
    ]
    block = '\n'.join(block_lines) + '\n\n'

    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121135406.32">#TODO: this only makes sense as part of the Cmdln class.
#      Add hooks to add help preprocessing template vars and put
#      this one on that class.
def _help_preprocess_cmd_option_list(self, help, cmdname=None):
    marker = "${cmd_option_list}"
    handler = self._get_cmd_handler(cmdname)
    if not handler:
        raise CmdlnError("cannot preprocess '%s' into help string: "
                         "could not find command handler for %r" 
                         % (marker, cmdname))
    indent, indent_width = _get_indent(marker, help)
    suffix = _get_trailing_whitespace(marker, help)
    if hasattr(handler, "optparser"):
        # Setup formatting options and format.
        # - Indentation of 4 is better than optparse default of 2.
        #   C.f. Damian Conway's discussion of this in Perl Best
        #   Practices.
        handler.optparser.formatter.indent_increment = 4
        handler.optparser.formatter.current_indent = indent_width
        block = handler.optparser.format_option_help() + '\n'
    else:
        block = ""

    help = help.replace(indent+marker+suffix, block, 1)
    return help

</t>
<t tx="ekr.20080121135406.33">def _get_canonical_cmd_name(self, token):
    map = self._get_canonical_map()
    return map.get(token, None)

</t>
<t tx="ekr.20080121135406.34">def _get_canonical_map(self):
    """Return a mapping of available command names and aliases to
    their canonical command name.
    """
    cacheattr = "_token2canonical"
    if not hasattr(self, cacheattr):
        # Get the list of commands and their aliases, if any.
        token2canonical = {}
        cmd2funcname = {} # use a dict to strip duplicates
        for attr in self.get_names():
            if attr.startswith("do_"):    cmdname = attr[3:]
            elif attr.startswith("_do_"): cmdname = attr[4:]
            else:
                continue
            cmd2funcname[cmdname] = attr
            token2canonical[cmdname] = cmdname
        for cmdname, funcname in cmd2funcname.items(): # add aliases
            func = getattr(self, funcname)
            aliases = getattr(func, "aliases", [])
            for alias in aliases:
                if alias in cmd2funcname:
                    import warnings
                    warnings.warn("'%s' alias for '%s' command conflicts "
                                  "with '%s' handler"
                                  % (alias, cmdname, cmd2funcname[alias]))
                    continue
                token2canonical[alias] = cmdname
        setattr(self, cacheattr, token2canonical)
    return getattr(self, cacheattr)

</t>
<t tx="ekr.20080121135406.35">def _get_cmd_handler(self, cmdname):
    handler = None
    try:
        handler = getattr(self, 'do_' + cmdname)
    except AttributeError:
        try:
            # Private command handlers begin with "_do_".
            handler = getattr(self, '_do_' + cmdname)
        except AttributeError:
            pass
    return handler

</t>
<t tx="ekr.20080121135406.36">def _do_EOF(self, argv):
    # Default EOF handler
    # Note: an actual EOF is redirected to this command.
    #TODO: separate name for this. Currently it is available from
    #      command-line. Is that okay?
    self.stdout.write('\n')
    self.stdout.flush()
    self.stop = True

</t>
<t tx="ekr.20080121135406.37">def emptyline(self):
    # Different from cmd.Cmd: don't repeat the last command for an
    # emptyline.
    if self.cmdlooping:
        pass
    else:
        return self.do_help(["help"])


</t>
<t tx="ekr.20080121135406.38">#---- optparse.py extension to fix (IMO) some deficiencies
#
# See the class _OptionParserEx docstring for details.
#

class StopOptionProcessing(Exception):
    """Indicate that option *and argument* processing should stop
    cleanly. This is not an error condition. It is similar in spirit to
    StopIteration. This is raised by _OptionParserEx's default "help"
    and "version" option actions and can be raised by custom option
    callbacks too.
    
    Hence the typical CmdlnOptionParser (a subclass of _OptionParserEx)
    usage is:

        parser = CmdlnOptionParser(mycmd)
        parser.add_option("-f", "--force", dest="force")
        ...
        try:
            opts, args = parser.parse_args()
        except StopOptionProcessing:
            # normal termination, "--help" was probably given
            sys.exit(0)
    """

</t>
<t tx="ekr.20080121135406.39">class _OptionParserEx(optparse.OptionParser):
    """An optparse.OptionParser that uses exceptions instead of sys.exit.

    This class is an extension of optparse.OptionParser that differs
    as follows:
    - Correct (IMO) the default OptionParser error handling to never
      sys.exit(). Instead OptParseError exceptions are passed through.
    - Add the StopOptionProcessing exception (a la StopIteration) to
      indicate normal termination of option processing.
      See StopOptionProcessing's docstring for details.

    I'd also like to see the following in the core optparse.py, perhaps
    as a RawOptionParser which would serve as a base class for the more
    generally used OptionParser (that works as current):
    - Remove the implicit addition of the -h|--help and --version
      options. They can get in the way (e.g. if want '-?' and '-V' for
      these as well) and it is not hard to do:
        optparser.add_option("-h", "--help", action="help")
        optparser.add_option("--version", action="version")
      These are good practices, just not valid defaults if they can
      get in the way.
    """
    @others
</t>
<t tx="ekr.20080121135406.40">def error(self, msg):
    raise optparse.OptParseError(msg)

</t>
<t tx="ekr.20080121135406.41">def exit(self, status=0, msg=None):
    if status == 0:
        raise StopOptionProcessing(msg)
    else:
        #TODO: don't lose status info here
        raise optparse.OptParseError(msg)



</t>
<t tx="ekr.20080121135406.42">#---- optparse.py-based option processing support

class CmdlnOptionParser(_OptionParserEx):
    """An optparse.OptionParser class more appropriate for top-level
    Cmdln options. For parsing of sub-command options, see
    SubCmdOptionParser.

    Changes:
    - disable_interspersed_args() by default, because a Cmdln instance
      has sub-commands which may themselves have options.
    - Redirect print_help() to the Cmdln.do_help() which is better
      equiped to handle the "help" action.
    - error() will raise a CmdlnUserError: OptionParse.error() is meant
      to be called for user errors. Raising a well-known error here can
      make error handling clearer.
    - Also see the changes in _OptionParserEx.
    """
    @others
</t>
<t tx="ekr.20080121135406.43">def __init__(self, cmdln, **kwargs):
    self.cmdln = cmdln
    kwargs["prog"] = self.cmdln.name
    _OptionParserEx.__init__(self, **kwargs)
    self.disable_interspersed_args()

</t>
<t tx="ekr.20080121135406.44">def print_help(self, file=None):
    self.cmdln.onecmd(["help"])

</t>
<t tx="ekr.20080121135406.45">def error(self, msg):
    raise CmdlnUserError(msg)


</t>
<t tx="ekr.20080121135406.46">class SubCmdOptionParser(_OptionParserEx):
    @others
</t>
<t tx="ekr.20080121135406.47">def set_cmdln_info(self, cmdln, subcmd):
    """Called by Cmdln to pass relevant info about itself needed
    for print_help().
    """
    self.cmdln = cmdln
    self.subcmd = subcmd

</t>
<t tx="ekr.20080121135406.48">def print_help(self, file=None):
    self.cmdln.onecmd(["help", self.subcmd])

</t>
<t tx="ekr.20080121135406.49">def error(self, msg):
    raise CmdlnUserError(msg)


</t>
<t tx="ekr.20080121135406.50">def option(*args, **kwargs):
    """Decorator to add an option to the optparser argument of a Cmdln
    subcommand.
    
    Example:
        class MyShell(cmdln.Cmdln):
            @cmdln.option("-f", "--force", help="force removal")
            def do_remove(self, subcmd, opts, *args):
                #...
    """
    #XXX Is there a possible optimization for many options to not have a
    #    large stack depth here?
    def decorate(f):
        if not hasattr(f, "optparser"):
            f.optparser = SubCmdOptionParser()
        f.optparser.add_option(*args, **kwargs)
        return f
    return decorate


</t>
<t tx="ekr.20080121135406.51">class Cmdln(RawCmdln):
    """An improved (on cmd.Cmd) framework for building multi-subcommand
    scripts (think "svn" &amp; "cvs") and simple shells (think "pdb" and
    "gdb").

    A simple example:

        import cmdln

        class MySVN(cmdln.Cmdln):
            name = "svn"

            @cmdln.aliases('stat', 'st')
            @cmdln.option('-v', '--verbose', action='store_true'
                          help='print verbose information')
            def do_status(self, subcmd, opts, *paths):
                print "handle 'svn status' command"

            #...

        if __name__ == "__main__":
            shell = MySVN()
            retval = shell.main()
            sys.exit(retval)

    'Cmdln' extends 'RawCmdln' by providing optparse option processing
    integration.  See this class' _dispatch_cmd() docstring and
    &lt;http://trentm.com/projects/cmdln&gt; for more information.
    """
    @others
</t>
<t tx="ekr.20080121135406.52">def _dispatch_cmd(self, handler, argv):
    """Introspect sub-command handler signature to determine how to
    dispatch the command. The raw handler provided by the base
    'RawCmdln' class is still supported:

        def do_foo(self, argv):
            # 'argv' is the vector of command line args, argv[0] is
            # the command name itself (i.e. "foo" or an alias)
            pass

    In addition, if the handler has more than 2 arguments option
    processing is automatically done (using optparse):

        @cmdln.option('-v', '--verbose', action='store_true')
        def do_bar(self, subcmd, opts, *args):
            # subcmd = &lt;"bar" or an alias&gt;
            # opts = &lt;an optparse.Values instance&gt;
            if opts.verbose:
                print "lots of debugging output..."
            # args = &lt;tuple of arguments&gt;
            for arg in args:
                bar(arg)

    TODO: explain that "*args" can be other signatures as well.

    The `cmdln.option` decorator corresponds to an `add_option()`
    method call on an `optparse.OptionParser` instance.

    You can declare a specific number of arguments:

        @cmdln.option('-v', '--verbose', action='store_true')
        def do_bar2(self, subcmd, opts, bar_one, bar_two):
            #...

    and an appropriate error message will be raised/printed if the
    command is called with a different number of args.
    """
    co_argcount = handler.im_func.func_code.co_argcount
    if co_argcount == 2:   # handler ::= do_foo(self, argv)
        return handler(argv)
    elif co_argcount &gt;= 3: # handler ::= do_foo(self, subcmd, opts, ...)
        try:
            optparser = handler.optparser
        except AttributeError:
            optparser = handler.im_func.optparser = SubCmdOptionParser()
        assert isinstance(optparser, SubCmdOptionParser)
        optparser.set_cmdln_info(self, argv[0])
        try:
            opts, args = optparser.parse_args(argv[1:])
        except StopOptionProcessing:
            #TODO: this doesn't really fly for a replacement of
            #      optparse.py behaviour, does it?
            return 0 # Normal command termination

        try:
            return handler(argv[0], opts, *args)
        except TypeError, ex:
            # Some TypeError's are user errors:
            #   do_foo() takes at least 4 arguments (3 given)
            #   do_foo() takes at most 5 arguments (6 given)
            #   do_foo() takes exactly 5 arguments (6 given)
            # Raise CmdlnUserError for these with a suitably
            # massaged error message.
            import sys
            tb = sys.exc_info()[2] # the traceback object
            if tb.tb_next is not None:
                # If the traceback is more than one level deep, then the
                # TypeError do *not* happen on the "handler(...)" call
                # above. In that we don't want to handle it specially
                # here: it would falsely mask deeper code errors.
                raise
            msg = ex.args[0]
            match = _INCORRECT_NUM_ARGS_RE.search(msg)
            if match:
                msg = list(match.groups())
                msg[1] = int(msg[1]) - 3
                if msg[1] == 1:
                    msg[2] = msg[2].replace("arguments", "argument")
                msg[3] = int(msg[3]) - 3
                msg = ''.join(map(str, msg))
                raise CmdlnUserError(msg)
            else:
                raise
    else:
        raise CmdlnError("incorrect argcount for %s(): takes %d, must "
                         "take 2 for 'argv' signature or 3+ for 'opts' "
                         "signature" % (handler.__name__, co_argcount))
    


</t>
<t tx="ekr.20080121135406.53">#---- internal support functions

def _format_linedata(linedata, indent, indent_width):
    """Format specific linedata into a pleasant layout.
    
        "linedata" is a list of 2-tuples of the form:
            (&lt;item-display-string&gt;, &lt;item-docstring&gt;)
        "indent" is a string to use for one level of indentation
        "indent_width" is a number of columns by which the
            formatted data will be indented when printed.

    The &lt;item-display-string&gt; column is held to 15 columns.
    """
    lines = []
    WIDTH = 78 - indent_width
    SPACING = 2
    NAME_WIDTH_LOWER_BOUND = 13
    NAME_WIDTH_UPPER_BOUND = 16
    NAME_WIDTH = max([len(s) for s,d in linedata])
    if NAME_WIDTH &lt; NAME_WIDTH_LOWER_BOUND:
        NAME_WIDTH = NAME_WIDTH_LOWER_BOUND
    else:
        NAME_WIDTH = NAME_WIDTH_UPPER_BOUND

    DOC_WIDTH = WIDTH - NAME_WIDTH - SPACING
    for namestr, doc in linedata:
        line = indent + namestr
        if len(namestr) &lt;= NAME_WIDTH:
            line += ' ' * (NAME_WIDTH + SPACING - len(namestr))
        else:
            lines.append(line)
            line = indent + ' ' * (NAME_WIDTH + SPACING)
        line += _summarize_doc(doc, DOC_WIDTH)
        lines.append(line.rstrip())
    return lines

</t>
<t tx="ekr.20080121135406.54">def _summarize_doc(doc, length=60):
    r"""Parse out a short one line summary from the given doclines.
    
        "doc" is the doc string to summarize.
        "length" is the max length for the summary

    &gt;&gt;&gt; _summarize_doc("this function does this")
    'this function does this'
    &gt;&gt;&gt; _summarize_doc("this function does this", 10)
    'this fu...'
    &gt;&gt;&gt; _summarize_doc("this function does this\nand that")
    'this function does this and that'
    &gt;&gt;&gt; _summarize_doc("this function does this\n\nand that")
    'this function does this'
    """
    import re
    if doc is None:
        return ""
    assert length &gt; 3, "length &lt;= 3 is absurdly short for a doc summary"
    doclines = doc.strip().splitlines(0)
    if not doclines:
        return ""

    summlines = []
    for i, line in enumerate(doclines):
        stripped = line.strip()
        if not stripped:
            break
        summlines.append(stripped)
        if len(''.join(summlines)) &gt;= length:
            break

    summary = ' '.join(summlines)
    if len(summary) &gt; length:
        summary = summary[:length-3] + "..." 
    return summary


</t>
<t tx="ekr.20080121135406.55">def line2argv(line):
    r"""Parse the given line into an argument vector.
    
        "line" is the line of input to parse.

    This may get niggly when dealing with quoting and escaping. The
    current state of this parsing may not be completely thorough/correct
    in this respect.
    
    &gt;&gt;&gt; from cmdln import line2argv
    &gt;&gt;&gt; line2argv("foo")
    ['foo']
    &gt;&gt;&gt; line2argv("foo bar")
    ['foo', 'bar']
    &gt;&gt;&gt; line2argv("foo bar ")
    ['foo', 'bar']
    &gt;&gt;&gt; line2argv(" foo bar")
    ['foo', 'bar']

    Quote handling:
    
    &gt;&gt;&gt; line2argv("'foo bar'")
    ['foo bar']
    &gt;&gt;&gt; line2argv('"foo bar"')
    ['foo bar']
    &gt;&gt;&gt; line2argv(r'"foo\"bar"')
    ['foo"bar']
    &gt;&gt;&gt; line2argv("'foo bar' spam")
    ['foo bar', 'spam']
    &gt;&gt;&gt; line2argv("'foo 'bar spam")
    ['foo bar', 'spam']
    &gt;&gt;&gt; line2argv("'foo")
    Traceback (most recent call last):
        ...
    ValueError: command line is not terminated: unfinished single-quoted segment
    &gt;&gt;&gt; line2argv('"foo')
    Traceback (most recent call last):
        ...
    ValueError: command line is not terminated: unfinished double-quoted segment
    &gt;&gt;&gt; line2argv('some\tsimple\ttests')
    ['some', 'simple', 'tests']
    &gt;&gt;&gt; line2argv('a "more complex" test')
    ['a', 'more complex', 'test']
    &gt;&gt;&gt; line2argv('a more="complex test of " quotes')
    ['a', 'more=complex test of ', 'quotes']
    &gt;&gt;&gt; line2argv('a more" complex test of " quotes')
    ['a', 'more complex test of ', 'quotes']
    &gt;&gt;&gt; line2argv('an "embedded \\"quote\\""')
    ['an', 'embedded "quote"']
    """
    import string
    line = line.strip()
    argv = []
    state = "default"
    arg = None  # the current argument being parsed
    i = -1
    while 1:
        i += 1
        if i &gt;= len(line): break
        ch = line[i]

        if ch == "\\": # escaped char always added to arg, regardless of state
            if arg is None: arg = ""
            i += 1
            arg += line[i]
            continue

        if state == "single-quoted":
            if ch == "'":
                state = "default"
            else:
                arg += ch
        elif state == "double-quoted":
            if ch == '"':
                state = "default"
            else:
                arg += ch
        elif state == "default":
            if ch == '"':
                if arg is None: arg = ""
                state = "double-quoted"
            elif ch == "'":
                if arg is None: arg = ""
                state = "single-quoted"
            elif ch in string.whitespace:
                if arg is not None:
                    argv.append(arg)
                arg = None
            else:
                if arg is None: arg = ""
                arg += ch
    if arg is not None:
        argv.append(arg)
    if state != "default":
        raise ValueError("command line is not terminated: unfinished %s "
                         "segment" % state)
    return argv


</t>
<t tx="ekr.20080121135406.56">def argv2line(argv):
    r"""Put together the given argument vector into a command line.
    
        "argv" is the argument vector to process.
    
    &gt;&gt;&gt; from cmdln import argv2line
    &gt;&gt;&gt; argv2line(['foo'])
    'foo'
    &gt;&gt;&gt; argv2line(['foo', 'bar'])
    'foo bar'
    &gt;&gt;&gt; argv2line(['foo', 'bar baz'])
    'foo "bar baz"'
    &gt;&gt;&gt; argv2line(['foo"bar'])
    'foo"bar'
    &gt;&gt;&gt; print argv2line(['foo" bar'])
    'foo" bar'
    &gt;&gt;&gt; print argv2line(["foo' bar"])
    "foo' bar"
    &gt;&gt;&gt; argv2line(["foo'bar"])
    "foo'bar"
    """
    escapedArgs = []
    for arg in argv:
        if ' ' in arg and '"' not in arg:
            arg = '"'+arg+'"'
        elif ' ' in arg and "'" not in arg:
            arg = "'"+arg+"'"
        elif ' ' in arg:
            arg = arg.replace('"', r'\"')
            arg = '"'+arg+'"'
        escapedArgs.append(arg)
    return ' '.join(escapedArgs)


</t>
<t tx="ekr.20080121135406.57"># Recipe: dedent (0.1) in /Users/trentm/tm/recipes/cookbook
def _dedentlines(lines, tabsize=8, skip_first_line=False):
    """_dedentlines(lines, tabsize=8, skip_first_line=False) -&gt; dedented lines
    
        "lines" is a list of lines to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    Same as dedent() except operates on a sequence of lines. Note: the
    lines list is modified **in-place**.
    """
    DEBUG = False
    if DEBUG: 
        print "dedent: dedent(..., tabsize=%d, skip_first_line=%r)"\
              % (tabsize, skip_first_line)
    indents = []
    margin = None
    for i, line in enumerate(lines):
        if i == 0 and skip_first_line: continue
        indent = 0
        for ch in line:
            if ch == ' ':
                indent += 1
            elif ch == '\t':
                indent += tabsize - (indent % tabsize)
            elif ch in '\r\n':
                continue # skip all-whitespace lines
            else:
                break
        else:
            continue # skip all-whitespace lines
        if DEBUG: print "dedent: indent=%d: %r" % (indent, line)
        if margin is None:
            margin = indent
        else:
            margin = min(margin, indent)
    if DEBUG: print "dedent: margin=%r" % margin

    if margin is not None and margin &gt; 0:
        for i, line in enumerate(lines):
            if i == 0 and skip_first_line: continue
            removed = 0
            for j, ch in enumerate(line):
                if ch == ' ':
                    removed += 1
                elif ch == '\t':
                    removed += tabsize - (removed % tabsize)
                elif ch in '\r\n':
                    if DEBUG: print "dedent: %r: EOL -&gt; strip up to EOL" % line
                    lines[i] = lines[i][j:]
                    break
                else:
                    raise ValueError("unexpected non-whitespace char %r in "
                                     "line %r while removing %d-space margin"
                                     % (ch, line, margin))
                if DEBUG:
                    print "dedent: %r: %r -&gt; removed %d/%d"\
                          % (line, ch, removed, margin)
                if removed == margin:
                    lines[i] = lines[i][j+1:]
                    break
                elif removed &gt; margin:
                    lines[i] = ' '*(removed-margin) + lines[i][j+1:]
                    break
    return lines

</t>
<t tx="ekr.20080121135406.58">def _dedent(text, tabsize=8, skip_first_line=False):
    """_dedent(text, tabsize=8, skip_first_line=False) -&gt; dedented text

        "text" is the text to dedent.
        "tabsize" is the tab width to use for indent width calculations.
        "skip_first_line" is a boolean indicating if the first line should
            be skipped for calculating the indent width and for dedenting.
            This is sometimes useful for docstrings and similar.
    
    textwrap.dedent(s), but don't expand tabs to spaces
    """
    lines = text.splitlines(1)
    _dedentlines(lines, tabsize=tabsize, skip_first_line=skip_first_line)
    return ''.join(lines)


</t>
<t tx="ekr.20080121135406.59">def _get_indent(marker, s, tab_width=8):
    """_get_indent(marker, s, tab_width=8) -&gt;
        (&lt;indentation-of-'marker'&gt;, &lt;indentation-width&gt;)"""
    # Figure out how much the marker is indented.
    INDENT_CHARS = tuple(' \t')
    start = s.index(marker)
    i = start
    while i &gt; 0:
        if s[i-1] not in INDENT_CHARS:
            break
        i -= 1
    indent = s[i:start]
    indent_width = 0
    for ch in indent:
        if ch == ' ':
            indent_width += 1
        elif ch == '\t':
            indent_width += tab_width - (indent_width % tab_width)
    return indent, indent_width

</t>
<t tx="ekr.20080121135406.60">def _get_trailing_whitespace(marker, s):
    """Return the whitespace content trailing the given 'marker' in string 's',
    up to and including a newline.
    """
    suffix = ''
    start = s.index(marker) + len(marker)
    i = start
    while i &lt; len(s):
        if s[i] in ' \t':
            suffix += s[i]
        elif s[i] in '\r\n':
            suffix += s[i]
            if s[i] == '\r' and i+1 &lt; len(s) and s[i+1] == '\n':
                suffix += s[i+1]
            break
        else:
            break
        i += 1
    return suffix

</t>
<t tx="ekr.20080121135406.61"># ***** LICENSE BLOCK *****

"""Basic luddite commands."""

import os
from os.path import basename, dirname, join, exists, abspath, splitext
import logging
import string
import re

from ludditelib import parser, gen, constants
from ludditelib.common import LudditeError, guid_pat, norm_guid, \
                              generate_guid

_log = logging.getLogger("luddite.commands")


</t>
<t tx="ekr.20080121135406.62">def compile(udl_path, output_dir=None, include_path=None, log=None):
    """Compile the given .udl file to a Komodo lexer resource.
    
    If not given, the output dir will be the same as the input .udl file.
    The output filename is "${safe_lang}.lexres", where "safe_lang" is a
    slightly massaged version of the language name defined in the .udl
    file with the "language" UDL statement.
    
    "include_path" is a list of directories from which support .udl files
    can be included (by default the current dir, the dir of the input .udl
    file is alway part of the include path).
    """
    log = log or _log
    if output_dir is None:
        output_dir = dirname(udl_path) or os.curdir

    # Clean up after PLY. It leaves some turds that can break subsequent
    # parsing if the parser source is changed.
    turds = ["parser.out", "parsetab.py", "parsetab.pyc"]
    for turd in turds:
        if exists(turd):
            log.debug("remove `%s'", turd)
            os.remove(turd)

    # Parse and load the UDL definition.
    log.debug("parse `%s'", udl_path)
    parse_tree = parse(udl_path, include_path=include_path)
    if parse_tree is None:
        raise LudditeError("parse failed");
    mainObj = gen.MainObj()
    analyzer = gen.Analyzer(mainObj)
    analyzer.processTree(parse_tree)
    mainObj.calcUniqueStates()

    #XXX Grr. Crappy error handling again. This should be changed to
    #    raise a LudditeError if the semanticCheck fails then just call:
    #       analyzer.semanticCheck()
    if analyzer.semanticCheck() is None:
        return 1

    # Make sure don't trounce files before generating outputs and setup
    # output dir.
    lang_name = mainObj.languageName
    safe_lang_name = mainObj.safeLangName
    lexres_path = join(output_dir, safe_lang_name+".lexres")
    log.info("compile `%s' to `%s'", udl_path, lexres_path)
    if exists(lexres_path):
        log.debug("rm `%s'", lexres_path)
        os.remove(lexres_path)

    # Generate all outputs.
    if not exists(dirname(lexres_path)):
        os.makedirs(dirname(lexres_path))
    log.debug("create `%s'", lexres_path)
    mainObj.dumpAsTable(constants.vals, lexres_path)



</t>
<t tx="ekr.20080121135406.63">def deprecated_compile(udl_path, skel=False, guid=None, guid_from_lang=None,
                       ext=None, force=False, log=None):
    """Compile the given .udl file to Komodo language resources.
    
    DEPRECATED: The 'skel' generation in luddite has been deprecated in
    favour of the more generic support of the 'koext' tool.
    
    One of "guid" or "guid_from_lang" can be given to specify the XPCOM
    language service GUID. If neither is given then a new one will be
    generated.
    """
    # Dev Notes:
    # - Compiling builds into build/$languange/... and creates:
    #       ${language}.lexres                  lexer resource
    # - If skel is True then also build skeletons for:
    #       ko${language}_UDL_Language.py       language component
    #       ${language}.${ext}                  empty Komodo template
    # - Add support for other options that Eric had in the preceding
    #   luddite.py?
    log = log or _log
    log.debug("compile('%s', ...)", udl_path)

    # Clean up after PLY. It leaves some turds that can break subsequent
    # parsing if the parser source is changed.
    turds = ["parser.out", "parsetab.py", "parsetab.pyc"]
    for turd in turds:
        if exists(turd):
            log.debug("remove `%s'", turd)
            os.remove(turd)

    # Parse and load the UDL definition.
    parse_tree = parse(udl_path)
    if parse_tree is None:
        raise LudditeError("parse failed");
    mainObj = gen.MainObj()
    analyzer = gen.Analyzer(mainObj)
    analyzer.processTree(parse_tree)
    mainObj.calcUniqueStates()

    #XXX Grr. Crappy error handling again. This should be changed to
    #    raise a LudditeError if the semanticCheck fails then just call:
    #       analyzer.semanticCheck()
    if analyzer.semanticCheck() is None:
        return 1

    def raise_force_error(path):
        raise LudditeError("`%s' already exists: use "
                           "-f|--force option to allow it to be "
                           "overwritted" % path)

    # Make sure don't trounce files before generating outputs and setup
    # output dir.
    lang_name = mainObj.languageName
    safe_lang_name = mainObj.safeLangName
    build_dir = _get_build_dir(lang_name)
    if not exists(build_dir):
        log.debug("mkdir `%s'", build_dir)
        os.makedirs(build_dir)

    # Generate all outputs.
    lexres_path = join(build_dir, "lexers", safe_lang_name+".lexres")
    if exists(lexres_path):
        if not force: raise_force_error(lexres_path)
        log.debug("rm `%s'", lexres_path)
        os.remove(lexres_path)
    if not exists(dirname(lexres_path)):
        os.makedirs(dirname(lexres_path))
    log.info("create lexres `%s'", lexres_path)
    mainObj.dumpAsTable(constants.vals, lexres_path)

    if skel:
        lang_service_path \
            = join(build_dir, "components", "ko%s_UDL_Language.py" % safe_lang_name)
        if exists(lang_service_path):
            if not force: raise_force_error(lang_service_path)
            log.debug("rm `%s'", lang_service_path)
            os.remove(lang_service_path)
        if not exists(dirname(lang_service_path)):
            os.makedirs(dirname(lang_service_path))
        log.info("create lang service `%s'", lang_service_path)
        if guid is not None:
            assert guid_pat.match(guid)
            guid = norm_guid(guid)
        elif guid_from_lang:
            try:
                guid = guid_from_lang[mainObj.languageName]
            except KeyError:
                raise LudditeError("could not find `%s' in GUIDs text file"
                                   % mainObj.languageName)
        else:
            log.warn("generating new GUID for `%s' language service: it is "
                     "recommended that you use the -g|--guid option to ensure "
                     "a constant GUID from build to build",
                     mainObj.languageName)
            guid = generate_guid()
        mainObj.dumpLanguageService(lang_service_path, guid, ext=ext)

        if not ext:
            log.warn("no file extension was given: no skeleton "
                     "Komodo templates will be created")
        else:
            template_paths = [
                join(build_dir, "templates", "All Languages",
                     safe_lang_name+ext),
                join(build_dir, "templates", "Common", safe_lang_name+ext),
            ]
            for template_path in template_paths:
                if exists(template_path):
                    if not force: raise_force_error(template_path)
                    log.debug("rm `%s'", template_path)
                    os.remove(template_path)
                if not exists(dirname(template_path)):
                    os.makedirs(dirname(template_path))
                log.info("create template `%s'", template_path)
                mainObj.generateKomodoTemplateFile(template_path)

    # Clean up after PLY. It leaves some turds that can break subsequent
    # parsing if the parser source is changed.
    for turd in turds:
        if exists(turd):
            log.debug("remove `%s'", turd)
            os.remove(turd)


</t>
<t tx="ekr.20080121135406.64">def parse(udl_path, include_path=None, log=None):
    """Parse the given .udl file.
    
    PLY (i.e. yacc.py and lex.py) are messy. They leave 'parser.out' and
    'parsetab.py' turds in the current directory. Attempting to hack around
    this by cd'ing into the build dir to run. However this breaks the parse
    for a reason I don't understand. It would be good to fix that at some
    point.
    
    Notes on the above analysis: The 'parser.out' debug file can be
    suppressed with `yaccdebug = 0` in yacc.py. The 'parsetab.py' file
    is generated by yacc.py::lr_write_tables() and can be suppressed
    with the `yacc(..., write_tables=0)` argument. TODO: Try this and
    see if can remove the above-mentioned hacking around.
    """
    log = log or _log
    log.debug("parse('%s')", udl_path)
    parse_tree = parser.parse_udl_path(udl_path, include_path=include_path)

    # Ick. This modules uses a global for an error count.
    if parser.num_errs:
        raise LudditeError("could not parse '%s': %d error(s)"
                           % (udl_path, parser.num_errs))
    return parse_tree
    

</t>
<t tx="ekr.20080121135406.65">def deprecated_package(language_name, version=None, creator=None,
                       name=None, description=None,
                       id=None, force=False, log=None):
    """Package the (built) resources for the given languages into a Komodo
    extension.
    
    Note: This is DEPRECATED in favour of the more general Komodo extension
    packaging support in the "koext" tool (also in the Komodo SDK).
    
        "language_name" is the language name for which to build a package.
            The resources for this language must already have been built via
            "luddite.py compile ...".

    These arguments are optional, but should be specified:
        "version" (optional, default "1.0.0") is the version number for this
            package.
        "creator" (optional, default "Anonymous Coward") is the name of the
            person creating/maintaining this package.

    These arguments are optional and it is generally fine to not specify them
    because they have reasonable defaults:
        "name" (optional) is the name for the extension.
        "description" (optional) is a short description of the extension.
        "id" (optional) is the extension's id -- an internal short string used
            as a key to identify the extension. It is used in the extension's
            install path.
    
    Dev Notes:
    - For now packaging requires a 'zip' executable somewhere on the
      PATH. This *could* be removed (by using Python's zlib) if too
      burdensome.
    """
    log = log or _log

    build_dir = _get_build_dir(language_name)
    if not exists(build_dir):
        raise LudditeError("`%s': the build dir does not exist: you must first "
                           "build the language resources with "
                           "'luddite compile ...'" % build_dir)

    # Determine package info and create the extension's install.rdf.
    if name is None:
        name = language_name + " Language"
    codename = _codename_from_name(name)
    if id is None:
        id = "%s@ActiveState.com" % codename
    if version is None:
        version = "1.0.0"
        log.warn("defaulting 'version' to '%s' (use version option)",
                 version)
    #else:
    #    XXX validate version
    if description is None:
        description = "%s language support for Komodo (UDL-based)" % language_name
    if creator is None:
        creator = "Anonymous Coward"
        log.warn("defaulting 'creator' to '%s' (use creator option)", creator)

    install_rdf_in = join(dirname(constants.__file__), "install.rdf.in")
    log.debug("reading 'install.rdf' template from '%s'", install_rdf_in)
    install_rdf_template = string.Template(open(install_rdf_in, 'r').read())
    install_rdf = install_rdf_template.substitute(
        id=id, name=name, codename=codename, version=version,
        description=description, creator=creator)
    install_rdf_path = join(build_dir, "install.rdf")
    log.info("create `%s'", install_rdf_path)
    fout = open(install_rdf_path, 'w')
    fout.write(install_rdf)
    fout.close()

    # Create the chrome.manifest file, if necessary. (Empty because we don't
    # install skin, locales or chrome, but should still have it).
    chrome_manifest_path = join(build_dir, "chrome.manifest")
    if not exists(chrome_manifest_path):
        log.info("create `%s'", chrome_manifest_path)
        fout = open(chrome_manifest_path, 'w')
        fout.close()

    # Create the xpi.
    xpi_name = "%s-%s-ko.xpi" % (codename, version)
    xpi_path = xpi_name # put in top-level dir for now
    if exists(xpi_path):
        if not force:
            raise LudditeError("`%s' exists: use force option to overwrite"
                               % xpi_path)
        log.debug("rm `%s'", xpi_path)
        os.remove(xpi_path)
    zip_opts = ""
    if not log.isEnabledFor(logging.DEBUG):
        zip_opts += "-q"
    cmd = 'zip -r %s "%s" *' % (zip_opts, abspath(xpi_path))
    _run_in_dir(cmd, build_dir, log.debug)
    log.info("`%s' successfully created", xpi_path)



</t>
<t tx="ekr.20080121135406.66">#---- internal support

def _get_build_dir(lang):
    return join("build", lang)

</t>
<t tx="ekr.20080121135406.67">def _codename_from_name(name):
    """Transform a Komodo extension name to a "code" name, i.e. one that is
    safe for use in a filename and an extension id.
    """
    return re.sub(r'\W', '_', name.lower())


</t>
<t tx="ekr.20080121135406.68"># Recipe: run (0.5.3) in C:\trentm\tm\recipes\cookbook
_RUN_DEFAULT_LOGSTREAM = ("RUN", "DEFAULT", "LOGSTREAM")
def __run_log(logstream, msg, *args, **kwargs):
    if not logstream:
        pass
    elif logstream is _RUN_DEFAULT_LOGSTREAM:
        try:
            log
        except NameError:
            pass
        else:
            if hasattr(log, "debug"):
                log.debug(msg, *args, **kwargs)
    else:
        logstream(msg, *args, **kwargs)

</t>
<t tx="ekr.20080121135406.69">def _run(cmd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command.

        "cmd" is the command to run
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    __run_log(logstream, "running '%s'", cmd)
    retval = os.system(cmd)
    if hasattr(os, "WEXITSTATUS"):
        status = os.WEXITSTATUS(retval)
    else:
        status = retval
    if status:
        #TODO: add std OSError attributes or pick more approp. exception
        raise OSError("error running '%s': %r" % (cmd, status))

</t>
<t tx="ekr.20080121135406.70">def _run_in_dir(cmd, cwd, logstream=_RUN_DEFAULT_LOGSTREAM):
    """Run the given command in the given working directory.

        "cmd" is the command to run
        "cwd" is the directory in which the commmand is run.
        "logstream" is an optional logging stream on which to log the 
            command. If None, no logging is done. If unspecifed, this 
            looks for a Logger instance named 'log' and logs the command 
            on log.debug().

    Raises OSError is the command returns a non-zero exit status.
    """
    old_dir = os.getcwd()
    try:
        os.chdir(cwd)
        __run_log(logstream, "running '%s' in '%s'", cmd, cwd)
        _run(cmd, logstream=None)
    finally:
        os.chdir(old_dir)</t>
<t tx="ekr.20080121135406.71"># ***** LICENSE BLOCK *****

"""Shared stuff for ludditelib modules."""

__revision__ = "$Id$"
__version_info__ = (1, 1, 0)
__version__ = '.'.join(map(str, __version_info__))

import re
import sys


</t>
<t tx="ekr.20080121135406.72">class LudditeError(Exception):
    pass



</t>
<t tx="ekr.20080121135406.73">def is_source_tree_layout():
    """Return True iff this luddite is being run in the Komodo source
    tree layout.
    """
    from os.path import dirname, join, exists, abspath
    up_one_dir = dirname(dirname(abspath(__file__)))
    return exists(join(up_one_dir, "luddite.py"))
    


</t>
<t tx="ekr.20080121135406.74">#---- some GUID support
# This stuff should be unnecessary when the deprecated "compile" and
# "package" commands are dropped.

def norm_guid(g):
    if not g.startswith("{"):
        g = "{"+g
    if not g.endswith("}"):
        g += "}"
    return g

</t>
<t tx="ekr.20080121135406.75">guid_pat = re.compile(r"^{?[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}"
                        "-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}}?$")

def generate_guid():
    """Return a GUID/UUID in the typical
        {12345678-90ab-cdef-1234-567890abcdef}
    format (*with* the braces).
    """
    try:
        import uuid
    except ImportError:
        from ludditelib import uuid
    guid = str(uuid.uuid4())
    return guid
</t>
<t tx="ekr.20080121135406.76"># ***** LICENSE BLOCK *****

# Generated on  Mon Sep 11 12:45:29 2006
#
# List of constants used by luddite

vals = {   'ASTC_CREATE_NEW_TRAN': 36,
    'ASTC_CURRENT_FAMILY': 18,
    'ASTC_EXTENSION': 44,
    'ASTC_FLIPPER_COUNT': 17,
    'ASTC_F_COLOR': 14,
    'ASTC_F_DEFAULT_STATE': 19,
    'ASTC_F_FLIPPER': 20,
    'ASTC_F_KEYWORD_STYLE': 22,
    'ASTC_F_LOOKBACK_TESTS_COUNT': 25,
    'ASTC_F_LOOKBACK_TESTS_CREATE': 23,
    'ASTC_F_LOOKBACK_TESTS_INIT': 24,
    'ASTC_F_OPERATOR': 16,
    'ASTC_F_STYLE': 15,
    'ASTC_F_WORDLIST': 21,
    'ASTC_LANGUAGE_NAME': 13,
    'ASTC_LBT_ACTION_STYLE': 27,
    'ASTC_LBT_DEFAULT': 30,
    'ASTC_LBT_GET': 26,
    'ASTC_LBT_STRINGS': 28,
    'ASTC_LBT_TEST': 31,
    'ASTC_LBT_WORDLIST': 29,
    'ASTC_META_COMMENTS': 1,
    'ASTC_META_VERSION_MAJOR': 2,
    'ASTC_META_VERSION_MINOR': 3,
    'ASTC_META_VERSION_SUBMINOR': 4,
    'ASTC_NOP': 0,
    'ASTC_SCRATCH_BUFFER_APPEND': 12,
    'ASTC_SCRATCH_BUFFER_START': 11,
    'ASTC_SUBLANGUAGE_NAME': 43,
    'ASTC_TBLOCK_APPEND_TRAN': 40,
    'ASTC_TBLOCK_EMPTY_TRAN': 42,
    'ASTC_TBLOCK_EOF_TRAN': 41,
    'ASTC_TRAN_EOL_STATE': 45,
    'ASTC_TRAN_KEEP_DELIMITER': 47,
    'ASTC_TRAN_POP_STATE': 39,
    'ASTC_TRAN_PUSH_STATE': 38,
    'ASTC_TRAN_SET_DELIMITER': 46,
    'ASTC_TRAN_SET_F': 37,
    'ASTC_TRAN_WRITER_VERSION': 48,
    'ASTC_TTABLE_CREATE_TRANS': 34,
    'ASTC_TTABLE_GET_TBLOCK': 35,
    'ASTC_TTABLE_NUM_UNIQUE_STATES': 32,
    'ASTC_TTABLE_UNIQUE_STATE': 33,
    'LBTEST_ACTION_ACCEPT': 1,
    'LBTEST_ACTION_REJECT': 2,
    'LBTEST_ACTION_SKIP': 0,
    'LBTEST_LIST_ALL': 1,
    'LBTEST_LIST_KEYWORDS': 2,
    'LBTEST_LIST_STRINGS': 3,
    'LBTEST_NUM_ACTIONS': 3,
    'NUM_FAMILIES': 5,
    'NUM_VECTORS': 30,
    'READER_VERSION_MAJOR': 1,
    'READER_VERSION_MINOR': 0,
    'READER_VERSION_SUBMINOR': 0,
    'SCE_UDL_CSL_COMMENT': 23,
    'SCE_UDL_CSL_COMMENTBLOCK': 24,
    'SCE_UDL_CSL_DEFAULT': 22,
    'SCE_UDL_CSL_IDENTIFIER': 28,
    'SCE_UDL_CSL_NUMBER': 25,
    'SCE_UDL_CSL_OPERATOR': 29,
    'SCE_UDL_CSL_REGEX': 30,
    'SCE_UDL_CSL_STRING': 26,
    'SCE_UDL_CSL_WORD': 27,
    'SCE_UDL_CSS_COMMENT': 16,
    'SCE_UDL_CSS_DEFAULT': 15,
    'SCE_UDL_CSS_IDENTIFIER': 20,
    'SCE_UDL_CSS_NUMBER': 17,
    'SCE_UDL_CSS_OPERATOR': 21,
    'SCE_UDL_CSS_STRING': 18,
    'SCE_UDL_CSS_WORD': 19,
    'SCE_UDL_M_ATTRNAME': 4,
    'SCE_UDL_M_CDATA': 13,
    'SCE_UDL_M_COMMENT': 14,
    'SCE_UDL_M_DEFAULT': 0,
    'SCE_UDL_M_EMP_TAGC': 7,
    'SCE_UDL_M_ENTITY': 11,
    'SCE_UDL_M_ETAGC': 10,
    'SCE_UDL_M_ETAGO': 9,
    'SCE_UDL_M_OPERATOR': 5,
    'SCE_UDL_M_PI': 12,
    'SCE_UDL_M_STAGC': 6,
    'SCE_UDL_M_STAGO': 1,
    'SCE_UDL_M_STRING': 8,
    'SCE_UDL_M_TAGNAME': 2,
    'SCE_UDL_M_TAGSPACE': 3,
    'SCE_UDL_SSL_COMMENT': 40,
    'SCE_UDL_SSL_COMMENTBLOCK': 41,
    'SCE_UDL_SSL_DEFAULT': 31,
    'SCE_UDL_SSL_IDENTIFIER': 45,
    'SCE_UDL_SSL_NUMBER': 42,
    'SCE_UDL_SSL_OPERATOR': 46,
    'SCE_UDL_SSL_REGEX': 47,
    'SCE_UDL_SSL_STRING': 43,
    'SCE_UDL_SSL_VARIABLE': 48,
    'SCE_UDL_SSL_WORD': 44,
    'SCE_UDL_TPL_COMMENT': 50,
    'SCE_UDL_TPL_COMMENTBLOCK': 51,
    'SCE_UDL_TPL_DEFAULT': 49,
    'SCE_UDL_TPL_IDENTIFIER': 55,
    'SCE_UDL_TPL_NUMBER': 52,
    'SCE_UDL_TPL_OPERATOR': 56,
    'SCE_UDL_TPL_STRING': 53,
    'SCE_UDL_TPL_VARIABLE': 57,
    'SCE_UDL_TPL_WORD': 54,
    'SCE_UDL_UPPER_BOUND': 57,
    'TRAN_FAMILY_CSL': 2,
    'TRAN_FAMILY_CSS': 1,
    'TRAN_FAMILY_MARKUP': 0,
    'TRAN_FAMILY_SSL': 3,
    'TRAN_FAMILY_TEMPLATE': 4,
    'TRAN_SEARCH_DELIMITER': 5,
    'TRAN_SEARCH_EMPTY': 3,
    'TRAN_SEARCH_EOF': 4,
    'TRAN_SEARCH_REGEX': 2,
    'TRAN_SEARCH_STRING': 1}
</t>
<t tx="ekr.20080121135406.77">#!/usr/bin/env python
# ***** LICENSE BLOCK *****

"""Support for generating representations of lexed text for debugging."""

import os
from os.path import basename, dirname, join, exists, abspath
from glob import glob
import sys
import re
from cStringIO import StringIO
import logging
from pprint import pprint

from ludditelib.common import is_source_tree_layout

</t>
<t tx="ekr.20080121135406.78">def _add_libs():
    """Get a SilverCity build on sys.path.
    Get Komodo's 'styles.py' on sys.path.
    """

    # Must be using the same Python version as Komodo's internal Python
    # because SilverCity is a binary ext.
    assert sys.version_info[:2] == (2, 5), "you must use Python 2.5.x"

    if is_source_tree_layout():
        ko_dev_dir = dirname(dirname(abspath(__file__)))
        while not exists(join(ko_dev_dir, "Construct")):
            d = dirname(ko_dev_dir)
            if d == "ko_dev_dir":
                raise RuntimeError("couldn't find SilverCity lib")
            ko_dev_dir = d
        lib_dirs = [
            glob(join(ko_dev_dir, "build", "release", "silvercity",
                      "build", "lib.*"))[0],
            join(ko_dev_dir, "src", "schemes"),
        ]
    else: # in SDK
        dist_dir = dirname(dirname(dirname(
            dirname(dirname(abspath(__file__))))))
        if exists(join(dist_dir, "bin", "is_dev_tree.txt")): # in a dev build
            # from: $mozObjDir/dist/komodo-bits/sdk/pylib/ludditelib/debug.py
            # to:   $mozObjDir/dist/bin/python/komodo
            lib_dirs = [join(dist_dir, "bin", "python", "komodo")]
        elif sys.platform == "darwin": # in a Komodo install on Mac OS X
            # from: Contents/SharedSupport/sdk/pylib/ludditelib/debug.py
            # to:   Contents/MacOS/python/komodo
            lib_dirs = [join(dist_dir, "MacOS", "python", "komodo")]
        else: # in a Komodo install on Windows or Linux
            # from: lib/sdk/pylib/ludditelib/debug.py
            # to:   lib/mozilla/python/komodo
            lib_dirs = [join(dist_dir, "lib", "mozilla", "python", "komodo")]
    for lib_dir in lib_dirs:
        sys.path.insert(0, lib_dir)

</t>
<t tx="ekr.20080121135406.79">_add_libs()

import SilverCity
from SilverCity import ScintillaConstants
from SilverCity.Lexer import Lexer



#---- globals

log = logging.getLogger("luddite.debug")



#---- public routines

def lex(content, lang):
    """Lex the given content and lang and print a summary to stdout."""
    lexer = UDLLexer(lang)
    accessor = SilverCityAccessor(lexer, content)
    out = sys.stdout.write
    for token in accessor.gen_tokens():
        #pprint(token)
        out("token %(start_line)d,%(start_column)d"
            "-%(end_line)d,%(end_column)d"
            " (chars %(start_index)d-%(end_index)d):" % token)
        style_names = _style_names_from_style_num(token["style"])
        out(" %s (%d)\n" % (', '.join(style_names), token["style"]))
        out(_indent(_escaped_text_from_text(token["text"]), 2) + '\n')


</t>
<t tx="ekr.20080121135406.80">def lex_to_html(content, lang, include_styling=True, include_html=True,
                title=None):
    """Return a styled HTML snippet for the given content and language.
    
        "include_styling" (optional, default True) is a boolean
            indicating if the CSS/JS/informational-HTML should be
            included.
        "include_html" (optional, default True) is a boolean indicating
            if the HTML output should be wrapped into a complete HTML
            document.
        "title" is the HTML document title to use if 'include_html' is
            True.
    """
    if title is None:
        title = "%s content" % lang

    html = StringIO()

    if include_html:
        html.write('''\
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8" /&gt;
&lt;title&gt;%s&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
''' % title)

    if include_styling:
        html.write('''
&lt;script type="application/x-javascript"&gt;
    function show_class(span) {
        var infobox = document.getElementById("infobox");
        infobox.innerHTML = span.getAttribute("class");
    }
&lt;/script&gt;

&lt;style&gt;
#infobox {
    border: 4px solid #e0e0e0;
    background-color: #f0f0f0;
    padding: 10px;
    position: fixed;
    top: 5px;
    right: 5px;
}

/* token highlighting and debugging info */
div.code span:hover {
    background-color: #e0e0e0;
}

div.code span.udl-region:hover {
    background-color: #f0f0f0;
}

/* language-neutral syntax coloring */
div.code {
    font-family: "Courier New", Courier, monospace;
    font-size: small;
}

div.code .comments    { color: grey; }
div.code .keywords    { font-weight: bold; }
div.code .identifiers { color: black; }
div.code .strings     { color: blue; }
div.code .classes,
div.code .functions   { color: green; }
div.code .stderr      { background-color: red; }
div.code .stdout      { background-color: blue; }
div.code .tags        { color: red; }

&lt;/style&gt;

&lt;div id="infobox"&gt;&lt;/div&gt;
''')

    #XXX escape lang name for CSS class
    html.write('&lt;div class="code %s"&gt;\n' % lang.lower())


    lexer = UDLLexer(lang)
    accessor = SilverCityAccessor(lexer, content)
    curr_udl_region = None
    ch = last_ch = None
    for token in accessor.gen_tokens():
        css_classes = _style_names_from_style_num(token["style"])
        if css_classes and css_classes[0].startswith("SCE_UDL_"):
            udl_region = css_classes[0].split('_')[2]
            if udl_region == curr_udl_region:
                pass
            else:
                if curr_udl_region:
                    html.write('\n&lt;/span&gt;\n')
                html.write('\n&lt;span class="udl-region"&gt;\n')
                curr_udl_region = udl_region
        html.write('&lt;span class="%s" onmouseover="show_class(event.target);"&gt;'
                   % ' '.join(css_classes))
        for i, ch in enumerate(token["text"]):
            if ch == "\n" and last_ch == "\r":
                # Treat '\r\n' as one char.
                continue
            #TODO: tab expansion.
            html.write(_htmlescape(ch, quote=True, whitespace=True))
            last_ch = ch
        html.write('&lt;/span&gt;')
    if curr_udl_region:
        html.write('\n&lt;/span&gt;\n')
    html.write('&lt;/div&gt;\n')

    if include_html:
        html.write('''
&lt;/body&gt;
&lt;/html&gt;
''')

    return html.getvalue()



</t>
<t tx="ekr.20080121135406.81">#---- internal Lexer stuff (mostly from codeintel)

# Lazily built cache of SCE_* style number (per language) to constant name.
_style_name_from_style_num_from_lang = {}
_sce_prefixes = ["SCE_UDL_"]

def _style_names_from_style_num(style_num):
    #XXX Would like to have python-foo instead of p_foo or SCE_P_FOO, but
    #    that requires a more comprehensive solution for all langs and
    #    multi-langs.
    style_names = []

    # Get the constant name from ScintillaConstants.
    if "UDL" not in _style_name_from_style_num_from_lang:
        name_from_num = _style_name_from_style_num_from_lang["UDL"] = {}
        for attr in dir(ScintillaConstants):
            for sce_prefix in _sce_prefixes:
                if attr.startswith(sce_prefix):
                    name_from_num[getattr(ScintillaConstants, attr)] = attr
    else:
        name_from_num = _style_name_from_style_num_from_lang["UDL"]
    const_name = _style_name_from_style_num_from_lang["UDL"][style_num]
    style_names.append(const_name)
    
    # Get a style group from styles.py.
    import styles
    if "UDL" in styles.StateMap:
        for style_group, const_names in styles.StateMap["UDL"].items():
            if const_name in const_names:
                style_names.append(style_group)
                break
    else:
        log.warn("lang 'UDL' not in styles.StateMap: won't have "
                 "common style groups in HTML output")
    
    return style_names


</t>
<t tx="ekr.20080121135406.82">_re_bad_filename_char = re.compile(r'([% 	\x80-\xff])')
def _lexudl_path_escape(m):
    return '%%%02X' % ord(m.group(1))
</t>
<t tx="ekr.20080121135406.83">def _urlescape(s):
    return _re_bad_filename_char.sub(_lexudl_path_escape, s)

</t>
<t tx="ekr.20080121135406.84">class UDLLexer(Lexer):
    """LexUDL wants the path to the .lexres file as the first element of
    the first keywords list.
    """
    @others
</t>
<t tx="ekr.20080121135406.85">def __init__(self, lang):
    self.lang = lang
    self._properties = SilverCity.PropertySet()
    self._lexer = SilverCity.find_lexer_module_by_id(ScintillaConstants.SCLEX_UDL)
    lexres_path = _urlescape(self._get_lexres_path(lang))
    #log.debug("escaped lexres_path: %r", lexres_path)
    self._keyword_lists = [
        SilverCity.WordList(lexres_path),
    ]

</t>
<t tx="ekr.20080121135406.86">def _gen_lexres_candidate_paths(self, lang):
    if is_source_tree_layout():
        # Look for a lexres path in a local luddite build.
        udl_dir = dirname(dirname(__file__))
        yield join(udl_dir, "build", lang, "lexers", lang+".lexres")
        # Look in the Komodo-devel build tree.
        ko_dir = dirname(dirname(udl_dir))
        yield join(ko_dir, "build", "release", "udl",
                   "build", lang, "lexers", lang+".lexres")

    # We are an installed Komodo SDK layout or in the Komodo build
    # $MOZ_OBJDIR.
    else:
        import koextlib
        ko_info = koextlib.KomodoInfo()
        for ext_dir in ko_info.ext_dirs:
            yield join(ext_dir, "lexers", lang+".lexres")

</t>
<t tx="ekr.20080121135406.87">def _get_lexres_path(self, lang):
    candidates = []
    for path in self._gen_lexres_candidate_paths(lang):
        candidates.append(path)
        if exists(path):
            log.debug("using `%s' lexres file", path)
            return path
    else:
        raise RuntimeError("could not find a lexres file for %s: "
                           "none of '%s' exist"
                           % (lang, "', '".join(candidates)))



</t>
<t tx="ekr.20080121135406.88">#---- internal Accessor stuff (from codeintel)

class Accessor(object):
    """Virtual base class for a lexed text accessor. This defines an API
    with which lexed text data (the text content, styling info, etc.) is
    accessed by trigger/completion/etc. handling. Actual instances will
    be one of the subclasses.
    """
    @others
</t>
<t tx="ekr.20080121135406.89">def char_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.90">def style_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.91">def line_and_col_at_pos(self, pos):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.92">def gen_char_and_style_back(self, start, stop):
    """Generate (char, style) tuples backward from start to stop
    a la range(start, stop, -1) -- i.e. exclusive at 'stop' index.

    For SciMozAccessor this can be implemented more efficiently than
    the naive usage of char_at_pos()/style_at_pos().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.93">def gen_char_and_style(self, start, stop):
    """Generate (char, style) tuples forward from start to stop
    a la range(start, stop) -- i.e. exclusive at 'stop' index.

    For SciMozAccessor this can be implemented more efficiently than
    the naive usage of char_at_pos()/style_at_pos().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.94">def match_at_pos(self, pos, s):
    """Return True if the given string matches the text at the given
    position.
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.95">def line_from_pos(self, pos):
    """Return the 0-based line number for the given position."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.96">def line_start_pos_from_pos(self, pos):
    """Return the position of the start of the line of the given pos."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.97">def pos_from_line_and_col(self, line, col):
    """Return the position of the given line and column."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.98">@property
def text(self):
    """All buffer content (as a unicode string)."""
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.99">def text_range(self, start, end):
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.100">def length(self):
    """Return the length of the buffer.

    Note that whether this returns a *character* pos or a *byte* pos is
    left fuzzy so that SilverCity and SciMoz implementations can be
    efficient. All that is guaranteed is that the *_at_pos() methods
    work as expected.
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.101">#def gen_pos_and_char_fwd(self, start_pos):
#    """Generate (&lt;pos&gt;, &lt;char&gt;) tuples forward from the starting
#    position until the end of the document.
#    
#    Note that whether &lt;pos&gt; is a *character* pos or a *byte* pos is
#    left fuzzy so that SilverCity and SciMoz implementations can be
#    efficient.
#    """
#    raise VirtualMethodError()
def gen_tokens(self):
    """Generator for all styled tokens in the buffer.
    
    Currently this should yield token dict a la SilverCity's
    tokenize_by_style().
    """
    raise VirtualMethodError()
</t>
<t tx="ekr.20080121135406.102">def contiguous_style_range_from_pos(self, pos):
    """Returns a 2-tuple (start, end) giving the span of the sequence of
    characters with the style at position pos."""
    raise VirtualMethodError()


</t>
<t tx="ekr.20080121135406.103">class SilverCityAccessor(Accessor):
    @others
</t>
<t tx="ekr.20080121135406.104">def __init__(self, lexer, content):
    #XXX i18n: need encoding arg?
    self.lexer = lexer
    self.content = content #XXX i18n: this should be a unicode buffer

</t>
<t tx="ekr.20080121135406.105">def reset_content(self, content):
    """A backdoor specific to this accessor to allow the equivalent of
    updating the buffer/file/content.
    """
    self.content = content
    self.__tokens_cache = None

</t>
<t tx="ekr.20080121135406.106">__tokens_cache = None
@property
def tokens(self):
    if self.__tokens_cache is None:
        self.__tokens_cache = self.lexer.tokenize_by_style(self.content)
    return self.__tokens_cache
    
</t>
<t tx="ekr.20080121135406.107">def char_at_pos(self, pos):
    return self.content[pos]

</t>
<t tx="ekr.20080121135406.108">def _token_at_pos(self, pos):
    #XXX Locality of reference should offer an optimization here.
    # Binary search for appropriate token.
    lower, upper = 0, len(self.tokens)  # [lower-limit, upper-limit)
    sentinel = 15
    while sentinel &gt; 0:
        idx = ((upper - lower) / 2) + lower
        token = self.tokens[idx]
        #print "_token_at_pos %d: token idx=%d text[%d:%d]=%r"\
        #      % (pos, idx, token["start_index"], token["end_index"],
        #         token["text"])
        start, end = token["start_index"], token["end_index"]
        if pos &lt; token["start_index"]:
            upper = idx
        elif pos &gt; token["end_index"]:
            lower = idx + 1
        else:
            return token
        sentinel -= 1
    else:
        raise Error("style_at_pos binary search sentinel hit: there "
                    "is likely a logic problem here!")

</t>
<t tx="ekr.20080121135406.109">def style_at_pos(self, pos):
    return self._token_at_pos(pos)["style"]

</t>
<t tx="ekr.20080121135406.110">def line_and_col_at_pos(self, pos):
    #TODO: Fix this. This is busted for line 0 (at least).
    line = self.line_from_pos(pos) - 1
    # I assume that since we got the line, __start_pos_from_line exists
    col = pos - self.__start_pos_from_line[line]
    return line, col

</t>
<t tx="ekr.20080121135406.111">#PERF: If perf is important for this accessor then could do much
#      better with smarter use of _token_at_pos() for these two.
def gen_char_and_style_back(self, start, stop):
    assert -1 &lt;= stop &lt;= start, "stop: %r, start: %r" % (stop, start)
    for pos in range(start, stop, -1):
        yield (self.char_at_pos(pos), self.style_at_pos(pos))
</t>
<t tx="ekr.20080121135406.112">def gen_char_and_style(self, start, stop):
    assert 0 &lt;= start &lt;= stop, "start: %r, stop: %r" % (start, stop)
    for pos in range(start, stop):
        yield (self.char_at_pos(pos), self.style_at_pos(pos))

</t>
<t tx="ekr.20080121135406.113">def match_at_pos(self, pos, s):
    return self.content[pos:pos+len(s)] == s

</t>
<t tx="ekr.20080121135406.114">__start_pos_from_line = None
def line_from_pos(self, pos):
    r"""
        &gt;&gt;&gt; sa = SilverCityAccessor(lexer,
        ...         #0         1           2         3
        ...         #01234567890 123456789 01234567890 12345
        ...         'import sys\nif True:\nprint "hi"\n# bye')
        &gt;&gt;&gt; sa.line_from_pos(0)
        0
        &gt;&gt;&gt; sa.line_from_pos(9)
        0
        &gt;&gt;&gt; sa.line_from_pos(10)
        0
        &gt;&gt;&gt; sa.line_from_pos(11)
        1
        &gt;&gt;&gt; sa.line_from_pos(22)
        2
        &gt;&gt;&gt; sa.line_from_pos(34)
        3
        &gt;&gt;&gt; sa.line_from_pos(35)
        3
    """
    # Lazily build the line -&gt; start-pos info.
    if self.__start_pos_from_line is None:
        self.__start_pos_from_line = [0]
        for line_str in self.content.splitlines(True):
            self.__start_pos_from_line.append(
                self.__start_pos_from_line[-1] + len(line_str))

    # Binary search for line number.
    lower, upper = 0, len(self.__start_pos_from_line)
    sentinel = 15
    while sentinel &gt; 0:
        line = ((upper - lower) / 2) + lower
        #print "LINE %d: limits=(%d, %d) start-pos=%d"\
        #      % (line, lower, upper, self.__start_pos_from_line[line])
        if pos &lt; self.__start_pos_from_line[line]:
            upper = line
        elif line+1 == upper or self.__start_pos_from_line[line+1] &gt; pos:
            return line
        else:
            lower = line
        sentinel -= 1
    else:
        raise Error("line_from_pos binary search sentinel hit: there "
                    "is likely a logic problem here!")

</t>
<t tx="ekr.20080121135406.115">def line_start_pos_from_pos(self, pos):
    token = self._token_at_pos(pos)
    return token["start_index"] - token["start_column"]
</t>
<t tx="ekr.20080121135406.116">def pos_from_line_and_col(self, line, col):
    if not self.__start_pos_from_line:
        self.line_from_pos(len(self.text)) # force init
    return self.__start_pos_from_line[line] + col

</t>
<t tx="ekr.20080121135406.117">@property
def text(self):
    return self.content
</t>
<t tx="ekr.20080121135406.118">def text_range(self, start, end):
    return self.content[start:end]
</t>
<t tx="ekr.20080121135406.119">def length(self):
    return len(self.content)
</t>
<t tx="ekr.20080121135406.120">def gen_tokens(self):
    for token in self.tokens:
        yield token
</t>
<t tx="ekr.20080121135406.121">def contiguous_style_range_from_pos(self, pos):
    token = self._token_at_pos(pos)
    return (token["start_index"], token["end_index"] + 1)


</t>
<t tx="ekr.20080121135406.122">#---- other internal stuff

# Recipe: htmlescape (1.1)
def _htmlescape(s, quote=False, whitespace=False):
    """Replace special characters '&amp;', '&lt;' and '&gt;' by SGML entities.
    
    Also optionally replace quotes and whitespace with entities and &lt;br/&gt;
    as appropriate.
    """
    s = s.replace("&amp;", "&amp;amp;") # Must be done first!
    s = s.replace("&lt;", "&amp;lt;")
    s = s.replace("&gt;", "&amp;gt;")
    if quote:
        s = s.replace('"', "&amp;quot;")
    if whitespace:
        s = s.replace(' ', "&amp;nbsp;")
        #XXX Adding that '\n' might be controversial.
        s = re.sub(r"(\r\n|\r|\n)", "&lt;br /&gt;\n", s)
    return s


</t>
<t tx="ekr.20080121135406.123"># Recipe: indent (0.2.1)
def _indent(s, width=4, skip_first_line=False):
    """_indent(s, [width=4]) -&gt; 's' indented by 'width' spaces

    The optional "skip_first_line" argument is a boolean (default False)
    indicating if the first line should NOT be indented.
    """
    lines = s.splitlines(1)
    indentstr = ' '*width
    if skip_first_line:
        return indentstr.join(lines)
    else:
        return indentstr + indentstr.join(lines)

</t>
<t tx="ekr.20080121135406.124"># Recipe: text_escape (0.1)
def _escaped_text_from_text(text, escapes="eol"):
    r"""Return escaped version of text.

        "escapes" is either a mapping of chars in the source text to
            replacement text for each such char or one of a set of
            strings identifying a particular escape style:
                eol
                    replace EOL chars with '\r' and '\n', maintain the actual
                    EOLs though too
                whitespace
                    replace EOL chars as above, tabs with '\t' and spaces
                    with periods ('.')
                eol-one-line
                    replace EOL chars with '\r' and '\n'
                whitespace-one-line
                    replace EOL chars as above, tabs with '\t' and spaces
                    with periods ('.')
    """
    #TODO:
    # - Add 'c-string' style.
    # - Add _escaped_html_from_text() with a similar call sig.
    import re
    
    if isinstance(escapes, basestring):
        if escapes == "eol":
            escapes = {'\r\n': "\\r\\n\r\n", '\n': "\\n\n", '\r': "\\r\r"}
        elif escapes == "whitespace":
            escapes = {'\r\n': "\\r\\n\r\n", '\n': "\\n\n", '\r': "\\r\r",
                       '\t': "\\t", ' ': "."}
        elif escapes == "eol-one-line":
            escapes = {'\n': "\\n", '\r': "\\r"}
        elif escapes == "whitespace-one-line":
            escapes = {'\n': "\\n", '\r': "\\r", '\t': "\\t", ' ': '.'}
        else:
            raise ValueError("unknown text escape style: %r" % escapes)

    # Sort longer replacements first to allow, e.g. '\r\n' to beat '\r' and
    # '\n'.
    escapes_keys = escapes.keys()
    escapes_keys.sort(key=lambda a: len(a), reverse=True)
    def repl(match):
        val = escapes[match.group(0)]
        return val
    escaped = re.sub("(%s)" % '|'.join([re.escape(k) for k in escapes_keys]),
                     repl,
                     text)

    return escaped

</t>
<t tx="ekr.20080121135406.125">def _one_line_summary_from_text(text, length=78,
        escapes={'\n':"\\n", '\r':"\\r", '\t':"\\t"}):
    r"""Summarize the given text with one line of the given length.
    
        "text" is the text to summarize
        "length" (default 78) is the max length for the summary
        "escapes" is a mapping of chars in the source text to
            replacement text for each such char. By default '\r', '\n'
            and '\t' are escaped with their '\'-escaped repr.
    """
    if len(text) &gt; length:
        head = text[:length-3]
    else:
        head = text
    escaped = _escaped_text_from_text(head, escapes)
    if len(text) &gt; length:
        summary = escaped[:length-3] + "..."
    else:
        summary = escaped
    return summary
</t>
<t tx="ekr.20080121135406.126"># ***** LICENSE BLOCK *****

"""Luddite output file generation code."""

import copy
import os
from os.path import basename, join, exists
import re
import sys
import datetime
import logging
from pprint import pprint

from ludditelib.common import LudditeError, __version_info__


#---- globals

log = logging.getLogger("luddite")



</t>
<t tx="ekr.20080121135406.127">#---- support stuff


def isTemplateStateName(stateName):
    return stateName.startswith("IN_TPL_")

</t>
<t tx="ekr.20080121135406.128">def die(msg, cond=None):
    if not cond:
        return
    if msg[-1] != "\n":
        msg += "\n"
    sys.stderr.write(msg)
    sys.exit(0)
    # raise(msg)

</t>
<t tx="ekr.20080121135406.129">def warn(fmt, *vals):
    if fmt[-1] == "\n":
        fmt2 = fmt[:-1]
    else:
        fmt2 = fmt
    sys.stderr.write(fmt2 % vals)
    sys.stderr.write("\n")


</t>
<t tx="ekr.20080121135406.130">def qq(s):
    return '"' + s + '"'


</t>
<t tx="ekr.20080121135406.131">def test_assign_entry(lst, idx, val, dft_val=None):
    if idx &gt;= len(lst):
        while idx &gt;= len(lst):
            lst.append(dft_val)
        lst[idx] = val
    elif lst[idx] is None:
        lst[idx] = val


</t>
<t tx="ekr.20080121135406.132">class MainObj:
    @others
</t>
<t tx="ekr.20080121135406.133">def __init__(self):
    self.stateTable = []
    self.stateCount = 0
    self.holdUniqueStates = {}
    self.familyList = {} # Things like lookBackTests, kwds, etc
    self.languageName = None
    self.nameTable = {}  # Hash state names to unique numbers
    self.nameInfo = []    # Keep info on state numbers
    self.verbose = False  #XXX Should go away in favour of log.debug usage
    self.families = {
        'markup' : 0,
        'css' : 1,
        'csl' : 2,
        'ssl' : 3,
        'tpl' : 4,
    }
    self._re_dollar_var = re.compile(r'\$([A-Z]+)')
    self._re_is_word = re.compile(r'^[\w_][\w\d_]+$')

    self._re_dequote_start = None
    self.languageService_xmlNames = {'namespace' : ['namespaces', {}, ],
                                     'public_id' : ['publicIdList', {}, ],
                                     'system_id' : ['systemIdList', {}, ],
                                     }

</t>
<t tx="ekr.20080121135406.134">def _get_safe_lang_name(self):
    """Map [^-_.\w\d]+ in language name to _."""
    return re.sub(r'[^-_.\w\d]+', '_', self.languageName)
</t>
<t tx="ekr.20080121135406.135">safeLangName = property(_get_safe_lang_name, None, None,
                        "an identifier-safe version of languageName")

def calcUniqueStates(self):
    # Here we show which colors can be relied on to map to an
    # internal state.  The current position will be at the first
    # character in the buffer styled that color, so this might not
    # work in all cases.
    self.uniqueStates = {}
    for k in self.holdUniqueStates.keys():
        v = self.holdUniqueStates[k]
        if len(v.keys()) == 1:
            self.uniqueStates[k] = v.keys()[0]
            log.debug("Map style [%s] to state [%s]", k, v.keys()[0])
        log.debug("Style [%s] maps to states [%s]", k,
                  ", ".join(v.keys()))
    self.holdUniqueStates = None

</t>
<t tx="ekr.20080121135406.136">def _split_quote_string(self, s, len):
    return re.sub('(.{%d}[^ ]+) ' % (len,), '\\1"\n    " ', s)

</t>
<t tx="ekr.20080121135406.137">def _all_words(self, str_list):
    for s in str_list:
        if not self._re_is_word.match(s):
            return False
    return True

</t>
<t tx="ekr.20080121135406.138">def _has_ptn_var(self, s):
    mobj = self._re_dollar_var.search(s)
    if mobj is None: return None
    return mobj.group(1)

</t>
<t tx="ekr.20080121135406.139">def _state_num_from_name(self, nameTable, target_state_name, cmd):
    target_state_num = nameTable.get(target_state_name, None)
    if target_state_num is None:
        die("%s: State %s isn't defined" % (cmd, target_state_name,), True)
    return target_state_num
    
</t>
<t tx="ekr.20080121135406.140">def dumpAsTable(self, resConstants, out_file):
    self.resConstants = resConstants
    resDefinesPath = (resConstants and True)
    fout = open(out_file, 'w')
    WRITER_VERSION_MAJOR = 1
    WRITER_VERSION_MINOR = 0
    WRITER_VERSION_SUBMINOR = 0

    if not resDefinesPath:
        # Print some common declarations
        fout.write("""
                   
#define WRITER_VERSION_MAJOR	%d
#define WRITER_VERSION_MINOR	%d
#define WRITER_VERSION_SUBMINOR	%d

// We're executing inside MainInfo::Init()
TransitionTable *p_TransitionTable;
TransitionInfo *p_TranBlock;
Transition *p_Tran;
FamilyInfo *p_FamilyInfo;\n""" % (WRITER_VERSION_MAJOR, WRITER_VERSION_MINOR,
                              WRITER_VERSION_SUBMINOR))
        if filter(lambda(x): hasattr(x, 'tokenCheckBlock'), self.familyList.values()):
            fout.write("LookBackTests *p_LBTests;\n")
            fout.write("LookBackTestObj *p_LBTestObj;\n")

        fout.write("p_TransitionTable = GetTable();\n") # p_MainInfo-&gt;
        fout.write("if (!p_TransitionTable) return false;\n")
        if self.languageName:
            fout.write('p_language_name = "%s";\n'
                       % self.escapeStr(self.languageName))
        
    else:
        # Write out version info for the reader
        fout.write("1:lexer resource\n")
        for name, ver in zip(["MAJOR", "MINOR", "SUBMINOR"],
                             __version_info__):
            fout.write("%d:%d\n"
                       % (resConstants["ASTC_META_VERSION_"+name], ver))
        fout.write("%d:%d:%d:%d\n" %
                   (resConstants["ASTC_TRAN_WRITER_VERSION"],
                    WRITER_VERSION_MAJOR, WRITER_VERSION_MINOR,
                              WRITER_VERSION_SUBMINOR))
        if self.languageName:
            self.emitScratchBuffer(fout, self.languageName)
            fout.write("%s\n" % resConstants['ASTC_LANGUAGE_NAME'])
    # otherwise this is done by the loader.

    nameTable = self.nameTable
    # Dump all the transitions

    # Initialize some hard-wired data
    if 1:
        family_name_pairs = [
            ('MARKUP', 'M'),
            ('CSS', 'CSS'),
            ('CSL', 'CSL'),
            ('SSL', 'SSL'),
            ('TEMPLATE', 'TPL')]
        for pair in family_name_pairs:
            (long_name, short_name) = pair
            deft_name = "IN_" + short_name + "_DEFAULT";
            if self.verbose and not (resDefinesPath or nameTable.has_key(deft_name)):
                warn("Can't figure out a value for state %s, using 0\n",
                     deft_name)
            
            f_idx = "TRAN_FAMILY_" + long_name
            if not resDefinesPath:
                fout.write("familyColors[%s] = %s;\n"
                           % (f_idx, self.fullStyleName(short_name + "_DEFAULT")))
                fout.write("familyOperators[%s] = %s;\n"
                           % (f_idx, self.fullStyleName(short_name + "_OPERATOR")))
                fout.write("familyStyles[%s] = %s; // %s\n"
                           % (f_idx, nameTable.get(deft_name, 0), deft_name))
            else:
                fout.write("%d:%d:%d\n"
                           % (resConstants['ASTC_F_COLOR'],
                              resConstants[f_idx],
                              resConstants[self.fullStyleName(short_name + "_DEFAULT")]))
                fout.write("%d:%d:%d\n"
                           % (resConstants['ASTC_F_OPERATOR'],
                              resConstants[f_idx],
                              resConstants[self.fullStyleName(short_name + "_OPERATOR")]))
                fout.write("%d:%d:%d\n"
                           % (resConstants['ASTC_F_STYLE'],
                              resConstants[f_idx],
                              nameTable.get(deft_name, 0)))

    family_names = map(lambda x: x.lower(), self.familyList.keys())
    family_names.sort(lambda a, b: self.families[a] - self.families[b])
    globalFlipCount = 0
    for family_name in family_names:
        globalFlipCount += len(self.familyList[family_name].flippers)

    if globalFlipCount &gt; 0:
        if not resDefinesPath:
            fout.write("SetFlipperCount(%d);" % globalFlipCount)
        else:
            fout.write("%d:%d\n"
                       % (resConstants['ASTC_FLIPPER_COUNT'],
                          globalFlipCount))
    flipIdx = 0

    for family_name in family_names:
        family_num = self.families[family_name]
        if not resDefinesPath:
            fout.write("SetCurrFamily(%d);" % family_num) # p_MainInfo-&gt;
            fout.write("p_FamilyInfo = GetCurrFamily();\n") # p_MainInfo-&gt;
        else:
            fout.write("%d:%d\n"
                       % (resConstants['ASTC_CURRENT_FAMILY'],
                          family_num))
            
        obj = self.familyList[family_name]
        if 1:
            st_name = obj.initialState
            st_val = None
            if st_name:
                st_val = nameTable[st_name]
            else:
                st_val = 0
                st_name = '??'
            
            if not resDefinesPath:
                #XXX Eric, my change from printf() to fout.write()
                #    has *added* a newline at the end of this line.
                #    I.e. before my change the next line
                #    (SetSublanguageName()) was in the "// ..." comment.
                #    Which is correct?
                fout.write("p_FamilyInfo-&gt;Init(%d); // %s\n"
                           % (st_val, st_name))
                if obj.subLanguageName:
                    fout.write("p_FamilyInfo-&gt;SetSublanguageName(\"%s\");"
                               % obj.subLanguageName)
            else:
                fout.write("%d:%d\n"
                           % (resConstants['ASTC_F_DEFAULT_STATE'],
                              st_val))
                if obj.subLanguageName:
                    self.emitScratchBuffer(fout, obj.subLanguageName)
                    fout.write("%s\n" % resConstants['ASTC_SUBLANGUAGE_NAME'])
        if not resDefinesPath:
            fout.write('\n')

        #XXX Don't worry about the constant name, as we'll be generating
        # a compiled table soon.
        keywordList = getattr(obj, 'keywordList', None)
        if keywordList:
            sorted_keywordList = copy.copy(keywordList)
            sorted_keywordList.sort()
            kstring = " ".join(sorted_keywordList)
            if not resDefinesPath:
                kstring2 = self._split_quote_string(kstring, 68)
                fout.write("p_FamilyInfo-&gt;SetWordList(\"%s\");\n"
                           % kstring2)
                fout.write("p_FamilyInfo-&gt;SetKeywordStyle(%s, %s);\n\n"
                           % (self.fullStyleName(obj.keywordStyle[0]),
                              self.fullStyleName(obj.keywordStyle[1])))
            else:
                self.emitScratchBuffer(fout, kstring)
                fout.write("%d\n" % resConstants['ASTC_F_WORDLIST'])
                fout.write("%d:%d:%d\n"
                           % (resConstants['ASTC_F_KEYWORD_STYLE'],
                              resConstants[self.fullStyleName(obj.keywordStyle[0])],
                              resConstants[self.fullStyleName(obj.keywordStyle[1])]))

        # Now populate the LookBackTables
        tcBlock = getattr(obj, 'tokenCheckBlock', None)
        if tcBlock:
            if not resDefinesPath:
                fout.write("p_LBTests = p_FamilyInfo-&gt;CreateNewLookBackTests();\n")
                fout.write("if (!p_LBTests) return false;\n")
            else:
                fout.write("%d\n" % resConstants['ASTC_F_LOOKBACK_TESTS_CREATE'])

            startStyleName = self.fullStyleName(obj.start_style)
            endStyleName = self.fullStyleName(obj.end_style)
            if not resDefinesPath:
                fout.write("p_LBTests-&gt;Init(%s, %s - %s + 1);"
                           % (startStyleName, endStyleName,
                              startStyleName))
            else:
                fout.write("%d:%d:%d\n"
                           % (resConstants['ASTC_F_LOOKBACK_TESTS_INIT'],
                              resConstants[startStyleName],
                              resConstants[endStyleName] - resConstants[startStyleName]))

            num_tests = len(tcBlock)
            if num_tests &gt; 0:
                if not resDefinesPath:
                    fout.write("p_LBTests-&gt;SetTestCount(%d);" % num_tests)
                else:
                    fout.write("%d:%d\n"
                               % (resConstants['ASTC_F_LOOKBACK_TESTS_COUNT'],
                                  num_tests))
                
                for i in xrange(0, num_tests):
                    tc = tcBlock[i]
                    sel = tc['selectors']
                    name = tc['name']
                    action = tc['type']
                    if not resDefinesPath:
                        fout.write("p_LBTestObj = p_LBTests-&gt;GetTest(%d);" % i)
                        fout.write("if (p_LBTestObj) {\n")
                    else:
                        fout.write("%d:%d\n"
                                   % (resConstants['ASTC_LBT_GET'], i))


                    if 1:
                        #Fake Python "block" to reflect the generated code.
                        if not resDefinesPath:
                            fout.write("p_LBTestObj-&gt;SetActionStyle(LBTEST_ACTION_%s, %s);"
                                       % (action.upper(), self.fullStyleName(name)))
                        else:
                            fout.write("%d:%d:%d\n"
                                       % (resConstants['ASTC_LBT_ACTION_STYLE'],
                                          resConstants["LBTEST_ACTION_" + action.upper()],
                                          resConstants[self.fullStyleName(name)]))

                        if sel == 'all':
                            # We're done
                            pass
                        else:
                            die("Expecting an array, got &lt;sel&gt;",
                                isinstance(sel, dict))
                            if sel:
                                sel.sort()
                                kstring = self.escapeStr(" ".join(sel))
                                set_word_list = self._all_words(sel)
                                if not resDefinesPath:
                                    kstring2 = self._split_quote_string(kstring, 68)
                                    cmd = (set_word_list and 'SetWordList') or 'SetStrings'
                                    fout.write("p_LBTestObj-&gt;%s(\"%s\");"
                                               % (cmd, kstring2))
                                else:
                                    self.emitScratchBuffer(fout, kstring)
                                    cmd = (set_word_list and 'ASTC_LBT_WORDLIST') or 'ASTC_LBT_STRINGS'
                                    fout.write("%s\n" % resConstants[cmd])
                                    
                        if not resDefinesPath:
                            fout.write("p_LBTests-&gt;SetTest(%d, p_LBTestObj);" % i)
                        else:
                            fout.write("%d:%d\n"
                                       % (resConstants['ASTC_LBT_TEST'], i))
                    if not resDefinesPath:
                        fout.write("}\n")

            # Issue the defaults
            tokenValues = {}
            vals = {'reject': 1, 'accept': 2, 'skip': 4}
            defaultActions = ["LBTEST_ACTION_REJECT", # None given, reject all
                              "LBTEST_ACTION_ACCEPT", # Only rej, acc others
                              "LBTEST_ACTION_REJECT", # Only acc, rej others
                              "LBTEST_ACTION_SKIP",	# Acc|rej, skip others
                              "LBTEST_ACTION_REJECT", # Only skip, rej others
                              "LBTEST_ACTION_ACCEPT", # Rej|skip, acc others
                              "LBTEST_ACTION_REJECT", # Acc|skip, rej others
                              "LBTEST_ACTION_REJECT", # Spec all, rej others
                             ]
            for tc in tcBlock:
                sel = tc['selectors']
                if isinstance(sel, (list, tuple)):
                    name = tc['name']
                    tokenValues[name] = tokenValues.get('name',
                                                        vals[tc['type']])
            style_names = tokenValues.keys()
            style_names.sort()
            for style_name in style_names:
                if not resDefinesPath:
                    fout.write("p_LBTests-&gt;SetDefault(%s, %s);"
                               % (self.fullStyleName(style_name),
                                  defaultActions[tokenValues[style_name]]))
                else:
                    fout.write("%d:%d:%d\n"
                               % (resConstants['ASTC_LBT_DEFAULT'],
                                  resConstants[self.fullStyleName(style_name)],
                                  resConstants[defaultActions[tokenValues[style_name]]]))

        flipCount = len(obj.flippers)
        if flipCount &gt; 0:
            for i in xrange(flipCount):
                node = obj.flippers[i]
                if not resDefinesPath:
                    fout.write("SetFlipper(%d, \"%s\", %s, %d);"
                               % (flipIdx, self.escapeStr(node['name']),
                                  self.fullStyleName(node['style']),
                                  node['value']))
                else:
                    self.emitScratchBuffer(fout, self.escapeStr(node['name']))
                    fout.write("%d:%d:%d:%d\n"
                               % (resConstants['ASTC_F_FLIPPER'],
                                  flipIdx,
                                  resConstants[self.fullStyleName(node['style'])],
                                  node['value']))
                flipIdx += 1

    # Transition table info and unique states are global

    stateTable = self.stateTable
    stateSize = (stateTable and len(stateTable)) or 0

    us_hash = self.uniqueStates
    if us_hash:
        keys = us_hash.keys()
        i = 0
        if not resDefinesPath:
            fout.write("p_TransitionTable-&gt;SetNumUniqueStates(%d);" % len(keys))
        else:
            fout.write("%d:%d\n"
                       % (resConstants['ASTC_TTABLE_NUM_UNIQUE_STATES'],
                          len(keys)))
        if keys: keys.sort()
        for k in keys:
            k2 = self.fullStyleName(k)
            int_state_name = us_hash[k]
            if not resDefinesPath:
                fout.write("p_TransitionTable-&gt;SetUniqueState(%d, %s, %d); // %s\n"
                           % (i, k2, nameTable[int_state_name],
                              int_state_name))
            else:
                fout.write("%d:%d:%d:%d\n"
                           % (resConstants['ASTC_TTABLE_UNIQUE_STATE'],
                              i, resConstants[k2],
                              nameTable[int_state_name]))
            i += 1
            
    if not resDefinesPath:
        fout.write("\n\n")
        
    if not (stateTable is None):
        size = len(stateTable)
        if not resDefinesPath:
            fout.write("p_TransitionTable-&gt;CreateNewTransitions(%d);"
                       % size)
        else:
            fout.write("%d:%d\n"
                       % (resConstants['ASTC_TTABLE_CREATE_TRANS'],
                          size))
            
    for i in xrange(stateSize):
        stateTrans = stateTable[i]
        if not (stateTrans is None):
            # i is the state number
            old_family_name = self.getFamilyOwner(i)

            if not resDefinesPath:
                fout.write("p_TranBlock = p_TransitionTable-&gt;Get(%d);" % i)
                fout.write("if (!p_TranBlock) return false;\n")
            else:
                fout.write("%d:%d\n"
                           % (resConstants['ASTC_TTABLE_GET_TBLOCK'], i))

            for stateTran in stateTrans:
                trans_value = stateTran['value']
                state_type = None
                final_trans_value = None
                ignore_case = 0; # Set to 1 for patterns
                
                if stateTran['type'] == 'string':
                    if len(trans_value) == 0:
                        state_type = 'TRAN_SEARCH_EMPTY'
                    else:
                        state_type = 'TRAN_SEARCH_STRING'
                        final_trans_value = '"' + self.escapeStr(trans_value) + '"'
                elif stateTran['type'] == 'pattern':
                    if len(trans_value[0]) == 0:
                        state_type = 'TRAN_SEARCH_EMPTY'
                        final_trans_value = 'NULL'
                    elif trans_value[0] == '\\z':
                        state_type = 'TRAN_SEARCH_EOF'
                        final_trans_value = 'NULL'
                    else:
                        state_type = 'TRAN_SEARCH_REGEX'
                        final_trans_value = trans_value[0]
                        ignore_case = trans_value[1]
                        
                        obj = self.familyList[old_family_name]
                        die ("Can't get a family obj for state %d" % ((stateTran.get('trans_num', i)),),
                             obj is None)
                        # Do variable substitution
                        lim = 1000
                        i = 0
                        processed_part = ''
                        while len(final_trans_value) &gt; 0:
                            d1 = final_trans_value.find('$')
                            if d1 == -1:
                                processed_part += final_trans_value
                                break
                            d2 = final_trans_value.find('\\')
                            if 0 &lt;= d2 and d2 &lt; d1:
                                # Pass everything up to and including \. on
                                # Could be \$, so don't process $ this time
                                d2 += 2
                                processed_part += final_trans_value[:d2]
                                final_trans_value = final_trans_value[d2:]
                                continue
                            ptn1 = self._has_ptn_var(final_trans_value)
                            if not ptn1:
                                # Keep $ not followed by a letter
                                d1 += 1
                                processed_part += final_trans_value[:d1]
                                final_trans_value = final_trans_value[d1:]
                                continue
                            if not obj.patterns.has_key(ptn1):
                                die("Undefined pattern " + ptn1 + " in str " + trans_value[0] + ", family " + family_name, True)
                            final_trans_value = final_trans_value.replace("$" + ptn1, obj.patterns[ptn1])
                            i += 1
                            if i &gt; lim:
                                warn("Warning: Possible infinite loop trying to resolve %s -- giving up after %d cycles at final_trans_value"
                                     % (trans_value[0], lim))
                                processed_part += final_trans_value
                                break
                            
                        final_trans_value = processed_part.replace('\\', '\\\\')
                        if self.verbose and trans_value[0] != final_trans_value:
                            warn("Mapped %s to %s" % (trans_value[0], final_trans_value))
                        final_trans_value = qq(final_trans_value)
                elif stateTran['type'] == 'delimiter':
                    state_type = 'TRAN_SEARCH_DELIMITER'
                    final_trans_value = '*current delimiter*'
                else:
                    die("cmd [%d] -- weird cmd of %s" % (i, trans_value), False)
                # final_trans_value =~ s/([\\\"])/\\$1/g;  # Escape problem chars
                redo = 'false'
                no_keyword = 'false'
                colors = {'upto' : '-1', 'include' : '-1'}
                cmds = stateTran.get('cmds', [])
                pushPopStateDirective = None
                eolDirective = setDelimiterDirective = None
                setOppositeDelimiterDirective = None
                keepDelimiterDirective = None
                for cmd in cmds:
                    if cmd[0] == 'paint':
                        cmd_val = cmd[1]
                        die("Unexpected type of " + cmd_val['type'],
                            colors[cmd_val['type']] is None)
                        colors[cmd_val['type']] = self.fullStyleName(cmd_val['value'])
                    elif cmd[0] == 'redo':
                        redo = 'true'
                    elif cmd[0] == 'no_keyword':
                        no_keyword = 'true'
                    elif cmd[0] == 'spush_check':
                        target_state_name = cmd[1]
                        die("No state name to push", target_state_name is None)
                        if pushPopStateDirective:
                            die("Can't push and pop at state " +
                                self.nameInfo[i]['name'] +
                                " matching " + final_trans_value,
                                True)
                        target_state_num = self._state_num_from_name(nameTable, target_state_name, cmd[0])
                        new_family_name = self.getFamilyOwner(target_state_num)
                        if not resDefinesPath:
                            pushPopStateDirective = ("p_Tran-&gt;SetPushState(%d, %s);" % (target_state_num, self.families[new_family_name]))
                        else:
                            pushPopStateDirective = \
                                ("%d:%d:%d" % (
                                        resConstants['ASTC_TRAN_PUSH_STATE'],
                                        target_state_num,
                                        self.families[new_family_name]))
                    elif cmd[0] == 'spop_check':
                        if pushPopStateDirective:
                            die("Can't both push and pop at state " +
                                self.nameInfo[i]['name'] +
                                " matching " +
                                final_trans_value, pushPopStateDirective)
                        if not resDefinesPath:
                            pushPopStateDirective = "p_Tran-&gt;SetPopState();"
                        else:
                            pushPopStateDirective = str(resConstants['ASTC_TRAN_POP_STATE'])
                    elif cmd[0] == 'at_eol':
                        target_state_name = cmd[1]
                        die("No state name at eof", target_state_name is None)
                        target_state_num = self._state_num_from_name(nameTable, target_state_name, cmd[0])
                        new_family_name = self.getFamilyOwner(target_state_num)
                        if not resDefinesPath:
                            eolDirective = ("p_Tran-&gt;SetEolTransition(%d, %s);" % (target_state_num, self.families[new_family_name]))
                        else:
                            eolDirective = \
                                ("%d:%d:%d" % (
                                        resConstants['ASTC_TRAN_EOL_STATE'],
                                        target_state_num,
                                        self.families[new_family_name]))
                    elif cmd[0] == 'keep_delimiter':
                        if state_type != 'TRAN_SEARCH_DELIMITER':
                            raise LudditeError("The %s action can only be specified when matching against a delimiter" %
                                               (cmd[0],));                            
                        if not resDefinesPath:
                            keepDelimiterDirective = ("p_Tran-&gt;KeepDelimiter();")
                        else:
                            keepDelimiterDirective = str(resConstants['ASTC_TRAN_KEEP_DELIMITER'])
                    elif cmd[0] == 'set_delimiter':
                        if state_type != 'TRAN_SEARCH_REGEX':
                            raise LudditeError("The %s action can only be specified when matching patterns" %
                                               (cmd[0],));
                        if not resDefinesPath:
                            setOppositeDelimiterDirective = ("p_Tran-&gt;SetDelimiter(false, %s);" % (cmd[1]))
                        else:
                            setOppositeDelimiterDirective = \
                                ("%d:0:%s" % (
                                        resConstants['ASTC_TRAN_SET_DELIMITER'],
                                        cmd[1]))
                    elif cmd[0] == 'set_opposite_delimiter':
                        if state_type != 'TRAN_SEARCH_REGEX':
                            raise LudditeError("The %s action can only be specified when matching patterns, %s-%s given" %
                                               (cmd[0], stateTran['type'], trans_value or ""));
                        if not resDefinesPath:
                            setDelimiterDirective = ("p_Tran-&gt;SetDelimiter(true, %s);" % (cmd[1]))
                        else:
                            setDelimiterDirective = \
                                ("%d:1:%s" % (
                                        resConstants['ASTC_TRAN_SET_DELIMITER'],
                                        cmd[1]))
                    elif cmd[0] == 'clear_delimiter':
                        if not resDefinesPath:
                            setDelimiterDirective = ("p_Tran-&gt;ClearDelimiter();")
                        else:
                            setDelimiterDirective = \
                                ("%d" % (
                                        resConstants['ASTC_TRAN_CLEAR_DELIMITER'],))
                    else:
                        die("Unexpected cmd type of " + cmd[0], True)
                if redo == 'true' and colors['include'] != '-1':
                    raise LudditeError("Error in state %s, transition %s: the include paint action and the redo action can't be given for the same transition" % (st_name, final_trans_value))
                final_state = final_state_comment = None
                new_family_name = None
                final_state = stateTran.get('trans_num', None)
                if not (final_state is None):
                    new_family_name = self.getFamilyOwner(final_state)
                    final_state_comment = (" // =&gt; %s " %
                                           (stateTran.get('trans_str', '??'),))
                else:
                    final_state = -1
                    final_state_comment = ''
                    new_family_name = old_family_name
                token_check = (stateTran.get('token_check', 0)) or 0
                cmd = None
                if not resDefinesPath:
                    cmd = ((state_type == 'TRAN_SEARCH_EOF') and 'SetEOFInfo'
                            or (((state_type == 'TRAN_SEARCH_EMPTY') and 'SetEmptyInfo')
                                or 'Append'))
                else:
                    cmd = ((state_type == 'TRAN_SEARCH_EOF') and 'ASTC_TBLOCK_EOF_TRAN'
                            or (((state_type == 'TRAN_SEARCH_EMPTY') and 'ASTC_TBLOCK_EMPTY_TRAN')
                                or 'ASTC_TBLOCK_APPEND_TRAN'))
                            
                if not resDefinesPath:
                    fout.write("p_Tran = new Transition(%s, %s, %s, %s, %s, %d, %d, %s, %d);%s\n"
                               % (state_type, final_trans_value,
                                  colors['upto'], colors['include'],
                                  redo, final_state, token_check,
                                  ignore_case, no_keyword, final_state_comment))
                else:
                    self.emitScratchBuffer(fout, final_trans_value)
                    fout.write("%d:%d:%d:%d:%d:%d:%d:%d:%d\n"
                               % (resConstants['ASTC_CREATE_NEW_TRAN'],
                                  resConstants[state_type],
                                  colors['upto'] == "-1" and -1 or resConstants[colors['upto']],
                                  colors['include'] == "-1" and -1 or resConstants[colors['include']],
                                  redo == 'true' and 1 or 0,
                                  final_state,
                                  token_check and 1 or 0,
                                  ignore_case,
                                  no_keyword == 'true' and 1 or 0
                                  ))
                for directive in [pushPopStateDirective, eolDirective,
                                  setDelimiterDirective,
                                  setOppositeDelimiterDirective,
                                  keepDelimiterDirective]:
                    if directive:
                        fout.write(directive + "\n")
                if not resDefinesPath:
                    fout.write("p_TranBlock-&gt;" + cmd + "(p_Tran);" + "\n")
                else:
                    fout.write("%d\n" % resConstants[cmd])

                if old_family_name != new_family_name:
                    if not resDefinesPath:
                        fout.write("p_Tran-&gt;SetNewFamily(%d); // %s\n"
                                   % (self.families[new_family_name],
                                      new_family_name))
                    else:
                        fout.write("%d:%d\n"
                                   % (resConstants['ASTC_TRAN_SET_F'],
                                      self.families[new_family_name]))
    fout.close()

</t>
<t tx="ekr.20080121135406.141">def dumpLanguageService(self, path, guid, ext=None):
    if not self.languageName:
        raise LudditeError("'language' was not specified in .udl file")

    lang_from_udl_family = {}
    for udl_family, curr_info in self.familyList.items():
        norm_udl_family = {"csl": "CSL", "css": "CSS",
                           "markup": "M", "ssl": "SSL",
                           "tpl": "TPL"}[udl_family]
        lang_from_udl_family[norm_udl_family] = curr_info.subLanguageName
    data = {
        'langName': self.languageName,
        'safeLangName': self.safeLangName,
        'guid': guid,
        'date': datetime.datetime.now().ctime(),
        'defaultExtDecl': (ext and 'defaultExtension = %r' % ext or None),
        'lang_from_udl_family': lang_from_udl_family,
        'baseImport': "koUDLLanguageBase",
        'baseClass': "KoUDLLanguage",
    }
    if 'M' in lang_from_udl_family:
        if lang_from_udl_family["M"] == "XML":
            data['baseImport'] = "koXMLLanguageBase"
            data['baseClass'] = "koXMLLanguageBase"
        elif lang_from_udl_family["M"] == "HTML":
            data['baseImport'] = "koXMLLanguageBase"
            data['baseClass'] = "koHTMLLanguageBase"
        
    fout = open(path, "w")
    try:
        template = """# Komodo %(langName)s language service.
#
# Generated by 'luddite.py' on %(date)s.
#

import logging
from %(baseImport)s import %(baseClass)s


log = logging.getLogger("ko%(safeLangName)sLanguage")
#log.setLevel(logging.DEBUG)


def registerLanguage(registry):
log.debug("Registering language %(langName)s")
registry.registerLanguage(Ko%(safeLangName)sLanguage())


class Ko%(safeLangName)sLanguage(%(baseClass)s):
name = "%(langName)s"
lexresLangName = "%(safeLangName)s"
_reg_desc_ = "%%s Language" %% name
_reg_contractid_ = "@activestate.com/koLanguage?language=%%s;1" %% name
_reg_clsid_ = "%(guid)s"
%(defaultExtDecl)s

lang_from_udl_family = %(lang_from_udl_family)r

"""
        fout.write(template % data)
        for groupMap in self.languageService_xmlNames.values():
            langSvcName = groupMap[0]
            groupVals = groupMap[1]
            names = groupVals.keys()
            if len(names) &gt; 0:
                #XXX escaping needed on the values?
                fout.write('    %s = ["%s"]\n' % (langSvcName, '", "'.join(names)))
        if hasattr(self, 'sample'):
            fout.write('\n\n    sample = r"""%s"""\n' % self.sample)
    finally:
        fout.close()

</t>
<t tx="ekr.20080121135406.142">def emitScratchBuffer(self, fout, s):
    if self._re_dequote_start is None:
        self._re_dequote_start = re.compile('^[\'\"]')
        self._re_dequote_end = re.compile('[\'\"]$')

        self.re_bspair = re.compile(r'(\\)\\(.*)$')
        self.re_escaped_quote = re.compile(r'\\([\'\"])(.*)$')
        self.re_escaped_other = re.compile(r'(\\.)(.*)$')
        self.re_non_escape = re.compile(r'([^\\]+)(.*)$')
        self.re_esb_set = [self.re_bspair,
                           self.re_escaped_quote,
                           self.re_escaped_other,
                           self.re_non_escape,]
        self.re_75 = re.compile('(.{1,75})(.*)$', re.DOTALL)
        
    s1 = re.sub(self._re_dequote_end, '',
                re.sub(self._re_dequote_start, '', s))

    # todo: unescape \' and \"
    # leave \r and \n alone
    # map all pairs \\ to \
    pieces = []
    while len(s1) &gt; 0:
        did_match = False
        for this_re in self.re_esb_set:
            mobj = this_re.match(s1)
            if mobj:
                pieces.append(mobj.group(1))
                s1 = mobj.group(2)
                did_match = True
                break
        if not did_match:
            die("emitScratchBuffer: Can't match '" + s1 + "'", True)
    s2 = "".join(pieces)
    
    # $kstring =~ s/(?&lt;=[^\\](?:\\\\)*)\\([\'\"])/$1/g;
    # $kstring =~ s/\\\\/\\/g;  # We don't need to escape quotes and backslashes
    fout.write("%d:%d\n"
               % (self.resConstants['ASTC_SCRATCH_BUFFER_START'],
                  len(s2)))
    
    while len(s2) &gt; 0:
        mobj = self.re_75.match(s2)
        die("Can't match anything on " + s2, mobj is None)
        fout.write("%d:%s\n"
                   % (self.resConstants['ASTC_SCRATCH_BUFFER_APPEND'],
                      mobj.group(1)))
        s2 = mobj.group(2)

</t>
<t tx="ekr.20080121135406.143">def escapeStr(self, s):
    return s.replace('\'', '\\\'').replace('"', '\\"').replace('\t', '\\t')

</t>
<t tx="ekr.20080121135406.144">def fullStyleName(self, k):
    if not k.startswith("SCE_UDL_"):
        k2 = 'SCE_UDL_' + k
    else:
        k2 = k
    if self.resConstants and not self.resConstants.has_key(k2):
        die("Style " + k2 + " is unknown. ", True)
    return k2

</t>
<t tx="ekr.20080121135406.145">def generateKomodoTemplateFile(self, template_path):
    f = open(template_path, "w")
    # Just an empty template for now.
    f.close()

</t>
<t tx="ekr.20080121135406.146">def getFamilyOwner(self, stateNum):
    die ("No owning family for state #" + str(stateNum),
         not self.nameInfo[stateNum].has_key('owningFamily'))
    familyName = self.nameInfo[stateNum]['owningFamily']
    die ("No owning family for state #" + str(stateNum),
         familyName is None)
    return familyName
    
</t>
<t tx="ekr.20080121135406.147">def internStateName(self, name):        
    nameTable = self.nameTable
    if not nameTable.has_key(name):
        self.stateCount += 1
        stateNum = nameTable[name] = self.stateCount
        test_assign_entry(self.nameInfo, stateNum, {})
        self.nameInfo[stateNum]['name'] = name
    return nameTable[name]

</t>
<t tx="ekr.20080121135406.148">def setFamilyOwner(self, stateNum, permFamilyInfo):
    nameInfo = self.nameInfo
    test_assign_entry(nameInfo, stateNum, {})
    nameInfo[stateNum]['owningFamily'] = nameInfo[stateNum].get('owningFamily', permFamilyInfo.currFamily)
    
</t>
<t tx="ekr.20080121135406.149">class CurrentInfo:
    @others
</t>
<t tx="ekr.20080121135406.150">def __init__(self, currFamily):
    self.patterns = {}
    self.flippers = []
    self.initialState = None
    self.currFamily = currFamily
    self.subLanguageName = None
    self.specified = False

</t>
<t tx="ekr.20080121135406.151">def __repr__(self):
    return "&lt;CurrentInfo %r&gt;" % self.subLanguageName

</t>
<t tx="ekr.20080121135406.152">class Analyzer:
    @others
</t>
<t tx="ekr.20080121135406.153">def __init__(self, mainObj):
    self.mainObj = mainObj
    
</t>
<t tx="ekr.20080121135406.154">def semanticCheck(self):
    familyNames = [x.lower() for x in self.mainObj.familyList.keys()]
    for k in familyNames:
        if not self.mainObj.families.has_key(k):
            warn("Family %s isn't recognized, expected one of [%s]\n",
                 k, " ".join(self.mainObj.families.keys()))
            return
    for k in familyNames:
        obj = self.mainObj.familyList[k]
        if obj.specified:
            if obj.subLanguageName is None:
                warn("No sublanguage name specified for family %s",
                     obj.currFamily)
        if hasattr(obj, 'tokenCheckBlock'):
            if not (hasattr(obj, 'start_style')
                    and hasattr(obj, 'end_style')):
                msg = """No %s specified.  To do look-back token checking,
    you need to specify which styles are the start_style and the end_style.
    See the sample JavaScript lexer.\n"""
                if not hasattr(obj, 'start_style'):
                    warn(msg, 'start_style')
                else:
                    warn(msg, 'end_style')
                return
        if hasattr(obj, 'keywordList'):
            ok = True
            try:
                if not (obj.keywordStyle[0] and obj.keywordStyle[1]):
                    ok = False
            except:
                ok = False
            if not ok:
                warn("keywords were specified, but no keyword_style statement was given,\nlike &lt;&lt;keyword_style CSS_IDENTIFIER =&gt; CSS_WORD&gt;&gt;\n")
                return
        # Make sure no states put us in dead ends
        nameTable = self.mainObj.nameTable
        nameInfo = self.mainObj.nameInfo
        for state_name in nameTable.keys():
            state_num = nameTable[state_name]
            if not nameInfo[state_num].has_key('owningFamily'):
                warn("At least one transition moves to undefined state " + state_name +
                "\n This state needs to be defined somewhere.\n")
                return
    if self.mainObj.languageName is None:
        warn("No main language declaration given -- this language needs a name")
        return
    return True

</t>
<t tx="ekr.20080121135406.155">def _assign_once_dups_ok(self, obj, attrname, new_val, extra_msg=''):
    if not hasattr(obj, attrname):
        setattr(obj, attrname, new_val)
        return
    old_val = getattr(obj, attrname)
    if old_val is None:
        setattr(obj, attrname, new_val)
        return
    if old_val == new_val:
        return
    raise LudditeError(
        'Already specified %s "%s"%s, now specifying "%s"'
        % (attrname, extra_msg, old_val, new_val))
    
</t>
<t tx="ekr.20080121135406.156">def processTree(self, tree, currFamily='markup'):
    if not self.mainObj.familyList.has_key(currFamily):
        self.mainObj.familyList[currFamily] = CurrentInfo(currFamily)
    permFamilyInfo = self.mainObj.familyList[currFamily]
    for node in tree:
        if node[0] == 'module':
            self.processTree(node[1], currFamily)
        elif node[0] == 'pattern':
            node2 = node[1]
            permFamilyInfo.patterns[node2['name']] = node2['value']
        elif node[0] == 'family':
            # Stay with names for now
            currFamily = node[1].lower()
            self.mainObj.familyList[currFamily] = self.mainObj.familyList.get(currFamily, CurrentInfo(currFamily))
            permFamilyInfo = self.mainObj.familyList[currFamily]
            permFamilyInfo.specified = True
        elif node[0] == 'initial':
            permFamilyInfo.initialState = permFamilyInfo.initialState or node[1]['name']
        elif node[0] == 'language':
            self._assign_once_dups_ok(self.mainObj, 'languageName', node[1])
        elif node[0] == 'sublanguage':
            self._assign_once_dups_ok(permFamilyInfo, 'subLanguageName', node[1],
                                      "for family " + currFamily)
        elif node[0] == 'stateBlock':
            node2 = node[1]
            stateName = node2['name']
            stateNum = self.mainObj.internStateName(stateName)
            self.mainObj.setFamilyOwner(stateNum, permFamilyInfo)
            stateBlock = node2['value']
            test_assign_entry(self.mainObj.stateTable, stateNum, [])
            stateTable = self.mainObj.stateTable[stateNum]

            # Variables to track for synthesizing an eof action
            common_color = None
            synthesize_eof = True
            for transition in stateBlock:
                if transition[0] != 'transition':
                    raise LudditeError("Expecting 'transition', got %s"
                                       % transition[0])
                
                inner_tran = transition[1]
                inner_data = { 'type' : inner_tran['type'],
                               'value' : inner_tran['value'],
                               'token_check' : inner_tran['token_check'],
                               }
                if inner_tran['cmds']:
                    inner_data['cmds'] = inner_tran['cmds']
                
                if inner_tran['trans']:
                    inner_data['trans_str'] = inner_tran['trans']
                    inner_data['trans_num'] = self.mainObj.internStateName(inner_tran['trans'])
                
                # Check for synthesizing eof transition
                curr_color = self._favor_upto_color(inner_tran['cmds'])
                if curr_color and not isTemplateStateName(stateName):
                    # These are global across all families
                    if not self.mainObj.holdUniqueStates.has_key(curr_color):
                        self.mainObj.holdUniqueStates[curr_color] = {}
                    self.mainObj.holdUniqueStates[curr_color][stateName] = None
                
                if synthesize_eof:
                    if not inner_tran['cmds']:
                        # A transition with no commands doesn't affect
                        # EOF-synthesis
                        pass
                    elif inner_tran['type'] == 'pattern' and inner_tran['value'] == r'\z':
                        # They specified an explicit EOF transition
                        synthesize_eof = False
                    elif not curr_color:
                        synthesize_eof = False
                    elif common_color is None:
                        common_color = curr_color
                    elif common_color != curr_color:
                        synthesize_eof = False
                    
                stateTable.append(inner_data)
                
            if synthesize_eof:
                if common_color is not None:
                    inner_data = { 'type' : 'pattern',
                                   'value' : [r'\z', 0],
                                   'cmds' : [[ 'paint',
                                               { 'type' : 'upto',
                                                 'value' : common_color},
                                                ]],
                                   }
                    stateTable.append(inner_data)
                else:
                    warn("State %s might need an explicit \\z pattern rule" % (stateName,))
            
        elif node[0] == 'keywordList':
            permFamilyInfo.keywordList = node[1]
        elif node[0] == 'keywordStyle':
            permFamilyInfo.keywordStyle = [node[1], node[2]]
        elif node[0] == 'tokenCheckBlock':
            permFamilyInfo.tokenCheckBlock = node[1]
        elif node[0] == 'start_style':
            permFamilyInfo.start_style = node[1]
        elif node[0] == 'end_style':
            permFamilyInfo.end_style = node[1]
        elif node[0] == 'fold':
            permFamilyInfo.flippers.append(node[1])
        elif node[0] in ('namespace', 'public_id', 'system_id'):
            name = node[1]
            self.mainObj.languageService_xmlNames[node[0]][1][name] = None

</t>
<t tx="ekr.20080121135406.157">def _favor_upto_color(self, cmds):
    # Favor the upto-color, but use the include-color if that's all they gave
    if cmds is None: return None
    color = None
    for cmd in cmds:
        if not isinstance(cmd, (list, tuple)):
            continue
        if cmd[0] == 'paint':
            if cmd[1]['type'] == 'upto':
                return cmd[1]['value']
            else:
                color = cmd[1]['value']
    return color


</t>
<t tx="ekr.20080121135406.158">#-----------------------------------------------------------------------------
# ply: lex.py
#
# Author: David M. Beazley (dave@dabeaz.com)
#
# Copyright (C) 2001-2006, David M. Beazley
#
# $Header$
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
# 
# See the file COPYING for a complete copy of the LGPL.
#
# 
# This module automatically constructs a lexical analysis module from regular
# expression rules defined in a user-defined module.  The idea is essentially the same
# as that used in John Aycock's Spark framework, but the implementation works
# at the module level rather than requiring the use of classes.
#
# This module tries to provide an interface that is closely modeled after
# the traditional lex interface in Unix.  It also differs from Spark
# in that:
#
#   -  It provides more extensive error checking and reporting if
#      the user supplies a set of regular expressions that can't
#      be compiled or if there is any other kind of a problem in
#      the specification.
#
#   -  The interface is geared towards LALR(1) and LR(1) parser
#      generators.  That is tokens are generated one at a time
#      rather than being generated in advanced all in one step.
#
# There are a few limitations of this module
#
#   -  The module interface makes it somewhat awkward to support more
#      than one lexer at a time.  Although somewhat inelegant from a
#      design perspective, this is rarely a practical concern for
#      most compiler projects.
#
#   -  The lexer requires that the entire input text be read into
#      a string before scanning.  I suppose that most machines have
#      enough memory to make this a minor issues, but it makes
#      the lexer somewhat difficult to use in interactive sessions
#      or with streaming data.
#
#-----------------------------------------------------------------------------

r"""
lex.py

This module builds lex-like scanners based on regular expression rules.
To use the module, simply write a collection of regular expression rules
and actions like this:

# lexer.py
import lex

# Define a list of valid tokens
tokens = (
    'IDENTIFIER', 'NUMBER', 'PLUS', 'MINUS'
    )

# Define tokens as functions
def t_IDENTIFIER(t):
    r' ([a-zA-Z_](\w|_)* '
    return t

def t_NUMBER(t):
    r' \d+ '
    return t

# Some simple tokens with no actions
t_PLUS = r'\+'
t_MINUS = r'-'

# Initialize the lexer
lex.lex()

The tokens list is required and contains a complete list of all valid
token types that the lexer is allowed to produce.  Token types are
restricted to be valid identifiers.  This means that 'MINUS' is a valid
token type whereas '-' is not.

Rules are defined by writing a function with a name of the form
t_rulename.  Each rule must accept a single argument which is
a token object generated by the lexer. This token has the following
attributes:

    t.type   = type string of the token.  This is initially set to the
               name of the rule without the leading t_
    t.value  = The value of the lexeme.
    t.lineno = The value of the line number where the token was encountered
    
For example, the t_NUMBER() rule above might be called with the following:
    
    t.type  = 'NUMBER'
    t.value = '42'
    t.lineno = 3

Each rule returns the token object it would like to supply to the
parser.  In most cases, the token t is returned with few, if any
modifications.  To discard a token for things like whitespace or
comments, simply return nothing.  For instance:

def t_whitespace(t):
    r' \s+ '
    pass

For faster lexing, you can also define this in terms of the ignore set like this:

t_ignore = ' \t'

The characters in this string are ignored by the lexer. Use of this feature can speed
up parsing significantly since scanning will immediately proceed to the next token.

lex requires that the token returned by each rule has an attribute
t.type.  Other than this, rules are free to return any kind of token
object that they wish and may construct a new type of token object
from the attributes of t (provided the new object has the required
type attribute).

If illegal characters are encountered, the scanner executes the
function t_error(t) where t is a token representing the rest of the
string that hasn't been matched.  If this function isn't defined, a
LexError exception is raised.  The .text attribute of this exception
object contains the part of the string that wasn't matched.

The t.skip(n) method can be used to skip ahead n characters in the
input stream.  This is usually only used in the error handling rule.
For instance, the following rule would print an error message and
continue:

def t_error(t):
    print "Illegal character in input %s" % t.value[0]
    t.skip(1)

Of course, a nice scanner might wish to skip more than one character
if the input looks very corrupted.

The lex module defines a t.lineno attribute on each token that can be used
to track the current line number in the input.  The value of this
variable is not modified by lex so it is up to your lexer module
to correctly update its value depending on the lexical properties
of the input language.  To do this, you might write rules such as
the following:

def t_newline(t):
    r' \n+ '
    t.lineno += t.value.count("\n")

To initialize your lexer so that it can be used, simply call the lex.lex()
function in your rule file.  If there are any errors in your
specification, warning messages or an exception will be generated to
alert you to the problem.

To use the newly constructed lexer from another module, simply do
this:

    import lex
    import lexer
    lex.input("position = initial + rate*60")

    while 1:
        token = lex.token()       # Get a token
        if not token: break        # No more tokens
        ... do whatever ...

Assuming that the module 'lexer' has initialized lex as shown
above, parsing modules can safely import 'lex' without having
to import the rule file or any additional imformation about the
scanner you have defined.
"""    

# -----------------------------------------------------------------------------


__version__ = "1.7"

import re, types, sys, copy

# Available instance types.  This is used when lexers are defined by a class.
# it's a little funky because I want to preserve backwards compatibility
# with Python 2.0 where types.ObjectType is undefined.

try:
   _INSTANCETYPE = (types.InstanceType, types.ObjectType)
except AttributeError:
   _INSTANCETYPE = types.InstanceType

</t>
<t tx="ekr.20080121135406.159"># Exception thrown when invalid token encountered and no default
class LexError(Exception):
    @others
</t>
<t tx="ekr.20080121135406.160">def __init__(self,message,s):
     self.args = (message,)
     self.text = s

</t>
<t tx="ekr.20080121135406.161"># Token class
class LexToken:
    @others
</t>
<t tx="ekr.20080121135406.162">def __str__(self):
    return "LexToken(%s,%r,%d)" % (self.type,self.value,self.lineno)
</t>
<t tx="ekr.20080121135406.163">def __repr__(self):
    return str(self)
</t>
<t tx="ekr.20080121135406.164">def skip(self,n):
    try:
        self._skipn += n
    except AttributeError:
        self._skipn = n

</t>
<t tx="ekr.20080121135406.165"># -----------------------------------------------------------------------------
# Lexer class
#
#    input()          -  Store a new string in the lexer
#    token()          -  Get the next token
# -----------------------------------------------------------------------------

class Lexer:
    @others
</t>
<t tx="ekr.20080121135406.166">def __init__(self):
    self.lexre = None           # Master regular expression
</t>
<t tx="ekr.20080121135406.167">self.lexreflags = 0         # Option re compile flags
    self.lexdata = None         # Actual input data (as a string)
    self.lexpos = 0             # Current position in input text
    self.lexlen = 0             # Length of the input text
    self.lexindexfunc = [ ]     # Reverse mapping of groups to functions and types
    self.lexerrorf = None       # Error rule (if any)
    self.lextokens = None       # List of valid tokens
    self.lexignore = None       # Ignored characters
    self.lineno = 1             # Current line number
    self.debug = 0              # Debugging mode
    self.optimize = 0           # Optimized mode
    self.token = self.errtoken

def __copy__(self):
    c = Lexer()
    c.lexre = self.lexre
</t>
<t tx="ekr.20080121135406.168">c.lexreflags = self.lexreflags
    c.lexdata = self.lexdata
    c.lexpos = self.lexpos
    c.lexlen = self.lexlen
    c.lexindexfunc = self.lexindexfunc
    c.lexerrorf = self.lexerrorf
    c.lextokens = self.lextokens
    c.lexignore = self.lexignore
c.debug = self.debug
    c.lineno = self.lineno
    c.optimize = self.optimize
    c.token = c.realtoken
return c

# ------------------------------------------------------------
# input() - Push a new string into the lexer
# ------------------------------------------------------------
def input(self,s):
    if not (isinstance(s,types.StringType) or isinstance(s,types.UnicodeType)):
        raise ValueError, "Expected a string"
    self.lexdata = s
    self.lexpos = 0
    self.lexlen = len(s)
    self.token = self.realtoken
    
    # Change the token routine to point to realtoken()
    global token
    if token == self.errtoken:
        token = self.token

</t>
<t tx="ekr.20080121135406.169"># ------------------------------------------------------------
# errtoken() - Return error if token is called with no data
# ------------------------------------------------------------
def errtoken(self):
    raise RuntimeError, "No input string given with input()"

</t>
<t tx="ekr.20080121135406.170"># ------------------------------------------------------------
# token() - Return the next token from the Lexer
#
# Note: This function has been carefully implemented to be as fast
# as possible.  Don't make changes unless you really know what
# you are doing
# ------------------------------------------------------------
def realtoken(self):
    # Make local copies of frequently referenced attributes
    lexpos    = self.lexpos
    lexlen    = self.lexlen
    lexignore = self.lexignore
    lexdata   = self.lexdata
    
    while lexpos &lt; lexlen:
        # This code provides some short-circuit code for whitespace, tabs, and other ignored characters
        if lexdata[lexpos] in lexignore:
            lexpos += 1
            continue

        # Look for a regular expression match
        m = self.lexre.match(lexdata,lexpos)
        if m:
            i = m.lastindex
            lexpos = m.end()
            tok = LexToken()
            tok.value = m.group()
            tok.lineno = self.lineno
            tok.lexer = self
            func,tok.type = self.lexindexfunc[i]
            if not func:
                self.lexpos = lexpos
                return tok
            
            # If token is processed by a function, call it
            self.lexpos = lexpos
            newtok = func(tok)
            self.lineno = tok.lineno     # Update line number
            
            # Every function must return a token, if nothing, we just move to next token
            if not newtok: continue
            
            # Verify type of the token.  If not in the token map, raise an error
            if not self.optimize:
                if not self.lextokens.has_key(newtok.type):
                    raise LexError, ("%s:%d: Rule '%s' returned an unknown token type '%s'" % (
                        func.func_code.co_filename, func.func_code.co_firstlineno,
                        func.__name__, newtok.type),lexdata[lexpos:])

            return newtok

        # No match. Call t_error() if defined.
        if self.lexerrorf:
            tok = LexToken()
            tok.value = self.lexdata[lexpos:]
            tok.lineno = self.lineno
            tok.type = "error"
            tok.lexer = self
            oldpos = lexpos
            newtok = self.lexerrorf(tok)
            lexpos += getattr(tok,"_skipn",0)
            if oldpos == lexpos:
                # Error method didn't change text position at all. This is an error.
                self.lexpos = lexpos
                raise LexError, ("Scanning error. Illegal character '%s'" % (lexdata[lexpos]), lexdata[lexpos:])
            if not newtok: continue
            self.lexpos = lexpos
            return newtok

        self.lexpos = lexpos
        raise LexError, ("No match found", lexdata[lexpos:])

    # No more input data
    self.lexpos = lexpos + 1
    return None

    
</t>
<t tx="ekr.20080121135406.171"># -----------------------------------------------------------------------------
# validate_file()
#
# This checks to see if there are duplicated t_rulename() functions or strings
# in the parser input file.  This is done using a simple regular expression
# match on each line in the filename.
# -----------------------------------------------------------------------------

def validate_file(filename):
    import os.path
    base,ext = os.path.splitext(filename)
    if ext != '.py': return 1        # No idea what the file is. Return OK

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return 1                       # Oh well

    fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
    sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')
    counthash = { }
    linen = 1
    noerror = 1
    for l in lines:
        m = fre.match(l)
        if not m:
            m = sre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                print "%s:%d: Rule %s redefined. Previously defined on line %d" % (filename,linen,name,prev)
                noerror = 0
        linen += 1
    return noerror

</t>
<t tx="ekr.20080121135406.172"># -----------------------------------------------------------------------------
# _read_lextab(module)
#
# Reads lexer table from a lextab file instead of using introspection.
# -----------------------------------------------------------------------------

def _read_lextab(lexer, fdict, module):
    exec "import %s as lextab" % module
    lexer.lexre = re.compile(lextab._lexre, re.VERBOSE | lextab._lexreflags)
    lexer.lexreflags = lextab._lexreflags
    lexer.lexindexfunc = lextab._lextab
    for i in range(len(lextab._lextab)):
        t = lexer.lexindexfunc[i]
        if t:
            if t[0]:
                lexer.lexindexfunc[i] = (fdict[t[0]],t[1])
    lexer.lextokens = lextab._lextokens
    lexer.lexignore = lextab._lexignore
    if lextab._lexerrorf:
        lexer.lexerrorf = fdict[lextab._lexerrorf]
        
</t>
<t tx="ekr.20080121135406.173"># -----------------------------------------------------------------------------
# lex(module)
#
# Build all of the regular expression rules from definitions in the supplied module
# -----------------------------------------------------------------------------
def lex(module=None,debug=0,optimize=0,lextab="lextab",reflags=0):
    ldict = None
    regex = ""
    error = 0
    files = { }
    lexer = Lexer()
    lexer.debug = debug
    lexer.optimize = optimize
    global token,input
    
    if module:
        # User supplied a module object.
        if isinstance(module, types.ModuleType):
            ldict = module.__dict__
        elif isinstance(module, _INSTANCETYPE):
            _items = [(k,getattr(module,k)) for k in dir(module)]
            ldict = { }
            for (i,v) in _items:
                ldict[i] = v
        else:
            raise ValueError,"Expected a module or instance"
        
    else:
        # No module given.  We might be able to get information from the caller.
        try:
            raise RuntimeError
        except RuntimeError:
            e,b,t = sys.exc_info()
            f = t.tb_frame
            f = f.f_back           # Walk out to our calling function
            ldict = f.f_globals    # Grab its globals dictionary

    if optimize and lextab:
        try:
            _read_lextab(lexer,ldict, lextab)
            if not lexer.lexignore: lexer.lexignore = ""            
            token = lexer.token
            input = lexer.input
            return lexer
        
        except ImportError:
            pass
        
    # Get the tokens map
    if (module and isinstance(module,_INSTANCETYPE)):
        tokens = getattr(module,"tokens",None)
    else:
        try:
            tokens = ldict["tokens"]
        except KeyError:
            tokens = None
        
    if not tokens:
        raise SyntaxError,"lex: module does not define 'tokens'"
    if not (isinstance(tokens,types.ListType) or isinstance(tokens,types.TupleType)):
        raise SyntaxError,"lex: tokens must be a list or tuple."

    # Build a dictionary of valid token names
    lexer.lextokens = { }
    if not optimize:

        # Utility function for verifying tokens
        def is_identifier(s):
            for c in s:
                if not (c.isalnum() or c == '_'): return 0
            return 1
        
        for n in tokens:
            if not is_identifier(n):
                print "lex: Bad token name '%s'" % n
                error = 1
            if lexer.lextokens.has_key(n):
                print "lex: Warning. Token '%s' multiply defined." % n
            lexer.lextokens[n] = None
    else:
        for n in tokens: lexer.lextokens[n] = None
        

    if debug:
        print "lex: tokens = '%s'" % lexer.lextokens.keys()

    # Get a list of symbols with the t_ prefix
    tsymbols = [f for f in ldict.keys() if f[:2] == 't_']
    
    # Now build up a list of functions and a list of strings
    fsymbols = [ ]
    ssymbols = [ ]
    for f in tsymbols:
        if callable(ldict[f]):
            fsymbols.append(ldict[f])
        elif (isinstance(ldict[f], types.StringType) or isinstance(ldict[f],types.UnicodeType)):
            ssymbols.append((f,ldict[f]))
        else:
            print "lex: %s not defined as a function or string" % f
            error = 1
            
    # Sort the functions by line number
    fsymbols.sort(lambda x,y: cmp(x.func_code.co_firstlineno,y.func_code.co_firstlineno))

    # Sort the strings by regular expression length
    ssymbols.sort(lambda x,y: (len(x[1]) &lt; len(y[1])) - (len(x[1]) &gt; len(y[1])))
    
    # Check for non-empty symbols
    if len(fsymbols) == 0 and len(ssymbols) == 0:
        raise SyntaxError,"lex: no rules of the form t_rulename are defined."

    # Add all of the rules defined with actions first
    for f in fsymbols:
        
        line = f.func_code.co_firstlineno
        file = f.func_code.co_filename
        files[file] = None

        ismethod = isinstance(f, types.MethodType)

        if not optimize:
            nargs = f.func_code.co_argcount
            if ismethod:
                reqargs = 2
            else:
                reqargs = 1
            if nargs &gt; reqargs:
                print "%s:%d: Rule '%s' has too many arguments." % (file,line,f.__name__)
                error = 1
                continue

            if nargs &lt; reqargs:
                print "%s:%d: Rule '%s' requires an argument." % (file,line,f.__name__)
                error = 1
                continue

            if f.__name__ == 't_ignore':
                print "%s:%d: Rule '%s' must be defined as a string." % (file,line,f.__name__)
                error = 1
                continue
        
        if f.__name__ == 't_error':
            lexer.lexerrorf = f
            continue

        if f.__doc__:
            if not optimize:
                try:
                    c = re.compile(f.__doc__, re.VERBOSE | reflags)
                except re.error,e:
                    print "%s:%d: Invalid regular expression for rule '%s'. %s" % (file,line,f.__name__,e)
                    error = 1
                    continue

                if debug:
                    print "lex: Adding rule %s -&gt; '%s'" % (f.__name__,f.__doc__)

            # Okay. The regular expression seemed okay.  Let's append it to the master regular
            # expression we're building
  
            if (regex): regex += "|"
            regex += "(?P&lt;%s&gt;%s)" % (f.__name__,f.__doc__)
        else:
            print "%s:%d: No regular expression defined for rule '%s'" % (file,line,f.__name__)

    # Now add all of the simple rules
    for name,r in ssymbols:

        if name == 't_ignore':
            lexer.lexignore = r
            continue
        
        if not optimize:
            if name == 't_error':
                raise SyntaxError,"lex: Rule 't_error' must be defined as a function"
                error = 1
                continue
        
            if not lexer.lextokens.has_key(name[2:]):
                print "lex: Rule '%s' defined for an unspecified token %s." % (name,name[2:])
                error = 1
                continue
            try:
                c = re.compile(r,re.VERBOSE)
            except re.error,e:
                print "lex: Invalid regular expression for rule '%s'. %s" % (name,e)
                error = 1
                continue
            if debug:
                print "lex: Adding rule %s -&gt; '%s'" % (name,r)
                
        if regex: regex += "|"
        regex += "(?P&lt;%s&gt;%s)" % (name,r)

    if not optimize:
        for f in files.keys():
            if not validate_file(f):
                error = 1
    try:
        if debug:
            print "lex: regex = '%s'" % regex
        lexer.lexre = re.compile(regex, re.VERBOSE | reflags)

        # Build the index to function map for the matching engine
        lexer.lexindexfunc = [ None ] * (max(lexer.lexre.groupindex.values())+1)
        for f,i in lexer.lexre.groupindex.items():
            handle = ldict[f]
            if type(handle) in (types.FunctionType, types.MethodType):
                lexer.lexindexfunc[i] = (handle,handle.__name__[2:])
            else:
                # If rule was specified as a string, we build an anonymous
                # callback function to carry out the action
                lexer.lexindexfunc[i] = (None,f[2:])

        # If a lextab was specified, we create a file containing the precomputed
        # regular expression and index table
        
        if lextab and optimize:
            lt = open(lextab+".py","w")
            lt.write("# %s.py.  This file automatically created by PLY. Don't edit.\n" % lextab)
            lt.write("_lexre = %s\n" % repr(regex))
            lt.write("_lexreflags = %d\n" % reflags)
            lt.write("_lextab = [\n");
            for i in range(0,len(lexer.lexindexfunc)):
                t = lexer.lexindexfunc[i]
                if t:
                    if t[0]:
                        lt.write("  ('%s',%s),\n"% (t[0].__name__, repr(t[1])))
                    else:
                        lt.write("  (None,%s),\n" % repr(t[1]))
                else:
                    lt.write("  None,\n")
                    
            lt.write("]\n");
            lt.write("_lextokens = %s\n" % repr(lexer.lextokens))
            lt.write("_lexignore = %s\n" % repr(lexer.lexignore))
            if (lexer.lexerrorf):
                lt.write("_lexerrorf = %s\n" % repr(lexer.lexerrorf.__name__))
            else:
                lt.write("_lexerrorf = None\n")
            lt.close()
        
    except re.error,e:
        print "lex: Fatal error. Unable to compile regular expression rules. %s" % e
        error = 1
    if error:
        raise SyntaxError,"lex: Unable to build lexer."
    if not lexer.lexerrorf:
        print "lex: Warning. no t_error rule is defined."

    if not lexer.lexignore: lexer.lexignore = ""
    
    # Create global versions of the token() and input() functions
    token = lexer.token
    input = lexer.input
    
    return lexer

</t>
<t tx="ekr.20080121135406.174"># -----------------------------------------------------------------------------
# run()
#
# This runs the lexer as a main program
# -----------------------------------------------------------------------------

def runmain(lexer=None,data=None):
    if not data:
        try:
            filename = sys.argv[1]
            f = open(filename)
            data = f.read()
            f.close()
        except IndexError:
            print "Reading from standard input (type EOF to end):"
            data = sys.stdin.read()

    if lexer:
        _input = lexer.input
    else:
        _input = input
    _input(data)
    if lexer:
        _token = lexer.token
    else:
        _token = token
        
    while 1:
        tok = _token()
        if not tok: break
        print "(%s,%r,%d)" % (tok.type, tok.value, tok.lineno)
        
    


</t>
<t tx="ekr.20080121135406.175"># ***** LICENSE BLOCK *****

# luddite_lexer.py -- lexer for Luddite, using PLY
#
# See http://systems.cs.uchicago.edu/ply for more information on
# PLY, the lexer/parser framework this code uses.
#
# Author(s):
#   Eric Promislow &lt;ericp@activestate.com&gt;
#

import sys
from ludditelib import lex
import copy

tokens = (
    'ARROW',
    'MINUS',
    'PLUS',
    'COMMA',
    'COLON',
    'SCOLON',
    'OPAREN',
    'CPAREN',
    'OBRACKET',
    'CBRACKET',
#    'OBRACE',
#    'CBRACE',
    'EQUALS',
    'NUMBER',
    'LB_NAME',
    'LB_STRING',
    'LB_REGEX',
    'HT_ACCEPT',
    'HT_ALL',
    'HT_CLEAR_DELIMITER',
    'HT_DELIMITER',
    'HT_FAMILY',
    'HT_FOLD',
    'HT_KEEP_DELIMITER',
    'HT_KEYWORDS',
    'HT_KEYWORD_STYLE',
    'HT_INCLUDE',
    'HT_INITIAL',
    'HT_LANGUAGE',
    'HT_X_NAMESPACE',
    'HT_NOKEYWORD',
    'HT_PAINT',
    'HT_PATTERN',
    'HT_PUBLIC_ID',
    'HT_REDO',
    'HT_REJECT',
    'HT_SET_DELIMITER',
    'HT_SET_OPPOSITE_DELIMITER',
    'HT_SKIP',
    'HT_STATE',
    'HT_SUBLANGUAGE',
    'HT_SYSTEM_ID',
    'HT_TOKEN_CHECK',
    'HT_START_STYLE',
    'HT_END_STYLE',
    'HT_UPTO',
    'HT_SPUSH_CHECK',
    'HT_SPOP_CHECK',
    'HT_AT_EOL',
    'LB_NL',
    )

t_ARROW = r'=&gt;'
t_MINUS = r'-'
t_PLUS = r'\+'
t_COMMA = r','
t_COLON = r':'
t_SCOLON = r';'
t_OPAREN = r'\('
t_CPAREN = r'\)'
t_OBRACKET = r'\['
t_CBRACKET = r'\]'
#t_OBRACE = r'{'
#t_CBRACE = r'}'
t_EQUALS = r'='

reserved = {
    'accept' : 'HT_ACCEPT',
    'all' : 'HT_ALL',
    'at_eol' : 'HT_AT_EOL',
    'clear_delimiter' : 'HT_CLEAR_DELIMITER',
    'delimiter' : 'HT_DELIMITER',
    'family' : 'HT_FAMILY',
    'fold' : 'HT_FOLD',
    'keep_delimiter' : 'HT_KEEP_DELIMITER',
    'keywords' : 'HT_KEYWORDS',
    'keyword_style' : 'HT_KEYWORD_STYLE',
    'include' : 'HT_INCLUDE',
    'initial' : 'HT_INITIAL',
    'language' : 'HT_LANGUAGE',
    # Calling this "HT_NO_KEYWORD" will confuse PLY
    'namespace' : 'HT_X_NAMESPACE',
    'no_keyword' : 'HT_NOKEYWORD',
    'paint' : 'HT_PAINT',
    'pattern' : 'HT_PATTERN',
    'public_id' : 'HT_PUBLIC_ID',
    'publicid' : 'HT_PUBLIC_ID',       # Same keyword
    'redo' : 'HT_REDO',
    'reject' : 'HT_REJECT',
    'set_delimiter' : 'HT_SET_DELIMITER',
    'set_opposite_delimiter' : 'HT_SET_OPPOSITE_DELIMITER',
    'skip' : 'HT_SKIP',
    'state' : 'HT_STATE',
    'sublanguage' : 'HT_SUBLANGUAGE',
    'sub_language' : 'HT_SUBLANGUAGE',  # Same keyword
    'systemid' : 'HT_SYSTEM_ID',         # Same keyword
    'system_id' : 'HT_SYSTEM_ID',
    'token_check' : 'HT_TOKEN_CHECK',
    'start_style' : 'HT_START_STYLE',
    'end_style' : 'HT_END_STYLE',
    'upto' : 'HT_UPTO',
    'spush_check' : 'HT_SPUSH_CHECK',
    'spop_check' : 'HT_SPOP_CHECK',
    }

</t>
<t tx="ekr.20080121135406.176"># These are right from the docs, work for Luddite

def t_LB_NAME(t):
    r'[a-zA-Z][a-zA-Z_0-9]*'
    t.type = reserved.get(t.value,'LB_NAME')    # Check for reserved words
    return t

</t>
<t tx="ekr.20080121135406.177">def t_NUMBER(t):
    r'\d+'
    try:
        t.value = int(t.value)
    except ValueError:
        print "Number %s is too large!" % t.value
        t.value = 0
    return t

</t>
<t tx="ekr.20080121135406.178"># Define a rule so we can track line numbers

# Sometimes we return this, but in lists we don't.

def t_LB_NL(t): # Newline
    r'\r?\n'
    t.lineno += 1
    return t

</t>
<t tx="ekr.20080121135406.179"># A string containing ignored characters (spaces and tabs)
t_ignore  = ' \t'

# Error handling rule
def t_error(t):
    print "Illegal character '%s'" % t.value[0]
    t.skip(1)

</t>
<t tx="ekr.20080121135406.180"># Comments

def t_comment(t):
    r'\#.*'
    t.skip(len(t.value))

</t>
<t tx="ekr.20080121135406.181">def t_nl_escape(t):
    r'\\\r?\n'
    t.lineno += 1
    t.skip(len(t.value))

</t>
<t tx="ekr.20080121135406.182">def t_LB_STRING(t):
    r'''((?:'[^'\\]*(?:\\.|[^'\\]+)*')|(?:"[^"\\]*(?:\\.|[^"\\]+)*"))'''
    return t

</t>
<t tx="ekr.20080121135406.183">def t_LB_REGEX(t):
    r'/(\\.|[^\\/]+)*/i?'
    return t

</t>
<t tx="ekr.20080121135406.184">class Lexer:
    @others
</t>
<t tx="ekr.20080121135406.185">def __init__(self):
    self.lexer = lex.lex(debug=0)

</t>
<t tx="ekr.20080121135406.186">def token(self):
    tok = self.lexer.token()
    return tok

</t>
<t tx="ekr.20080121135406.187">def input(self, s):
    self.lexer.input(s)

</t>
<t tx="ekr.20080121135406.188">def _test(self):
    tok = None
    while 1:
        prev_tok = tok
        tok = self.token()
        if not tok:
            break
        print tok

</t>
<t tx="ekr.20080121135406.189">def get_input(fname, searchPath=['.']):
        # Read in the file contents.
        fin = None
        if fname == '-':
            fin = sys.stdin
        else:
            for p in searchPath:
                try:
                    fpath = p + "/" + fname
                    fin = open(fpath, 'r')
                    # print "**************** Opening file " + fpath + "..."
                    break
                except:
                    # print "Can't open file " + fpath
                    pass
            if fin is None:
                print "Can't find file " + fname
                return None
        s = fin.read()
        fin.close()
        return s


</t>
<t tx="ekr.20080121135406.190">def do_main(fname):
    s = get_input(fname)
    lw = Lexer()
    lw.input(s)
    return lw._test()

</t>
<t tx="ekr.20080121135406.191">def main(argv):
    global searchPath
    from optparse import OptionParser
    parser = OptionParser()
    parser.add_option("-I", "--include", action="append", dest="path", 
                      help="add to search path")
    (options, args) = parser.parse_args()
    if options.path:
        searchPath += options.path
    
    if len(args) != 1:
        import py_compile
        raise py_compile.PyCompileError("Incorrect number of arguments: %r" % argv[1:])
    return do_main(args[0])

</t>
<t tx="ekr.20080121135406.192"># ***** LICENSE BLOCK *****

"""parser for Luddite, using PLY

See http://systems.cs.uchicago.edu/ply for more information on PLY, the
lexer/parser framework this code uses.
"""

import os
from os.path import dirname, join, exists
import re
import sys
from types import *
import logging

from ludditelib.common import LudditeError
from ludditelib import yacc
from ludditelib.lexer import Lexer, tokens  # tokens is used by Yacc stuff


log = logging.getLogger("luddite")



</t>
<t tx="ekr.20080121135406.193">#XXX review and Pythonify
def keep_non_empty_dicts(lst):
    return filter(lambda(x): x and type(x) == DictType and len(x.keys()) &gt; 0, lst)

</t>
<t tx="ekr.20080121135406.194">#XXX review and Pythonify
def keep_non_empty_lists(lst):
    return filter(lambda(x): x and type(x) == ListType and len(x) &gt; 0, lst)

</t>
<t tx="ekr.20080121135406.195">#XXX review and Pythonify
def combine_filter_list_dict(list1, item2):
    list2 = keep_non_empty_dicts(list1 or [])
    if type(item2) == DictType:
        list2.append(item2)
    return list2

</t>
<t tx="ekr.20080121135406.196">#XXX review and Pythonify
def combine_filter_list_item(list1, item2):
    k = keep_non_empty_lists(list1 + [item2])
    return k

</t>
<t tx="ekr.20080121135406.197">#XXX review and Pythonify
def combine_filter_list(list1, item2):
    k = [x for x in (list1 + [item2]) if x]
    return k

</t>
<t tx="ekr.20080121135406.198">def p_program(p):
    'program : statements'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.199">def p_statements(p):
    '''statements : statements_1
    | statements_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.200">def p_statements_1(p):
    'statements_1 : statements statement'
    p[0] = combine_filter_list_item(p[1], p[2])

</t>
<t tx="ekr.20080121135406.201">def p_statements_2(p):
    'statements_2 : empty'
    p[0] = []

</t>
<t tx="ekr.20080121135406.202">def p_statement(p):
    '''statement : statement_1
    | statement_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.203">def p_statement_1(p):
    '''statement_1 :  pattern eol_seq
|  namespace_decln eol_seq
|  public_id_decln eol_seq
|  system_id_decln eol_seq
|  family_decln eol_seq
|  fold_stmt eol_seq
|  include eol_seq
|  initial eol_seq
|  keyword_list eol_seq
|  keyword_style eol_seq
|  xlanguage eol_seq
|  stateBlock
|  sublanguage eol_seq
|  tokenCheckBlock
|  start_style_stmt
|  end_style_stmt'''  # newline handling has to be handled in the lexer/rule
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.204">def p_statement_2(p):
    'statement_2 : eol'
    p[0] = []

</t>
<t tx="ekr.20080121135406.205">def p_pattern(p):
    'pattern : HT_PATTERN name EQUALS string_const'
    p[0] = ['pattern', { 'name' : p[2], 'value' : p[4] }]

</t>
<t tx="ekr.20080121135406.206">def p_fold_stmt(p):
    'fold_stmt : HT_FOLD name_or_string LB_NAME plus_or_minus'
    p[0] = ['fold', { 'name' : p[2], 'style' : p[3], 'value' : p[4] }]

</t>
<t tx="ekr.20080121135406.207">def p_plus_or_minus(p):
    '''plus_or_minus : PLUS
| MINUS'''
    if p[1] == '+': p[0] = 1
    else: p[0] = -1

</t>
<t tx="ekr.20080121135406.208">def p_include(p):
    'include : HT_INCLUDE name_or_string'
    p[0] = ['include', p[2]]

</t>
<t tx="ekr.20080121135406.209">def p_namespace_decln(p):
    'namespace_decln : HT_X_NAMESPACE name_or_string'
    p[0] = ['namespace', p[2]]

</t>
<t tx="ekr.20080121135406.210">def p_public_id_decln(p):
    'public_id_decln : HT_PUBLIC_ID name_or_string'
    p[0] = ['public_id', p[2]]

</t>
<t tx="ekr.20080121135406.211">def p_system_id_decln(p):
    'system_id_decln : HT_SYSTEM_ID name_or_string'
    p[0] = ['system_id', p[2]]

</t>
<t tx="ekr.20080121135406.212">def p_family_decln(p):
    'family_decln : HT_FAMILY name'
    p[0] = ['family', p[2]]

</t>
<t tx="ekr.20080121135406.213">def p_initial(p):
    'initial : HT_INITIAL name'
    p[0] = ['initial', {'name' : p[2]}]

</t>
<t tx="ekr.20080121135406.214">def p_keyword_list(p):
    'keyword_list : HT_KEYWORDS name_and_string_list'
    p[0] = ['keywordList', p[2]]

</t>
<t tx="ekr.20080121135406.215">def p_keyword_style(p):
    'keyword_style : HT_KEYWORD_STYLE name ARROW name'
    p[0] = ['keywordStyle', p[2], p[4]]

</t>
<t tx="ekr.20080121135406.216"># Calling this 'language' will make the parser-generator unhappy.

def p_xlanguage(p):
    'xlanguage : HT_LANGUAGE name_or_string'
    p[0] = ['language', p[2]]

</t>
<t tx="ekr.20080121135406.217"># Calling this 'sub_language' will make the parser unhappy.

def p_sublanguage(p):
    'sublanguage : HT_SUBLANGUAGE name'
    p[0] = ['sublanguage', p[2]]

</t>
<t tx="ekr.20080121135406.218">#XXX : Turn newlines on and off
def p_name_and_string_list(p):
    'name_and_string_list : OBRACKET names_and_strings CBRACKET'
    p[0] = p[2]

</t>
<t tx="ekr.20080121135406.219">def p_stateBlock(p):
    'stateBlock :  HT_STATE state_name opt_colon_eol transitions'
    p[0] = ['stateBlock', { 'name' : p[2], 'value' : p[4]}]

</t>
<t tx="ekr.20080121135406.220">def p_transitions(p):
    '''transitions : transitions_1
    | transitions_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.221">def p_transitions_1(p):
    'transitions_1 : transitions transition'
    p[0] = combine_filter_list_item(p[1], p[2])

</t>
<t tx="ekr.20080121135406.222">def p_transitions_2(p):    
    'transitions_2 : empty'
    p[0] = []

</t>
<t tx="ekr.20080121135406.223">def p_transition(p):
    '''transition : transition_1
    | transition_2
    | transition_3
    | transition_4'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.224">def p_transition_1(p):
    'transition_1 : string_const opt_token_check opt_colon cmds_and_trans eol_seq'
    p[0] = ['transition', { 'type' : 'string', 'value' : p[1], 'token_check' : p[2], 'cmds' : p[4][0], 'trans' : p[4][1]}]
    
</t>
<t tx="ekr.20080121135406.225">def p_transition_2(p):
    'transition_2 : pattern_const opt_token_check opt_colon cmds_and_trans eol_seq'
    p[0] = ['transition', { 'type' : 'pattern', 'value' : p[1], 'token_check' : p[2], 'cmds' : p[4][0], 'trans' : p[4][1]}]

</t>
<t tx="ekr.20080121135406.226">def p_transition_3(p):
    'transition_3 : HT_DELIMITER opt_token_check opt_colon cmds_and_trans eol_seq'
    p[0] = ['transition', { 'type' : 'delimiter', 'value' : '', 'token_check' : p[2], 'cmds' : p[4][0], 'trans' : p[4][1]}]

</t>
<t tx="ekr.20080121135406.227">def p_transition_4(p):
    'transition_4 : eol'
    p[0] = None

</t>
<t tx="ekr.20080121135406.228">def p_cmds_and_trans(p):
    '''cmds_and_trans : cmds_and_trans_1
    | cmds_and_trans_2
    | cmds_and_trans_3
    | cmds_and_trans_4
    | cmds_and_trans_5'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.229">def p_cmds_and_trans_1(p):
    'cmds_and_trans_1 : state_tran'
    p[0] = [None, p[1]]

</t>
<t tx="ekr.20080121135406.230">def p_cmds_and_trans_2(p):
    'cmds_and_trans_2 : cmds COMMA state_tran'
    p[0] = [ p[1],  p[3] ]

</t>
<t tx="ekr.20080121135406.231">def p_cmds_and_trans_3(p):
    'cmds_and_trans_3 : cmds state_tran'
    p[0] = [ p[1],  p[2] ]

</t>
<t tx="ekr.20080121135406.232">def p_cmds_and_trans_4(p):
    'cmds_and_trans_4 : cmds'
    p[0] = [ p[1],  None ]

</t>
<t tx="ekr.20080121135406.233">def p_cmds_and_trans_5(p):
    'cmds_and_trans_5 : empty'
    p[0] = [None, None]

</t>
<t tx="ekr.20080121135406.234">def p_state_tran(p):
    'state_tran : ARROW state_name'
    p[0] = p[2]

</t>
<t tx="ekr.20080121135406.235">def p_tokenCheckBlock(p):
    'tokenCheckBlock : HT_TOKEN_CHECK COLON eol_seq tokenCheckDeclns'
    p[0] = ['tokenCheckBlock', p[4]]

</t>
<t tx="ekr.20080121135406.236">def p_tokenCheckDeclns(p):
    '''tokenCheckDeclns : tokenCheckDeclns_1
    | tokenCheckDeclns_2'''
    p[0] = p[1]
        
</t>
<t tx="ekr.20080121135406.237">def p_tokenCheckDeclns_1(p):
    'tokenCheckDeclns_1 : tokenCheckDeclns tokenCheckDecln'
    p[0] = combine_filter_list_dict(p[1], p[2])
    
</t>
<t tx="ekr.20080121135406.238">def p_tokenCheckDeclns_2(p):
    'tokenCheckDeclns_2 : empty'
    p[0] = None
    
</t>
<t tx="ekr.20080121135406.239">def p_tokenCheckDecln(p):
    '''tokenCheckDecln : tokenCheckDecln1
| tokenCheckDecln2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.240">def p_tokenCheckDecln1(p):
    'tokenCheckDecln1 : name COLON action_type action_selectors opt_term'
    p[0] = {'name' : p[1], 'type' : p[3], 'selectors' : p[4]}

</t>
<t tx="ekr.20080121135406.241">def p_tokenCheckDecln2(p):
    'tokenCheckDecln2 : eol'
    p[0] = None

</t>
<t tx="ekr.20080121135406.242">def p_action_type(p):
    '''action_type : HT_REJECT
    | HT_SKIP
    | HT_ACCEPT'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.243">def p_action_selectors(p):
    '''action_selectors : HT_ALL
| name_and_string_list'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.244">def p_start_style_stmt(p):
    'start_style_stmt : HT_START_STYLE name'
    p[0] = ['start_style', p[2]]

</t>
<t tx="ekr.20080121135406.245">def p_end_style_stmt(p):
    'end_style_stmt : HT_END_STYLE name'
    p[0] = ['end_style', p[2]]
    
</t>
<t tx="ekr.20080121135406.246">def p_string_const(p):
    'string_const : LB_STRING'
    # dequote the start of the raw string
    value1 = re.sub(r'^[\'\"]', '', p[1])
    value2 = re.sub(r'[\'\"]$', '', value1)
    if '\\' not in value2:
        p[0] = value2
    else:
        # Now handle only escaped quotes and tabs, all other backslashed
        # items will be handled by the generator.
        target = []
        esc_chars = {'"':'"',
                     "'":"'",
                     "t":"\t",
                     }
        srclen = len(value2)
        srclenSub1 = srclen - 1
        i = 0
        while i &lt; srclen:
            if value2[i] == '\\':
                if i &lt; srclenSub1:
                    c = esc_chars.get(value2[i + 1], None)
                    if c:
                        target.append(c)
                    else:
                        # Pass the backslash along when it doesn't
                        # precede a quote or t
                        target.append('\\')
                        target.append(value2[i+1])
                    i += 2
                    continue
            target.append(value2[i])
            i += 1
        p[0] = "".join(target)

</t>
<t tx="ekr.20080121135406.247">def p_pattern_const(p):
    'pattern_const : LB_REGEX'
    ptn = p[1]
    if ptn[-1] == 'i':
        ignore_case = True
        ptn = ptn[:-1]
    else:
        ignore_case = False
    ptn1 = re.sub('^/', '', ptn)
    ptn2 = re.sub('/$', '', ptn1)
    p[0] = [ptn2, ignore_case]

</t>
<t tx="ekr.20080121135406.248">def p_state_name(p):
    'state_name : LB_NAME'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.249">def p_cmds(p):
    '''cmds : cmds_1
| cmds_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.250">def p_cmds_1(p):
    'cmds_1 : cmds COMMA cmd'
    p[0] = combine_filter_list_item(p[1], p[3])

</t>
<t tx="ekr.20080121135406.251">def p_cmds_2(p):
    'cmds_2 : cmd'
    p[0] = [p[1]]

</t>
<t tx="ekr.20080121135406.252">def p_cmd(p):
    '''cmd : paint_cmd
    | at_eoltran_cmd
    | clear_delimiter_cmd
    | keep_delimiter_cmd
    | no_keyword_cmd
    | redo_cmd
    | set_delimiter_cmd
    | set_opposite_delimiter_cmd
    | spush_check_cmd
    | spop_check_cmd'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.253">def p_paint_cmd(p):
    'paint_cmd : HT_PAINT OPAREN paint_name COMMA color_sym CPAREN'
    p[0] = ['paint', {'type' : p[3], 'value' : p[5]}]

</t>
<t tx="ekr.20080121135406.254">def p_paint_name(p):
    '''paint_name : HT_INCLUDE
| HT_UPTO'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.255">def p_no_keyword_cmd(p):
    'no_keyword_cmd : HT_NOKEYWORD'
    p[0] = ['no_keyword']

</t>
<t tx="ekr.20080121135406.256">def p_at_eoltran_cmd(p):
    'at_eoltran_cmd : HT_AT_EOL opt_paren_state_name'
    p[0] = [ 'at_eol', p[2] ]

</t>
<t tx="ekr.20080121135406.257">def p_redo_cmd(p):
    'redo_cmd : HT_REDO'
    p[0] = ['redo']

</t>
<t tx="ekr.20080121135406.258">def p_clear_delimiter_cmd(p):
    'clear_delimiter_cmd : HT_CLEAR_DELIMITER'
    p[0] = ['clear_delimiter']

</t>
<t tx="ekr.20080121135406.259">def p_keep_delimiter_cmd(p):
    'keep_delimiter_cmd : HT_KEEP_DELIMITER'
    p[0] = ['keep_delimiter']

</t>
<t tx="ekr.20080121135406.260">def p_set_delimiter_cmd(p):
    'set_delimiter_cmd : HT_SET_DELIMITER opt_paren_number'
    p[0] = [p[1], p[2]]

</t>
<t tx="ekr.20080121135406.261">def p_set_opposite_delimiter_cmd(p):
    'set_opposite_delimiter_cmd : HT_SET_OPPOSITE_DELIMITER opt_paren_number'
    p[0] = [p[1], p[2]]

</t>
<t tx="ekr.20080121135406.262">def p_spush_check_cmd(p):
    'spush_check_cmd : HT_SPUSH_CHECK opt_paren_state_name'
    p[0] = [ 'spush_check', p[2] ]

</t>
<t tx="ekr.20080121135406.263">def p_opt_paren_state_name(p):
    '''opt_paren_state_name : opt_paren_state_name_1
| opt_paren_state_name_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.264">def p_opt_paren_state_name_1(p):
    'opt_paren_state_name_1 : OPAREN opt_paren_state_name CPAREN'
    p[0] = p[2]

</t>
<t tx="ekr.20080121135406.265">def p_opt_paren_state_name_2(p):
    'opt_paren_state_name_2 : state_name'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.266">def p_spop_check_cmd(p):
    'spop_check_cmd : HT_SPOP_CHECK'
    p[0] = [p[1]]

</t>
<t tx="ekr.20080121135406.267">def p_color_sym(p):
    'color_sym : LB_NAME'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.268">def p_name(p):
    'name : LB_NAME'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.269">def p_names_and_strings(p):
    '''names_and_strings : names_and_strings_1
    | names_and_strings_2'''
    p[0] = p[1]
    
</t>
<t tx="ekr.20080121135406.270">def p_names_and_strings_1(p):
    'names_and_strings_1 : names_and_strings name_or_string_opt_comma'
    p[0] = combine_filter_list(p[1], p[2])
    
</t>
<t tx="ekr.20080121135406.271">def p_names_and_strings_2(p):
    'names_and_strings_2 : empty'
    p[0] = []

</t>
<t tx="ekr.20080121135406.272">def p_name_or_string_opt_comma(p):
    '''name_or_string_opt_comma : name_or_string_opt_comma_1
| name_or_string_opt_comma_2'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.273">def p_name_or_string_opt_comma_1(p):
    'name_or_string_opt_comma_1 : name_or_string opt_comma'
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.274">def p_name_or_string_opt_comma_2(p):
    'name_or_string_opt_comma_2 : eol'
    p[0] = None

</t>
<t tx="ekr.20080121135406.275">def p_name_or_string(p):
    '''name_or_string : name
| string_const'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.276">def p_opt_paren_number(p):
    '''opt_paren_number : paren_number
| NUMBER'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.277">def p_paren_number(p):
    'paren_number : OPAREN NUMBER CPAREN'
    p[0] = p[2]

</t>
<t tx="ekr.20080121135406.278">def p_eol_seq(p):
    'eol_seq : opt_term eol'
    p[0] = None

</t>
<t tx="ekr.20080121135406.279">def p_opt_colon_eol(p):
    'opt_colon_eol : opt_colon eol'
    p[0] = None

</t>
<t tx="ekr.20080121135406.280">def p_eol(p):
    'eol : LB_NL'
    p[0] = None

</t>
<t tx="ekr.20080121135406.281">def p_opt_colon(p):
    '''opt_colon : COLON
| empty'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.282">def p_opt_comma(p):
    '''opt_comma : COMMA
| empty'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.283">def p_opt_term(p):
    '''opt_term : SCOLON
| empty'''
    p[0] = p[1]

</t>
<t tx="ekr.20080121135406.284">def p_opt_token_check(p):
    '''opt_token_check : HT_TOKEN_CHECK
| empty'''
    p[0] = (p[1] == 'token_check' and 1) or 0

</t>
<t tx="ekr.20080121135406.285">def p_empty(p):
    'empty : '
    pass
    # p[0] = None

</t>
<t tx="ekr.20080121135406.286">def p_error(p):
    global num_errs
    print "Syntax error at or near line %d, token '%s'" % (p.lexer.lineno,
                                                           p.value)
    num_errs += 1



</t>
<t tx="ekr.20080121135406.287">#---- the driver

def _wrap_read_file(fname, include_path):
    # Read in the file contents.
    if fname == '-':
        fin = sys.stdin
        s = fin.read()
    else:
        for p in [os.curdir] + include_path:
            fpath = join(p, fname)
            if exists(fpath):
                break
        else:
            raise LudditeError("`%s' does not exist on include path: '%s'"
                               % (fname, "', '".join(include_path)))
        fin = open(fpath, 'r')
        try:
            s = fin.read()
        finally:
            fin.close()
    return s

</t>
<t tx="ekr.20080121135406.288">def _read_file(fname, include_path):
    s = _wrap_read_file(fname, include_path)
    if s[-1] != "\n":
        s = s + "\n"
    return s    

</t>
<t tx="ekr.20080121135406.289">def parse_udl_path(udl_path, include_path=None, debug_level=1):
    log.debug("parse_udl_path('%s')", udl_path)
    if include_path is None:
        include_path = []

    dname = dirname(udl_path) or os.curdir
    if dname not in include_path and os.path.abspath(dname) != os.getcwd():
        include_path.append(dname)

    lexer = Lexer()
    content = _read_file(udl_path, include_path)
    lexer.input(content)

    global num_errs
    num_errs = 0
    # `write_tables=0` because we don't want 'parsetab.py' file. It can
    # cause subtle problems if the cwd changes.
    yacc.yacc(write_tables=0)
    p2 = yacc.parse(debug=debug_level, lexer=lexer)
    
    # Because 'include' is part of the language, and not a pre-processor
    # language, we need to parse each included module separately.
    if p2:
        for nodes in p2:
            if nodes[0] == 'include':
                udl_path2 = nodes[1]
                t2 = parse_udl_path(udl_path2, include_path=include_path,
                                    debug_level=debug_level)
                nodes[0] = 'module'
                nodes[1] = t2
    return p2

</t>
<t tx="ekr.20080121135406.290">"""UUID (universally unique identifiers) as specified in RFC 4122.

This module provides the UUID class and the functions uuid1(), uuid3(),
uuid4(), uuid5() for generating version 1, 3, 4, and 5 UUIDs respectively.

This module works with Python 2.3 or higher."""

__author__ = 'Ka-Ping Yee &lt;ping@zesty.ca&gt;'
__date__ = '$Date$'.split()[1].replace('/', '-')
__version__ = '$Revision$'

RESERVED_NCS, RFC_4122, RESERVED_MICROSOFT, RESERVED_FUTURE = [
    'reserved for NCS compatibility', 'specified in RFC 4122',
    'reserved for Microsoft compatibility', 'reserved for future definition']

</t>
<t tx="ekr.20080121135406.291">class UUID(object):
    """Instances of the UUID class represent UUIDs as specified in RFC 4122.
    Converting a UUID to a string using str() produces a string in the form
    "{12345678-1234-1234-1234-123456789abc}".  The UUID constructor accepts
    a similar string (braces and hyphens optional), or six integer arguments
    (with 32-bit, 16-bit, 16-bit, 8-bit, 8-bit, and 48-bit values
    respectively).  UUID objects have the following attributes:

        bytes       gets or sets the UUID as a 16-byte string

        urn         gets the UUID as a URN as specified in RFC 4122

        variant     gets or sets the UUID variant as one of the constants
                    RESERVED_NCS, RFC_4122, RESERVED_MICROSOFT, RESERVED_FUTURE

        version     gets or sets the UUID version number (1 through 5)
    """
    @others
    version = property(get_version, set_version)

</t>
<t tx="ekr.20080121135406.292">
def __init__(self, *args):
    """Create a UUID either from a string representation in hexadecimal
    or from six integers (32-bit time_low, 16-bit time_mid, 16-bit
    time_hi_ver, 8-bit clock_hi_res, 8-bit clock_low, 48-bit node)."""
    if len(args) == 1:
        digits = args[0].replace('urn:', '').replace('uuid:', '')
        digits = digits.replace('{', '').replace('}', '').replace('-', '')
        assert len(digits) == 32, ValueError('badly formed UUID string')
        time_low = int(digits[:8], 16)
        time_mid = int(digits[8:12], 16)
        time_hi_ver = int(digits[12:16], 16)
        clock_hi_res = int(digits[16:18], 16)
        clock_low = int(digits[18:20], 16)
        node = int(digits[20:32], 16)
    else:
        (time_low, time_mid, time_hi_ver,
         clock_hi_res, clock_low, node) = args
    assert 0 &lt;= time_low &lt; 0x100000000, ValueError('time_low out of range')
    assert 0 &lt;= time_mid &lt; 1&lt;&lt;16, ValueError('time_mid out of range')
    assert 0 &lt;= time_hi_ver &lt; 1&lt;&lt;16, ValueError('time_hi_ver out of range')
    assert 0 &lt;= clock_hi_res &lt; 1&lt;&lt;8, ValueError('clock_hi_res out of range')
    assert 0 &lt;= clock_low &lt; 1&lt;&lt;8, ValueError('clock_low out of range')
    assert 0 &lt;= node &lt; 0x1000000000000, ValueError('node out of range')
    self.time_low = time_low
    self.time_mid = time_mid
    self.time_hi_ver = time_hi_ver
    self.clock_hi_res = clock_hi_res
    self.clock_low = clock_low
    self.node = node

</t>
<t tx="ekr.20080121135406.293">def __cmp__(self, other):
    return cmp(self.bytes, getattr(other, 'bytes', other))

</t>
<t tx="ekr.20080121135406.294">def __str__(self):
    return '{%08x-%04x-%04x-%02x%02x-%012x}' % (
        self.time_low, self.time_mid, self.time_hi_ver,
        self.clock_hi_res, self.clock_low, self.node)

</t>
<t tx="ekr.20080121135406.295">def __repr__(self):
    return 'UUID(%r)' % str(self)

</t>
<t tx="ekr.20080121135406.296">def get_bytes(self):
    def byte(n):
        return chr(n &amp; 0xff)

    return (byte(self.time_low &gt;&gt; 24) + byte(self.time_low &gt;&gt; 16) +
            byte(self.time_low &gt;&gt; 8) + byte(self.time_low) +
            byte(self.time_mid &gt;&gt; 8) + byte(self.time_mid) +
            byte(self.time_hi_ver &gt;&gt; 8) + byte(self.time_hi_ver) +
            byte(self.clock_hi_res) + byte(self.clock_low) +
            byte(self.node &gt;&gt; 40) + byte(self.node &gt;&gt; 32) +
            byte(self.node &gt;&gt; 24) + byte(self.node &gt;&gt; 16) +
            byte(self.node &gt;&gt; 8) + byte(self.node))

</t>
<t tx="ekr.20080121135406.297">def set_bytes(self, bytes):
    values = map(ord, bytes)
    self.time_low = ((values[0] &lt;&lt; 24) + (values[1] &lt;&lt; 16) +
                     (values[2] &lt;&lt; 8) + values[3])
    self.time_mid = (values[4] &lt;&lt; 8) + values[5]
    self.time_hi_ver = (values[6] &lt;&lt; 8) + values[7]
    self.clock_hi_res = values[8]
    self.clock_low = values[9]
    self.node = ((values[10] &lt;&lt; 40) + (values[11] &lt;&lt; 32) +
                 (values[12] &lt;&lt; 24) + (values[13] &lt;&lt; 16) +
                 (values[14] &lt;&lt; 8) + values[15])

</t>
<t tx="ekr.20080121135406.298">bytes = property(get_bytes, set_bytes)

def get_urn(self):
    return 'urn:uuid:%08x-%04x-%04x-%02x%02x-%012x' % (
        self.time_low, self.time_mid, self.time_hi_ver,
        self.clock_hi_res, self.clock_low, self.node)

</t>
<t tx="ekr.20080121135406.299">urn = property(get_urn)

def get_variant(self):
    if not self.clock_hi_res &amp; 0x80:
        return RESERVED_NCS
    elif not self.clock_hi_res &amp; 0x40:
        return RFC_4122
    elif not self.clock_hi_res &amp; 0x20:
        return RESERVED_MICROSOFT
    else:
        return RESERVED_FUTURE

</t>
<t tx="ekr.20080121135406.300">def set_variant(self, variant):
    if variant == RESERVED_NCS:
        self.clock_hi_res &amp;= 0x7f
    elif variant == RFC_4122:
        self.clock_hi_res &amp;= 0x3f
        self.clock_hi_res |= 0x80
    elif variant == RESERVED_MICROSOFT:
        self.clock_hi_res &amp;= 0x1f
        self.clock_hi_res |= 0xc0
    elif variant == RESERVED_FUTURE:
        self.clock_hi_res &amp;= 0x1f
        self.clock_hi_res |= 0xe0
    else:
        raise ValueError('illegal variant identifier')

</t>
<t tx="ekr.20080121135406.301">variant = property(get_variant, set_variant)

def get_version(self):
    return self.time_hi_ver &gt;&gt; 12

</t>
<t tx="ekr.20080121135406.302">def set_version(self, version):
    assert 1 &lt;= version &lt;= 5, ValueError('illegal version number')
    self.time_hi_ver &amp;= 0x0fff
    self.time_hi_ver |= (version &lt;&lt; 12)

</t>
<t tx="ekr.20080121135406.303">def unixgetaddr(program):
    """Get the hardware address on a Unix machine."""
    from os import popen
    for line in popen(program):
        words = line.lower().split()
        if 'hwaddr' in words:
            addr = words[words.index('hwaddr') + 1]
            return int(addr.replace(':', ''), 16)
        if 'ether' in words:
            addr = words[words.index('ether') + 1]
            return int(addr.replace(':', ''), 16)

</t>
<t tx="ekr.20080121135406.304">def wingetaddr(program):
    """Get the hardware address on a Windows machine."""
    from os import popen
    for line in popen(program + ' /all'):
        if line.strip().lower().startswith('physical address'):
            addr = line.split(':')[-1].strip()
            return int(addr.replace('-', ''), 16)

</t>
<t tx="ekr.20080121135406.305">def getaddr():
    """Get the hardware address as a 48-bit integer."""
    from os.path import join, isfile
    for dir in ['/sbin', '/usr/sbin', r'c:\windows',
                r'c:\windows\system', r'c:\windows\system32']:
        if isfile(join(dir, 'ifconfig')):
            return unixgetaddr(join(dir, 'ifconfig'))
        if isfile(join(dir, 'ipconfig.exe')):
            return wingetaddr(join(dir, 'ipconfig.exe'))

</t>
<t tx="ekr.20080121135406.306">def uuid1():
    """Generate a UUID based on the time and hardware address."""
    from time import time
    from random import randrange
    nanoseconds = int(time() * 1e9)
    # 0x01b21dd213814000 is the number of 100-ns intervals between the
    # UUID epoch 1582-10-15 00:00:00 and the Unix epoch 1970-01-01 00:00:00.
    timestamp = int(nanoseconds/100) + 0x01b21dd213814000
    clock = randrange(1&lt;&lt;16) # don't use stable storage
    time_low = timestamp &amp; (0x100000000 - 1)
    time_mid = (timestamp &gt;&gt; 32) &amp; 0xffff
    time_hi_ver = (timestamp &gt;&gt; 48) &amp; 0x0fff
    clock_low = clock &amp; 0xff
    clock_hi_res = (clock &gt;&gt; 8) &amp; 0x3f
    node = getaddr()
    uuid = UUID(time_low, time_mid, time_hi_ver, clock_low, clock_hi_res, node)
    uuid.variant = RFC_4122
    uuid.version = 1
    return uuid

</t>
<t tx="ekr.20080121135406.307">def uuid3(namespace, name):
    """Generate a UUID from the MD5 hash of a namespace UUID and a name."""
    from md5 import md5
    uuid = UUID(0, 0, 0, 0, 0, 0)
    uuid.bytes = md5(namespace.bytes + name).digest()[:16]
    uuid.variant = RFC_4122
    uuid.version = 3
    return uuid

</t>
<t tx="ekr.20080121135406.308">def uuid4():
    """Generate a random UUID."""
    try:
        from os import urandom
    except:
        from random import randrange
        uuid = UUID(randrange(1&lt;&lt;32), randrange(1&lt;&lt;16), randrange(1&lt;&lt;16),
                    randrange(1&lt;&lt;8), randrange(1&lt;&lt;8), randrange(1&lt;&lt;48))
    else:
        uuid = UUID(0, 0, 0, 0, 0, 0)
        uuid.bytes = urandom(16)
    uuid.variant = RFC_4122
    uuid.version = 4
    return uuid

</t>
<t tx="ekr.20080121135406.309">def uuid5(namespace, name):
    """Generate a UUID from the SHA-1 hash of a namespace UUID and a name."""
    from sha import sha
    uuid = UUID(0, 0, 0, 0, 0, 0)
    uuid.bytes = sha(namespace.bytes + name).digest()[:16]
    uuid.variant = RFC_4122
    uuid.version = 5
    return uuid

</t>
<t tx="ekr.20080121135406.310">#-----------------------------------------------------------------------------
# ply: yacc.py
#
# Author(s): David M. Beazley (dave@dabeaz.com)
#
# Copyright (C) 2001-2006, David M. Beazley
#
# $Header$
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
# 
# See the file COPYING for a complete copy of the LGPL.
#
#
# This implements an LR parser that is constructed from grammar rules defined
# as Python functions.  Roughly speaking, this module is a cross between
# John Aycock's Spark system and the GNU bison utility.
#
# The current implementation is only somewhat object-oriented. The
# LR parser itself is defined in terms of an object (which allows multiple
# parsers to co-exist).  However, most of the variables used during table
# construction are defined in terms of global variables.  Users shouldn't
# notice unless they are trying to define multiple parsers at the same
# time using threads (in which case they should have their head examined).
#
# This implementation supports both SLR and LALR(1) parsing.  LALR(1)
# support was implemented by Elias Ioup (ezioup@alumni.uchicago.edu)
# and hacked abit by Dave to run faster.
#
# :::::::: WARNING :::::::
#
# Construction of LR parsing tables is fairly complicated and expensive.
# To make this module run fast, a *LOT* of work has been put into
# optimization---often at the expensive of readability and what might
# consider to be good Python "coding style."   Modify the code at your
# own risk!
# ----------------------------------------------------------------------------

__version__ = "1.7"

#-----------------------------------------------------------------------------
#                     === User configurable parameters ===
#
# Change these to modify the default behavior of yacc (if you wish)
#-----------------------------------------------------------------------------

yaccdebug   = 0                # Debugging mode.  If set, yacc generates a
                               # a 'parser.out' file in the current directory

debug_file  = 'parser.out'     # Default name of the debugging file
tab_module  = 'parsetab'       # Default name of the table module
default_lr  = 'SLR'            # Default LR table generation method

error_count = 3                # Number of symbols that must be shifted to leave recovery mode

import re, types, sys, cStringIO, md5, os.path

</t>
<t tx="ekr.20080121135406.311"># Exception raised for yacc-related errors
class YaccError(Exception):   pass

</t>
<t tx="ekr.20080121135406.312">#-----------------------------------------------------------------------------
#                        ===  LR Parsing Engine ===
#
# The following classes are used for the LR parser itself.  These are not
# used during table construction and are independent of the actual LR
# table generation algorithm
#-----------------------------------------------------------------------------

# This class is used to hold non-terminal grammar symbols during parsing.
# It normally has the following attributes set:
#        .type       = Grammar symbol type
#        .value      = Symbol value
#        .lineno     = Starting line number
#        .endlineno  = Ending line number (optional, set automatically)

class YaccSymbol:
    @others
</t>
<t tx="ekr.20080121135406.313">def __str__(self):    return self.type
</t>
<t tx="ekr.20080121135406.314">def __repr__(self):   return str(self)

</t>
<t tx="ekr.20080121135406.315"># This class is a wrapper around the objects actually passed to each
# grammar rule.   Index lookup and assignment actually assign the
# .value attribute of the underlying YaccSymbol object.
# The lineno() method returns the line number of a given
# item (or 0 if not defined).   The linespan() method returns
# a tuple of (startline,endline) representing the range of lines
# for a symbol.

class YaccProduction:
    @others
</t>
<t tx="ekr.20080121135406.316">def __init__(self,s):
    self.slice = s
    self.pbstack = []

</t>
<t tx="ekr.20080121135406.317">def __getitem__(self,n):
    return self.slice[n].value

</t>
<t tx="ekr.20080121135406.318">def __setitem__(self,n,v):
    self.slice[n].value = v

</t>
<t tx="ekr.20080121135406.319">def __len__(self):
    return len(self.slice)

</t>
<t tx="ekr.20080121135406.320">def lineno(self,n):
    return getattr(self.slice[n],"lineno",0)

</t>
<t tx="ekr.20080121135406.321">def linespan(self,n):
    startline = getattr(self.slice[n],"lineno",0)
    endline = getattr(self.slice[n],"endlineno",startline)
    return startline,endline

</t>
<t tx="ekr.20080121135406.322">def pushback(self,n):
    if n &lt;= 0:
        raise ValueError, "Expected a positive value"
    if n &gt; (len(self.slice)-1):
        raise ValueError, "Can't push %d tokens. Only %d are available." % (n,len(self.slice)-1)
    for i in range(0,n):
        self.pbstack.append(self.slice[-i-1])

</t>
<t tx="ekr.20080121135406.323"># The LR Parsing engine.   This is defined as a class so that multiple parsers
# can exist in the same process.  A user never instantiates this directly.
# Instead, the global yacc() function should be used to create a suitable Parser
# object. 

class Parser:
    @others
</t>
<t tx="ekr.20080121135406.324">def __init__(self,magic=None):

    # This is a hack to keep users from trying to instantiate a Parser
    # object directly.

    if magic != "xyzzy":
        raise YaccError, "Can't instantiate Parser. Use yacc() instead."

    # Reset internal state
    self.productions = None          # List of productions
    self.errorfunc   = None          # Error handling function
    self.action      = { }           # LR Action table
    self.goto        = { }           # LR goto table
    self.require     = { }           # Attribute require table
    self.method      = "Unknown LR"  # Table construction method used

</t>
<t tx="ekr.20080121135406.325">def errok(self):
    self.errorcount = 0

</t>
<t tx="ekr.20080121135406.326">def restart(self):
    del self.statestack[:]
    del self.symstack[:]
    sym = YaccSymbol()
    sym.type = '$'
    self.symstack.append(sym)
    self.statestack.append(0)
    
</t>
<t tx="ekr.20080121135406.327">def parse(self,input=None,lexer=None,debug=0):
    lookahead = None                 # Current lookahead symbol
    lookaheadstack = [ ]             # Stack of lookahead symbols
    actions = self.action            # Local reference to action table
    goto    = self.goto              # Local reference to goto table
    prod    = self.productions       # Local reference to production list
    pslice  = YaccProduction(None)   # Production object passed to grammar rules
    pslice.parser = self             # Parser object
    self.errorcount = 0              # Used during error recovery

    # If no lexer was given, we will try to use the lex module
    if not lexer:
        import lex as lexer

    pslice.lexer = lexer
    
    # If input was supplied, pass to lexer
    if input:
        lexer.input(input)

    # Tokenize function
    get_token = lexer.token

    statestack = [ ]                # Stack of parsing states
    self.statestack = statestack
    symstack   = [ ]                # Stack of grammar symbols
    self.symstack = symstack

    errtoken   = None               # Err token

    # The start state is assumed to be (0,$)
    statestack.append(0)
    sym = YaccSymbol()
    sym.type = '$'
    symstack.append(sym)
    
    while 1:
        # Get the next symbol on the input.  If a lookahead symbol
        # is already set, we just use that. Otherwise, we'll pull
        # the next token off of the lookaheadstack or from the lexer
        if not lookahead:
            if not lookaheadstack:
                lookahead = get_token()     # Get the next token
            else:
                lookahead = lookaheadstack.pop()
            if not lookahead:
                lookahead = YaccSymbol()
                lookahead.type = '$'
        if debug:
            errorlead = ("%s . %s" % (" ".join([xx.type for xx in symstack][1:]), str(lookahead))).lstrip()

        # Check the action table
        s = statestack[-1]
        ltype = lookahead.type
        t = actions.get((s,ltype),None)

        if t is not None:
            if t &gt; 0:
                # shift a symbol on the stack
                if ltype == '$':
                    # Error, end of input
                    sys.stderr.write("yacc: Parse error. EOF\n")
                    return
                statestack.append(t)
                if debug &gt; 1:
                    sys.stderr.write("%-60s shift state %s\n" % (errorlead, t))
                symstack.append(lookahead)
                lookahead = None

                # Decrease error count on successful shift
                if self.errorcount &gt; 0:
                    self.errorcount -= 1
                    
                continue
            
            if t &lt; 0:
                # reduce a symbol on the stack, emit a production
                p = prod[-t]
                pname = p.name
                plen  = p.len

                # Get production function
                sym = YaccSymbol()
                sym.type = pname       # Production name
                sym.value = None
                if debug &gt; 1:
                    sys.stderr.write("%-60s reduce %d\n" % (errorlead, -t))

                if plen:
                    targ = symstack[-plen-1:]
                    targ[0] = sym
                    try:
                        sym.lineno = targ[1].lineno
                        sym.endlineno = getattr(targ[-1],"endlineno",targ[-1].lineno)
                    except AttributeError:
                        sym.lineno = 0
                    del symstack[-plen:]
                    del statestack[-plen:]
                else:
                    sym.lineno = 0
                    targ = [ sym ]
                pslice.slice = targ
                pslice.pbstack = []
                # Call the grammar rule with our special slice object
                p.func(pslice)

                # If there was a pushback, put that on the stack
                if pslice.pbstack:
                    lookaheadstack.append(lookahead)
                    for _t in pslice.pbstack:
                        lookaheadstack.append(_t)
                    lookahead = None

                symstack.append(sym)
                statestack.append(goto[statestack[-1],pname])
                continue

            if t == 0:
                n = symstack[-1]
                return getattr(n,"value",None)
                sys.stderr.write(errorlead, "\n")

        if t == None:
            if debug:
                sys.stderr.write(errorlead + "\n")
            # We have some kind of parsing error here.  To handle
            # this, we are going to push the current token onto
            # the tokenstack and replace it with an 'error' token.
            # If there are any synchronization rules, they may
            # catch it.
            #
            # In addition to pushing the error token, we call call
            # the user defined p_error() function if this is the
            # first syntax error.  This function is only called if
            # errorcount == 0.
            if not self.errorcount:
                self.errorcount = error_count
                errtoken = lookahead
                if errtoken.type == '$':
                    errtoken = None               # End of file!
                if self.errorfunc:
                    global errok,token,restart
                    errok = self.errok        # Set some special functions available in error recovery
                    token = get_token
                    restart = self.restart
                    tok = self.errorfunc(errtoken)
                    del errok, token, restart   # Delete special functions
                    
                    if not self.errorcount:
                        # User must have done some kind of panic
                        # mode recovery on their own.  The
                        # returned token is the next lookahead
                        lookahead = tok
                        errtoken = None
                        continue
                else:
                    if errtoken:
                        if hasattr(errtoken,"lineno"): lineno = lookahead.lineno
                        else: lineno = 0
                        if lineno:
                            sys.stderr.write("yacc: Syntax error at line %d, token=%s\n" % (lineno, errtoken.type))
                        else:
                            sys.stderr.write("yacc: Syntax error, token=%s" % errtoken.type)
                    else:
                        sys.stderr.write("yacc: Parse error in input. EOF\n")
                        return

            else:
                self.errorcount = error_count
            
            # case 1:  the statestack only has 1 entry on it.  If we're in this state, the
            # entire parse has been rolled back and we're completely hosed.   The token is
            # discarded and we just keep going.

            if len(statestack) &lt;= 1 and lookahead.type != '$':
                lookahead = None
                errtoken = None
                # Nuke the pushback stack
                del lookaheadstack[:]
                continue

            # case 2: the statestack has a couple of entries on it, but we're
            # at the end of the file. nuke the top entry and generate an error token

            # Start nuking entries on the stack
            if lookahead.type == '$':
                # Whoa. We're really hosed here. Bail out
                return 

            if lookahead.type != 'error':
                sym = symstack[-1]
                if sym.type == 'error':
                    # Hmmm. Error is on top of stack, we'll just nuke input
                    # symbol and continue
                    lookahead = None
                    continue
                t = YaccSymbol()
                t.type = 'error'
                if hasattr(lookahead,"lineno"):
                    t.lineno = lookahead.lineno
                t.value = lookahead
                lookaheadstack.append(lookahead)
                lookahead = t
            else:
                symstack.pop()
                statestack.pop()

            continue

        # Call an error function here
        raise RuntimeError, "yacc: internal parser error!!!\n"

</t>
<t tx="ekr.20080121135406.328"># -----------------------------------------------------------------------------
#                          === Parser Construction ===
#
# The following functions and variables are used to implement the yacc() function
# itself.   This is pretty hairy stuff involving lots of error checking,
# construction of LR items, kernels, and so forth.   Although a lot of
# this work is done using global variables, the resulting Parser object
# is completely self contained--meaning that it is safe to repeatedly
# call yacc() with different grammars in the same application.
# -----------------------------------------------------------------------------
        
# -----------------------------------------------------------------------------
# validate_file()
#
# This function checks to see if there are duplicated p_rulename() functions
# in the parser module file.  Without this function, it is really easy for
# users to make mistakes by cutting and pasting code fragments (and it's a real
# bugger to try and figure out why the resulting parser doesn't work).  Therefore,
# we just do a little regular expression pattern matching of def statements
# to try and detect duplicates.
# -----------------------------------------------------------------------------

def validate_file(filename):
    base,ext = os.path.splitext(filename)
    if ext != '.py': return 1          # No idea. Assume it's okay.

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return 1                       # Oh well

    # Match def p_funcname(
    fre = re.compile(r'\s*def\s+(p_[a-zA-Z_0-9]*)\(')
    counthash = { }
    linen = 1
    noerror = 1
    for l in lines:
        m = fre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                sys.stderr.write("%s:%d: Function %s redefined. Previously defined on line %d\n" % (filename,linen,name,prev))
                noerror = 0
        linen += 1
    return noerror

</t>
<t tx="ekr.20080121135406.329"># This function looks for functions that might be grammar rules, but which don't have the proper p_suffix.
def validate_dict(d):
    for n,v in d.items(): 
        if n[0:2] == 'p_' and type(v) in (types.FunctionType, types.MethodType): continue
        if n[0:2] == 't_': continue

        if n[0:2] == 'p_':
            sys.stderr.write("yacc: Warning. '%s' not defined as a function\n" % n)
        if 1 and isinstance(v,types.FunctionType) and v.func_code.co_argcount == 1:
            try:
                doc = v.__doc__.split(" ")
                if doc[1] == ':':
                    sys.stderr.write("%s:%d: Warning. Possible grammar rule '%s' defined without p_ prefix.\n" % (v.func_code.co_filename, v.func_code.co_firstlineno,n))
            except StandardError:
                pass

</t>
<t tx="ekr.20080121135406.330"># -----------------------------------------------------------------------------
#                           === GRAMMAR FUNCTIONS ===
#
# The following global variables and functions are used to store, manipulate,
# and verify the grammar rules specified by the user.
# -----------------------------------------------------------------------------

# Initialize all of the global variables used during grammar construction
def initialize_vars():
    global Productions, Prodnames, Prodmap, Terminals 
    global Nonterminals, First, Follow, Precedence, LRitems
    global Errorfunc, Signature, Requires

    # LALR(1) globals
    global Prodempty, TReductions, NTReductions, GotoSetNum, Canonical
    
    Productions  = [None]  # A list of all of the productions.  The first
                           # entry is always reserved for the purpose of
                           # building an augmented grammar
                        
    Prodnames    = { }     # A dictionary mapping the names of nonterminals to a list of all
                           # productions of that nonterminal.
                        
    Prodmap      = { }     # A dictionary that is only used to detect duplicate
                           # productions.

    Terminals    = { }     # A dictionary mapping the names of terminal symbols to a
                           # list of the rules where they are used.

    Nonterminals = { }     # A dictionary mapping names of nonterminals to a list
                           # of rule numbers where they are used.

    First        = { }     # A dictionary of precomputed FIRST(x) symbols
    
    Follow       = { }     # A dictionary of precomputed FOLLOW(x) symbols

    Precedence   = { }     # Precedence rules for each terminal. Contains tuples of the
                           # form ('right',level) or ('nonassoc', level) or ('left',level)

    LRitems      = [ ]     # A list of all LR items for the grammar.  These are the
                           # productions with the "dot" like E -&gt; E . PLUS E

    Errorfunc    = None    # User defined error handler

    Signature    = md5.new()   # Digital signature of the grammar rules, precedence
                               # and other information.  Used to determined when a
                               # parsing table needs to be regenerated.

    Requires     = { }     # Requires list

    # LALR(1) Initialization
    Prodempty    = { }     # A dictionary of all productions that have an empty rule
                           # of the form P : &lt;empty&gt;

    TReductions  = { }     # A dictionary of precomputer reductions from
                           # nonterminals to terminals

    NTReductions = { }     # A dictionary of precomputed reductions from
                           # nonterminals to nonterminals

    GotoSetNum   = { }     # A dictionary that remembers goto sets based on
                           # the state number and symbol

    Canonical    = { }     # A list of LR item sets. A LR item set is a list of LR
                           # items that represent the state of the parser

    # File objects used when creating the parser.out debugging file
    global _vf, _vfc
    _vf           = cStringIO.StringIO()
    _vfc          = cStringIO.StringIO()

</t>
<t tx="ekr.20080121135406.331"># -----------------------------------------------------------------------------
# class Production:
#
# This class stores the raw information about a single production or grammar rule.
# It has a few required attributes:
#
#       name     - Name of the production (nonterminal)
#       prod     - A list of symbols making up its production
#       number   - Production number.
#
# In addition, a few additional attributes are used to help with debugging or
# optimization of table generation.
#
#       file     - File where production action is defined.
#       lineno   - Line number where action is defined
#       func     - Action function
#       prec     - Precedence level
#       lr_next  - Next LR item. Example, if we are ' E -&gt; E . PLUS E'
#                  then lr_next refers to 'E -&gt; E PLUS . E'   
#       lr_index - LR item index (location of the ".") in the prod list.
#       lookaheads - LALR lookahead symbols for this item
#       len      - Length of the production (number of symbols on right hand side)
# -----------------------------------------------------------------------------

class Production:
    @others
</t>
<t tx="ekr.20080121135406.332">def __init__(self,**kw):
    for k,v in kw.items():
        setattr(self,k,v)
    self.lr_index = -1
    self.lr0_added = 0    # Flag indicating whether or not added to LR0 closure
    self.lr1_added = 0    # Flag indicating whether or not added to LR1
    self.usyms = [ ]
    self.lookaheads = { }
    self.lk_added = { }
    self.setnumbers = [ ]
    
</t>
<t tx="ekr.20080121135406.333">def __str__(self):
    if self.prod:
        s = "%s -&gt; %s" % (self.name," ".join(self.prod))
    else:
        s = "%s -&gt; &lt;empty&gt;" % self.name
    return s

</t>
<t tx="ekr.20080121135406.334">def __repr__(self):
    return str(self)

</t>
<t tx="ekr.20080121135406.335"># Compute lr_items from the production
def lr_item(self,n):
    if n &gt; len(self.prod): return None
    p = Production()
    p.name = self.name
    p.prod = list(self.prod)
    p.number = self.number
    p.lr_index = n
    p.lookaheads = { }
    p.setnumbers = self.setnumbers
    p.prod.insert(n,".")
    p.prod = tuple(p.prod)
    p.len = len(p.prod)
    p.usyms = self.usyms

    # Precompute list of productions immediately following
    try:
        p.lrafter = Prodnames[p.prod[n+1]]
    except (IndexError,KeyError),e:
        p.lrafter = []
    try:
        p.lrbefore = p.prod[n-1]
    except IndexError:
        p.lrbefore = None

    return p

</t>
<t tx="ekr.20080121135406.336">class MiniProduction:
    pass

</t>
<t tx="ekr.20080121135406.337"># Utility function
def is_identifier(s):
    for c in s:
        if not (c.isalnum() or c == '_'): return 0
    return 1

</t>
<t tx="ekr.20080121135406.338"># -----------------------------------------------------------------------------
# add_production()
#
# Given an action function, this function assembles a production rule.
# The production rule is assumed to be found in the function's docstring.
# This rule has the general syntax:
#
#              name1 ::= production1
#                     |  production2
#                     |  production3
#                    ...
#                     |  productionn
#              name2 ::= production1
#                     |  production2
#                    ... 
# -----------------------------------------------------------------------------

def add_production(f,file,line,prodname,syms):
    
    if Terminals.has_key(prodname):
        sys.stderr.write("%s:%d: Illegal rule name '%s'. Already defined as a token.\n" % (file,line,prodname))
        return -1
    if prodname == 'error':
        sys.stderr.write("%s:%d: Illegal rule name '%s'. error is a reserved word.\n" % (file,line,prodname))
        return -1
                
    if not is_identifier(prodname):
        sys.stderr.write("%s:%d: Illegal rule name '%s'\n" % (file,line,prodname))
        return -1

    for s in syms:
        if not is_identifier(s) and s != '%prec':
            sys.stderr.write("%s:%d: Illegal name '%s' in rule '%s'\n" % (file,line,s, prodname))
            return -1

    # See if the rule is already in the rulemap
    map = "%s -&gt; %s" % (prodname,syms)
    if Prodmap.has_key(map):
        m = Prodmap[map]
        sys.stderr.write("%s:%d: Duplicate rule %s.\n" % (file,line, m))
        sys.stderr.write("%s:%d: Previous definition at %s:%d\n" % (file,line, m.file, m.line))
        return -1

    p = Production()
    p.name = prodname
    p.prod = syms
    p.file = file
    p.line = line
    p.func = f
    p.number = len(Productions)

            
    Productions.append(p)
    Prodmap[map] = p
    if not Nonterminals.has_key(prodname):
        Nonterminals[prodname] = [ ]
    
    # Add all terminals to Terminals
    i = 0
    while i &lt; len(p.prod):
        t = p.prod[i]
        if t == '%prec':
            try:
                precname = p.prod[i+1]
            except IndexError:
                sys.stderr.write("%s:%d: Syntax error. Nothing follows %%prec.\n" % (p.file,p.line))
                return -1

            prec = Precedence.get(precname,None)
            if not prec:
                sys.stderr.write("%s:%d: Nothing known about the precedence of '%s'\n" % (p.file,p.line,precname))
                return -1
            else:
                p.prec = prec
            del p.prod[i]
            del p.prod[i]
            continue

        if Terminals.has_key(t):
            Terminals[t].append(p.number)
            # Is a terminal.  We'll assign a precedence to p based on this
            if not hasattr(p,"prec"):
                p.prec = Precedence.get(t,('right',0))
        else:
            if not Nonterminals.has_key(t):
                Nonterminals[t] = [ ]
            Nonterminals[t].append(p.number)
        i += 1

    if not hasattr(p,"prec"):
        p.prec = ('right',0)
        
    # Set final length of productions
    p.len  = len(p.prod)
    p.prod = tuple(p.prod)

    # Calculate unique syms in the production
    p.usyms = [ ]
    for s in p.prod:
        if s not in p.usyms:
            p.usyms.append(s)
    
    # Add to the global productions list
    try:
        Prodnames[p.name].append(p)
    except KeyError:
        Prodnames[p.name] = [ p ]
    return 0

</t>
<t tx="ekr.20080121135406.339"># Given a raw rule function, this function rips out its doc string
# and adds rules to the grammar

def add_function(f):
    line = f.func_code.co_firstlineno
    file = f.func_code.co_filename
    error = 0

    if isinstance(f,types.MethodType):
        reqdargs = 2
    else:
        reqdargs = 1
        
    if f.func_code.co_argcount &gt; reqdargs:
        sys.stderr.write("%s:%d: Rule '%s' has too many arguments.\n" % (file,line,f.__name__))
        return -1

    if f.func_code.co_argcount &lt; reqdargs:
        sys.stderr.write("%s:%d: Rule '%s' requires an argument.\n" % (file,line,f.__name__))
        return -1
          
    if f.__doc__:
        # Split the doc string into lines
        pstrings = f.__doc__.splitlines()
        lastp = None
        dline = line
        for ps in pstrings:
            dline += 1
            p = ps.split()
            if not p: continue
            try:
                if p[0] == '|':
                    # This is a continuation of a previous rule
                    if not lastp:
                        sys.stderr.write("%s:%d: Misplaced '|'.\n" % (file,dline))
                        return -1
                    prodname = lastp
                    if len(p) &gt; 1:
                        syms = p[1:]
                    else:
                        syms = [ ]
                else:
                    prodname = p[0]
                    lastp = prodname
                    assign = p[1]
                    if len(p) &gt; 2:
                        syms = p[2:]
                    else:
                        syms = [ ]
                    if assign != ':' and assign != '::=':
                        sys.stderr.write("%s:%d: Syntax error. Expected ':'\n" % (file,dline))
                        return -1
                e = add_production(f,file,dline,prodname,syms)
                error += e
            except StandardError:
                sys.stderr.write("%s:%d: Syntax error in rule '%s'\n" % (file,dline,ps))
                error -= 1
    else:
        sys.stderr.write("%s:%d: No documentation string specified in function '%s'\n" % (file,line,f.__name__))
    return error


</t>
<t tx="ekr.20080121135406.340"># Cycle checking code (Michael Dyck)

def compute_reachable():
    '''
    Find each symbol that can be reached from the start symbol.
    Print a warning for any nonterminals that can't be reached.
    (Unused terminals have already had their warning.)
    '''
    Reachable = { }
    for s in Terminals.keys() + Nonterminals.keys():
        Reachable[s] = 0

    mark_reachable_from( Productions[0].prod[0], Reachable )

    for s in Nonterminals.keys():
        if not Reachable[s]:
            sys.stderr.write("yacc: Symbol '%s' is unreachable.\n" % s)

</t>
<t tx="ekr.20080121135406.341">def mark_reachable_from(s, Reachable):
    '''
    Mark all symbols that are reachable from symbol s.
    '''
    if Reachable[s]:
        # We've already reached symbol s.
        return
    Reachable[s] = 1
    for p in Prodnames.get(s,[]):
        for r in p.prod:
            mark_reachable_from(r, Reachable)

</t>
<t tx="ekr.20080121135406.342"># -----------------------------------------------------------------------------
# compute_terminates()
#
# This function looks at the various parsing rules and tries to detect
# infinite recursion cycles (grammar rules where there is no possible way
# to derive a string of only terminals).
# -----------------------------------------------------------------------------
def compute_terminates():
    '''
    Raise an error for any symbols that don't terminate.
    '''
    Terminates = {}

    # Terminals:
    for t in Terminals.keys():
        Terminates[t] = 1

    Terminates['$'] = 1

    # Nonterminals:

    # Initialize to false:
    for n in Nonterminals.keys():
        Terminates[n] = 0

    # Then propagate termination until no change:
    while 1:
        some_change = 0
        for (n,pl) in Prodnames.items():
            # Nonterminal n terminates iff any of its productions terminates.
            for p in pl:
                # Production p terminates iff all of its rhs symbols terminate.
                for s in p.prod:
                    if not Terminates[s]:
                        # The symbol s does not terminate,
                        # so production p does not terminate.
                        p_terminates = 0
                        break
                else:
                    # didn't break from the loop,
                    # so every symbol s terminates
                    # so production p terminates.
                    p_terminates = 1

                if p_terminates:
                    # symbol n terminates!
                    if not Terminates[n]:
                        Terminates[n] = 1
                        some_change = 1
                    # Don't need to consider any more productions for this n.
                    break

        if not some_change:
            break

    some_error = 0
    for (s,terminates) in Terminates.items():
        if not terminates:
            if not Prodnames.has_key(s) and not Terminals.has_key(s) and s != 'error':
                # s is used-but-not-defined, and we've already warned of that,
                # so it would be overkill to say that it's also non-terminating.
                pass
            else:
                sys.stderr.write("yacc: Infinite recursion detected for symbol '%s'.\n" % s)
                some_error = 1

    return some_error

</t>
<t tx="ekr.20080121135406.343"># -----------------------------------------------------------------------------
# verify_productions()
#
# This function examines all of the supplied rules to see if they seem valid.
# -----------------------------------------------------------------------------
def verify_productions(cycle_check=1):
    error = 0
    for p in Productions:
        if not p: continue

        for s in p.prod:
            if not Prodnames.has_key(s) and not Terminals.has_key(s) and s != 'error':
                sys.stderr.write("%s:%d: Symbol '%s' used, but not defined as a token or a rule.\n" % (p.file,p.line,s))
                error = 1
                continue

    unused_tok = 0 
    # Now verify all of the tokens
    if yaccdebug:
        _vf.write("Unused terminals:\n\n")
    for s,v in Terminals.items():
        if s != 'error' and not v:
            sys.stderr.write("yacc: Warning. Token '%s' defined, but not used.\n" % s)
            if yaccdebug: _vf.write("   %s\n"% s)
            unused_tok += 1

    # Print out all of the productions
    if yaccdebug:
        _vf.write("\nGrammar\n\n")
        for i in range(1,len(Productions)):
            _vf.write("Rule %-5d %s\n" % (i, Productions[i]))
        
    unused_prod = 0
    # Verify the use of all productions
    for s,v in Nonterminals.items():
        if not v:
            p = Prodnames[s][0]
            sys.stderr.write("%s:%d: Warning. Rule '%s' defined, but not used.\n" % (p.file,p.line, s))
            unused_prod += 1

    
    if unused_tok == 1:
        sys.stderr.write("yacc: Warning. There is 1 unused token.\n")
    if unused_tok &gt; 1:
        sys.stderr.write("yacc: Warning. There are %d unused tokens.\n" % unused_tok)

    if unused_prod == 1:
        sys.stderr.write("yacc: Warning. There is 1 unused rule.\n")
    if unused_prod &gt; 1:
        sys.stderr.write("yacc: Warning. There are %d unused rules.\n" % unused_prod)

    if yaccdebug:
        _vf.write("\nTerminals, with rules where they appear\n\n")
        ks = Terminals.keys()
        ks.sort()
        for k in ks:
            _vf.write("%-20s : %s\n" % (k, " ".join([str(s) for s in Terminals[k]])))
        _vf.write("\nNonterminals, with rules where they appear\n\n")
        ks = Nonterminals.keys()
        ks.sort()
        for k in ks:
            _vf.write("%-20s : %s\n" % (k, " ".join([str(s) for s in Nonterminals[k]])))

    if (cycle_check):
        compute_reachable()
        error += compute_terminates()
        # error += check_cycles()
    return error

</t>
<t tx="ekr.20080121135406.344"># -----------------------------------------------------------------------------
# build_lritems()
#
# This function walks the list of productions and builds a complete set of the
# LR items.  The LR items are stored in two ways:  First, they are uniquely
# numbered and placed in the list _lritems.  Second, a linked list of LR items
# is built for each production.  For example:
#
#   E -&gt; E PLUS E
#
# Creates the list
#
#  [E -&gt; . E PLUS E, E -&gt; E . PLUS E, E -&gt; E PLUS . E, E -&gt; E PLUS E . ] 
# -----------------------------------------------------------------------------

def build_lritems():
    for p in Productions:
        lastlri = p
        lri = p.lr_item(0)
        i = 0
        while 1:
            lri = p.lr_item(i)
            lastlri.lr_next = lri
            if not lri: break
            lri.lr_num = len(LRitems)
            LRitems.append(lri)
            lastlri = lri
            i += 1

    # In order for the rest of the parser generator to work, we need to
    # guarantee that no more lritems are generated.  Therefore, we nuke
    # the p.lr_item method.  (Only used in debugging)
    # Production.lr_item = None

</t>
<t tx="ekr.20080121135406.345"># -----------------------------------------------------------------------------
# add_precedence()
#
# Given a list of precedence rules, add to the precedence table.
# -----------------------------------------------------------------------------

def add_precedence(plist):
    plevel = 0
    error = 0
    for p in plist:
        plevel += 1
        try:
            prec = p[0]
            terms = p[1:]
            if prec != 'left' and prec != 'right' and prec != 'nonassoc':
                sys.stderr.write("yacc: Invalid precedence '%s'\n" % prec)
                return -1
            for t in terms:
                if Precedence.has_key(t):
                    sys.stderr.write("yacc: Precedence already specified for terminal '%s'\n" % t)
                    error += 1
                    continue
                Precedence[t] = (prec,plevel)
        except:
            sys.stderr.write("yacc: Invalid precedence table.\n")
            error += 1

    return error

</t>
<t tx="ekr.20080121135406.346"># -----------------------------------------------------------------------------
# augment_grammar()
#
# Compute the augmented grammar.  This is just a rule S' -&gt; start where start
# is the starting symbol.
# -----------------------------------------------------------------------------

def augment_grammar(start=None):
    if not start:
        start = Productions[1].name
    Productions[0] = Production(name="S'",prod=[start],number=0,len=1,prec=('right',0),func=None)
    Productions[0].usyms = [ start ]
    Nonterminals[start].append(0)


</t>
<t tx="ekr.20080121135406.347"># -------------------------------------------------------------------------
# first()
#
# Compute the value of FIRST1(beta) where beta is a tuple of symbols.
#
# During execution of compute_first1, the result may be incomplete.
# Afterward (e.g., when called from compute_follow()), it will be complete.
# -------------------------------------------------------------------------
def first(beta):

    # We are computing First(x1,x2,x3,...,xn)
    result = [ ]
    for x in beta:
        x_produces_empty = 0

        # Add all the non-&lt;empty&gt; symbols of First[x] to the result.
        for f in First[x]:
            if f == '&lt;empty&gt;':
                x_produces_empty = 1
            else:
                if f not in result: result.append(f)

        if x_produces_empty:
            # We have to consider the next x in beta,
            # i.e. stay in the loop.
            pass
        else:
            # We don't have to consider any further symbols in beta.
            break
    else:
        # There was no 'break' from the loop,
        # so x_produces_empty was true for all x in beta,
        # so beta produces empty as well.
        result.append('&lt;empty&gt;')

    return result


</t>
<t tx="ekr.20080121135406.348"># FOLLOW(x)
# Given a non-terminal.  This function computes the set of all symbols
# that might follow it.  Dragon book, p. 189.

def compute_follow(start=None):
    # Add '$' to the follow list of the start symbol
    for k in Nonterminals.keys():
        Follow[k] = [ ]

    if not start:
        start = Productions[1].name
        
    Follow[start] = [ '$' ]
        
    while 1:
        didadd = 0
        for p in Productions[1:]:
            # Here is the production set
            for i in range(len(p.prod)):
                B = p.prod[i]
                if Nonterminals.has_key(B):
                    # Okay. We got a non-terminal in a production
                    fst = first(p.prod[i+1:])
                    hasempty = 0
                    for f in fst:
                        if f != '&lt;empty&gt;' and f not in Follow[B]:
                            Follow[B].append(f)
                            didadd = 1
                        if f == '&lt;empty&gt;':
                            hasempty = 1
                    if hasempty or i == (len(p.prod)-1):
                        # Add elements of follow(a) to follow(b)
                        for f in Follow[p.name]:
                            if f not in Follow[B]:
                                Follow[B].append(f)
                                didadd = 1
        if not didadd: break

    if 0 and yaccdebug:
        _vf.write('\nFollow:\n')
        for k in Nonterminals.keys():
            _vf.write("%-20s : %s\n" % (k, " ".join([str(s) for s in Follow[k]])))

</t>
<t tx="ekr.20080121135406.349"># -------------------------------------------------------------------------
# compute_first1()
#
# Compute the value of FIRST1(X) for all symbols
# -------------------------------------------------------------------------
def compute_first1():

    # Terminals:
    for t in Terminals.keys():
        First[t] = [t]

    First['$'] = ['$']
    First['#'] = ['#'] # what's this for?

    # Nonterminals:

    # Initialize to the empty set:
    for n in Nonterminals.keys():
        First[n] = []

    # Then propagate symbols until no change:
    while 1:
        some_change = 0
        for n in Nonterminals.keys():
            for p in Prodnames[n]:
                for f in first(p.prod):
                    if f not in First[n]:
                        First[n].append( f )
                        some_change = 1
        if not some_change:
            break

    if 0 and yaccdebug:
        _vf.write('\nFirst:\n')
        for k in Nonterminals.keys():
            _vf.write("%-20s : %s\n" %
                (k, " ".join([str(s) for s in First[k]])))

</t>
<t tx="ekr.20080121135406.350"># -----------------------------------------------------------------------------
#                           === SLR Generation ===
#
# The following functions are used to construct SLR (Simple LR) parsing tables
# as described on p.221-229 of the dragon book.
# -----------------------------------------------------------------------------

# Global variables for the LR parsing engine
def lr_init_vars():
    global _lr_action, _lr_goto, _lr_method
    global _lr_goto_cache, _lr0_cidhash
    
    _lr_action       = { }        # Action table
    _lr_goto         = { }        # Goto table
    _lr_method       = "Unknown"  # LR method used
    _lr_goto_cache   = { }
    _lr0_cidhash     = { }


</t>
<t tx="ekr.20080121135406.351"># Compute the LR(0) closure operation on I, where I is a set of LR(0) items.
# prodlist is a list of productions.

_add_count = 0       # Counter used to detect cycles

def lr0_closure(I):
    global _add_count
    
    _add_count += 1
    prodlist = Productions
    
    # Add everything in I to J        
    J = I[:]
    didadd = 1
    while didadd:
        didadd = 0
        for j in J:
            for x in j.lrafter:
                if x.lr0_added == _add_count: continue
                # Add B --&gt; .G to J
                J.append(x.lr_next)
                x.lr0_added = _add_count
                didadd = 1
               
    return J

</t>
<t tx="ekr.20080121135406.352"># Compute the LR(0) goto function goto(I,X) where I is a set
# of LR(0) items and X is a grammar symbol.   This function is written
# in a way that guarantees uniqueness of the generated goto sets
# (i.e. the same goto set will never be returned as two different Python
# objects).  With uniqueness, we can later do fast set comparisons using
# id(obj) instead of element-wise comparison.

def lr0_goto(I,x):
    # First we look for a previously cached entry
    g = _lr_goto_cache.get((id(I),x),None)
    if g: return g

    # Now we generate the goto set in a way that guarantees uniqueness
    # of the result
    
    s = _lr_goto_cache.get(x,None)
    if not s:
        s = { }
        _lr_goto_cache[x] = s

    gs = [ ]
    for p in I:
        n = p.lr_next
        if n and n.lrbefore == x:
            s1 = s.get(id(n),None)
            if not s1:
                s1 = { }
                s[id(n)] = s1
            gs.append(n)
            s = s1
    g = s.get('$',None)
    if not g:
        if gs:
            g = lr0_closure(gs)
            s['$'] = g
        else:
            s['$'] = gs
    _lr_goto_cache[(id(I),x)] = g
    return g

</t>
<t tx="ekr.20080121135406.353"># Added for LALR(1)

# Given a setnumber of an lr0 state and a symbol return the setnumber of the goto state 
def lr0_goto_setnumber(I_setnumber, x):
    global Canonical
    global GotoSetNum

    if GotoSetNum.has_key((I_setnumber, x)):
        setnumber = GotoSetNum[(I_setnumber, x)]
    else:
        gset = lr0_goto(Canonical[I_setnumber], x)
        if not gset:
            return -1
        else:
            gsetlen = len(gset)            
            for i in xrange(len(gset[0].setnumbers)):
                inall = 1
                for item in gset:
                    if not item.setnumbers[i]:
                        inall = 0
                        break
                if inall and len(Canonical[i]) == gsetlen:
                    setnumber = i
                    break          # Note: DB. I added this to improve performance.
                                   # Not sure if this breaks the algorithm (it doesn't appear to).

            GotoSetNum[(I_setnumber, x)] = setnumber
            
    return setnumber

</t>
<t tx="ekr.20080121135406.354"># Compute the kernel of a set of LR(0) items
def lr0_kernel(I):
    KI = [ ]
    for p in I:
        if p.name == "S'" or p.lr_index &gt; 0 or p.len == 0:
            KI.append(p)

    return KI

</t>
<t tx="ekr.20080121135406.355">_lr0_cidhash = { }

# Compute the LR(0) sets of item function
def lr0_items():
    
    C = [ lr0_closure([Productions[0].lr_next]) ]
    i = 0
    for I in C:
        _lr0_cidhash[id(I)] = i
        i += 1

    # Loop over the items in C and each grammar symbols
    i = 0
    while i &lt; len(C):
        I = C[i]
        i += 1

        # Collect all of the symbols that could possibly be in the goto(I,X) sets
        asyms = { }
        for ii in I:
            for s in ii.usyms:
                asyms[s] = None

        for x in asyms.keys():
            g = lr0_goto(I,x)
            if not g:  continue
            if _lr0_cidhash.has_key(id(g)): continue
            _lr0_cidhash[id(g)] = len(C)            
            C.append(g)
            
    return C

</t>
<t tx="ekr.20080121135406.356"># -----------------------------------------------------------------------------
# slr_parse_table()
#
# This function constructs an SLR table.
# -----------------------------------------------------------------------------
def slr_parse_table():
    global _lr_method
    goto = _lr_goto           # Goto array
    action = _lr_action       # Action array
    actionp = { }             # Action production array (temporary)

    _lr_method = "SLR"
    
    n_srconflict = 0
    n_rrconflict = 0

    if yaccdebug:
        sys.stderr.write("yacc: Generating SLR parsing table...\n")        
        _vf.write("\n\nParsing method: SLR\n\n")
        
    # Step 1: Construct C = { I0, I1, ... IN}, collection of LR(0) items
    # This determines the number of states
    
    C = lr0_items()

    # Build the parser table, state by state
    st = 0
    for I in C:
        # Loop over each production in I
        actlist = [ ]              # List of actions
        
        if yaccdebug:
            _vf.write("\nstate %d\n\n" % st)
            for p in I:
                _vf.write("    (%d) %s\n" % (p.number, str(p)))
            _vf.write("\n")

        for p in I:
            try:
                if p.prod[-1] == ".":
                    if p.name == "S'":
                        # Start symbol. Accept!
                        action[st,"$"] = 0
                        actionp[st,"$"] = p
                    else:
                        # We are at the end of a production.  Reduce!
                        for a in Follow[p.name]:
                            actlist.append((a,p,"reduce using rule %d (%s)" % (p.number,p)))
                            r = action.get((st,a),None)
                            if r is not None:
                                # Whoa. Have a shift/reduce or reduce/reduce conflict
                                if r &gt; 0:
                                    # Need to decide on shift or reduce here
                                    # By default we favor shifting. Need to add
                                    # some precedence rules here.
                                    sprec,slevel = Productions[actionp[st,a].number].prec                                    
                                    rprec,rlevel = Precedence.get(a,('right',0))
                                    if (slevel &lt; rlevel) or ((slevel == rlevel) and (rprec == 'left')):
                                        # We really need to reduce here.  
                                        action[st,a] = -p.number
                                        actionp[st,a] = p
                                        if not slevel and not rlevel:
                                            _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                            n_srconflict += 1
                                    elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                        action[st,a] = None
                                    else:
                                        # Hmmm. Guess we'll keep the shift
                                        if not slevel and not rlevel:
                                            _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                            n_srconflict +=1                                    
                                elif r &lt; 0:
                                    # Reduce/reduce conflict.   In this case, we favor the rule
                                    # that was defined first in the grammar file
                                    oldp = Productions[-r]
                                    pp = Productions[p.number]
                                    if oldp.line &gt; pp.line:
                                        action[st,a] = -p.number
                                        actionp[st,a] = p
                                    # sys.stderr.write("Reduce/reduce conflict in state %d\n" % st)
                                    n_rrconflict += 1
                                    _vfc.write("reduce/reduce conflict in state %d resolved using rule %d (%s).\n" % (st, actionp[st,a].number, actionp[st,a]))
                                    _vf.write("  ! reduce/reduce conflict for %s resolved using rule %d (%s).\n" % (a,actionp[st,a].number, actionp[st,a]))
                                else:
                                    sys.stderr.write("Unknown conflict in state %d\n" % st)
                            else:
                                action[st,a] = -p.number
                                actionp[st,a] = p
                else:
                    i = p.lr_index
                    a = p.prod[i+1]       # Get symbol right after the "."
                    if Terminals.has_key(a):
                        g = lr0_goto(I,a)
                        j = _lr0_cidhash.get(id(g),-1)
                        if j &gt;= 0:
                            # We are in a shift state
                            actlist.append((a,p,"shift and go to state %d" % j))
                            r = action.get((st,a),None)
                            if r is not None:
                                # Whoa have a shift/reduce or shift/shift conflict
                                if r &gt; 0:
                                    if r != j:
                                        sys.stderr.write("Shift/shift conflict in state %d\n" % st)
                                elif r &lt; 0:
                                    # Do a precedence check.
                                    #   -  if precedence of reduce rule is higher, we reduce.
                                    #   -  if precedence of reduce is same and left assoc, we reduce.
                                    #   -  otherwise we shift
                                    rprec,rlevel = Productions[actionp[st,a].number].prec
                                    sprec,slevel = Precedence.get(a,('right',0))
                                    if (slevel &gt; rlevel) or ((slevel == rlevel) and (rprec != 'left')):
                                        # We decide to shift here... highest precedence to shift
                                        action[st,a] = j
                                        actionp[st,a] = p
                                        if not slevel and not rlevel:
                                            n_srconflict += 1
                                            _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                    elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                        action[st,a] = None
                                    else:                                            
                                        # Hmmm. Guess we'll keep the reduce
                                        if not slevel and not rlevel:
                                            n_srconflict +=1
                                            _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                            
                                else:
                                    sys.stderr.write("Unknown conflict in state %d\n" % st)
                            else:
                                action[st,a] = j
                                actionp[st,a] = p
                                
            except StandardError,e:
                raise YaccError, "Hosed in slr_parse_table", e

        # Print the actions associated with each terminal
        if yaccdebug:
          _actprint = { }
          for a,p,m in actlist:
            if action.has_key((st,a)):
                if p is actionp[st,a]:
                    _vf.write("    %-15s %s\n" % (a,m))
                    _actprint[(a,m)] = 1
          _vf.write("\n")
          for a,p,m in actlist:
            if action.has_key((st,a)):
                if p is not actionp[st,a]:
                    if not _actprint.has_key((a,m)):
                        _vf.write("  ! %-15s [ %s ]\n" % (a,m))
                        _actprint[(a,m)] = 1
            
        # Construct the goto table for this state
        if yaccdebug:
            _vf.write("\n")
        nkeys = { }
        for ii in I:
            for s in ii.usyms:
                if Nonterminals.has_key(s):
                    nkeys[s] = None
        for n in nkeys.keys():
            g = lr0_goto(I,n)
            j = _lr0_cidhash.get(id(g),-1)            
            if j &gt;= 0:
                goto[st,n] = j
                if yaccdebug:
                    _vf.write("    %-30s shift and go to state %d\n" % (n,j))

        st += 1

    if yaccdebug:
        if n_srconflict == 1:
            sys.stderr.write("yacc: %d shift/reduce conflict\n" % n_srconflict)
        if n_srconflict &gt; 1:
            sys.stderr.write("yacc: %d shift/reduce conflicts\n" % n_srconflict)
        if n_rrconflict == 1:
            sys.stderr.write("yacc: %d reduce/reduce conflict\n" % n_rrconflict)
        if n_rrconflict &gt; 1:
            sys.stderr.write("yacc: %d reduce/reduce conflicts\n" % n_rrconflict)



</t>
<t tx="ekr.20080121135406.357"># -----------------------------------------------------------------------------
#                       ==== LALR(1) Parsing ====
# FINISHED!  5/20/2003 by Elias Ioup
# -----------------------------------------------------------------------------


# Compute the lr1_closure of a set I.  I is a list of productions and setnumber
# is the state that you want the lr items that are made from the to come from.

_lr1_add_count = 0

def lr1_closure(I, setnumber = 0):
    global _add_count
    global Nonterminals

    _add_count += 1
    prodlist = Productions

    # Add everything in I to J        
    J = I[:]
    Jhash = { }
    for j in J:
        Jhash[id(j)] = 1
        
    didadd = 1
    while didadd:
        didadd = 0
        for j in J:
            jprod = j.prod
            jlr_index = j.lr_index
            jprodslice = jprod[jlr_index+2:]
            
            if jlr_index &lt; len(jprod) - 1 and Nonterminals.has_key(jprod[jlr_index+1]):
                first_syms = []

                if j.lk_added.setdefault(setnumber, 0) &lt; len(j.lookaheads[setnumber]): 
                    for a in j.lookaheads[setnumber][j.lk_added[setnumber]:]: 
                        # find b in FIRST(Xa) if j = [A-&gt;a.BX,a]
                        temp_first_syms = first(jprodslice + (a,))
                        for x in temp_first_syms:
                            if x not in first_syms:
                                first_syms.append(x)

                j.lk_added[setnumber] = len(j.lookaheads[setnumber]) 

                for x in j.lrafter:
                    
                    # Add B --&gt; .G to J
                    if x.lr_next.lookaheads.has_key(setnumber):
                        _xlook = x.lr_next.lookaheads[setnumber]                        
                        for s in first_syms:
                            if s not in _xlook:
                                _xlook.append(s)
                                didadd = 1
                    else:        
                        x.lr_next.lookaheads[setnumber] = first_syms
                        didadd = 1

                    nid = id(x.lr_next)
                    if not Jhash.has_key(nid):
                        J.append(x.lr_next)
                        Jhash[nid] = 1
                        
    return J

</t>
<t tx="ekr.20080121135406.358">def add_lookaheads(K):
    spontaneous = []
    propogate = []

    for setnumber in range(len(K)):
        for kitem in K[setnumber]:
            kitem.lookaheads[setnumber] = ['#']
            J = lr1_closure([kitem], setnumber)

            # find the lookaheads that are spontaneously created from closures
            # and the propogations of lookaheads between lr items
            for item in J:
                if item.lr_index &lt; len(item.prod)-1:
                    for lookahead in item.lookaheads[setnumber]:
                        goto_setnumber = lr0_goto_setnumber(setnumber, item.prod[item.lr_index+1]) 
                        next = None 
                        if lookahead != '#':
                            if item.lr_next in K[goto_setnumber]:
                                next = item.lr_next
                            if next:
                                spontaneous.append((next, (lookahead, goto_setnumber)))
                        else:
                            if goto_setnumber &gt; -1:
                                if item.lr_next in K[goto_setnumber]:
                                    next = item.lr_next
                                    
                            if next:
                                propogate.append(((kitem, setnumber), (next, goto_setnumber)))

        

        for x in K[setnumber]:
            x.lookaheads[setnumber] = []

    for x in spontaneous:
        if x[1][0] not in x[0].lookaheads[x[1][1]]:
            x[0].lookaheads[x[1][1]].append(x[1][0])

    K[0][0].lookaheads[0] = ['$']

    pitems = {}
    for x in propogate:
        if pitems.has_key(x[0]):
            pitems[x[0]].append(x[1])
        else:
            pitems[x[0]] = []
            pitems[x[0]].append(x[1])
            
    # propogate the lookaheads that were spontaneously generated
    # based on the propogations produced above
    stop = 0

    while not stop:
        stop = 1
        kindex = 0
        for set in K:
            for item in set:
                pkey = (item, kindex)
                if pitems.has_key(pkey):
                    for propogation in pitems[pkey]:
                        gitem = propogation[0]
                        gsetnumber = propogation[1]
                        glookaheads = gitem.lookaheads[gsetnumber]
                        for lookahead in item.lookaheads[kindex]:
                            if lookahead not in glookaheads:
                                glookaheads.append(lookahead)
                                stop = 0
            kindex += 1

</t>
<t tx="ekr.20080121135406.359">def ReduceNonterminals():
    global Nonterminals

    global TReductions
    global NTReductions

    for nt in Nonterminals.keys():
        TReductions[nt] = []
        NTReductions[nt] = []
        
    for nt in Nonterminals.keys():
        terms = ReduceToTerminals(nt)
        TReductions[nt].extend(terms)
        if not NTReductions.has_key(nt):
            ReduceToNonterminals(nt)
        


</t>
<t tx="ekr.20080121135406.360">def ReduceToTerminals(nt,cyclemap=None):
    global Prodnames
    global Terminals
    reducedterminals = []
    if not cyclemap: cyclemap = {}

    if cyclemap.has_key(nt): return []
    cyclemap[nt] = 1

    for p in Prodnames[nt]:
        if len(p.prod) &gt; 0:
            if Terminals.has_key(p.prod[0]):
                if p.prod[0] not in reducedterminals:
                    reducedterminals.append(p.prod[0])
            else:
                if p.prod[0] != nt:
                    terms = ReduceToTerminals(p.prod[0],cyclemap)
                    for t in terms:
                        if t not in reducedterminals:
                            reducedterminals.append(t)
    del cyclemap[nt]			  
    return reducedterminals

            
</t>
<t tx="ekr.20080121135406.361">def ReduceToNonterminals(nt):
    global Prodnames
    global Nonterminals
    global NTReductions
    reducednonterminals = []

    for p in Prodnames[nt]:
        if len(p.prod) &gt; 0:
            if Nonterminals.has_key(p.prod[0]):
                if p.prod[0] not in reducednonterminals:
                    reducednonterminals.append(p.prod[0])
                    if p.prod[0] != nt:
                        if not NTReductions.has_key(p.prod[0]):
                            ReduceToNonterminals(p.prod[0])
                        
                        nterms = NTReductions[p.prod[0]]
                        for nt in nterms:
                            if nt not in reducednonterminals:
                                reducednonterminals.append(nt)
                            

    NTReductions[nt] = reducednonterminals

</t>
<t tx="ekr.20080121135406.362"># -----------------------------------------------------------------------------
# lalr_parse_table()
#
# This function constructs an LALR table.
# -----------------------------------------------------------------------------
def lalr_parse_table():
    global _lr_method
    goto = _lr_goto           # Goto array
    action = _lr_action       # Action array
    actionp = { }             # Action production array (temporary)
    goto_cache = _lr_goto_cache
    cid_hash = _lr0_cidhash
    
    _lr_method = "LALR"
    
    n_srconflict = 0
    n_rrconflict = 0

    if yaccdebug:
        sys.stderr.write("yacc: Generating LALR(1) parsing table...\n")
        _vf.write("\n\nParsing method: LALR(1)\n\n")
        
    # Step 1: Construct C = { I0, I1, ... IN}, collection of LR(0) items
    # This determines the number of states

    C = lr0_items()

    global Canonical
    Canonical = C

    ###
    # Create the kernel states.
    ###
    K = []
    setC = [0]*len(C)
    for x in C:
        K.append(lr0_kernel(x))
        for y in x:
            y.setnumbers = setC[:]

    _cindex = 0
    for x in C:
        for y in x:
            y.lookaheads[_cindex] = [] 
            y.setnumbers[_cindex] = 1
        _cindex = _cindex + 1

    ###
    # Add lookaheads to the lr items
    ###

    add_lookaheads(K)

    ###
    # Do the reductions for parsing first and keep them in globals
    ###

    ReduceNonterminals()

    global TReductions
    global NTReductions
    global Prodempty

    EmptyAncestors = {}
    for y in Prodempty.keys():
        EmptyAncestors[y] = []
    for x in NTReductions.items():
        for y in x[1]:
            if Prodempty.has_key(y):
                EmptyAncestors[y].append(x[0])


    # Build the parser table, state by state
    st = 0
    for I in C:
        # Loop over each production in I
        actlist = [ ]              # List of actions
        acthash = { }
        
        idI = id(I)
        
        if yaccdebug:
            _vf.write("\nstate %d\n\n" % st)
            for p in I:
                _vf.write("    (%d) %s\n" % (p.number, str(p)))
            _vf.write("\n")

        global First
        for p in I:
            try:
                if p.prod[-1] == ".":
                    if p.name == "S'":
                        # Start symbol. Accept!
                        action[st,"$"] = 0
                        actionp[st,"$"] = p
                    elif len(p.prod) == 0:
                        ancestors = EmptyAncestors[p.name]
                        for i in ancestors:
                            for s in K:
                                if i in s:
                                    input_list = []
                                    plist = Productions[i.name]
                                    for x in plist:
                                        if len(x.prod) &gt; 0 and x.prod[0] == p.name:
                                            n = p.prod[1:]
                                            d = x.prod[lr_index+2:]
                                            for l in x.lookaheads.items():
                                                flist = First[tuple(n+d+[l])]
                                                for f in flist:
                                                    if f not in input_list and f in p.lookaheads[st]:
                                                        input_list.append(f)
                                        
                                    # We are at the end of a production.  Reduce!
                                    #print "input_list: %s" % input_list
                                    #print "Follow[p.name]: %s" % Follow[p.name]
                                    for a in input_list:
                                        actlist.append((a,p,"reduce using rule %d (%s) " % (p.number,p)))
                                        r = action.get((st,a),None)
                                        if r is not None:
                                            # Whoa. Have a shift/reduce or reduce/reduce conflict
                                            if r &gt; 0:
                                                # Need to decide on shift or reduce here
                                                # By default we favor shifting. Need to add
                                                # some precedence rules here.
                                                sprec,slevel = Productions[actionp[st,a].number].prec                                    
                                                rprec,rlevel = Precedence.get(a,('right',0))
                                                if (slevel &lt; rlevel) or ((slevel == rlevel) and (rprec == 'left')):
                                                    # We really need to reduce here.  
                                                    action[st,a] = -p.number
                                                    actionp[st,a] = p
                                                    if not slevel and not rlevel:
                                                        _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                                        _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                                        n_srconflict += 1
                                                elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                                    action[st,a] = None
                                                else:
                                                    # Hmmm. Guess we'll keep the shift
                                                    if not slevel and not rlevel:
                                                        _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                                        _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                                        n_srconflict +=1                                    
                                            elif r &lt; 0:
                                                # Reduce/reduce conflict.   In this case, we favor the rule
                                                # that was defined first in the grammar file
                                                oldp = Productions[-r]
                                                pp = Productions[p.number]
                                                if oldp.line &gt; pp.line:
                                                    action[st,a] = -p.number
                                                    actionp[st,a] = p
                                                    # print "Reduce/reduce conflict in state %d" % st
                                                    n_rrconflict += 1
                                                    _vfc.write("reduce/reduce conflict in state %d resolved using rule %d.\n" % (st, actionp[st,a].number))
                                                    _vf.write("  ! reduce/reduce conflict for %s resolved using rule %d.\n" % (a,actionp[st,a].number))
                                            else:
                                                sys.stderr.write("Unknown conflict in state %d\n" % st)
                                        else:
                                            action[st,a] = -p.number
                                            actionp[st,a] = p

                                    break           # break out of the for s in K loop because we only want to make
                                                    # sure that a production is in the Kernel
                        
                    else:
                        # We are at the end of a production.  Reduce!

                        for a in p.lookaheads[st]:
                            actlist.append((a,p,"reduce using rule %d (%s)" % (p.number,p)))
                            r = action.get((st,a),None)
                            if r is not None:
                                # Whoa. Have a shift/reduce or reduce/reduce conflict
                                if r &gt; 0:
                                    # Need to decide on shift or reduce here
                                    # By default we favor shifting. Need to add
                                    # some precedence rules here.
                                    sprec,slevel = Productions[actionp[st,a].number].prec                                    
                                    rprec,rlevel = Precedence.get(a,('right',0))                                    
                                    if (slevel &lt; rlevel) or ((slevel == rlevel) and (rprec == 'left')):
                                        # We really need to reduce here.  
                                        action[st,a] = -p.number
                                        actionp[st,a] = p
                                        if not slevel and not rlevel:
                                            _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                            n_srconflict += 1
                                    elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                        action[st,a] = None
                                    else:
                                        # Hmmm. Guess we'll keep the shift
                                        if not slevel and not rlevel:
                                            _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                            n_srconflict +=1                                    
                                elif r &lt; 0:
                                    # Reduce/reduce conflict.   In this case, we favor the rule
                                    # that was defined first in the grammar file
                                    oldp = Productions[-r]
                                    pp = Productions[p.number]
                                    if oldp.line &gt; pp.line:
                                        action[st,a] = -p.number
                                        actionp[st,a] = p
                                    # print "Reduce/reduce conflict in state %d" % st
                                    n_rrconflict += 1
                                    _vfc.write("reduce/reduce conflict in state %d resolved using rule %d.\n" % (st, actionp[st,a].number))
                                    _vf.write("  ! reduce/reduce conflict for %s resolved using rule %d.\n" % (a,actionp[st,a].number))
                                else:
                                    print "Unknown conflict in state %d" % st
                            else:
                                action[st,a] = -p.number
                                actionp[st,a] = p
                else:
                    i = p.lr_index
                    a = p.prod[i+1]       # Get symbol right after the "."
                    if Terminals.has_key(a):
                        g = goto_cache[(idI,a)]
                        j = cid_hash.get(id(g),-1)
                        if j &gt;= 0:
                            # We are in a shift state
                            _k = (a,j)
                            if not acthash.has_key(_k):
                                actlist.append((a,p,"shift and go to state %d" % j))
                                acthash[_k] = 1
                            r = action.get((st,a),None)
                            if r is not None:
                                # Whoa have a shift/reduce or shift/shift conflict
                                if r &gt; 0:
                                    if r != j:
                                        sys.stderr.write("Shift/shift conflict in state %d\n" % st)
                                elif r &lt; 0:
                                    # Do a precedence check.
                                    #   -  if precedence of reduce rule is higher, we reduce.
                                    #   -  if precedence of reduce is same and left assoc, we reduce.
                                    #   -  otherwise we shift
                                    rprec,rlevel = Productions[actionp[st,a].number].prec
                                    sprec,slevel = Precedence.get(a,('right',0))
                                    if (slevel &gt; rlevel) or ((slevel == rlevel) and (rprec != 'left')):
                                        # We decide to shift here... highest precedence to shift
                                        action[st,a] = j
                                        actionp[st,a] = p
                                        if not slevel and not rlevel:
                                            n_srconflict += 1
                                            _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                    elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                        action[st,a] = None
                                    else:                                            
                                        # Hmmm. Guess we'll keep the reduce
                                        if not slevel and not rlevel:
                                            n_srconflict +=1
                                            _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                            _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                            
                                else:
                                    sys.stderr.write("Unknown conflict in state %d\n" % st)
                            else:
                                action[st,a] = j
                                actionp[st,a] = p
                    else:
                        nonterminal = a
                        term_list = TReductions[nonterminal]
                        # DB: This loop gets executed a lot.  Try to optimize
                        for a in term_list:
                            g = goto_cache[(idI,a)]
                            j = cid_hash[id(g)]
                            if j &gt;= 0:
                                # We are in a shift state
                                # Don't put repeated shift actions on action list (performance hack)
                                _k = (a,j)
                                if not acthash.has_key(_k):
                                    actlist.append((a,p,"shift and go to state "+str(j)))
                                    acthash[_k] = 1
                                    
                                r = action.get((st,a),None)
                                if r is not None:
                                    # Whoa have a shift/reduce or shift/shift conflict
                                    if r &gt; 0:
                                        if r != j:
                                            sys.stderr.write("Shift/shift conflict in state %d\n" % st)
                                        continue
                                    elif r &lt; 0:
                                        # Do a precedence check.
                                        #   -  if precedence of reduce rule is higher, we reduce.
                                        #   -  if precedence of reduce is same and left assoc, we reduce.
                                        #   -  otherwise we shift
                                        rprec,rlevel = Productions[actionp[st,a].number].prec
                                        sprec,slevel = Precedence.get(a,('right',0))
                                        if (slevel &gt; rlevel) or ((slevel == rlevel) and (rprec != 'left')):
                                            # We decide to shift here... highest precedence to shift
                                            action[st,a] = j
                                            actionp[st,a] = p
                                            if not slevel and not rlevel:
                                                n_srconflict += 1
                                                _vfc.write("shift/reduce conflict in state %d resolved as shift.\n" % st)
                                                _vf.write("  ! shift/reduce conflict for %s resolved as shift.\n" % a)
                                        elif (slevel == rlevel) and (rprec == 'nonassoc'):
                                            action[st,a] = None
                                        else:                                            
                                            # Hmmm. Guess we'll keep the reduce
                                            if not slevel and not rlevel:
                                                n_srconflict +=1
                                                _vfc.write("shift/reduce conflict in state %d resolved as reduce.\n" % st)
                                                _vf.write("  ! shift/reduce conflict for %s resolved as reduce.\n" % a)
                                            
                                    else:
                                        sys.stderr.write("Unknown conflict in state %d\n" % st)
                                else:
                                    action[st,a] = j
                                    actionp[st,a] = p
                    
            except StandardError,e:
                raise YaccError, "Hosed in lalr_parse_table", e

        # Print the actions associated with each terminal
        if yaccdebug:
          for a,p,m in actlist:
            if action.has_key((st,a)):
                if p is actionp[st,a]:
                    _vf.write("    %-15s %s\n" % (a,m))
          _vf.write("\n")

          for a,p,m in actlist:
            if action.has_key((st,a)):
                if p is not actionp[st,a]:
                    _vf.write("  ! %-15s [ %s ]\n" % (a,m))
            
        # Construct the goto table for this state
        nkeys = { }
        for ii in I:
            for s in ii.usyms:
                if Nonterminals.has_key(s):
                    nkeys[s] = None

        # Construct the goto table for this state
        for n in nkeys.keys():
            g = lr0_goto(I,n)
            j = cid_hash.get(id(g),-1)            
            if j &gt;= 0:
                goto[st,n] = j
                if yaccdebug:
                    _vf.write("    %-30s shift and go to state %d\n" % (n,j))

        st += 1
    if yaccdebug:
        if n_srconflict == 1:
            sys.stderr.write("yacc: %d shift/reduce conflict\n" % n_srconflict)
        if n_srconflict &gt; 1:
            sys.stderr.write("yacc: %d shift/reduce conflicts\n" % n_srconflict)        
        if n_rrconflict == 1:
            sys.stderr.write("yacc: %d reduce/reduce conflict\n" % n_rrconflict)
        if n_rrconflict &gt; 1:
            sys.stderr.write("yacc: %d reduce/reduce conflicts\n" % n_rrconflict)

    
</t>
<t tx="ekr.20080121135406.363"># -----------------------------------------------------------------------------
#                          ==== LR Utility functions ====
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# _lr_write_tables()
#
# This function writes the LR parsing tables to a file
# -----------------------------------------------------------------------------

def lr_write_tables(modulename=tab_module,outputdir=''):
    filename = os.path.join(outputdir,modulename) + ".py"
    try:
        f = open(filename,"w")

        f.write("""
# %s
# This file is automatically generated. Do not edit.

_lr_method = %s

_lr_signature = %s
""" % (filename, repr(_lr_method), repr(Signature.digest())))

        # Change smaller to 0 to go back to original tables
        smaller = 1
                
        # Factor out names to try and make smaller
        if smaller:
            items = { }
        
            for k,v in _lr_action.items():
                i = items.get(k[1])
                if not i:
                    i = ([],[])
                    items[k[1]] = i
                i[0].append(k[0])
                i[1].append(v)

            f.write("\n_lr_action_items = {")
            for k,v in items.items():
                f.write("%r:([" % k)
                for i in v[0]:
                    f.write("%r," % i)
                f.write("],[")
                for i in v[1]:
                    f.write("%r," % i)
                           
                f.write("]),")
            f.write("}\n")

            f.write("""
_lr_action = { }
for _k, _v in _lr_action_items.items():
   for _x,_y in zip(_v[0],_v[1]):
       _lr_action[(_x,_k)] = _y
del _lr_action_items
""")
            
        else:
            f.write("\n_lr_action = { ");
            for k,v in _lr_action.items():
                f.write("(%r,%r):%r," % (k[0],k[1],v))
            f.write("}\n");

        if smaller:
            # Factor out names to try and make smaller
            items = { }
        
            for k,v in _lr_goto.items():
                i = items.get(k[1])
                if not i:
                    i = ([],[])
                    items[k[1]] = i
                i[0].append(k[0])
                i[1].append(v)

            f.write("\n_lr_goto_items = {")
            for k,v in items.items():
                f.write("%r:([" % k)
                for i in v[0]:
                    f.write("%r," % i)
                f.write("],[")
                for i in v[1]:
                    f.write("%r," % i)
                           
                f.write("]),")
            f.write("}\n")

            f.write("""
_lr_goto = { }
for _k, _v in _lr_goto_items.items():
   for _x,_y in zip(_v[0],_v[1]):
       _lr_goto[(_x,_k)] = _y
del _lr_goto_items
""")
        else:
            f.write("\n_lr_goto = { ");
            for k,v in _lr_goto.items():
                f.write("(%r,%r):%r," % (k[0],k[1],v))                    
            f.write("}\n");

        # Write production table
        f.write("_lr_productions = [\n")
        for p in Productions:
            if p:
                if (p.func):
                    f.write("  (%r,%d,%r,%r,%d),\n" % (p.name, p.len, p.func.__name__,p.file,p.line))
                else:
                    f.write("  (%r,%d,None,None,None),\n" % (p.name, p.len))
            else:
                f.write("  None,\n")
        f.write("]\n")
        f.close()

    except IOError,e:
        print "Unable to create '%s'" % filename
        print e
        return

</t>
<t tx="ekr.20080121135406.364">def lr_read_tables(module=tab_module,optimize=0):
    global _lr_action, _lr_goto, _lr_productions, _lr_method
    try:
        exec "import %s as parsetab" % module
        
        if (optimize) or (Signature.digest() == parsetab._lr_signature):
            _lr_action = parsetab._lr_action
            _lr_goto   = parsetab._lr_goto
            _lr_productions = parsetab._lr_productions
            _lr_method = parsetab._lr_method
            return 1
        else:
            return 0
        
    except (ImportError,AttributeError):
        return 0


</t>
<t tx="ekr.20080121135406.365"># Available instance types.  This is used when parsers are defined by a class.
# it's a little funky because I want to preserve backwards compatibility
# with Python 2.0 where types.ObjectType is undefined.

try:
   _INSTANCETYPE = (types.InstanceType, types.ObjectType)
except AttributeError:
   _INSTANCETYPE = types.InstanceType

# -----------------------------------------------------------------------------
# yacc(module)
#
# Build the parser module
# -----------------------------------------------------------------------------

def yacc(method=default_lr, debug=yaccdebug, module=None, tabmodule=tab_module, start=None, check_recursion=1, optimize=0,write_tables=1,debugfile=debug_file,outputdir=''):
    global yaccdebug
    yaccdebug = debug
    
    initialize_vars()
    files = { }
    error = 0

    # Add starting symbol to signature
    if start:
        Signature.update(start)

    # Add parsing method to signature
    Signature.update(method)
    
    # If a "module" parameter was supplied, extract its dictionary.
    # Note: a module may in fact be an instance as well.
    
    if module:
        # User supplied a module object.
        if isinstance(module, types.ModuleType):
            ldict = module.__dict__
        elif isinstance(module, _INSTANCETYPE):
            _items = [(k,getattr(module,k)) for k in dir(module)]
            ldict = { }
            for i in _items:
                ldict[i[0]] = i[1]
        else:
            raise ValueError,"Expected a module"
        
    else:
        # No module given.  We might be able to get information from the caller.
        # Throw an exception and unwind the traceback to get the globals
        
        try:
            raise RuntimeError
        except RuntimeError:
            e,b,t = sys.exc_info()
            f = t.tb_frame
            f = f.f_back           # Walk out to our calling function
            ldict = f.f_globals    # Grab its globals dictionary

    # If running in optimized mode.  We're going to

    if (optimize and lr_read_tables(tabmodule,1)):
        # Read parse table
        del Productions[:]
        for p in _lr_productions:
            if not p:
                Productions.append(None)
            else:
                m = MiniProduction()
                m.name = p[0]
                m.len  = p[1]
                m.file = p[3]
                m.line = p[4]
                if p[2]:
                    m.func = ldict[p[2]]
                Productions.append(m)
        
    else:
        # Get the tokens map
        if (module and isinstance(module,_INSTANCETYPE)):
            tokens = getattr(module,"tokens",None)
        else:
            tokens = ldict.get("tokens",None)
    
        if not tokens:
            raise YaccError,"module does not define a list 'tokens'"
        if not (isinstance(tokens,types.ListType) or isinstance(tokens,types.TupleType)):
            raise YaccError,"tokens must be a list or tuple."

        # Check to see if a requires dictionary is defined.
        requires = ldict.get("require",None)
        if requires:
            if not (isinstance(requires,types.DictType)):
                raise YaccError,"require must be a dictionary."

            for r,v in requires.items():
                try:
                    if not (isinstance(v,types.ListType)):
                        raise TypeError
                    v1 = [x.split(".") for x in v]
                    Requires[r] = v1
                except StandardError:
                    print "Invalid specification for rule '%s' in require. Expected a list of strings" % r            

        
        # Build the dictionary of terminals.  We a record a 0 in the
        # dictionary to track whether or not a terminal is actually
        # used in the grammar

        if 'error' in tokens:
            print "yacc: Illegal token 'error'.  Is a reserved word."
            raise YaccError,"Illegal token name"

        for n in tokens:
            if Terminals.has_key(n):
                print "yacc: Warning. Token '%s' multiply defined." % n
            Terminals[n] = [ ]

        Terminals['error'] = [ ]

        # Get the precedence map (if any)
        prec = ldict.get("precedence",None)
        if prec:
            if not (isinstance(prec,types.ListType) or isinstance(prec,types.TupleType)):
                raise YaccError,"precedence must be a list or tuple."
            add_precedence(prec)
            Signature.update(repr(prec))

        for n in tokens:
            if not Precedence.has_key(n):
                Precedence[n] = ('right',0)         # Default, right associative, 0 precedence

        # Look for error handler
        ef = ldict.get('p_error',None)
        if ef:
            if isinstance(ef,types.FunctionType):
                ismethod = 0
            elif isinstance(ef, types.MethodType):
                ismethod = 1
            else:
                raise YaccError,"'p_error' defined, but is not a function or method."                
            eline = ef.func_code.co_firstlineno
            efile = ef.func_code.co_filename
            files[efile] = None

            if (ef.func_code.co_argcount != 1+ismethod):
                raise YaccError,"%s:%d: p_error() requires 1 argument." % (efile,eline)
            global Errorfunc
            Errorfunc = ef
        else:
            print "yacc: Warning. no p_error() function is defined."
            
        # Get the list of built-in functions with p_ prefix
        symbols = [ldict[f] for f in ldict.keys()
               if (type(ldict[f]) in (types.FunctionType, types.MethodType) and ldict[f].__name__[:2] == 'p_'
                   and ldict[f].__name__ != 'p_error')]

        # Check for non-empty symbols
        if len(symbols) == 0:
            raise YaccError,"no rules of the form p_rulename are defined."
    
        # Sort the symbols by line number
        symbols.sort(lambda x,y: cmp(x.func_code.co_firstlineno,y.func_code.co_firstlineno))

        # Add all of the symbols to the grammar
        for f in symbols:
            if (add_function(f)) &lt; 0:
                error += 1
            else:
                files[f.func_code.co_filename] = None

        # Make a signature of the docstrings
        for f in symbols:
            if f.__doc__:
                Signature.update(f.__doc__)
    
        lr_init_vars()

        if error:
            raise YaccError,"Unable to construct parser."

        if not lr_read_tables(tabmodule):

            # Validate files
            for filename in files.keys():
                if not validate_file(filename):
                    error = 1

            # Validate dictionary
            validate_dict(ldict)

            if start and not Prodnames.has_key(start):
                raise YaccError,"Bad starting symbol '%s'" % start
        
            augment_grammar(start)    
            error = verify_productions(cycle_check=check_recursion)
            otherfunc = [ldict[f] for f in ldict.keys()
               if (type(f) in (types.FunctionType,types.MethodType) and ldict[f].__name__[:2] != 'p_')]

            if error:
                raise YaccError,"Unable to construct parser."
            
            build_lritems()
            compute_first1()
            compute_follow(start)
        
            if method == 'SLR':
                slr_parse_table()
            elif method == 'LALR':
                lalr_parse_table()
            else:
                raise YaccError, "Unknown parsing method '%s'" % method

            if write_tables:
                lr_write_tables(tabmodule,outputdir)        
    
            if yaccdebug:
                try:
                    f = open(os.path.join(outputdir,debugfile),"w")
                    f.write(_vfc.getvalue())
                    f.write("\n\n")
                    f.write(_vf.getvalue())
                    f.close()
                except IOError,e:
                    print "yacc: can't create '%s'" % debugfile,e
        
    # Made it here.   Create a parser object and set up its internal state.
    # Set global parse() method to bound method of parser object.

    p = Parser("xyzzy")
    p.productions = Productions
    p.errorfunc = Errorfunc
    p.action = _lr_action
    p.goto   = _lr_goto
    p.method = _lr_method
    p.require = Requires

    global parse
    parse = p.parse

    # Clean up all of the globals we created
    if (not optimize):
        yacc_cleanup()
    return p

</t>
<t tx="ekr.20080121135406.366"># yacc_cleanup function.  Delete all of the global variables
# used during table construction

def yacc_cleanup():
    global _lr_action, _lr_goto, _lr_method, _lr_goto_cache
    del _lr_action, _lr_goto, _lr_method, _lr_goto_cache

    global Productions, Prodnames, Prodmap, Terminals 
    global Nonterminals, First, Follow, Precedence, LRitems
    global Errorfunc, Signature, Requires
    global Prodempty, TReductions, NTReductions, GotoSetNum, Canonical
    
    del Productions, Prodnames, Prodmap, Terminals
    del Nonterminals, First, Follow, Precedence, LRitems
    del Errorfunc, Signature, Requires
    del Prodempty, TReductions, NTReductions, GotoSetNum, Canonical
    
    global _vf, _vfc
    del _vf, _vfc
    
    
</t>
<t tx="ekr.20080121135406.367"># Stub that raises an error if parsing is attempted without first calling yacc()
def parse(*args,**kwargs):
    raise YaccError, "yacc: No parser built with yacc()"

</t>
<t tx="ekr.20080121140752"># Version: MPL 1.1/GPL 2.0/LGPL 2.1
# 
# The contents of this file are subject to the Mozilla Public License
# Version 1.1 (the "License"); you may not use this file except in
# compliance with the License. You may obtain a copy of the License at
# http://www.mozilla.org/MPL/
# 
# Software distributed under the License is distributed on an "AS IS"
# basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
# License for the specific language governing rights and limitations
# under the License.
# 
# The Original Code is Komodo code.
# 
# The Initial Developer of the Original Code is ActiveState Software Inc.
# Portions created by ActiveState Software Inc are Copyright (C) 2000-2007
# ActiveState Software Inc. All Rights Reserved.
# 
# Contributor(s):
#   ActiveState Software Inc
# 
# Alternatively, the contents of this file may be used under the terms of
# either the GNU General Public License Version 2 or later (the "GPL"), or
# the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),
# in which case the provisions of the GPL or the LGPL are applicable instead
# of those above. If you wish to allow use of your version of this file only
# under the terms of either the GPL or the LGPL, and not to allow others to
# use your version of this file under the terms of the MPL, indicate your
# decision by deleting the provisions above and replace them with the notice
# and other provisions required by the GPL or the LGPL. If you do not delete
# the provisions above, a recipient may use your version of this file under
# the terms of any one of the MPL, the GPL or the LGPL.
# 
# ***** END LICENSE BLOCK *****</t>
<t tx="ekr.20080121142959.1">def addKomodoPaths ():

    '''Add paths to sys.path so Komodo imports will work.'''

    # Do not import sys: we must use the global
    import os
    baseDir = r'C:\Program Files\Komodo Edit 4.3'
    paths = (
        r'lib\mozilla\python\komodo', # For ciElementree.pyd
        r'lib\mozilla\python\komodo\codeintel2',
        r'lib\mozilla\python\komodo\codeintel2\catalogs',
        r'lib\mozilla\python\komodo\codeintel2\database',
        r'lib\mozilla\python\komodo\codeintel2\stdlibs',
    )
    for path in paths:
        path = os.path.join(baseDir,path)
        if path in sys.path:
            pass
        elif os.path.exists(path):
            sys.path.append(path)
        else:
            g.es_print('Does not exist: %s' % path)
</t>
<t tx="ekr.20080121143612">import sys

@others

addKomodoPaths()

&lt;&lt; imports &gt;&gt;

m = openManager()
print 'm',m
db = openDatabase(m)
print 'db',db
</t>
<t tx="ekr.20080121150435">def openManager():

    return manager.Manager(
        db_base_dir=None,
        on_scan_complete=None,
        langs=None,
        extra_lang_module_dirs=None,
        env=None,
        db_event_reporter=None,
        db_catalog_dirs=None,
        db_import_everything_langs=None)

@
"db_base_dir" (optional) specifies the base directory for
    the codeintel database. If not given it will default to
    '~/.codeintel'.
"on_scan_complete" (optional) is a callback for Citadel scan
    completion. It will be passed the ScanRequest instance
    as an argument.
"langs" (optional, default all) is a list of language names
    to register. By default all available supported languages are
    setup.
"extra_lang_module_dirs" (optional) is a list of extra dirs
    in which to look for and use "lang_*.py" lang support
    modules.
"env" (optional) is an Environment instance (or subclass).
    See environment.py for details.
"db_event_reporter" (optional) is a callback that will be called
        db_event_reporter(&lt;event-desc-string&gt;)
    before "significant" long processing events in the DB. This
    may be useful to forward to a status bar in a GUI.
"db_catalog_dirs" (optional) is a list of catalog dirs in
    addition to the std one to use for the CatalogsZone. All
    *.cix files in a catalog dir are made available.
"db_import_everything_langs" (optional) is a set of langs for which
    the extra effort to support Database
    `lib.hits_from_lpath()' should be made. See class
    Database for more details.</t>
<t tx="ekr.20080121150435.1">def openDatabase(mgr):

    return database.Database(mgr,
        base_dir=None,
        catalog_dirs=None,
        event_reporter=None,
        import_everything_langs=None)

@
"base_dir" (optional) specifies the base directory for the codeintel database.
If not given it will default to '~/.codeintel'.

"catalog_dirs" (optional) is a list of catalog dirs in addition to the std one
to use for the CatalogsZone. All *.cix files in a catalog dir are made
available.

"event_reporter" (optional) is a callback that will be called
event_reporter(&lt;event-desc-string&gt;) before "significant" long processing events
in the DB. This may be useful to forward to a status bar in a GUI.

"import_everything_langs" (optional) is a set of lang names for which the
`lib.hits_from_lpath()' API should be supported. This method is typically used
to support "import-everything" cpln eval semantics. Supporting it requires the
'toplevelname_index' indeces which adds significant space and perf burdens. If
not specified, only JavaScript and PHP are included in the set.
</t>
<t tx="ekr.20080121151821">
"""Base LangIntel class definition

Each lang_*.py registers a LangIntel instance -- a singleton (somewhat
similar to Komodo's language services, I suppose). This langintel defines
smarts for handling language content. This module contains some mixins
so that particular languages can implement the requisite interface easily.

Any single-language buffer has a '.langintel' attribute pointing to this
singleton. Any multi-language buffer (i.e. a subclass of UDLBuffer) has
a '.langintel_from_udl_family' dictionary.

TODO:
- document what interfaces a particular LangIntel is meant to provide

Dev Notes:
- Usage of LangIntel objects in code should always use 'langintel'.
"""</t>
<t tx="ekr.20080121151821.1">
# import database
import codeintel2.database.database as database
# print database
import manager
# print manager

if 0: # These work

    import ciElementTree as ET
    import codeintel2
    from codeintel2.buffer import Buffer
    from codeintel2.common import *
    from codeintel2.indexer import ScanRequest
    # print ET
    # print codeintel2</t>
<t tx="ekr.20080121152156">@nocolor
@

Jan 20, 2008: I began to create @auto nodes.
Jan 21:
- Finished creating @auto nodes for all files that appeared to be significant.
- Aha: We can run code unchanged if we add Komodo paths to sys.path.
  This allows me to run Komodo code unchanged.
- Wrote addKomoPaths, openManager and openDatabase.
** First major milestone: the ability to execute Komodo code from Leo scripts.</t>
</tnodes>
</leo_file>
